Thu Jul 10 22:13:23 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-10 22:13:23,782 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-10 22:13:23,783 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-10 22:13:23,783 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-10 22:13:24,009 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-10 22:13:24,009 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-10 22:13:24,009 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-10 22:13:24,009 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-10 22:13:24,009 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 33715 22
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-10 22:13:24,010 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 33715 9.1.143.59 22
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-10 22:13:24,011 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-10 22:13:24,013 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=102
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-10 22:13:24,014 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-10 22:13:24,015 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-10 22:13:24,015 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-10 22:13:24,017 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-10 22:13:24,017 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-10 22:13:24,241 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-10 22:13:24,665 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-10 22:13:24,758 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-10 22:13:24,771 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-10 22:13:24,833 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-10 22:13:24,834 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-10 22:13:24,834 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-10 22:13:24,839 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-10 22:13:24,844 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-10 22:13:24,922 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-10 22:13:24,923 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-10 22:13:24,927 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-10 22:13:24,929 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-10 22:13:25,002 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-10 22:13:25,058 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-10 22:13:25,068 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-10 22:13:25,069 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-10 22:13:25,069 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-10 22:13:25,069 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-10 22:13:25,392 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-10 22:13:25,436 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-10 22:13:25,437 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-10 22:13:25,439 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:13:25,439 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-10 22:13:25,469 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:13:25,472 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:13:25,477 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-10 22:13:25,482 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-10 22:13:25,603 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/master
2014-07-10 22:13:25,604 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-07-10 22:13:26,138 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:13:26,139 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-10 22:13:26,163 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14723d71b110000, negotiated timeout = 90000
2014-07-10 22:13:57,654 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x921d7f9, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:13:57,656 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x921d7f9 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:13:57,656 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:13:57,657 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-10 22:13:57,670 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x4723d71c3f0001, negotiated timeout = 90000
2014-07-10 22:13:57,927 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@70eb4f20
2014-07-10 22:13:57,932 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-10 22:13:57,937 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-10 22:13:57,945 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-10 22:13:57,981 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-10 22:13:57,988 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-10 22:13:57,992 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-10 22:13:58,016 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405055603120 with port=60020, startcode=1405055604855
2014-07-10 22:13:58,365 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-10 22:13:58,365 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-10 22:13:58,366 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-10 22:13:58,404 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-10 22:13:58,413 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855
2014-07-10 22:13:58,450 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-10 22:13:58,461 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 22:13:58,559 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055638470
2014-07-10 22:13:58,574 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-10 22:13:58,581 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-10 22:13:58,585 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-10 22:13:58,590 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-10 22:13:58,592 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 22:13:58,592 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 22:13:58,592 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 22:13:58,593 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 22:13:58,593 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-10 22:13:58,602 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1405055604855, sceplus-vm48.almaden.ibm.com,60020,1405055604969] other RSs: [slave1,60020,1405055604855, sceplus-vm48.almaden.ibm.com,60020,1405055604969]
2014-07-10 22:13:58,629 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-10 22:13:58,631 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x63925a7e, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:13:58,632 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x63925a7e connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:13:58,633 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:13:58,634 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-10 22:13:58,637 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14723d71b110004, negotiated timeout = 90000
2014-07-10 22:13:58,643 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-10 22:13:58,644 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-10 22:13:58,695 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405055604855, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x14723d71b110000
2014-07-10 22:13:58,695 INFO  [SplitLogWorker-slave1,60020,1405055604855] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405055604855 starting
2014-07-10 22:13:58,695 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-10 22:13:58,695 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405055604855
2014-07-10 22:13:58,695 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405055604855'
2014-07-10 22:13:58,696 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-10 22:13:58,696 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-10 22:13:58,697 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-10 22:14:02,464 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-10 22:14:02,562 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:02,589 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:02,590 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855
2014-07-10 22:14:02,591 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 22:14:02,625 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055642596.meta
2014-07-10 22:14:02,646 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-10 22:14:02,667 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-10 22:14:02,673 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-10 22:14:02,677 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-10 22:14:02,682 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-10 22:14:02,682 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-10 22:14:02,682 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-10 22:14:02,767 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:14:02,810 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-10 22:14:02,872 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/27b51fac6e3e4a1f937f9a6a922ca4e9, isReference=false, isBulkLoadResult=false, seqid=3806, majorCompaction=true
2014-07-10 22:14:02,889 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for 3d0a57c625f4451f894133811c6341cf
2014-07-10 22:14:02,890 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3d0a57c625f4451f894133811c6341cf, isReference=false, isBulkLoadResult=false, seqid=3832, majorCompaction=false
2014-07-10 22:14:02,929 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-10 22:14:02,939 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=3833
2014-07-10 22:14:02,939 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-10 22:14:02,943 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-10 22:14:02,943 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1405055604855
2014-07-10 22:14:02,949 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-10 22:14:02,949 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:02,953 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:02,953 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:02,954 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1405055604855
2014-07-10 22:14:03,347 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:03,386 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:03,386 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 32ebfe8403f093689b75ac5789684fc6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,388 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:03,389 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0bd3c894954124772f4c6bdcf90bde65 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,390 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:14:03,391 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5d88cc9914130e02dc315e04dbdf567c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,397 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 32ebfe8403f093689b75ac5789684fc6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,397 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0bd3c894954124772f4c6bdcf90bde65 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,398 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 32ebfe8403f093689b75ac5789684fc6, NAME => 'usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-10 22:14:03,398 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 0bd3c894954124772f4c6bdcf90bde65, NAME => 'usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 22:14:03,399 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5d88cc9914130e02dc315e04dbdf567c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,400 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 5d88cc9914130e02dc315e04dbdf567c, NAME => 'usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-10 22:14:03,400 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0bd3c894954124772f4c6bdcf90bde65
2014-07-10 22:14:03,400 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 32ebfe8403f093689b75ac5789684fc6
2014-07-10 22:14:03,401 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:03,401 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:03,402 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5d88cc9914130e02dc315e04dbdf567c
2014-07-10 22:14:03,402 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:03,404 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:03,404 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:03,409 INFO  [RS_OPEN_REGION-slave1:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-10 22:14:03,432 INFO  [RS_OPEN_REGION-slave1:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-10 22:14:03,439 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-10 22:14:03,439 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:14:03,439 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-10 22:14:03,450 INFO  [StoreOpener-32ebfe8403f093689b75ac5789684fc6-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:14:03,453 INFO  [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:14:03,455 INFO  [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:14:03,529 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-10 22:14:03,533 DEBUG [StoreOpener-32ebfe8403f093689b75ac5789684fc6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/297a79d2b0d2499ab5dbd96d2496348b, isReference=false, isBulkLoadResult=false, seqid=1869, majorCompaction=false
2014-07-10 22:14:03,537 DEBUG [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c/family/1c60cc6ccfc9459788529c85a6aa4b35, isReference=false, isBulkLoadResult=false, seqid=1974, majorCompaction=false
2014-07-10 22:14:03,546 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/059a4769208a496592c16f08a3d2a588, isReference=false, isBulkLoadResult=false, seqid=838, majorCompaction=false
2014-07-10 22:14:03,551 DEBUG [StoreOpener-32ebfe8403f093689b75ac5789684fc6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/2d2473f84ed142c0a20aabe558f6b1c4, isReference=false, isBulkLoadResult=false, seqid=2152, majorCompaction=false
2014-07-10 22:14:03,568 DEBUG [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c/family/4032228252d14bf38d77b6511f5f39f6, isReference=false, isBulkLoadResult=false, seqid=773, majorCompaction=true
2014-07-10 22:14:03,573 DEBUG [StoreOpener-32ebfe8403f093689b75ac5789684fc6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/69e3aef57cae44e596efaf237758ab96, isReference=false, isBulkLoadResult=false, seqid=1419, majorCompaction=false
2014-07-10 22:14:03,579 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/127ce78e899b4737b8bd87943a393174, isReference=false, isBulkLoadResult=false, seqid=1040, majorCompaction=false
2014-07-10 22:14:03,588 DEBUG [StoreOpener-32ebfe8403f093689b75ac5789684fc6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/8b39169053c44cfbb3e581b6350b3c50, isReference=false, isBulkLoadResult=false, seqid=1039, majorCompaction=true
2014-07-10 22:14:03,591 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6
2014-07-10 22:14:03,592 DEBUG [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c/family/51de6279ed9b42298ce4472e35475910, isReference=false, isBulkLoadResult=false, seqid=940, majorCompaction=false
2014-07-10 22:14:03,593 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 32ebfe8403f093689b75ac5789684fc6; next sequenceid=2153
2014-07-10 22:14:03,594 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 32ebfe8403f093689b75ac5789684fc6
2014-07-10 22:14:03,596 INFO  [PostOpenDeployTasks:32ebfe8403f093689b75ac5789684fc6] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:03,597 DEBUG [PostOpenDeployTasks:32ebfe8403f093689b75ac5789684fc6] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:14:03,600 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:14:03,602 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 899507438 starting at candidate #0 after considering 3 permutations with 2 in ratio
2014-07-10 22:14:03,604 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.HStore: 32ebfe8403f093689b75ac5789684fc6 - family: Initiating major compaction
2014-07-10 22:14:03,604 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:03,604 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/.tmp, totalSize=857.8m
2014-07-10 22:14:03,606 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/8b39169053c44cfbb3e581b6350b3c50, keycount=583389, bloomtype=ROW, size=415.4m, encoding=NONE, seqNum=1039, earliestPutTs=1405054917708
2014-07-10 22:14:03,606 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/69e3aef57cae44e596efaf237758ab96, keycount=214329, bloomtype=ROW, size=152.6m, encoding=NONE, seqNum=1419, earliestPutTs=1405055298804
2014-07-10 22:14:03,607 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/297a79d2b0d2499ab5dbd96d2496348b, keycount=252428, bloomtype=ROW, size=179.8m, encoding=NONE, seqNum=1869, earliestPutTs=1405055355122
2014-07-10 22:14:03,607 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/32ebfe8403f093689b75ac5789684fc6/family/2d2473f84ed142c0a20aabe558f6b1c4, keycount=154571, bloomtype=ROW, size=110.0m, encoding=NONE, seqNum=2152, earliestPutTs=1405055465790
2014-07-10 22:14:03,607 DEBUG [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c/family/60dea70db04c448791702b5ee4208326, isReference=false, isBulkLoadResult=false, seqid=2150, majorCompaction=false
2014-07-10 22:14:03,614 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/254c99112cdc41569a11b56d8e989ba6, isReference=false, isBulkLoadResult=false, seqid=1680, majorCompaction=false
2014-07-10 22:14:03,631 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-10 22:14:03,632 DEBUG [StoreOpener-5d88cc9914130e02dc315e04dbdf567c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c/family/74ff3313bcd14995b03f378007d21493, isReference=false, isBulkLoadResult=false, seqid=1387, majorCompaction=false
2014-07-10 22:14:03,636 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/2f736d22e3014177921449390abf049f, isReference=false, isBulkLoadResult=false, seqid=669, majorCompaction=false
2014-07-10 22:14:03,637 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5d88cc9914130e02dc315e04dbdf567c
2014-07-10 22:14:03,641 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 5d88cc9914130e02dc315e04dbdf567c; next sequenceid=2151
2014-07-10 22:14:03,641 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5d88cc9914130e02dc315e04dbdf567c
2014-07-10 22:14:03,643 INFO  [PostOpenDeployTasks:5d88cc9914130e02dc315e04dbdf567c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:03,644 DEBUG [PostOpenDeployTasks:5d88cc9914130e02dc315e04dbdf567c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 22:14:03,653 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/606910a48b5d4ce690a3f605176b4196, isReference=false, isBulkLoadResult=false, seqid=2150, majorCompaction=false
2014-07-10 22:14:03,679 DEBUG [StoreOpener-0bd3c894954124772f4c6bdcf90bde65-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65/family/9d9fea9e9a604699b18e8bdf0727228a, isReference=false, isBulkLoadResult=false, seqid=501, majorCompaction=true
2014-07-10 22:14:03,679 DEBUG [regionserver60020-smallCompactions-1405055643597] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:14:03,681 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0bd3c894954124772f4c6bdcf90bde65
2014-07-10 22:14:03,688 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 0bd3c894954124772f4c6bdcf90bde65; next sequenceid=2151
2014-07-10 22:14:03,688 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0bd3c894954124772f4c6bdcf90bde65
2014-07-10 22:14:03,689 INFO  [PostOpenDeployTasks:0bd3c894954124772f4c6bdcf90bde65] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:03,690 DEBUG [PostOpenDeployTasks:0bd3c894954124772f4c6bdcf90bde65] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 22:14:03,762 INFO  [PostOpenDeployTasks:32ebfe8403f093689b75ac5789684fc6] catalog.MetaEditor: Updated row usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,762 INFO  [PostOpenDeployTasks:5d88cc9914130e02dc315e04dbdf567c] catalog.MetaEditor: Updated row usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,763 INFO  [PostOpenDeployTasks:32ebfe8403f093689b75ac5789684fc6] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:03,762 INFO  [PostOpenDeployTasks:0bd3c894954124772f4c6bdcf90bde65] catalog.MetaEditor: Updated row usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,763 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 32ebfe8403f093689b75ac5789684fc6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,763 INFO  [PostOpenDeployTasks:5d88cc9914130e02dc315e04dbdf567c] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:03,763 INFO  [PostOpenDeployTasks:0bd3c894954124772f4c6bdcf90bde65] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:03,764 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5d88cc9914130e02dc315e04dbdf567c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,764 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0bd3c894954124772f4c6bdcf90bde65 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,767 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 32ebfe8403f093689b75ac5789684fc6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,767 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 32ebfe8403f093689b75ac5789684fc6 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,767 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6. on slave1,60020,1405055604855
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0bd3c894954124772f4c6bdcf90bde65 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 0bd3c894954124772f4c6bdcf90bde65 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5d88cc9914130e02dc315e04dbdf567c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 5d88cc9914130e02dc315e04dbdf567c to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65. on slave1,60020,1405055604855
2014-07-10 22:14:03,768 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c. on slave1,60020,1405055604855
2014-07-10 22:14:03,769 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 36a94d55b7388b23d186ce15d3f0e0e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,769 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning effe1239b3f382864ed48d1f7e70f4a3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,774 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,774 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-10 22:14:03,775 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:14:03,775 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:14:03,779 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 36a94d55b7388b23d186ce15d3f0e0e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,779 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 36a94d55b7388b23d186ce15d3f0e0e0, NAME => 'usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-10 22:14:03,779 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 36a94d55b7388b23d186ce15d3f0e0e0
2014-07-10 22:14:03,780 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node effe1239b3f382864ed48d1f7e70f4a3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:14:03,780 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:03,780 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => effe1239b3f382864ed48d1f7e70f4a3, NAME => 'usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-10 22:14:03,781 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable effe1239b3f382864ed48d1f7e70f4a3
2014-07-10 22:14:03,781 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:03,783 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:14:03,787 INFO  [StoreOpener-36a94d55b7388b23d186ce15d3f0e0e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:14:03,789 INFO  [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:14:03,808 DEBUG [StoreOpener-36a94d55b7388b23d186ce15d3f0e0e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/36a94d55b7388b23d186ce15d3f0e0e0/family/1fb92a6c483a4d968f7c066af1fc0d45, isReference=false, isBulkLoadResult=false, seqid=550, majorCompaction=false
2014-07-10 22:14:03,808 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-10 22:14:03,811 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:14:03,811 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/0fbc6978aaa040d783232f824cbe8cd0, isReference=false, isBulkLoadResult=false, seqid=1195, majorCompaction=false
2014-07-10 22:14:03,816 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-10 22:14:03,816 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:14:03,817 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:14:03,823 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,823 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:14:03,824 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,825 DEBUG [StoreOpener-36a94d55b7388b23d186ce15d3f0e0e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/36a94d55b7388b23d186ce15d3f0e0e0/family/211bd8a59ed841d0aec48a4758defc68, isReference=false, isBulkLoadResult=false, seqid=1198, majorCompaction=false
2014-07-10 22:14:03,832 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/10cdc41fd69f4be090444ebbc4b6f018, isReference=false, isBulkLoadResult=false, seqid=600, majorCompaction=true
2014-07-10 22:14:03,834 DEBUG [StoreOpener-36a94d55b7388b23d186ce15d3f0e0e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/36a94d55b7388b23d186ce15d3f0e0e0/family/b1ab235ad5b344ffa8e61cd902e3e5e1, isReference=false, isBulkLoadResult=false, seqid=2133, majorCompaction=false
2014-07-10 22:14:03,834 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,835 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,835 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405055604855
2014-07-10 22:14:03,846 DEBUG [StoreOpener-36a94d55b7388b23d186ce15d3f0e0e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/36a94d55b7388b23d186ce15d3f0e0e0/family/dc8ef336b43f4c5b90a284a4827a8f78, isReference=false, isBulkLoadResult=false, seqid=2145, majorCompaction=false
2014-07-10 22:14:03,848 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/36a94d55b7388b23d186ce15d3f0e0e0
2014-07-10 22:14:03,850 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 36a94d55b7388b23d186ce15d3f0e0e0; next sequenceid=2146
2014-07-10 22:14:03,850 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 36a94d55b7388b23d186ce15d3f0e0e0
2014-07-10 22:14:03,852 INFO  [PostOpenDeployTasks:36a94d55b7388b23d186ce15d3f0e0e0] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:03,853 DEBUG [PostOpenDeployTasks:36a94d55b7388b23d186ce15d3f0e0e0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:14:03,861 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/25b22c1e3b7345b8adea47386b24b901, isReference=false, isBulkLoadResult=false, seqid=937, majorCompaction=false
2014-07-10 22:14:03,862 INFO  [PostOpenDeployTasks:36a94d55b7388b23d186ce15d3f0e0e0] catalog.MetaEditor: Updated row usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,862 INFO  [PostOpenDeployTasks:36a94d55b7388b23d186ce15d3f0e0e0] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:03,863 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 36a94d55b7388b23d186ce15d3f0e0e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,870 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 36a94d55b7388b23d186ce15d3f0e0e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,870 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 36a94d55b7388b23d186ce15d3f0e0e0 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,870 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0. on slave1,60020,1405055604855
2014-07-10 22:14:03,878 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/33ac4ff8fc1a4ad2acf1a681c1d669aa, isReference=false, isBulkLoadResult=false, seqid=767, majorCompaction=false
2014-07-10 22:14:03,893 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/7165c07b74704a398ec60796124e2023, isReference=false, isBulkLoadResult=false, seqid=1698, majorCompaction=false
2014-07-10 22:14:03,903 DEBUG [StoreOpener-effe1239b3f382864ed48d1f7e70f4a3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3/family/ced17ec5225a4e7692f5533aac82bf45, isReference=false, isBulkLoadResult=false, seqid=2150, majorCompaction=false
2014-07-10 22:14:03,907 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/effe1239b3f382864ed48d1f7e70f4a3
2014-07-10 22:14:03,909 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined effe1239b3f382864ed48d1f7e70f4a3; next sequenceid=2151
2014-07-10 22:14:03,909 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node effe1239b3f382864ed48d1f7e70f4a3
2014-07-10 22:14:03,911 INFO  [PostOpenDeployTasks:effe1239b3f382864ed48d1f7e70f4a3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:03,911 DEBUG [PostOpenDeployTasks:effe1239b3f382864ed48d1f7e70f4a3] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-10 22:14:03,917 INFO  [PostOpenDeployTasks:effe1239b3f382864ed48d1f7e70f4a3] catalog.MetaEditor: Updated row usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3. with server=slave1,60020,1405055604855
2014-07-10 22:14:03,917 INFO  [PostOpenDeployTasks:effe1239b3f382864ed48d1f7e70f4a3] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:03,918 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning effe1239b3f382864ed48d1f7e70f4a3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,922 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node effe1239b3f382864ed48d1f7e70f4a3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:14:03,922 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned effe1239b3f382864ed48d1f7e70f4a3 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:14:03,922 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3. on slave1,60020,1405055604855
2014-07-10 22:14:08,596 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-10 22:14:08,596 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-10 22:14:08,596 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-10 22:14:08,597 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-10 22:14:31,363 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Close 0bd3c894954124772f4c6bdcf90bde65, via zk=yes, znode version=0, on null
2014-07-10 22:14:31,364 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close effe1239b3f382864ed48d1f7e70f4a3, via zk=yes, znode version=0, on null
2014-07-10 22:14:31,363 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 32ebfe8403f093689b75ac5789684fc6, via zk=yes, znode version=0, on null
2014-07-10 22:14:31,364 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close 36a94d55b7388b23d186ce15d3f0e0e0, via zk=yes, znode version=0, on null
2014-07-10 22:14:31,364 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 5d88cc9914130e02dc315e04dbdf567c, via zk=yes, znode version=0, on null
2014-07-10 22:14:31,366 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:31,366 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:31,367 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:31,369 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.: disabling compactions & flushes
2014-07-10 22:14:31,369 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: waiting for 1 compactions to complete for region usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:31,370 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.: disabling compactions & flushes
2014-07-10 22:14:31,370 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.: disabling compactions & flushes
2014-07-10 22:14:31,370 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:31,370 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:31,402 INFO  [StoreCloserThread-usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.-1] regionserver.HStore: Closed family
2014-07-10 22:14:31,402 INFO  [StoreCloserThread-usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.-1] regionserver.HStore: Closed family
2014-07-10 22:14:31,404 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:31,404 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:31,404 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning effe1239b3f382864ed48d1f7e70f4a3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,404 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0bd3c894954124772f4c6bdcf90bde65 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,778 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node effe1239b3f382864ed48d1f7e70f4a3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,778 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3. on slave1,60020,1405055604855
2014-07-10 22:14:31,778 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3.
2014-07-10 22:14:31,779 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:31,850 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0bd3c894954124772f4c6bdcf90bde65 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,850 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65. on slave1,60020,1405055604855
2014-07-10 22:14:31,851 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65.
2014-07-10 22:14:31,851 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:31,853 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.: disabling compactions & flushes
2014-07-10 22:14:31,853 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:31,856 INFO  [StoreCloserThread-usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.-1] regionserver.HStore: Closed family
2014-07-10 22:14:31,857 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:31,858 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 36a94d55b7388b23d186ce15d3f0e0e0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,989 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HRegion: compaction interrupted
java.io.InterruptedIOException: Aborting compaction of store family in region usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6. because it was interrupted.
	at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:81)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:109)
	at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1086)
	at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1481)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:475)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-10 22:14:31,989 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.: disabling compactions & flushes
2014-07-10 22:14:31,990 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:31,990 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:31,993 INFO  [StoreCloserThread-usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.-1] regionserver.HStore: Closed family
2014-07-10 22:14:31,994 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:31,994 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5d88cc9914130e02dc315e04dbdf567c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,994 INFO  [StoreCloserThread-usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.-1] regionserver.HStore: Closed family
2014-07-10 22:14:31,994 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:31,994 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 32ebfe8403f093689b75ac5789684fc6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,997 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Aborted compaction: Request = regionName=usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6., storeName=family, fileCount=4, fileSize=857.8m, priority=16, time=9551030989657; duration=28sec
2014-07-10 22:14:31,997 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405054900324.0bd3c894954124772f4c6bdcf90bde65. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user8,1405054900324.effe1239b3f382864ed48d1f7e70f4a3. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c. because compaction request was cancelled
2014-07-10 22:14:31,998 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c. because compaction request was cancelled
2014-07-10 22:14:31,999 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 36a94d55b7388b23d186ce15d3f0e0e0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:31,999 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0. on slave1,60020,1405055604855
2014-07-10 22:14:32,000 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user9,1405054900324.36a94d55b7388b23d186ce15d3f0e0e0.
2014-07-10 22:14:32,000 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5d88cc9914130e02dc315e04dbdf567c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:32,000 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c. on slave1,60020,1405055604855
2014-07-10 22:14:32,000 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user6,1405054900324.5d88cc9914130e02dc315e04dbdf567c.
2014-07-10 22:14:32,002 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 32ebfe8403f093689b75ac5789684fc6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:14:32,002 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6. on slave1,60020,1405055604855
2014-07-10 22:14:32,002 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user5,1405054900324.32ebfe8403f093689b75ac5789684fc6.
2014-07-10 22:14:33,264 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-10 22:14:33,265 DEBUG [Priority.RpcServer.handler=5,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-10 22:14:33,266 DEBUG [Priority.RpcServer.handler=5,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-10 22:14:33,267 DEBUG [Priority.RpcServer.handler=5,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@380f5e67; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:14:33,267 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-10 22:14:33,268 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=16.2k
2014-07-10 22:14:33,268 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/27b51fac6e3e4a1f937f9a6a922ca4e9, keycount=71, bloomtype=NONE, size=9.1k, encoding=NONE, seqNum=3806, earliestPutTs=1402645258588
2014-07-10 22:14:33,268 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3d0a57c625f4451f894133811c6341cf, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=3832, earliestPutTs=1405054551286
2014-07-10 22:14:33,274 DEBUG [regionserver60020-smallCompactions-1405055643597] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:14:33,312 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/7b53de2fe5284cffbe107b450f7f9e0d as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/7b53de2fe5284cffbe107b450f7f9e0d
2014-07-10 22:14:33,329 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.HStore: Removing store files after compaction...
2014-07-10 22:14:33,342 DEBUG [regionserver60020-smallCompactions-1405055643597] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/27b51fac6e3e4a1f937f9a6a922ca4e9, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/27b51fac6e3e4a1f937f9a6a922ca4e9
2014-07-10 22:14:33,345 DEBUG [regionserver60020-smallCompactions-1405055643597] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3d0a57c625f4451f894133811c6341cf, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/3d0a57c625f4451f894133811c6341cf
2014-07-10 22:14:33,345 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 7b53de2fe5284cffbe107b450f7f9e0d(size=9.1k), total size for store is 9.1k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-10 22:14:33,345 INFO  [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=16.2k, priority=1, time=9580693250390; duration=0sec
2014-07-10 22:14:33,345 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:18:24,939 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=7108, hits=68, hitRatio=0.95%, , cachingAccesses=70, cachingHits=65, cachingHitsRatio=92.85%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:19:40,932 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Open usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:19:40,945 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Open usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:19:40,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,946 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Open usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:19:40,946 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,947 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Open usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:19:40,947 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,948 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Open usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:19:40,957 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,957 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 00f080342d6cf14f8ce3232ee199c1c6, NAME => 'usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 22:19:40,957 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,958 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 239da979f9d39d355c125213b17fb3e3, NAME => 'usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-10 22:19:40,958 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:19:40,959 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:19:40,959 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:40,959 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 239da979f9d39d355c125213b17fb3e3
2014-07-10 22:19:40,959 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 3ccb2cf30c2a44be7e02096daace7564, NAME => 'usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-10 22:19:40,960 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:19:40,962 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:19:40,962 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:19:40,973 INFO  [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:19:40,984 INFO  [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:19:40,984 INFO  [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:19:40,988 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:19:40,988 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3
2014-07-10 22:19:40,989 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:19:40,991 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 00f080342d6cf14f8ce3232ee199c1c6; next sequenceid=1
2014-07-10 22:19:40,991 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:19:40,991 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 239da979f9d39d355c125213b17fb3e3; next sequenceid=1
2014-07-10 22:19:40,991 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 239da979f9d39d355c125213b17fb3e3
2014-07-10 22:19:40,992 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:19:40,993 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:19:41,009 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] catalog.MetaEditor: Updated row usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. with server=slave1,60020,1405055604855
2014-07-10 22:19:41,009 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:19:41,010 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 00f080342d6cf14f8ce3232ee199c1c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,010 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] catalog.MetaEditor: Updated row usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. with server=slave1,60020,1405055604855
2014-07-10 22:19:41,010 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:19:41,011 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 239da979f9d39d355c125213b17fb3e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,018 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 00f080342d6cf14f8ce3232ee199c1c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,018 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 00f080342d6cf14f8ce3232ee199c1c6 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:19:41,018 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. on slave1,60020,1405055604855
2014-07-10 22:19:41,019 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:41,022 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 239da979f9d39d355c125213b17fb3e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,022 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 239da979f9d39d355c125213b17fb3e3 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:19:41,023 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. on slave1,60020,1405055604855
2014-07-10 22:19:41,023 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:41,029 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 3ccb2cf30c2a44be7e02096daace7564; next sequenceid=1
2014-07-10 22:19:41,029 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:19:41,030 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:41,030 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 2d8a9466290952db9948506eb024ccc2, NAME => 'usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-10 22:19:41,031 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2d8a9466290952db9948506eb024ccc2
2014-07-10 22:19:41,031 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:19:41,031 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:19:41,037 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:19:41,038 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => dd9d264e19b844e86a917d3f2a0d3b85, NAME => 'usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-10 22:19:41,038 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:19:41,039 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:19:41,039 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] catalog.MetaEditor: Updated row usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. with server=slave1,60020,1405055604855
2014-07-10 22:19:41,040 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:19:41,041 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3ccb2cf30c2a44be7e02096daace7564 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,042 INFO  [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:19:41,044 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3ccb2cf30c2a44be7e02096daace7564 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,045 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 3ccb2cf30c2a44be7e02096daace7564 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:19:41,045 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. on slave1,60020,1405055604855
2014-07-10 22:19:41,048 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2
2014-07-10 22:19:41,055 INFO  [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:19:41,056 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 2d8a9466290952db9948506eb024ccc2; next sequenceid=1
2014-07-10 22:19:41,056 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2d8a9466290952db9948506eb024ccc2
2014-07-10 22:19:41,058 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:19:41,058 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:19:41,060 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined dd9d264e19b844e86a917d3f2a0d3b85; next sequenceid=1
2014-07-10 22:19:41,061 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:19:41,062 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:19:41,065 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] catalog.MetaEditor: Updated row usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. with server=slave1,60020,1405055604855
2014-07-10 22:19:41,066 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:19:41,068 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d8a9466290952db9948506eb024ccc2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,073 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] catalog.MetaEditor: Updated row usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. with server=slave1,60020,1405055604855
2014-07-10 22:19:41,073 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:19:41,074 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd9d264e19b844e86a917d3f2a0d3b85 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,074 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d8a9466290952db9948506eb024ccc2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,074 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 2d8a9466290952db9948506eb024ccc2 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:19:41,074 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. on slave1,60020,1405055604855
2014-07-10 22:19:41,077 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723d71b110000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd9d264e19b844e86a917d3f2a0d3b85 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:19:41,077 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned dd9d264e19b844e86a917d3f2a0d3b85 to OPENED in zk on slave1,60020,1405055604855
2014-07-10 22:19:41,077 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. on slave1,60020,1405055604855
2014-07-10 22:19:59,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:19:59,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87 synced till here 78
2014-07-10 22:19:59,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055638470 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055999781
2014-07-10 22:20:01,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:01,924 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 164 synced till here 160
2014-07-10 22:20:02,002 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055999781 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056001906
2014-07-10 22:20:03,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:03,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 238 synced till here 236
2014-07-10 22:20:03,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056001906 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056003757
2014-07-10 22:20:11,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:11,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056003757 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056011058
2014-07-10 22:20:22,687 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:22,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 382 synced till here 381
2014-07-10 22:20:22,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056011058 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056022687
2014-07-10 22:20:24,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:24,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 455 synced till here 454
2014-07-10 22:20:24,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056022687 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056024124
2014-07-10 22:20:26,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:26,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056024124 with entries=72, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056026207
2014-07-10 22:20:31,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:34,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056026207 with entries=155, filesize=132.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056031392
2014-07-10 22:20:36,589 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:36,623 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 764 synced till here 762
2014-07-10 22:20:36,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056031392 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056036590
2014-07-10 22:20:48,706 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 20064ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:20:48,713 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 20050ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:20:48,709 WARN  [regionserver60020] util.Sleeper: We slept 13069ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:20:48,776 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11251ms
GC pool 'ParNew' had collection(s): count=2 time=172ms
2014-07-10 22:20:50,170 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:20:50,173 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 256.3m
2014-07-10 22:20:50,990 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056035727,"queuetimems":0,"class":"HRegionServer","responsesize":19691,"method":"Multi"}
2014-07-10 22:20:51,032 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15034,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056035997,"queuetimems":1,"class":"HRegionServer","responsesize":19389,"method":"Multi"}
2014-07-10 22:20:51,084 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036157,"queuetimems":1,"class":"HRegionServer","responsesize":19657,"method":"Multi"}
2014-07-10 22:20:51,084 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15441,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056035590,"queuetimems":0,"class":"HRegionServer","responsesize":19479,"method":"Multi"}
2014-07-10 22:20:51,083 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15234,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056035797,"queuetimems":1,"class":"HRegionServer","responsesize":19903,"method":"Multi"}
2014-07-10 22:20:51,083 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056035837,"queuetimems":0,"class":"HRegionServer","responsesize":20442,"method":"Multi"}
2014-07-10 22:20:51,160 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:20:51,171 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 262.7m
2014-07-10 22:20:51,172 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14953,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036219,"queuetimems":1,"class":"HRegionServer","responsesize":18944,"method":"Multi"}
2014-07-10 22:20:51,219 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:20:51,536 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15172,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036363,"queuetimems":1,"class":"HRegionServer","responsesize":19769,"method":"Multi"}
2014-07-10 22:20:51,536 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15110,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036425,"queuetimems":0,"class":"HRegionServer","responsesize":19574,"method":"Multi"}
2014-07-10 22:20:51,536 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036583,"queuetimems":0,"class":"HRegionServer","responsesize":19702,"method":"Multi"}
2014-07-10 22:20:51,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:51,793 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:20:51,794 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15164,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036620,"queuetimems":1,"class":"HRegionServer","responsesize":19438,"method":"Multi"}
2014-07-10 22:20:51,815 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:20:51,827 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:20:51,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 839 synced till here 835
2014-07-10 22:20:51,883 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15106,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036777,"queuetimems":0,"class":"HRegionServer","responsesize":19716,"method":"Multi"}
2014-07-10 22:20:51,884 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056036825,"queuetimems":1,"class":"HRegionServer","responsesize":19722,"method":"Multi"}
2014-07-10 22:20:51,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056036590 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056051789
2014-07-10 22:20:52,018 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:20:52,208 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:20:52,367 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056037152,"queuetimems":0,"class":"HRegionServer","responsesize":19820,"method":"Multi"}
2014-07-10 22:20:52,367 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44535","starttimems":1405056037098,"queuetimems":1,"class":"HRegionServer","responsesize":20039,"method":"Multi"}
2014-07-10 22:20:55,699 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:55,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 911 synced till here 910
2014-07-10 22:20:55,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056051789 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056055699
2014-07-10 22:20:59,730 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:20:59,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 990 synced till here 984
2014-07-10 22:21:00,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056055699 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056059731
2014-07-10 22:21:03,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:21:03,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056059731 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056063643
2014-07-10 22:21:08,710 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=171, memsize=262.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/5aabab464591431e80ed25bb82a89879
2014-07-10 22:21:08,738 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/5aabab464591431e80ed25bb82a89879 as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/5aabab464591431e80ed25bb82a89879
2014-07-10 22:21:08,755 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/5aabab464591431e80ed25bb82a89879, entries=955280, sequenceid=171, filesize=68.0m
2014-07-10 22:21:08,755 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.4m/275114240, currentsize=70.0m/73354560 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 18582ms, sequenceid=171, compaction requested=false
2014-07-10 22:21:08,784 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 333.2m
2014-07-10 22:21:09,753 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=171, memsize=262.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/83cc027a8b0b4c5e8f94e0aeb85275fd
2014-07-10 22:21:09,793 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/83cc027a8b0b4c5e8f94e0aeb85275fd as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/83cc027a8b0b4c5e8f94e0aeb85275fd
2014-07-10 22:21:09,807 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/83cc027a8b0b4c5e8f94e0aeb85275fd, entries=956560, sequenceid=171, filesize=68.1m
2014-07-10 22:21:09,807 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.7m/275481360, currentsize=70.1m/73488720 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 18637ms, sequenceid=171, compaction requested=false
2014-07-10 22:21:09,808 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 331.9m
2014-07-10 22:21:09,829 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:21:10,063 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:21:27,830 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9295ms
No GCs detected
2014-07-10 22:21:38,996 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=216, memsize=331.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/adab7229735c4995a5acabf28e296e88
2014-07-10 22:21:39,048 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/adab7229735c4995a5acabf28e296e88 as hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/adab7229735c4995a5acabf28e296e88
2014-07-10 22:21:39,087 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/adab7229735c4995a5acabf28e296e88, entries=1208590, sequenceid=216, filesize=86.1m
2014-07-10 22:21:39,088 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~331.9m/348066560, currentsize=0.0/0 for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. in 29279ms, sequenceid=216, compaction requested=false
2014-07-10 22:21:39,088 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2., current region memstore size 331.7m
2014-07-10 22:21:39,576 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=216, memsize=333.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/ff94d9b48ef14ff6a448bec24da32d97
2014-07-10 22:21:39,579 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:21:39,602 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/ff94d9b48ef14ff6a448bec24da32d97 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/ff94d9b48ef14ff6a448bec24da32d97
2014-07-10 22:21:39,629 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/ff94d9b48ef14ff6a448bec24da32d97, entries=1213320, sequenceid=216, filesize=86.4m
2014-07-10 22:21:39,632 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~333.2m/349424720, currentsize=0.0/0 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 30848ms, sequenceid=216, compaction requested=false
2014-07-10 22:22:02,200 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=216, memsize=331.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/85b670b86b5c44aca1c11ef9027a592b
2014-07-10 22:22:02,220 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/85b670b86b5c44aca1c11ef9027a592b as hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/85b670b86b5c44aca1c11ef9027a592b
2014-07-10 22:22:02,243 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/85b670b86b5c44aca1c11ef9027a592b, entries=1207830, sequenceid=216, filesize=86.0m
2014-07-10 22:22:02,243 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~331.7m/347847280, currentsize=0.0/0 for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. in 23155ms, sequenceid=216, compaction requested=false
2014-07-10 22:22:08,198 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:08,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1136 synced till here 1132
2014-07-10 22:22:09,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056063643 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056128199
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055638470
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405055999781
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056001906
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056003757
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056011058
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056022687
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056024124
2014-07-10 22:22:09,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056026207
2014-07-10 22:22:09,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056031392
2014-07-10 22:22:14,116 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:14,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056128199 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056134117
2014-07-10 22:22:27,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:28,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056134117 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056147974
2014-07-10 22:22:31,062 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:32,881 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1380 synced till here 1379
2014-07-10 22:22:32,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056147974 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056151063
2014-07-10 22:22:35,579 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:35,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1455 synced till here 1451
2014-07-10 22:22:35,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056151063 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056155580
2014-07-10 22:22:40,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:40,786 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1529 synced till here 1527
2014-07-10 22:22:40,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056155580 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056160726
2014-07-10 22:22:44,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:44,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1613 synced till here 1601
2014-07-10 22:22:45,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056160726 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056164799
2014-07-10 22:22:47,831 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:22:47,831 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 259.5m
2014-07-10 22:22:48,021 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:22:48,021 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 259.8m
2014-07-10 22:22:48,461 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:22:48,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:48,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1694 synced till here 1686
2014-07-10 22:22:48,812 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:22:48,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056164799 with entries=81, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056168526
2014-07-10 22:22:52,025 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:52,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1781 synced till here 1768
2014-07-10 22:22:52,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056168526 with entries=87, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056172025
2014-07-10 22:22:55,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:22:56,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1886 synced till here 1872
2014-07-10 22:22:57,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056172025 with entries=105, filesize=90.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056175672
2014-07-10 22:22:57,752 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:22:58,103 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:22:58,434 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:23:01,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:01,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1970 synced till here 1966
2014-07-10 22:23:01,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056175672 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056181474
2014-07-10 22:23:05,016 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:05,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2059 synced till here 2048
2014-07-10 22:23:06,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056181474 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056185017
2014-07-10 22:23:13,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:13,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2145 synced till here 2133
2014-07-10 22:23:13,778 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10005,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056183773,"queuetimems":0,"class":"HRegionServer","responsesize":19393,"method":"Multi"}
2014-07-10 22:23:13,790 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=341, memsize=262.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/9930c4a253bf4f549dc17913eeb3a3b9
2014-07-10 22:23:13,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056185017 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056193302
2014-07-10 22:23:13,976 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/9930c4a253bf4f549dc17913eeb3a3b9 as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/9930c4a253bf4f549dc17913eeb3a3b9
2014-07-10 22:23:13,989 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/9930c4a253bf4f549dc17913eeb3a3b9, entries=956120, sequenceid=341, filesize=68.2m
2014-07-10 22:23:13,989 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.6m/275355680, currentsize=156.7m/164340000 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 26158ms, sequenceid=341, compaction requested=false
2014-07-10 22:23:13,990 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 330.8m
2014-07-10 22:23:14,446 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=342, memsize=264.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/3816cd903e3049bebf58881d49fd7289
2014-07-10 22:23:14,498 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/3816cd903e3049bebf58881d49fd7289 as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3816cd903e3049bebf58881d49fd7289
2014-07-10 22:23:14,521 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3816cd903e3049bebf58881d49fd7289, entries=962880, sequenceid=342, filesize=68.6m
2014-07-10 22:23:14,521 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.5m/277300560, currentsize=147.5m/154622800 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 26500ms, sequenceid=342, compaction requested=false
2014-07-10 22:23:14,521 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 329.7m
2014-07-10 22:23:16,827 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:23:16,954 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:23:20,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:20,242 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10229,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056190007,"queuetimems":0,"class":"HRegionServer","responsesize":19465,"method":"Multi"}
2014-07-10 22:23:20,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2237 synced till here 2230
2014-07-10 22:23:20,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056193302 with entries=92, filesize=79.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056200233
2014-07-10 22:23:20,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056036590
2014-07-10 22:23:20,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056051789
2014-07-10 22:23:20,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056055699
2014-07-10 22:23:20,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056059731
2014-07-10 22:23:24,948 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=7612, hits=570, hitRatio=7.48%, , cachingAccesses=574, cachingHits=567, cachingHitsRatio=98.78%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:23:25,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:25,603 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2327 synced till here 2314
2014-07-10 22:23:26,177 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056200233 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056205428
2014-07-10 22:23:26,822 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10043,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056196778,"queuetimems":1,"class":"HRegionServer","responsesize":19447,"method":"Multi"}
2014-07-10 22:23:28,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:28,862 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2408 synced till here 2400
2014-07-10 22:23:29,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056205428 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056208810
2014-07-10 22:23:35,283 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:23:35,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:35,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2496 synced till here 2481
2014-07-10 22:23:36,476 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:23:36,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056208810 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056215714
2014-07-10 22:23:38,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:38,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2588 synced till here 2577
2014-07-10 22:23:39,028 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056215714 with entries=92, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056218779
2014-07-10 22:23:43,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:44,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2671 synced till here 2661
2014-07-10 22:23:45,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056218779 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056223603
2014-07-10 22:23:52,658 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056221188,"queuetimems":0,"class":"HRegionServer","responsesize":19987,"method":"Multi"}
2014-07-10 22:23:53,828 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:54,117 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2774 synced till here 2757
2014-07-10 22:23:54,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056223603 with entries=103, filesize=88.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056233829
2014-07-10 22:23:54,994 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056222946,"queuetimems":1,"class":"HRegionServer","responsesize":19813,"method":"Multi"}
2014-07-10 22:23:54,994 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12742,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056222252,"queuetimems":0,"class":"HRegionServer","responsesize":19693,"method":"Multi"}
2014-07-10 22:23:55,662 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12734,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056222928,"queuetimems":0,"class":"HRegionServer","responsesize":19676,"method":"Multi"}
2014-07-10 22:23:57,115 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13556,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056223558,"queuetimems":572,"class":"HRegionServer","responsesize":19680,"method":"Multi"}
2014-07-10 22:23:58,378 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14795,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056223582,"queuetimems":1,"class":"HRegionServer","responsesize":19829,"method":"Multi"}
2014-07-10 22:23:58,378 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13903,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056224474,"queuetimems":0,"class":"HRegionServer","responsesize":20147,"method":"Multi"}
2014-07-10 22:23:58,378 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13287,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056225090,"queuetimems":1,"class":"HRegionServer","responsesize":19719,"method":"Multi"}
2014-07-10 22:23:58,378 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13957,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056224421,"queuetimems":0,"class":"HRegionServer","responsesize":19730,"method":"Multi"}
2014-07-10 22:23:58,379 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056224435,"queuetimems":0,"class":"HRegionServer","responsesize":19712,"method":"Multi"}
2014-07-10 22:23:58,408 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056225725,"queuetimems":18,"class":"HRegionServer","responsesize":19715,"method":"Multi"}
2014-07-10 22:23:58,408 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12633,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056225775,"queuetimems":0,"class":"HRegionServer","responsesize":19641,"method":"Multi"}
2014-07-10 22:23:59,268 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14163,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056225104,"queuetimems":1,"class":"HRegionServer","responsesize":19781,"method":"Multi"}
2014-07-10 22:23:59,278 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056226327,"queuetimems":0,"class":"HRegionServer","responsesize":19560,"method":"Multi"}
2014-07-10 22:23:59,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:23:59,797 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13490,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056226306,"queuetimems":0,"class":"HRegionServer","responsesize":19370,"method":"Multi"}
2014-07-10 22:23:59,797 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056227204,"queuetimems":0,"class":"HRegionServer","responsesize":19740,"method":"Multi"}
2014-07-10 22:23:59,797 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12599,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056227198,"queuetimems":8,"class":"HRegionServer","responsesize":19906,"method":"Multi"}
2014-07-10 22:23:59,797 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12550,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056227247,"queuetimems":0,"class":"HRegionServer","responsesize":19697,"method":"Multi"}
2014-07-10 22:24:00,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2878 synced till here 2853
2014-07-10 22:24:00,723 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10934,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056229787,"queuetimems":1,"class":"HRegionServer","responsesize":20454,"method":"Multi"}
2014-07-10 22:24:00,727 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11935,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056228791,"queuetimems":0,"class":"HRegionServer","responsesize":19883,"method":"Multi"}
2014-07-10 22:24:00,728 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11949,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056228778,"queuetimems":719,"class":"HRegionServer","responsesize":19788,"method":"Multi"}
2014-07-10 22:24:00,732 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10459,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056230272,"queuetimems":1,"class":"HRegionServer","responsesize":19802,"method":"Multi"}
2014-07-10 22:24:00,738 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056228026,"queuetimems":19,"class":"HRegionServer","responsesize":20168,"method":"Multi"}
2014-07-10 22:24:00,738 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056228927,"queuetimems":0,"class":"HRegionServer","responsesize":19403,"method":"Multi"}
2014-07-10 22:24:01,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056233829 with entries=104, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056239796
2014-07-10 22:24:02,510 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11845,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056230664,"queuetimems":0,"class":"HRegionServer","responsesize":19567,"method":"Multi"}
2014-07-10 22:24:02,510 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12165,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056230345,"queuetimems":1,"class":"HRegionServer","responsesize":19774,"method":"Multi"}
2014-07-10 22:24:02,513 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056230700,"queuetimems":0,"class":"HRegionServer","responsesize":20265,"method":"Multi"}
2014-07-10 22:24:02,514 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056232490,"queuetimems":1,"class":"HRegionServer","responsesize":19370,"method":"Multi"}
2014-07-10 22:24:02,515 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056230304,"queuetimems":0,"class":"HRegionServer","responsesize":19440,"method":"Multi"}
2014-07-10 22:24:02,523 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056231451,"queuetimems":0,"class":"HRegionServer","responsesize":20130,"method":"Multi"}
2014-07-10 22:24:02,523 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056232464,"queuetimems":1,"class":"HRegionServer","responsesize":19335,"method":"Multi"}
2014-07-10 22:24:02,523 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056231807,"queuetimems":0,"class":"HRegionServer","responsesize":19736,"method":"Multi"}
2014-07-10 22:24:02,525 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056232115,"queuetimems":1,"class":"HRegionServer","responsesize":19440,"method":"Multi"}
2014-07-10 22:24:02,526 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11052,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056231474,"queuetimems":0,"class":"HRegionServer","responsesize":19567,"method":"Multi"}
2014-07-10 22:24:02,538 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056232090,"queuetimems":9,"class":"HRegionServer","responsesize":19672,"method":"Multi"}
2014-07-10 22:24:02,539 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056231120,"queuetimems":1,"class":"HRegionServer","responsesize":19913,"method":"Multi"}
2014-07-10 22:24:02,539 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10386,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056232153,"queuetimems":1,"class":"HRegionServer","responsesize":19801,"method":"Multi"}
2014-07-10 22:24:02,540 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10769,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056231770,"queuetimems":1,"class":"HRegionServer","responsesize":19841,"method":"Multi"}
2014-07-10 22:24:06,061 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:06,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2973 synced till here 2955
2014-07-10 22:24:07,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056239796 with entries=95, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056246062
2014-07-10 22:24:10,313 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:10,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3058 synced till here 3046
2014-07-10 22:24:10,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056246062 with entries=85, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056250315
2014-07-10 22:24:14,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:14,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3150 synced till here 3135
2014-07-10 22:24:14,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056250315 with entries=92, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056254040
2014-07-10 22:24:18,337 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:19,197 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=437, memsize=341.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/3730611a49584b5dad6ed3c1f6224627
2014-07-10 22:24:19,198 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=430, memsize=331.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/7b845d04f0a842a0a4b3da745646309a
2014-07-10 22:24:19,222 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/7b845d04f0a842a0a4b3da745646309a as hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/7b845d04f0a842a0a4b3da745646309a
2014-07-10 22:24:19,222 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/3730611a49584b5dad6ed3c1f6224627 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/3730611a49584b5dad6ed3c1f6224627
2014-07-10 22:24:19,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3283 synced till here 3249
2014-07-10 22:24:19,858 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/3730611a49584b5dad6ed3c1f6224627, entries=1243280, sequenceid=437, filesize=88.6m
2014-07-10 22:24:19,859 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~341.5m/358054720, currentsize=331.4m/347480960 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 65869ms, sequenceid=437, compaction requested=false
2014-07-10 22:24:19,860 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2., current region memstore size 656.0m
2014-07-10 22:24:19,884 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:24:19,898 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/7b845d04f0a842a0a4b3da745646309a, entries=1206270, sequenceid=430, filesize=85.9m
2014-07-10 22:24:19,898 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~331.3m/347395040, currentsize=333.9m/350118640 for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. in 65377ms, sequenceid=430, compaction requested=false
2014-07-10 22:24:19,901 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 515.4m
2014-07-10 22:24:20,410 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:24:20,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056254040 with entries=133, filesize=113.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056258338
2014-07-10 22:24:22,269 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:24:22,859 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:24:23,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:24,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3383 synced till here 3365
2014-07-10 22:24:24,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056258338 with entries=100, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056263921
2014-07-10 22:24:28,329 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:28,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3482 synced till here 3468
2014-07-10 22:24:28,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056263921 with entries=99, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056268330
2014-07-10 22:24:31,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:31,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3572 synced till here 3559
2014-07-10 22:24:32,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056268330 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056271707
2014-07-10 22:24:35,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:35,855 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3655 synced till here 3646
2014-07-10 22:24:36,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056271707 with entries=83, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056275398
2014-07-10 22:24:54,748 WARN  [regionserver60020] util.Sleeper: We slept 17563ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:24:54,749 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 25551ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:24:54,750 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 25551ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:24:54,751 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17077ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=17487ms
2014-07-10 22:24:54,832 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056272707,"queuetimems":0,"class":"HRegionServer","responsesize":19653,"method":"Multi"}
2014-07-10 22:24:54,832 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056272204,"queuetimems":0,"class":"HRegionServer","responsesize":19957,"method":"Multi"}
2014-07-10 22:24:54,832 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273023,"queuetimems":1,"class":"HRegionServer","responsesize":19880,"method":"Multi"}
2014-07-10 22:24:54,832 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22855,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056271976,"queuetimems":0,"class":"HRegionServer","responsesize":19868,"method":"Multi"}
2014-07-10 22:24:54,847 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21791,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273056,"queuetimems":0,"class":"HRegionServer","responsesize":19347,"method":"Multi"}
2014-07-10 22:24:54,856 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21565,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273290,"queuetimems":0,"class":"HRegionServer","responsesize":19800,"method":"Multi"}
2014-07-10 22:24:54,950 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20983,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273966,"queuetimems":243,"class":"HRegionServer","responsesize":19454,"method":"Multi"}
2014-07-10 22:24:54,950 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21279,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273670,"queuetimems":2,"class":"HRegionServer","responsesize":19600,"method":"Multi"}
2014-07-10 22:24:55,002 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21005,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056273996,"queuetimems":0,"class":"HRegionServer","responsesize":19462,"method":"Multi"}
2014-07-10 22:24:55,640 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20358,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275282,"queuetimems":0,"class":"HRegionServer","responsesize":19800,"method":"Multi"}
2014-07-10 22:24:55,645 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20298,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275346,"queuetimems":0,"class":"HRegionServer","responsesize":19923,"method":"Multi"}
2014-07-10 22:24:55,640 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20555,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275085,"queuetimems":0,"class":"HRegionServer","responsesize":20068,"method":"Multi"}
2014-07-10 22:24:55,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:55,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3744 synced till here 3732
2014-07-10 22:24:56,490 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20639,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275850,"queuetimems":0,"class":"HRegionServer","responsesize":19707,"method":"Multi"}
2014-07-10 22:24:58,009 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275391,"queuetimems":0,"class":"HRegionServer","responsesize":19962,"method":"Multi"}
2014-07-10 22:24:58,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056275398 with entries=89, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056295874
2014-07-10 22:24:58,257 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21992,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056276264,"queuetimems":0,"class":"HRegionServer","responsesize":19658,"method":"Multi"}
2014-07-10 22:24:58,264 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056277217,"queuetimems":0,"class":"HRegionServer","responsesize":19647,"method":"Multi"}
2014-07-10 22:24:58,368 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21167,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056277201,"queuetimems":0,"class":"HRegionServer","responsesize":19966,"method":"Multi"}
2014-07-10 22:24:58,371 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22481,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056275888,"queuetimems":0,"class":"HRegionServer","responsesize":19645,"method":"Multi"}
2014-07-10 22:24:58,371 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056276291,"queuetimems":1,"class":"HRegionServer","responsesize":19928,"method":"Multi"}
2014-07-10 22:24:59,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:24:59,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3842 synced till here 3822
2014-07-10 22:25:00,458 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056295874 with entries=98, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056299041
2014-07-10 22:25:01,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:01,619 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3917 synced till here 3916
2014-07-10 22:25:01,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056299041 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056301519
2014-07-10 22:25:03,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:03,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4001 synced till here 3990
2014-07-10 22:25:03,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056301519 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056303504
2014-07-10 22:25:05,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:05,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4080 synced till here 4075
2014-07-10 22:25:05,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056303504 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056305275
2014-07-10 22:25:07,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:09,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4201 synced till here 4185
2014-07-10 22:25:09,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056305275 with entries=121, filesize=104.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056307108
2014-07-10 22:25:10,126 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:10,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4275 synced till here 4272
2014-07-10 22:25:10,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056307108 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056310127
2014-07-10 22:25:12,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:12,361 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056310127 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056312102
2014-07-10 22:25:12,684 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:25:12,785 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:25:15,739 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=677, memsize=520.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/f5e28d79db5743cb879e11d8610e7b6c
2014-07-10 22:25:15,758 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/f5e28d79db5743cb879e11d8610e7b6c as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/f5e28d79db5743cb879e11d8610e7b6c
2014-07-10 22:25:15,772 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/f5e28d79db5743cb879e11d8610e7b6c, entries=1893370, sequenceid=677, filesize=134.9m
2014-07-10 22:25:15,772 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~520.0m/545274880, currentsize=311.5m/326617760 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 55871ms, sequenceid=677, compaction requested=true
2014-07-10 22:25:15,780 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:25:15,780 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:25:15,780 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-10 22:25:15,780 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2995ms
2014-07-10 22:25:15,780 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:25:15,780 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 829.3m
2014-07-10 22:25:15,780 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:25:15,780 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:25:15,781 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3097ms
2014-07-10 22:25:15,781 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:25:15,781 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:25:16,096 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:25:16,496 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:25:20,260 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=644, memsize=663.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/aec493a0936142d9ab911a607e18b56b
2014-07-10 22:25:20,284 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/aec493a0936142d9ab911a607e18b56b as hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/aec493a0936142d9ab911a607e18b56b
2014-07-10 22:25:20,322 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/aec493a0936142d9ab911a607e18b56b, entries=2416900, sequenceid=644, filesize=172.1m
2014-07-10 22:25:20,322 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~663.8m/696044400, currentsize=368.8m/386675920 for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. in 60463ms, sequenceid=644, compaction requested=false
2014-07-10 22:25:20,323 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 689.7m
2014-07-10 22:25:20,848 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:25:42,723 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=882, memsize=689.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/f1210aa6c6e746d69b18a04456150082
2014-07-10 22:25:42,742 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/f1210aa6c6e746d69b18a04456150082 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f1210aa6c6e746d69b18a04456150082
2014-07-10 22:25:42,763 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f1210aa6c6e746d69b18a04456150082, entries=2511180, sequenceid=882, filesize=178.8m
2014-07-10 22:25:42,764 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~689.7m/723201920, currentsize=0.0/0 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 22440ms, sequenceid=882, compaction requested=true
2014-07-10 22:25:42,764 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:25:42,764 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:25:42,764 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-10 22:25:42,764 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:25:42,765 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:25:42,765 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 700.9m
2014-07-10 22:25:42,765 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:25:42,980 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=877, memsize=829.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/02fd95bccb394ec0bc7be3f13bf78475
2014-07-10 22:25:43,005 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/02fd95bccb394ec0bc7be3f13bf78475 as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/02fd95bccb394ec0bc7be3f13bf78475
2014-07-10 22:25:43,139 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/02fd95bccb394ec0bc7be3f13bf78475, entries=3019470, sequenceid=877, filesize=215.0m
2014-07-10 22:25:43,139 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~829.3m/869584480, currentsize=7.8m/8167440 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 27359ms, sequenceid=877, compaction requested=true
2014-07-10 22:25:43,140 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:25:43,140 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 319.2m
2014-07-10 22:25:43,140 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:25:43,140 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-10 22:25:43,140 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:25:43,140 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:25:43,140 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:25:43,220 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:25:43,333 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:25:46,538 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:25:47,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:47,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056312102 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056347499
2014-07-10 22:25:47,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056063643
2014-07-10 22:25:47,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056128199
2014-07-10 22:25:47,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056134117
2014-07-10 22:25:47,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056147974
2014-07-10 22:25:47,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056151063
2014-07-10 22:25:47,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056155580
2014-07-10 22:25:47,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056160726
2014-07-10 22:25:47,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056164799
2014-07-10 22:25:47,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056168526
2014-07-10 22:25:47,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056172025
2014-07-10 22:25:47,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056175672
2014-07-10 22:25:47,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056181474
2014-07-10 22:25:47,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056185017
2014-07-10 22:25:50,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:50,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056347499 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056350853
2014-07-10 22:25:53,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:53,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4572 synced till here 4570
2014-07-10 22:25:53,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056350853 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056353036
2014-07-10 22:25:54,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:54,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4645 synced till here 4644
2014-07-10 22:25:54,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056353036 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056354674
2014-07-10 22:25:55,088 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=883, memsize=319.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/97c365d43e5145319acf8a4f475820e2
2014-07-10 22:25:55,107 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/97c365d43e5145319acf8a4f475820e2 as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/97c365d43e5145319acf8a4f475820e2
2014-07-10 22:25:55,119 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/97c365d43e5145319acf8a4f475820e2, entries=1162340, sequenceid=883, filesize=82.7m
2014-07-10 22:25:55,120 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~319.2m/334744880, currentsize=86.9m/91118240 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 11979ms, sequenceid=883, compaction requested=true
2014-07-10 22:25:55,121 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:25:55,121 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:25:55,121 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-10 22:25:55,121 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:25:55,121 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2., current region memstore size 449.5m
2014-07-10 22:25:55,121 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:25:55,122 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:25:55,669 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:25:56,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:56,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4721 synced till here 4719
2014-07-10 22:25:56,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056354674 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056356273
2014-07-10 22:25:58,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:25:58,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4796 synced till here 4795
2014-07-10 22:25:58,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056356273 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056358023
2014-07-10 22:25:59,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:01,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4898 synced till here 4897
2014-07-10 22:26:01,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056358023 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056359956
2014-07-10 22:26:01,856 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:01,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056359956 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056361856
2014-07-10 22:26:12,214 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=882, memsize=700.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/04cd14cef5064ecc9c0397ab577b5a3a
2014-07-10 22:26:12,237 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/04cd14cef5064ecc9c0397ab577b5a3a as hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/04cd14cef5064ecc9c0397ab577b5a3a
2014-07-10 22:26:12,324 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/04cd14cef5064ecc9c0397ab577b5a3a, entries=2551830, sequenceid=882, filesize=181.7m
2014-07-10 22:26:12,324 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~700.9m/734904480, currentsize=195.9m/205385040 for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. in 29559ms, sequenceid=882, compaction requested=true
2014-07-10 22:26:12,325 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:26:12,325 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:26:12,325 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-10 22:26:12,325 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:26:12,325 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:26:12,325 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. because compaction request was cancelled
2014-07-10 22:26:14,243 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=936, memsize=452.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/6d14a4dd36434a2ea9243493add61fa5
2014-07-10 22:26:14,262 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/6d14a4dd36434a2ea9243493add61fa5 as hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/6d14a4dd36434a2ea9243493add61fa5
2014-07-10 22:26:14,539 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/6d14a4dd36434a2ea9243493add61fa5, entries=1648070, sequenceid=936, filesize=117.4m
2014-07-10 22:26:14,539 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~452.6m/474631520, currentsize=111.6m/117066240 for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. in 19418ms, sequenceid=936, compaction requested=true
2014-07-10 22:26:14,539 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:26:14,539 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:26:14,540 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-10 22:26:14,540 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:26:14,540 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:26:14,540 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. because compaction request was cancelled
2014-07-10 22:26:38,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:38,205 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056361856 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056398177
2014-07-10 22:26:38,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056193302
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056200233
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056205428
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056208810
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056215714
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056218779
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056223603
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056233829
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056239796
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056246062
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056250315
2014-07-10 22:26:38,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056254040
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056258338
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056263921
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056268330
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056271707
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056275398
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056295874
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056299041
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056301519
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056303504
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056305275
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056307108
2014-07-10 22:26:38,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056310127
2014-07-10 22:26:40,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:40,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5118 synced till here 5114
2014-07-10 22:26:40,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056398177 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056400218
2014-07-10 22:26:41,575 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:26:41,576 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 256.2m
2014-07-10 22:26:41,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:41,774 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:26:42,474 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5204 synced till here 5201
2014-07-10 22:26:42,519 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:26:42,519 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 256.2m
2014-07-10 22:26:42,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056400218 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056401661
2014-07-10 22:26:42,670 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:26:42,726 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:26:42,754 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:26:43,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:43,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5279 synced till here 5275
2014-07-10 22:26:43,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056401661 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056403168
2014-07-10 22:26:44,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:44,635 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5354 synced till here 5351
2014-07-10 22:26:44,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056403168 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056404622
2014-07-10 22:26:46,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:46,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5428 synced till here 5427
2014-07-10 22:26:46,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056404622 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056406443
2014-07-10 22:26:48,540 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:48,541 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:26:48,678 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5510 synced till here 5508
2014-07-10 22:26:48,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056406443 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056408541
2014-07-10 22:26:51,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:51,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5595 synced till here 5584
2014-07-10 22:26:51,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056408541 with entries=85, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056411358
2014-07-10 22:26:53,649 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1263ms
GC pool 'ParNew' had collection(s): count=1 time=1673ms
2014-07-10 22:26:54,064 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:54,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056411358 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056414065
2014-07-10 22:26:55,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:55,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5763 synced till here 5756
2014-07-10 22:26:56,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056414065 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056415932
2014-07-10 22:26:56,575 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1043, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/d366a14bcd5b4b7db9e7b7c9ddf26a54
2014-07-10 22:26:57,610 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/d366a14bcd5b4b7db9e7b7c9ddf26a54 as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/d366a14bcd5b4b7db9e7b7c9ddf26a54
2014-07-10 22:26:57,669 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/d366a14bcd5b4b7db9e7b7c9ddf26a54, entries=932740, sequenceid=1043, filesize=66.5m
2014-07-10 22:26:57,669 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268620720, currentsize=199.0m/208618560 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 16093ms, sequenceid=1043, compaction requested=true
2014-07-10 22:26:57,670 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:26:57,670 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:26:57,670 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-10 22:26:57,670 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 446.0m
2014-07-10 22:26:57,670 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:26:57,670 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:26:57,670 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:26:57,720 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1051, memsize=259.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/49ab3bf573de4614a9b229ae63372699
2014-07-10 22:26:57,758 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:26:57,998 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:26:58,015 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/49ab3bf573de4614a9b229ae63372699 as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/49ab3bf573de4614a9b229ae63372699
2014-07-10 22:26:58,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5851 synced till here 5837
2014-07-10 22:26:58,075 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/49ab3bf573de4614a9b229ae63372699, entries=944380, sequenceid=1051, filesize=67.3m
2014-07-10 22:26:58,106 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.4m/271974640, currentsize=206.4m/216463120 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 15586ms, sequenceid=1051, compaction requested=true
2014-07-10 22:26:58,106 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:26:58,106 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:26:58,106 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-10 22:26:58,106 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 448.6m
2014-07-10 22:26:58,106 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:26:58,106 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:26:58,106 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:26:58,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056415932 with entries=88, filesize=75.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056417758
2014-07-10 22:26:58,633 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:27:00,173 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1067ms
GC pool 'ParNew' had collection(s): count=1 time=1412ms
2014-07-10 22:27:00,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:00,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5934 synced till here 5926
2014-07-10 22:27:00,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056417758 with entries=83, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056420292
2014-07-10 22:27:01,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:01,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6012 synced till here 6008
2014-07-10 22:27:01,852 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:27:01,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056420292 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056421379
2014-07-10 22:27:02,104 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:27:02,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:02,739 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056421379 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056422707
2014-07-10 22:27:08,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:09,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6158 synced till here 6157
2014-07-10 22:27:09,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056422707 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056428928
2014-07-10 22:27:10,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:11,380 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056428928 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056430951
2014-07-10 22:27:13,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:13,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6304 synced till here 6303
2014-07-10 22:27:13,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056430951 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056433398
2014-07-10 22:27:15,591 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1171, memsize=447.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/cc5301d12d1e409ba769ab247dcfa238
2014-07-10 22:27:15,620 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/cc5301d12d1e409ba769ab247dcfa238 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/cc5301d12d1e409ba769ab247dcfa238
2014-07-10 22:27:15,642 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/cc5301d12d1e409ba769ab247dcfa238, entries=1629350, sequenceid=1171, filesize=116.1m
2014-07-10 22:27:15,643 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~447.5m/469238320, currentsize=159.6m/167391680 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 17973ms, sequenceid=1171, compaction requested=true
2014-07-10 22:27:15,644 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:15,644 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:27:15,644 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-10 22:27:15,644 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:15,644 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:15,644 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2., current region memstore size 523.8m
2014-07-10 22:27:15,644 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:27:15,982 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:27:16,983 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1175, memsize=453.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/29439bc4f1e945e1bd0286668b6418ca
2014-07-10 22:27:17,000 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/29439bc4f1e945e1bd0286668b6418ca as hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/29439bc4f1e945e1bd0286668b6418ca
2014-07-10 22:27:17,014 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/29439bc4f1e945e1bd0286668b6418ca, entries=1650140, sequenceid=1175, filesize=117.6m
2014-07-10 22:27:17,015 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~453.2m/475228560, currentsize=161.8m/169610000 for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. in 18909ms, sequenceid=1175, compaction requested=true
2014-07-10 22:27:17,015 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:17,016 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:27:17,016 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-10 22:27:17,016 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 368.4m
2014-07-10 22:27:17,016 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:17,016 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:17,016 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. because compaction request was cancelled
2014-07-10 22:27:17,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:17,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056433398 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056437071
2014-07-10 22:27:17,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056312102
2014-07-10 22:27:17,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056347499
2014-07-10 22:27:17,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056350853
2014-07-10 22:27:17,100 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056353036
2014-07-10 22:27:17,308 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:27:20,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:21,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056437071 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056440969
2014-07-10 22:27:22,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:22,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6524 synced till here 6521
2014-07-10 22:27:22,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056440969 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056442323
2014-07-10 22:27:23,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:23,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6600 synced till here 6598
2014-07-10 22:27:23,659 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056442323 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056443570
2014-07-10 22:27:25,173 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:27:25,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:26,007 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:27:26,251 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6702 synced till here 6701
2014-07-10 22:27:26,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056443570 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056445887
2014-07-10 22:27:27,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:27,752 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6777 synced till here 6775
2014-07-10 22:27:27,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056445887 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056447729
2014-07-10 22:27:28,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:29,023 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6851 synced till here 6850
2014-07-10 22:27:29,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056447729 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056448998
2014-07-10 22:27:30,334 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:30,723 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6964 synced till here 6961
2014-07-10 22:27:30,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056448998 with entries=113, filesize=97.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056450335
2014-07-10 22:27:31,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:32,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056450335 with entries=99, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056451875
2014-07-10 22:27:32,933 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1282, memsize=370.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/b9d53ff93119469bb88fa4069ac277ed
2014-07-10 22:27:32,946 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/b9d53ff93119469bb88fa4069ac277ed as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b9d53ff93119469bb88fa4069ac277ed
2014-07-10 22:27:32,958 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b9d53ff93119469bb88fa4069ac277ed, entries=1347080, sequenceid=1282, filesize=95.9m
2014-07-10 22:27:32,959 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~370.0m/387947920, currentsize=219.4m/230042400 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 15942ms, sequenceid=1282, compaction requested=true
2014-07-10 22:27:32,959 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:32,959 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:27:32,959 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-10 22:27:32,959 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:32,959 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 582.7m
2014-07-10 22:27:32,959 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:32,959 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:27:33,380 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:27:33,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:33,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7159 synced till here 7157
2014-07-10 22:27:33,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056451875 with entries=96, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056453580
2014-07-10 22:27:35,146 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:27:35,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:35,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7236 synced till here 7233
2014-07-10 22:27:35,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056453580 with entries=77, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056455527
2014-07-10 22:27:37,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:37,076 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7311 synced till here 7309
2014-07-10 22:27:37,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056455527 with entries=75, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056457054
2014-07-10 22:27:38,379 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1274, memsize=523.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/d4b8b6ee40ad40969add80c0a58b86f5
2014-07-10 22:27:38,396 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/d4b8b6ee40ad40969add80c0a58b86f5 as hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/d4b8b6ee40ad40969add80c0a58b86f5
2014-07-10 22:27:38,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:38,412 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/d4b8b6ee40ad40969add80c0a58b86f5, entries=1907120, sequenceid=1274, filesize=135.8m
2014-07-10 22:27:38,412 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~523.8m/549236720, currentsize=317.4m/332810080 for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. in 22768ms, sequenceid=1274, compaction requested=true
2014-07-10 22:27:38,413 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:27:38,413 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-10 22:27:38,413 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:38,413 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:38,413 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. because compaction request was cancelled
2014-07-10 22:27:38,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7386 synced till here 7385
2014-07-10 22:27:38,417 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:38,417 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 482.6m
2014-07-10 22:27:38,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056457054 with entries=75, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056458400
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056354674
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056356273
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056358023
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056359956
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056361856
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056398177
2014-07-10 22:27:38,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056400218
2014-07-10 22:27:38,441 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:27:38,776 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:27:39,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:39,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7459 synced till here 7458
2014-07-10 22:27:39,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056458400 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056459587
2014-07-10 22:27:40,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:40,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7533 synced till here 7532
2014-07-10 22:27:40,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056459587 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056460842
2014-07-10 22:27:41,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:42,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7612 synced till here 7611
2014-07-10 22:27:42,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056460842 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056461884
2014-07-10 22:27:43,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:43,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7694 synced till here 7691
2014-07-10 22:27:43,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056461884 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056463131
2014-07-10 22:27:44,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:44,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7767 synced till here 7766
2014-07-10 22:27:44,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056463131 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056464349
2014-07-10 22:27:46,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:46,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7840 synced till here 7839
2014-07-10 22:27:46,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056464349 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056466013
2014-07-10 22:27:47,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:47,494 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7917 synced till here 7914
2014-07-10 22:27:47,547 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056466013 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056467462
2014-07-10 22:27:48,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:49,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8041 synced till here 8039
2014-07-10 22:27:49,579 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056467462 with entries=124, filesize=106.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056468755
2014-07-10 22:27:50,738 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:50,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8114 synced till here 8112
2014-07-10 22:27:50,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056468755 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056470739
2014-07-10 22:27:51,943 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:52,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8217 synced till here 8211
2014-07-10 22:27:52,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056470739 with entries=103, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056471943
2014-07-10 22:27:54,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:55,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8324 synced till here 8316
2014-07-10 22:27:55,361 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056471943 with entries=107, filesize=91.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056474429
2014-07-10 22:27:56,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:56,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056474429 with entries=71, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056476084
2014-07-10 22:27:57,814 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:57,840 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8471 synced till here 8468
2014-07-10 22:27:57,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056476084 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056477814
2014-07-10 22:27:59,292 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,293 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,295 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,296 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,317 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:27:59,323 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,324 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,333 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,333 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,356 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,393 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,416 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,471 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1485, memsize=485.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/f87bfb8755b54698aa022be4cbbeaef4
2014-07-10 22:27:59,479 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:27:59,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056477814 with entries=79, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056479321
2014-07-10 22:27:59,535 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/f87bfb8755b54698aa022be4cbbeaef4 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f87bfb8755b54698aa022be4cbbeaef4
2014-07-10 22:27:59,549 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f87bfb8755b54698aa022be4cbbeaef4, entries=1768510, sequenceid=1485, filesize=126.0m
2014-07-10 22:27:59,549 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~485.7m/509318560, currentsize=357.7m/375106800 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 21132ms, sequenceid=1485, compaction requested=true
2014-07-10 22:27:59,549 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:59,549 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:27:59,549 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-10 22:27:59,549 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 70ms
2014-07-10 22:27:59,549 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:59,550 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 833.0m
2014-07-10 22:27:59,550 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,550 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:59,550 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 134ms
2014-07-10 22:27:59,550 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:27:59,550 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,550 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 157ms
2014-07-10 22:27:59,550 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,550 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 194ms
2014-07-10 22:27:59,550 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,551 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 218ms
2014-07-10 22:27:59,551 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,551 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 218ms
2014-07-10 22:27:59,551 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,565 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 242ms
2014-07-10 22:27:59,565 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,565 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 242ms
2014-07-10 22:27:59,565 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,573 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 256ms
2014-07-10 22:27:59,573 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,573 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 277ms
2014-07-10 22:27:59,573 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,573 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 278ms
2014-07-10 22:27:59,573 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,573 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 280ms
2014-07-10 22:27:59,573 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,577 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 285ms
2014-07-10 22:27:59,577 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:27:59,709 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:27:59,750 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1429, memsize=585.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/2065d7553e5345db97bd314d37b4f26e
2014-07-10 22:27:59,763 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/.tmp/2065d7553e5345db97bd314d37b4f26e as hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/2065d7553e5345db97bd314d37b4f26e
2014-07-10 22:27:59,775 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/2065d7553e5345db97bd314d37b4f26e, entries=2132660, sequenceid=1429, filesize=151.8m
2014-07-10 22:27:59,775 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~585.7m/614188400, currentsize=461.0m/483414480 for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. in 26816ms, sequenceid=1429, compaction requested=true
2014-07-10 22:27:59,775 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:27:59,776 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:27:59,776 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:27:59,776 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:27:59,776 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:27:59,776 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:27:59,776 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 685.3m
2014-07-10 22:27:59,816 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:28:00,758 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:00,841 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:00,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8627 synced till here 8624
2014-07-10 22:28:00,920 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056479321 with entries=77, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056480842
2014-07-10 22:28:00,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056401661
2014-07-10 22:28:00,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056403168
2014-07-10 22:28:00,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056404622
2014-07-10 22:28:00,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056406443
2014-07-10 22:28:00,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056408541
2014-07-10 22:28:00,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056411358
2014-07-10 22:28:00,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056414065
2014-07-10 22:28:00,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056415932
2014-07-10 22:28:00,928 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:02,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:02,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8703 synced till here 8699
2014-07-10 22:28:02,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056480842 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056482142
2014-07-10 22:28:03,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:03,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056482142 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056483287
2014-07-10 22:28:04,066 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:04,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056483287 with entries=89, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056484067
2014-07-10 22:28:05,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:05,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8938 synced till here 8937
2014-07-10 22:28:05,580 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056484067 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056485522
2014-07-10 22:28:06,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:06,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9012 synced till here 9011
2014-07-10 22:28:06,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056485522 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056486670
2014-07-10 22:28:07,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:07,859 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9087 synced till here 9083
2014-07-10 22:28:07,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056486670 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056487835
2014-07-10 22:28:09,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:09,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9161 synced till here 9160
2014-07-10 22:28:09,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056487835 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056489529
2014-07-10 22:28:10,767 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,769 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,778 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,795 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,810 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:10,819 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,828 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9237 synced till here 9236
2014-07-10 22:28:10,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056489529 with entries=76, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056490810
2014-07-10 22:28:10,855 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,917 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:10,959 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,000 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,052 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,106 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,142 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,156 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,195 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,231 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,290 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,345 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,380 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,416 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,453 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,489 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,525 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,561 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,599 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,633 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,668 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,704 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,740 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,777 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,815 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:11,852 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:15,768 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:15,769 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,778 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,796 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,820 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:15,828 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,855 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,917 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:15,959 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,001 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,052 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,106 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,142 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,156 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,195 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,231 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,290 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,345 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,380 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,416 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,453 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,489 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,525 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,562 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,600 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,633 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,668 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,705 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,740 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,778 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:16,815 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:16,852 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:20,768 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,770 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,779 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:20,796 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,820 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,829 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,856 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:20,918 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:20,960 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 22:28:21,001 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,053 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,107 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,143 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,157 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,195 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,232 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,291 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,346 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,381 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,416 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,454 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,490 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 22:28:21,525 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,562 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,600 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,634 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,669 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,706 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,741 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:21,778 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,816 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:21,852 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:24,189 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1727, memsize=688.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/b249848ec13147408f5ece0dc5727ce0
2014-07-10 22:28:24,213 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/b249848ec13147408f5ece0dc5727ce0 as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b249848ec13147408f5ece0dc5727ce0
2014-07-10 22:28:24,230 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b249848ec13147408f5ece0dc5727ce0, entries=2507190, sequenceid=1727, filesize=178.4m
2014-07-10 22:28:24,231 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~688.6m/722051600, currentsize=199.2m/208910880 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 24455ms, sequenceid=1727, compaction requested=true
2014-07-10 22:28:24,231 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:28:24,231 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:28:24,231 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:28:24,231 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12380ms
2014-07-10 22:28:24,232 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:28:24,232 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2., current region memstore size 891.6m
2014-07-10 22:28:24,232 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,232 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:28:24,232 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12417ms
2014-07-10 22:28:24,232 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,232 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:28:24,232 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12455ms
2014-07-10 22:28:24,232 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,233 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12493ms
2014-07-10 22:28:24,233 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,237 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12533ms
2014-07-10 22:28:24,237 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,245 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12577ms
2014-07-10 22:28:24,245 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,247 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12613ms
2014-07-10 22:28:24,247 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,247 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12648ms
2014-07-10 22:28:24,247 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,247 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12686ms
2014-07-10 22:28:24,248 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,253 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12729ms
2014-07-10 22:28:24,253 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,257 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12769ms
2014-07-10 22:28:24,257 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,261 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12808ms
2014-07-10 22:28:24,261 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,262 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12845ms
2014-07-10 22:28:24,262 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,269 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12889ms
2014-07-10 22:28:24,269 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,270 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12924ms
2014-07-10 22:28:24,270 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,277 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12988ms
2014-07-10 22:28:24,277 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,279 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13049ms
2014-07-10 22:28:24,279 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,285 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13091ms
2014-07-10 22:28:24,285 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,293 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13137ms
2014-07-10 22:28:24,293 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,297 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13155ms
2014-07-10 22:28:24,297 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,297 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13192ms
2014-07-10 22:28:24,297 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,305 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13254ms
2014-07-10 22:28:24,305 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,305 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13305ms
2014-07-10 22:28:24,305 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,305 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13347ms
2014-07-10 22:28:24,305 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,305 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13388ms
2014-07-10 22:28:24,306 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,306 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13451ms
2014-07-10 22:28:24,306 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,313 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13485ms
2014-07-10 22:28:24,313 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,313 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13494ms
2014-07-10 22:28:24,313 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,313 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13518ms
2014-07-10 22:28:24,313 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,314 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13535ms
2014-07-10 22:28:24,314 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,316 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13546ms
2014-07-10 22:28:24,316 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,321 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13554ms
2014-07-10 22:28:24,322 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:24,371 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490216,"queuetimems":0,"class":"HRegionServer","responsesize":19617,"method":"Multi"}
2014-07-10 22:28:24,385 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14237,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490147,"queuetimems":1,"class":"HRegionServer","responsesize":19818,"method":"Multi"}
2014-07-10 22:28:24,488 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490634,"queuetimems":0,"class":"HRegionServer","responsesize":8744,"method":"Multi"}
2014-07-10 22:28:24,756 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490603,"queuetimems":0,"class":"HRegionServer","responsesize":19448,"method":"Multi"}
2014-07-10 22:28:24,756 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490618,"queuetimems":1,"class":"HRegionServer","responsesize":20159,"method":"Multi"}
2014-07-10 22:28:24,940 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=8082, hits=1040, hitRatio=12.86%, , cachingAccesses=1044, cachingHits=1037, cachingHitsRatio=99.32%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:28:25,108 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:25,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:25,292 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13805,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491487,"queuetimems":0,"class":"HRegionServer","responsesize":19985,"method":"Multi"}
2014-07-10 22:28:25,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9339 synced till here 9315
2014-07-10 22:28:25,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056490810 with entries=102, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056505292
2014-07-10 22:28:25,698 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491050,"queuetimems":1,"class":"HRegionServer","responsesize":19712,"method":"Multi"}
2014-07-10 22:28:25,699 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491813,"queuetimems":0,"class":"HRegionServer","responsesize":19791,"method":"Multi"}
2014-07-10 22:28:25,700 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491193,"queuetimems":1,"class":"HRegionServer","responsesize":19802,"method":"Multi"}
2014-07-10 22:28:25,706 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14075,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491631,"queuetimems":0,"class":"HRegionServer","responsesize":19958,"method":"Multi"}
2014-07-10 22:28:25,732 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491523,"queuetimems":1,"class":"HRegionServer","responsesize":19909,"method":"Multi"}
2014-07-10 22:28:25,732 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491140,"queuetimems":0,"class":"HRegionServer","responsesize":19982,"method":"Multi"}
2014-07-10 22:28:25,732 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14353,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491378,"queuetimems":0,"class":"HRegionServer","responsesize":19323,"method":"Multi"}
2014-07-10 22:28:25,917 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14465,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491451,"queuetimems":1,"class":"HRegionServer","responsesize":19860,"method":"Multi"}
2014-07-10 22:28:25,917 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490853,"queuetimems":1,"class":"HRegionServer","responsesize":20391,"method":"Multi"}
2014-07-10 22:28:25,917 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14357,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491559,"queuetimems":0,"class":"HRegionServer","responsesize":19874,"method":"Multi"}
2014-07-10 22:28:26,406 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15407,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490999,"queuetimems":1,"class":"HRegionServer","responsesize":19597,"method":"Multi"}
2014-07-10 22:28:26,439 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491155,"queuetimems":0,"class":"HRegionServer","responsesize":9027,"method":"Multi"}
2014-07-10 22:28:26,454 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491595,"queuetimems":0,"class":"HRegionServer","responsesize":19850,"method":"Multi"}
2014-07-10 22:28:26,623 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14957,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491666,"queuetimems":0,"class":"HRegionServer","responsesize":19448,"method":"Multi"}
2014-07-10 22:28:26,624 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15520,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491103,"queuetimems":0,"class":"HRegionServer","responsesize":19713,"method":"Multi"}
2014-07-10 22:28:26,623 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491414,"queuetimems":0,"class":"HRegionServer","responsesize":19923,"method":"Multi"}
2014-07-10 22:28:26,623 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14920,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491703,"queuetimems":1,"class":"HRegionServer","responsesize":19588,"method":"Multi"}
2014-07-10 22:28:26,623 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15830,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490793,"queuetimems":0,"class":"HRegionServer","responsesize":19527,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490956,"queuetimems":0,"class":"HRegionServer","responsesize":20328,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15709,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056490915,"queuetimems":0,"class":"HRegionServer","responsesize":19876,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15336,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491288,"queuetimems":0,"class":"HRegionServer","responsesize":19506,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15281,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491343,"queuetimems":0,"class":"HRegionServer","responsesize":19509,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14887,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491738,"queuetimems":0,"class":"HRegionServer","responsesize":19750,"method":"Multi"}
2014-07-10 22:28:26,625 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491229,"queuetimems":1,"class":"HRegionServer","responsesize":19764,"method":"Multi"}
2014-07-10 22:28:26,626 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14775,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491850,"queuetimems":0,"class":"HRegionServer","responsesize":20034,"method":"Multi"}
2014-07-10 22:28:26,626 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14849,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056491776,"queuetimems":1,"class":"HRegionServer","responsesize":19791,"method":"Multi"}
2014-07-10 22:28:26,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:26,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9421 synced till here 9415
2014-07-10 22:28:26,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056505292 with entries=82, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056506751
2014-07-10 22:28:27,028 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:28:28,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:28,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9498 synced till here 9492
2014-07-10 22:28:29,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056506751 with entries=77, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056508823
2014-07-10 22:28:30,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:30,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9581 synced till here 9571
2014-07-10 22:28:30,904 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056508823 with entries=83, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056510784
2014-07-10 22:28:31,447 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1713, memsize=833.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/a80ac53aee744d29ba0622becf6594b2
2014-07-10 22:28:31,483 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/.tmp/a80ac53aee744d29ba0622becf6594b2 as hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/a80ac53aee744d29ba0622becf6594b2
2014-07-10 22:28:31,965 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/a80ac53aee744d29ba0622becf6594b2, entries=3033030, sequenceid=1713, filesize=215.9m
2014-07-10 22:28:31,966 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~833.0m/873485520, currentsize=341.9m/358551360 for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. in 32415ms, sequenceid=1713, compaction requested=true
2014-07-10 22:28:31,966 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:28:31,966 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:28:31,966 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-10 22:28:31,966 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85., current region memstore size 696.6m
2014-07-10 22:28:31,966 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:28:31,966 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:28:31,966 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. because compaction request was cancelled
2014-07-10 22:28:31,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:32,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9662 synced till here 9656
2014-07-10 22:28:32,069 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:28:32,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056510784 with entries=81, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056511999
2014-07-10 22:28:32,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056417758
2014-07-10 22:28:32,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056420292
2014-07-10 22:28:32,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056421379
2014-07-10 22:28:32,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056422707
2014-07-10 22:28:32,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056428928
2014-07-10 22:28:32,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056430951
2014-07-10 22:28:32,610 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:33,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:33,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9740 synced till here 9736
2014-07-10 22:28:33,080 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056511999 with entries=78, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056513029
2014-07-10 22:28:34,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:34,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9816 synced till here 9814
2014-07-10 22:28:34,501 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056513029 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056514397
2014-07-10 22:28:35,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:35,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9895 synced till here 9891
2014-07-10 22:28:35,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056514397 with entries=79, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056515901
2014-07-10 22:28:37,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:37,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9974 synced till here 9969
2014-07-10 22:28:37,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056515901 with entries=79, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056517254
2014-07-10 22:28:39,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:39,016 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10053 synced till here 10050
2014-07-10 22:28:39,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056517254 with entries=79, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056519001
2014-07-10 22:28:40,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:40,357 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10130 synced till here 10127
2014-07-10 22:28:40,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056519001 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056520335
2014-07-10 22:28:41,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:41,886 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10208 synced till here 10204
2014-07-10 22:28:41,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056520335 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056521385
2014-07-10 22:28:42,190 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,191 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,199 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,210 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,234 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,248 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,248 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,256 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,282 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,284 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,285 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,324 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,366 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,418 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,522 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,526 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,526 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,550 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:42,589 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405055604855: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:28:47,191 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:47,191 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,199 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,211 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:47,235 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,248 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,249 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:47,257 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:28:47,282 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,284 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,285 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,324 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,366 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:28:47,929 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5340ms
2014-07-10 22:28:47,929 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5511ms
2014-07-10 22:28:47,929 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5414ms
2014-07-10 22:28:47,930 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5454ms
2014-07-10 22:28:47,930 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5469ms
2014-07-10 22:28:47,930 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5380ms
2014-07-10 22:28:52,191 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,192 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,200 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,211 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,235 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,249 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,249 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,258 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 22:28:52,283 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,284 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:28:52,286 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,325 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,367 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:28:52,929 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10340ms
2014-07-10 22:28:52,930 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10512ms
2014-07-10 22:28:52,930 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10415ms
2014-07-10 22:28:52,930 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10454ms
2014-07-10 22:28:52,930 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10469ms
2014-07-10 22:28:52,930 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10380ms
2014-07-10 22:28:57,192 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:28:57,192 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,201 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,211 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,236 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:28:57,250 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,250 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:28:57,260 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-10 22:28:57,283 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,285 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,286 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,326 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,367 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:28:57,930 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15341ms
2014-07-10 22:28:57,930 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15454ms
2014-07-10 22:28:57,931 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15416ms
2014-07-10 22:28:57,932 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15514ms
2014-07-10 22:28:57,932 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15382ms
2014-07-10 22:28:57,932 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15471ms
2014-07-10 22:28:57,983 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1940, memsize=701.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/b01b64bbb59a4e9a8f98aa9a3285a2a8
2014-07-10 22:28:57,996 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/.tmp/b01b64bbb59a4e9a8f98aa9a3285a2a8 as hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/b01b64bbb59a4e9a8f98aa9a3285a2a8
2014-07-10 22:28:58,006 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/b01b64bbb59a4e9a8f98aa9a3285a2a8, entries=2553020, sequenceid=1940, filesize=181.6m
2014-07-10 22:28:58,007 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~701.2m/735249360, currentsize=176.9m/185467840 for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. in 26040ms, sequenceid=1940, compaction requested=true
2014-07-10 22:28:58,007 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:28:58,007 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:28:58,007 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15546ms
2014-07-10 22:28:58,007 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,007 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:28:58,007 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564., current region memstore size 969.1m
2014-07-10 22:28:58,007 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15457ms
2014-07-10 22:28:58,007 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,009 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15591ms
2014-07-10 22:28:58,009 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,009 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15494ms
2014-07-10 22:28:58,009 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,009 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15533ms
2014-07-10 22:28:58,009 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,009 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15420ms
2014-07-10 22:28:58,009 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,011 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15645ms
2014-07-10 22:28:58,011 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,007 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:28:58,011 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:28:58,011 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:28:58,012 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15688ms
2014-07-10 22:28:58,012 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,013 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15728ms
2014-07-10 22:28:58,013 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,013 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15729ms
2014-07-10 22:28:58,013 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,013 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15731ms
2014-07-10 22:28:58,013 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,013 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15757ms
2014-07-10 22:28:58,013 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,017 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15769ms
2014-07-10 22:28:58,017 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,017 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15769ms
2014-07-10 22:28:58,017 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,017 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15783ms
2014-07-10 22:28:58,017 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,017 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15807ms
2014-07-10 22:28:58,017 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,021 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15822ms
2014-07-10 22:28:58,021 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,021 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15830ms
2014-07-10 22:28:58,021 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,021 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15831ms
2014-07-10 22:28:58,021 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405055604855
2014-07-10 22:28:58,236 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16356,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521880,"queuetimems":0,"class":"HRegionServer","responsesize":20150,"method":"Multi"}
2014-07-10 22:28:58,236 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16834,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521402,"queuetimems":0,"class":"HRegionServer","responsesize":19371,"method":"Multi"}
2014-07-10 22:28:58,264 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1850, memsize=891.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/1e3380838b8a46d5a1946b97c3db4442
2014-07-10 22:28:58,275 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/.tmp/1e3380838b8a46d5a1946b97c3db4442 as hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/1e3380838b8a46d5a1946b97c3db4442
2014-07-10 22:28:58,287 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/1e3380838b8a46d5a1946b97c3db4442, entries=3246290, sequenceid=1850, filesize=231.0m
2014-07-10 22:28:58,287 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~891.6m/934903440, currentsize=305.5m/320349840 for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. in 34055ms, sequenceid=1850, compaction requested=true
2014-07-10 22:28:58,287 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:28:58,287 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:28:58,288 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-10 22:28:58,288 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:28:58,288 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6., current region memstore size 504.1m
2014-07-10 22:28:58,288 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:28:58,288 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. because compaction request was cancelled
2014-07-10 22:28:58,428 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:28:58,428 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16511,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521917,"queuetimems":1,"class":"HRegionServer","responsesize":19821,"method":"Multi"}
2014-07-10 22:28:58,505 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521965,"queuetimems":1,"class":"HRegionServer","responsesize":19749,"method":"Multi"}
2014-07-10 22:28:58,505 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17163,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521342,"queuetimems":1,"class":"HRegionServer","responsesize":19496,"method":"Multi"}
2014-07-10 22:28:58,505 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16612,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056521893,"queuetimems":1,"class":"HRegionServer","responsesize":19809,"method":"Multi"}
2014-07-10 22:28:58,581 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:28:58,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10292 synced till here 10281
2014-07-10 22:28:58,692 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:58,877 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:28:59,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056521385 with entries=84, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056538581
2014-07-10 22:28:59,069 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056433398
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056437071
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056440969
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056442323
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056443570
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056445887
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056447729
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056448998
2014-07-10 22:28:59,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056450335
2014-07-10 22:28:59,207 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522459,"queuetimems":0,"class":"HRegionServer","responsesize":19685,"method":"Multi"}
2014-07-10 22:28:59,208 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522108,"queuetimems":1,"class":"HRegionServer","responsesize":19855,"method":"Multi"}
2014-07-10 22:28:59,207 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522151,"queuetimems":0,"class":"HRegionServer","responsesize":20011,"method":"Multi"}
2014-07-10 22:28:59,207 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16731,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522475,"queuetimems":0,"class":"HRegionServer","responsesize":8934,"method":"Multi"}
2014-07-10 22:28:59,222 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522511,"queuetimems":0,"class":"HRegionServer","responsesize":19465,"method":"Multi"}
2014-07-10 22:28:59,328 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522280,"queuetimems":0,"class":"HRegionServer","responsesize":19497,"method":"Multi"}
2014-07-10 22:28:59,328 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522208,"queuetimems":0,"class":"HRegionServer","responsesize":19285,"method":"Multi"}
2014-07-10 22:28:59,328 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16739,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522588,"queuetimems":0,"class":"HRegionServer","responsesize":21096,"method":"Multi"}
2014-07-10 22:28:59,353 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522245,"queuetimems":1,"class":"HRegionServer","responsesize":19799,"method":"Multi"}
2014-07-10 22:28:59,353 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16989,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522363,"queuetimems":0,"class":"HRegionServer","responsesize":19796,"method":"Multi"}
2014-07-10 22:28:59,353 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522322,"queuetimems":0,"class":"HRegionServer","responsesize":20097,"method":"Multi"}
2014-07-10 22:28:59,353 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522417,"queuetimems":1,"class":"HRegionServer","responsesize":19607,"method":"Multi"}
2014-07-10 22:28:59,353 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16803,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44538","starttimems":1405056522549,"queuetimems":1,"class":"HRegionServer","responsesize":20159,"method":"Multi"}
2014-07-10 22:29:00,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:29:00,286 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056538581 with entries=83, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056540254
2014-07-10 22:29:01,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:29:01,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056540254 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056541163
2014-07-10 22:29:02,322 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:29:02,440 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:29:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10525 synced till here 10522
2014-07-10 22:29:02,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056541163 with entries=76, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056542440
2014-07-10 22:29:03,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:29:04,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056542440 with entries=107, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405055604855/slave1%2C60020%2C1405055604855.1405056543882
2014-07-10 22:29:15,242 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2060, memsize=508.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/3c4d4eab02584596837e3842d5d2e0b4
2014-07-10 22:29:15,256 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/.tmp/3c4d4eab02584596837e3842d5d2e0b4 as hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3c4d4eab02584596837e3842d5d2e0b4
2014-07-10 22:29:15,266 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3c4d4eab02584596837e3842d5d2e0b4, entries=1852480, sequenceid=2060, filesize=132.0m
2014-07-10 22:29:15,267 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~508.8m/533498560, currentsize=128.8m/135004400 for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. in 16978ms, sequenceid=2060, compaction requested=true
2014-07-10 22:29:15,267 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:29:15,267 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-10 22:29:15,267 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-10 22:29:15,267 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:29:15,267 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3., current region memstore size 657.7m
2014-07-10 22:29:15,267 DEBUG [regionserver60020-smallCompactions-1405055643597] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:29:15,267 DEBUG [regionserver60020-smallCompactions-1405055643597] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:29:15,686 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
