Thu Jul 10 22:30:35 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-10 22:30:36,072 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-10 22:30:36,073 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-10 22:30:36,073 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-10 22:30:36,314 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 34857 22
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-10 22:30:36,315 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 34857 9.1.143.59 22
2014-07-10 22:30:36,316 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-10 22:30:36,317 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-10 22:30:36,317 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-10 22:30:36,319 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=115
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-10 22:30:36,320 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-10 22:30:36,322 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-10 22:30:36,323 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-10 22:30:36,556 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-10 22:30:36,994 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-10 22:30:37,094 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-10 22:30:37,108 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-10 22:30:37,171 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-10 22:30:37,172 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-10 22:30:37,172 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-10 22:30:37,178 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-10 22:30:37,182 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-10 22:30:37,264 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-10 22:30:37,264 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-10 22:30:37,268 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-10 22:30:37,271 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-10 22:30:37,359 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-10 22:30:37,425 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-10 22:30:37,436 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-10 22:30:37,438 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-10 22:30:37,438 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-10 22:30:37,438 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-10 22:30:37,762 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-10 22:30:37,809 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-10 22:30:37,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-10 22:30:37,810 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-10 22:30:37,811 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:30:37,843 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:30:37,851 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:30:37,855 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-10 22:30:37,871 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14723e6d7340000, negotiated timeout = 90000
2014-07-10 22:31:09,866 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x76d5b222, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:31:09,867 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x76d5b222 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:31:09,868 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:31:09,870 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-10 22:31:09,883 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x4723e6d8690004, negotiated timeout = 90000
2014-07-10 22:31:10,190 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@a46f82b
2014-07-10 22:31:10,195 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-10 22:31:10,200 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-10 22:31:10,215 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-10 22:31:10,248 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-10 22:31:10,254 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-10 22:31:10,258 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-10 22:31:10,274 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405056635404 with port=60020, startcode=1405056637193
2014-07-10 22:31:10,574 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-10 22:31:10,574 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-10 22:31:10,574 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-10 22:31:10,604 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-10 22:31:10,612 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193
2014-07-10 22:31:10,654 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-10 22:31:10,667 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 22:31:10,761 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405056670674
2014-07-10 22:31:10,782 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-10 22:31:10,786 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-10 22:31:10,790 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-10 22:31:10,794 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-10 22:31:10,797 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 22:31:10,797 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 22:31:10,797 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 22:31:10,797 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 22:31:10,797 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-10 22:31:10,807 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1405056637193, sceplus-vm48.almaden.ibm.com,60020,1405056637259] other RSs: [slave1,60020,1405056637193, sceplus-vm48.almaden.ibm.com,60020,1405056637259]
2014-07-10 22:31:10,831 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-10 22:31:10,833 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x706c8123, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 22:31:10,834 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x706c8123 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 22:31:10,835 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 22:31:10,835 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-10 22:31:10,839 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14723e6d7340001, negotiated timeout = 90000
2014-07-10 22:31:10,845 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-10 22:31:10,846 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-10 22:31:10,889 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405056637193, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x14723e6d7340000
2014-07-10 22:31:10,889 INFO  [SplitLogWorker-slave1,60020,1405056637193] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405056637193 starting
2014-07-10 22:31:10,890 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-10 22:31:10,890 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405056637193
2014-07-10 22:31:10,890 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405056637193'
2014-07-10 22:31:10,891 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-10 22:31:10,892 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-10 22:31:10,892 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-10 22:31:14,701 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-10 22:31:14,807 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:14,831 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:14,831 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193
2014-07-10 22:31:14,832 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 22:31:14,866 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405056674837.meta
2014-07-10 22:31:14,890 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-10 22:31:14,911 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-10 22:31:14,916 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-10 22:31:14,920 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-10 22:31:14,925 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-10 22:31:14,926 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-10 22:31:14,926 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-10 22:31:15,002 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:31:15,042 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-10 22:31:15,093 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/7b53de2fe5284cffbe107b450f7f9e0d, isReference=false, isBulkLoadResult=false, seqid=3832, majorCompaction=true
2014-07-10 22:31:15,112 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for e22de16c80524c23b290f993f8048aae
2014-07-10 22:31:15,112 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e22de16c80524c23b290f993f8048aae, isReference=false, isBulkLoadResult=false, seqid=3858, majorCompaction=false
2014-07-10 22:31:15,146 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-10 22:31:15,154 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=3859
2014-07-10 22:31:15,154 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-10 22:31:15,158 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-10 22:31:15,159 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1405056637193
2014-07-10 22:31:15,168 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-10 22:31:15,169 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,175 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,175 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:15,176 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1405056637193
2014-07-10 22:31:15,538 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:15,564 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:15,565 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,566 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:31:15,566 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,570 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,570 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,570 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 3ccb2cf30c2a44be7e02096daace7564, NAME => 'usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-10 22:31:15,571 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => dd9d264e19b844e86a917d3f2a0d3b85, NAME => 'usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-10 22:31:15,572 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:31:15,572 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:15,572 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:31:15,573 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:15,579 INFO  [RS_OPEN_REGION-slave1:60020-0] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-10 22:31:15,581 INFO  [RS_OPEN_REGION-slave1:60020-0] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-10 22:31:15,583 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-10 22:31:15,583 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:31:15,584 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:15,585 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,585 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:15,586 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:15,591 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,592 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-10 22:31:15,610 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:31:15,615 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:31:15,618 INFO  [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:31:15,620 INFO  [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:31:15,642 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:31:15,656 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-10 22:31:15,658 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/0a6a89d69c8b476cb6c6c2535a9fdd36, isReference=false, isBulkLoadResult=false, seqid=2148, majorCompaction=false
2014-07-10 22:31:15,663 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/2065d7553e5345db97bd314d37b4f26e, isReference=false, isBulkLoadResult=false, seqid=1429, majorCompaction=false
2014-07-10 22:31:15,685 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-10 22:31:15,689 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/49ab3bf573de4614a9b229ae63372699, isReference=false, isBulkLoadResult=false, seqid=1051, majorCompaction=false
2014-07-10 22:31:15,692 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/3730611a49584b5dad6ed3c1f6224627, isReference=false, isBulkLoadResult=false, seqid=437, majorCompaction=false
2014-07-10 22:31:15,703 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:31:15,715 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-10 22:31:15,715 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-10 22:31:15,717 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:31:15,734 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/b01b64bbb59a4e9a8f98aa9a3285a2a8, isReference=false, isBulkLoadResult=false, seqid=1940, majorCompaction=false
2014-07-10 22:31:15,738 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/5aabab464591431e80ed25bb82a89879, isReference=false, isBulkLoadResult=false, seqid=171, majorCompaction=false
2014-07-10 22:31:15,794 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/91dbb39963604984ae39fcb509a609e9, isReference=false, isBulkLoadResult=false, seqid=2149, majorCompaction=false
2014-07-10 22:31:15,795 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/cc5301d12d1e409ba769ab247dcfa238, isReference=false, isBulkLoadResult=false, seqid=1171, majorCompaction=false
2014-07-10 22:31:15,817 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/97c365d43e5145319acf8a4f475820e2, isReference=false, isBulkLoadResult=false, seqid=883, majorCompaction=false
2014-07-10 22:31:15,819 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f1210aa6c6e746d69b18a04456150082, isReference=false, isBulkLoadResult=false, seqid=882, majorCompaction=false
2014-07-10 22:31:15,840 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/9930c4a253bf4f549dc17913eeb3a3b9, isReference=false, isBulkLoadResult=false, seqid=341, majorCompaction=false
2014-07-10 22:31:15,841 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/f87bfb8755b54698aa022be4cbbeaef4, isReference=false, isBulkLoadResult=false, seqid=1485, majorCompaction=false
2014-07-10 22:31:15,855 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405056637193
2014-07-10 22:31:15,855 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-10 22:31:15,856 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,860 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,860 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:15,860 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405056637193
2014-07-10 22:31:15,860 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,861 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/cb8dd57c72df45d88bef40482d9c87c8, isReference=false, isBulkLoadResult=false, seqid=2059, majorCompaction=false
2014-07-10 22:31:15,867 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,868 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 239da979f9d39d355c125213b17fb3e3, NAME => 'usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-10 22:31:15,869 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 239da979f9d39d355c125213b17fb3e3
2014-07-10 22:31:15,869 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:15,871 DEBUG [StoreOpener-dd9d264e19b844e86a917d3f2a0d3b85-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85/family/ff94d9b48ef14ff6a448bec24da32d97, isReference=false, isBulkLoadResult=false, seqid=216, majorCompaction=false
2014-07-10 22:31:15,876 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:31:15,881 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined dd9d264e19b844e86a917d3f2a0d3b85; next sequenceid=2149
2014-07-10 22:31:15,881 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node dd9d264e19b844e86a917d3f2a0d3b85
2014-07-10 22:31:15,883 INFO  [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:31:15,884 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:15,887 DEBUG [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:15,888 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-10 22:31:15,888 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-10 22:31:15,891 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:15,891 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:15,899 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:31:15,901 DEBUG [StoreOpener-3ccb2cf30c2a44be7e02096daace7564-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564/family/f5e28d79db5743cb879e11d8610e7b6c, isReference=false, isBulkLoadResult=false, seqid=677, majorCompaction=false
2014-07-10 22:31:15,904 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:31:15,905 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] catalog.MetaEditor: Updated row usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. with server=slave1,60020,1405056637193
2014-07-10 22:31:15,905 INFO  [PostOpenDeployTasks:dd9d264e19b844e86a917d3f2a0d3b85] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:15,906 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd9d264e19b844e86a917d3f2a0d3b85 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,908 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 3ccb2cf30c2a44be7e02096daace7564; next sequenceid=2150
2014-07-10 22:31:15,908 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3ccb2cf30c2a44be7e02096daace7564
2014-07-10 22:31:15,910 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:15,911 DEBUG [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:15,911 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-10 22:31:15,912 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-10 22:31:15,912 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:15,912 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd9d264e19b844e86a917d3f2a0d3b85 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,912 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned dd9d264e19b844e86a917d3f2a0d3b85 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:15,912 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:15,912 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. on slave1,60020,1405056637193
2014-07-10 22:31:15,912 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:31:15,912 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,915 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,916 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 00f080342d6cf14f8ce3232ee199c1c6, NAME => 'usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 22:31:15,916 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:31:15,916 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:15,918 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] catalog.MetaEditor: Updated row usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. with server=slave1,60020,1405056637193
2014-07-10 22:31:15,918 INFO  [PostOpenDeployTasks:3ccb2cf30c2a44be7e02096daace7564] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:15,919 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3ccb2cf30c2a44be7e02096daace7564 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,922 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3ccb2cf30c2a44be7e02096daace7564 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:15,922 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 3ccb2cf30c2a44be7e02096daace7564 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:15,922 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. on slave1,60020,1405056637193
2014-07-10 22:31:15,922 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,923 INFO  [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:31:15,926 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:31:15,926 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 2d8a9466290952db9948506eb024ccc2, NAME => 'usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-10 22:31:15,927 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2d8a9466290952db9948506eb024ccc2
2014-07-10 22:31:15,927 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:15,927 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/04cd14cef5064ecc9c0397ab577b5a3a, isReference=false, isBulkLoadResult=false, seqid=882, majorCompaction=false
2014-07-10 22:31:15,974 INFO  [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 22:31:15,994 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/29439bc4f1e945e1bd0286668b6418ca, isReference=false, isBulkLoadResult=false, seqid=1175, majorCompaction=false
2014-07-10 22:31:15,999 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/02fd95bccb394ec0bc7be3f13bf78475, isReference=false, isBulkLoadResult=false, seqid=877, majorCompaction=false
2014-07-10 22:31:16,002 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/1e3380838b8a46d5a1946b97c3db4442, isReference=false, isBulkLoadResult=false, seqid=1850, majorCompaction=false
2014-07-10 22:31:16,012 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/5cb04665cc624a6c896122e80c88de01, isReference=false, isBulkLoadResult=false, seqid=2147, majorCompaction=false
2014-07-10 22:31:16,017 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3816cd903e3049bebf58881d49fd7289, isReference=false, isBulkLoadResult=false, seqid=342, majorCompaction=false
2014-07-10 22:31:16,020 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/7b845d04f0a842a0a4b3da745646309a, isReference=false, isBulkLoadResult=false, seqid=430, majorCompaction=false
2014-07-10 22:31:16,028 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/6d14a4dd36434a2ea9243493add61fa5, isReference=false, isBulkLoadResult=false, seqid=936, majorCompaction=false
2014-07-10 22:31:16,030 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/3c4d4eab02584596837e3842d5d2e0b4, isReference=false, isBulkLoadResult=false, seqid=2060, majorCompaction=false
2014-07-10 22:31:16,031 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/a80ac53aee744d29ba0622becf6594b2, isReference=false, isBulkLoadResult=false, seqid=1713, majorCompaction=false
2014-07-10 22:31:16,044 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/83cc027a8b0b4c5e8f94e0aeb85275fd, isReference=false, isBulkLoadResult=false, seqid=171, majorCompaction=false
2014-07-10 22:31:16,046 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/85b670b86b5c44aca1c11ef9027a592b, isReference=false, isBulkLoadResult=false, seqid=216, majorCompaction=false
2014-07-10 22:31:16,060 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/adab7229735c4995a5acabf28e296e88, isReference=false, isBulkLoadResult=false, seqid=216, majorCompaction=false
2014-07-10 22:31:16,064 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b249848ec13147408f5ece0dc5727ce0, isReference=false, isBulkLoadResult=false, seqid=1727, majorCompaction=false
2014-07-10 22:31:16,076 DEBUG [StoreOpener-239da979f9d39d355c125213b17fb3e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3/family/d8654c51c3784c5fbf6dd4205e339db7, isReference=false, isBulkLoadResult=false, seqid=2147, majorCompaction=false
2014-07-10 22:31:16,081 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/aec493a0936142d9ab911a607e18b56b, isReference=false, isBulkLoadResult=false, seqid=644, majorCompaction=false
2014-07-10 22:31:16,082 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/239da979f9d39d355c125213b17fb3e3
2014-07-10 22:31:16,084 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b35ce292a60b447b8454449950ca742a, isReference=false, isBulkLoadResult=false, seqid=2149, majorCompaction=false
2014-07-10 22:31:16,085 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 239da979f9d39d355c125213b17fb3e3; next sequenceid=2148
2014-07-10 22:31:16,085 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 239da979f9d39d355c125213b17fb3e3
2014-07-10 22:31:16,087 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:16,087 DEBUG [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:16,087 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:31:16,088 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:31:16,088 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:16,088 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:16,088 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. because compaction request was cancelled
2014-07-10 22:31:16,095 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] catalog.MetaEditor: Updated row usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. with server=slave1,60020,1405056637193
2014-07-10 22:31:16,095 INFO  [PostOpenDeployTasks:239da979f9d39d355c125213b17fb3e3] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:16,096 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 239da979f9d39d355c125213b17fb3e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,098 DEBUG [StoreOpener-2d8a9466290952db9948506eb024ccc2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2/family/d4b8b6ee40ad40969add80c0a58b86f5, isReference=false, isBulkLoadResult=false, seqid=1274, majorCompaction=false
2014-07-10 22:31:16,099 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 239da979f9d39d355c125213b17fb3e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,100 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 239da979f9d39d355c125213b17fb3e3 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:16,100 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. on slave1,60020,1405056637193
2014-07-10 22:31:16,112 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2d8a9466290952db9948506eb024ccc2
2014-07-10 22:31:16,118 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/b9d53ff93119469bb88fa4069ac277ed, isReference=false, isBulkLoadResult=false, seqid=1282, majorCompaction=false
2014-07-10 22:31:16,121 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 2d8a9466290952db9948506eb024ccc2; next sequenceid=2148
2014-07-10 22:31:16,121 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2d8a9466290952db9948506eb024ccc2
2014-07-10 22:31:16,126 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:16,127 DEBUG [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:16,127 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:31:16,127 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:31:16,127 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:16,127 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:16,128 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. because compaction request was cancelled
2014-07-10 22:31:16,135 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] catalog.MetaEditor: Updated row usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. with server=slave1,60020,1405056637193
2014-07-10 22:31:16,135 INFO  [PostOpenDeployTasks:2d8a9466290952db9948506eb024ccc2] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:16,135 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d8a9466290952db9948506eb024ccc2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,139 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d8a9466290952db9948506eb024ccc2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,139 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 2d8a9466290952db9948506eb024ccc2 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:16,139 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. on slave1,60020,1405056637193
2014-07-10 22:31:16,171 DEBUG [StoreOpener-00f080342d6cf14f8ce3232ee199c1c6-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6/family/d366a14bcd5b4b7db9e7b7c9ddf26a54, isReference=false, isBulkLoadResult=false, seqid=1043, majorCompaction=false
2014-07-10 22:31:16,174 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:31:16,176 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 00f080342d6cf14f8ce3232ee199c1c6; next sequenceid=2150
2014-07-10 22:31:16,176 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 00f080342d6cf14f8ce3232ee199c1c6
2014-07-10 22:31:16,178 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:16,178 DEBUG [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:16,179 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-10 22:31:16,179 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-10 22:31:16,179 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:16,179 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:16,179 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:31:16,188 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] catalog.MetaEditor: Updated row usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. with server=slave1,60020,1405056637193
2014-07-10 22:31:16,188 INFO  [PostOpenDeployTasks:00f080342d6cf14f8ce3232ee199c1c6] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:16,189 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 00f080342d6cf14f8ce3232ee199c1c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,193 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 00f080342d6cf14f8ce3232ee199c1c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:31:16,193 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 00f080342d6cf14f8ce3232ee199c1c6 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:31:16,193 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. on slave1,60020,1405056637193
2014-07-10 22:31:20,802 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:20,802 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-10 22:31:20,802 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-10 22:31:20,802 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 22:31:20,803 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:20,803 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:20,803 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 22:31:20,803 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. because compaction request was cancelled
2014-07-10 22:31:20,803 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:31:20,803 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-10 22:31:20,804 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-10 22:31:20,803 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:31:20,804 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:20,804 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:20,804 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. because compaction request was cancelled
2014-07-10 22:31:20,804 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. because compaction request was cancelled
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:31:20,805 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. because compaction request was cancelled
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:31:20,806 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. because compaction request was cancelled
2014-07-10 22:31:43,724 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 2d8a9466290952db9948506eb024ccc2, via zk=yes, znode version=0, on null
2014-07-10 22:31:43,725 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close dd9d264e19b844e86a917d3f2a0d3b85, via zk=yes, znode version=0, on null
2014-07-10 22:31:43,725 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 3ccb2cf30c2a44be7e02096daace7564, via zk=yes, znode version=0, on null
2014-07-10 22:31:43,725 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close 00f080342d6cf14f8ce3232ee199c1c6, via zk=yes, znode version=0, on null
2014-07-10 22:31:43,726 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close 239da979f9d39d355c125213b17fb3e3, via zk=yes, znode version=0, on null
2014-07-10 22:31:43,731 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:43,731 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:43,731 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:43,733 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.: disabling compactions & flushes
2014-07-10 22:31:43,735 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:43,736 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.: disabling compactions & flushes
2014-07-10 22:31:43,736 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:43,736 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.: disabling compactions & flushes
2014-07-10 22:31:43,738 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:43,785 INFO  [StoreCloserThread-usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.-1] regionserver.HStore: Closed family
2014-07-10 22:31:43,785 INFO  [StoreCloserThread-usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.-1] regionserver.HStore: Closed family
2014-07-10 22:31:43,786 INFO  [StoreCloserThread-usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.-1] regionserver.HStore: Closed family
2014-07-10 22:31:43,789 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:43,789 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:43,789 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,789 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,789 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:43,789 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,793 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d8a9466290952db9948506eb024ccc2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,793 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2. on slave1,60020,1405056637193
2014-07-10 22:31:43,793 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user8,1405055980943.2d8a9466290952db9948506eb024ccc2.
2014-07-10 22:31:43,794 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd9d264e19b844e86a917d3f2a0d3b85 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,794 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:43,794 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85. on slave1,60020,1405056637193
2014-07-10 22:31:43,794 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 239da979f9d39d355c125213b17fb3e3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,795 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3. on slave1,60020,1405056637193
2014-07-10 22:31:43,794 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user4,1405055980943.dd9d264e19b844e86a917d3f2a0d3b85.
2014-07-10 22:31:43,795 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user6,1405055980943.239da979f9d39d355c125213b17fb3e3.
2014-07-10 22:31:43,795 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:43,797 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.: disabling compactions & flushes
2014-07-10 22:31:43,797 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:43,797 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.: disabling compactions & flushes
2014-07-10 22:31:43,797 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:43,800 INFO  [StoreCloserThread-usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.-1] regionserver.HStore: Closed family
2014-07-10 22:31:43,801 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:43,802 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,804 INFO  [StoreCloserThread-usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.-1] regionserver.HStore: Closed family
2014-07-10 22:31:43,805 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:43,805 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,806 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3ccb2cf30c2a44be7e02096daace7564 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,806 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564. on slave1,60020,1405056637193
2014-07-10 22:31:43,806 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user1,1405055980943.3ccb2cf30c2a44be7e02096daace7564.
2014-07-10 22:31:43,814 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 00f080342d6cf14f8ce3232ee199c1c6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 22:31:43,814 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6. on slave1,60020,1405056637193
2014-07-10 22:31:43,814 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user2,1405055980943.00f080342d6cf14f8ce3232ee199c1c6.
2014-07-10 22:31:46,620 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-10 22:31:46,621 DEBUG [Priority.RpcServer.handler=7,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-10 22:31:46,622 DEBUG [Priority.RpcServer.handler=7,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-10 22:31:46,622 DEBUG [Priority.RpcServer.handler=7,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@15e45b9; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:31:46,623 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-10 22:31:46,624 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=16.1k
2014-07-10 22:31:46,627 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/7b53de2fe5284cffbe107b450f7f9e0d, keycount=71, bloomtype=NONE, size=9.1k, encoding=NONE, seqNum=3832, earliestPutTs=1402645258588
2014-07-10 22:31:46,627 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e22de16c80524c23b290f993f8048aae, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=3858, earliestPutTs=1405055643820
2014-07-10 22:31:46,637 DEBUG [regionserver60020-smallCompactions-1405056675886] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:31:46,702 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/4f8a2eef51494cafbb61c62b9b9a85b2 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/4f8a2eef51494cafbb61c62b9b9a85b2
2014-07-10 22:31:46,727 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Removing store files after compaction...
2014-07-10 22:31:46,742 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/7b53de2fe5284cffbe107b450f7f9e0d, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/7b53de2fe5284cffbe107b450f7f9e0d
2014-07-10 22:31:46,745 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e22de16c80524c23b290f993f8048aae, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/e22de16c80524c23b290f993f8048aae
2014-07-10 22:31:46,745 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 4f8a2eef51494cafbb61c62b9b9a85b2(size=9.1k), total size for store is 9.1k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-10 22:31:46,747 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=16.1k, priority=1, time=10614049062269; duration=0sec
2014-07-10 22:31:46,747 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:35:37,282 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=82, hits=77, hitRatio=93.90%, , cachingAccesses=79, cachingHits=74, cachingHitsRatio=93.67%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:36:54,321 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:36:54,334 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:36:54,335 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0afa782426206ca7b66634ebb84ca48d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,336 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:36:54,337 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 620a02e3b6f5bca4f53190d7d83a9113 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,336 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:36:54,338 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 61ae40bb3344e2f026ef21a6bb386de1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,338 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:36:54,343 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0afa782426206ca7b66634ebb84ca48d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,343 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 0afa782426206ca7b66634ebb84ca48d, NAME => 'usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 620a02e3b6f5bca4f53190d7d83a9113 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0afa782426206ca7b66634ebb84ca48d
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 61ae40bb3344e2f026ef21a6bb386de1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 620a02e3b6f5bca4f53190d7d83a9113, NAME => 'usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-10 22:36:54,344 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 61ae40bb3344e2f026ef21a6bb386de1, NAME => 'usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 22:36:54,346 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 61ae40bb3344e2f026ef21a6bb386de1
2014-07-10 22:36:54,346 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:36:54,346 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 620a02e3b6f5bca4f53190d7d83a9113
2014-07-10 22:36:54,347 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:36:54,354 INFO  [StoreOpener-0afa782426206ca7b66634ebb84ca48d-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:36:54,357 INFO  [StoreOpener-61ae40bb3344e2f026ef21a6bb386de1-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:36:54,359 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d
2014-07-10 22:36:54,360 INFO  [StoreOpener-620a02e3b6f5bca4f53190d7d83a9113-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:36:54,363 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1
2014-07-10 22:36:54,364 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 0afa782426206ca7b66634ebb84ca48d; next sequenceid=1
2014-07-10 22:36:54,364 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0afa782426206ca7b66634ebb84ca48d
2014-07-10 22:36:54,365 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113
2014-07-10 22:36:54,366 INFO  [PostOpenDeployTasks:0afa782426206ca7b66634ebb84ca48d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:36:54,368 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 61ae40bb3344e2f026ef21a6bb386de1; next sequenceid=1
2014-07-10 22:36:54,368 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 61ae40bb3344e2f026ef21a6bb386de1
2014-07-10 22:36:54,371 INFO  [PostOpenDeployTasks:61ae40bb3344e2f026ef21a6bb386de1] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:36:54,382 INFO  [PostOpenDeployTasks:0afa782426206ca7b66634ebb84ca48d] catalog.MetaEditor: Updated row usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. with server=slave1,60020,1405056637193
2014-07-10 22:36:54,382 INFO  [PostOpenDeployTasks:0afa782426206ca7b66634ebb84ca48d] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:36:54,384 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0afa782426206ca7b66634ebb84ca48d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,385 INFO  [PostOpenDeployTasks:61ae40bb3344e2f026ef21a6bb386de1] catalog.MetaEditor: Updated row usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. with server=slave1,60020,1405056637193
2014-07-10 22:36:54,386 INFO  [PostOpenDeployTasks:61ae40bb3344e2f026ef21a6bb386de1] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:36:54,387 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 61ae40bb3344e2f026ef21a6bb386de1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,405 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 620a02e3b6f5bca4f53190d7d83a9113; next sequenceid=1
2014-07-10 22:36:54,405 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 620a02e3b6f5bca4f53190d7d83a9113
2014-07-10 22:36:54,407 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0afa782426206ca7b66634ebb84ca48d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,407 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 0afa782426206ca7b66634ebb84ca48d to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:36:54,407 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. on slave1,60020,1405056637193
2014-07-10 22:36:54,407 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cdb7e3c24ac3c1e2ebe797f67da3b061 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,408 INFO  [PostOpenDeployTasks:620a02e3b6f5bca4f53190d7d83a9113] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:36:54,409 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 61ae40bb3344e2f026ef21a6bb386de1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,409 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 61ae40bb3344e2f026ef21a6bb386de1 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:36:54,409 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. on slave1,60020,1405056637193
2014-07-10 22:36:54,409 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5f0ad63c1591a52a494a87192ca35e1f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,412 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cdb7e3c24ac3c1e2ebe797f67da3b061 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,413 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => cdb7e3c24ac3c1e2ebe797f67da3b061, NAME => 'usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-10 22:36:54,413 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable cdb7e3c24ac3c1e2ebe797f67da3b061
2014-07-10 22:36:54,414 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:36:54,414 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5f0ad63c1591a52a494a87192ca35e1f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 22:36:54,414 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 5f0ad63c1591a52a494a87192ca35e1f, NAME => 'usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-10 22:36:54,415 INFO  [PostOpenDeployTasks:620a02e3b6f5bca4f53190d7d83a9113] catalog.MetaEditor: Updated row usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. with server=slave1,60020,1405056637193
2014-07-10 22:36:54,415 INFO  [PostOpenDeployTasks:620a02e3b6f5bca4f53190d7d83a9113] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:36:54,416 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 620a02e3b6f5bca4f53190d7d83a9113 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,416 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5f0ad63c1591a52a494a87192ca35e1f
2014-07-10 22:36:54,416 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:36:54,420 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 620a02e3b6f5bca4f53190d7d83a9113 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,420 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 620a02e3b6f5bca4f53190d7d83a9113 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:36:54,420 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. on slave1,60020,1405056637193
2014-07-10 22:36:54,425 INFO  [StoreOpener-cdb7e3c24ac3c1e2ebe797f67da3b061-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:36:54,427 INFO  [StoreOpener-5f0ad63c1591a52a494a87192ca35e1f-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 22:36:54,433 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061
2014-07-10 22:36:54,434 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f
2014-07-10 22:36:54,436 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined cdb7e3c24ac3c1e2ebe797f67da3b061; next sequenceid=1
2014-07-10 22:36:54,437 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node cdb7e3c24ac3c1e2ebe797f67da3b061
2014-07-10 22:36:54,437 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 5f0ad63c1591a52a494a87192ca35e1f; next sequenceid=1
2014-07-10 22:36:54,437 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5f0ad63c1591a52a494a87192ca35e1f
2014-07-10 22:36:54,439 INFO  [PostOpenDeployTasks:cdb7e3c24ac3c1e2ebe797f67da3b061] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:36:54,439 INFO  [PostOpenDeployTasks:5f0ad63c1591a52a494a87192ca35e1f] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:36:54,446 INFO  [PostOpenDeployTasks:cdb7e3c24ac3c1e2ebe797f67da3b061] catalog.MetaEditor: Updated row usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. with server=slave1,60020,1405056637193
2014-07-10 22:36:54,446 INFO  [PostOpenDeployTasks:cdb7e3c24ac3c1e2ebe797f67da3b061] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:36:54,447 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cdb7e3c24ac3c1e2ebe797f67da3b061 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,450 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cdb7e3c24ac3c1e2ebe797f67da3b061 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,450 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned cdb7e3c24ac3c1e2ebe797f67da3b061 to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:36:54,450 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. on slave1,60020,1405056637193
2014-07-10 22:36:54,486 INFO  [PostOpenDeployTasks:5f0ad63c1591a52a494a87192ca35e1f] catalog.MetaEditor: Updated row usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. with server=slave1,60020,1405056637193
2014-07-10 22:36:54,486 INFO  [PostOpenDeployTasks:5f0ad63c1591a52a494a87192ca35e1f] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:36:54,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5f0ad63c1591a52a494a87192ca35e1f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,492 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14723e6d7340000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5f0ad63c1591a52a494a87192ca35e1f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 22:36:54,492 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 5f0ad63c1591a52a494a87192ca35e1f to OPENED in zk on slave1,60020,1405056637193
2014-07-10 22:36:54,492 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. on slave1,60020,1405056637193
2014-07-10 22:37:13,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:13,219 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74 synced till here 71
2014-07-10 22:37:13,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405056670674 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057033119
2014-07-10 22:37:15,132 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:15,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 150 synced till here 148
2014-07-10 22:37:15,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057033119 with entries=76, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057035133
2014-07-10 22:37:16,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:17,005 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 273 synced till here 267
2014-07-10 22:37:17,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057035133 with entries=123, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057036965
2014-07-10 22:37:18,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:18,523 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 392 synced till here 391
2014-07-10 22:37:18,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057036965 with entries=119, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057038506
2014-07-10 22:37:24,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:24,363 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 681 synced till here 679
2014-07-10 22:37:24,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057038506 with entries=289, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057044242
2014-07-10 22:37:26,297 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:26,342 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 769 synced till here 764
2014-07-10 22:37:26,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057044242 with entries=88, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057046298
2014-07-10 22:37:28,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:28,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 854 synced till here 850
2014-07-10 22:37:28,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057046298 with entries=85, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057048442
2014-07-10 22:37:30,425 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:30,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057048442 with entries=191, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057050426
2014-07-10 22:37:36,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:36,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1369 synced till here 1364
2014-07-10 22:37:37,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057050426 with entries=324, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057056880
2014-07-10 22:37:39,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:39,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057056880 with entries=90, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057059117
2014-07-10 22:37:51,514 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:37:51,515 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 256.1m
2014-07-10 22:37:51,671 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:37:53,018 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:37:53,019 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 256.2m
2014-07-10 22:37:53,227 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:37:53,352 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:37:53,356 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:37:53,357 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:37:53,723 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:37:53,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:53,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1764 synced till here 1761
2014-07-10 22:37:54,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057059117 with entries=305, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057073932
2014-07-10 22:37:56,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:37:56,166 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057073932 with entries=71, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057076130
2014-07-10 22:38:07,476 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:38:07,478 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10096ms
GC pool 'ParNew' had collection(s): count=1 time=10528ms
2014-07-10 22:38:07,690 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11197,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076317,"queuetimems":1,"class":"HRegionServer","responsesize":15907,"method":"Multi"}
2014-07-10 22:38:07,690 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11280,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076197,"queuetimems":1,"class":"HRegionServer","responsesize":15252,"method":"Multi"}
2014-07-10 22:38:07,690 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076662,"queuetimems":1,"class":"HRegionServer","responsesize":5800,"method":"Multi"}
2014-07-10 22:38:07,691 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076809,"queuetimems":0,"class":"HRegionServer","responsesize":1799,"method":"Multi"}
2014-07-10 22:38:07,714 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10872,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076841,"queuetimems":0,"class":"HRegionServer","responsesize":5066,"method":"Multi"}
2014-07-10 22:38:07,733 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11376,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076357,"queuetimems":0,"class":"HRegionServer","responsesize":20805,"method":"Multi"}
2014-07-10 22:38:07,754 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11079,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076674,"queuetimems":1,"class":"HRegionServer","responsesize":5882,"method":"Multi"}
2014-07-10 22:38:07,873 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11219,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076654,"queuetimems":0,"class":"HRegionServer","responsesize":15442,"method":"Multi"}
2014-07-10 22:38:07,892 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076832,"queuetimems":1,"class":"HRegionServer","responsesize":11316,"method":"Multi"}
2014-07-10 22:38:07,969 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11160,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076808,"queuetimems":0,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-10 22:38:08,018 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11511,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057076507,"queuetimems":1,"class":"HRegionServer","responsesize":19852,"method":"Multi"}
2014-07-10 22:38:11,295 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:38:11,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057076130 with entries=84, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057091295
2014-07-10 22:38:14,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:38:14,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2056 synced till here 2047
2014-07-10 22:38:14,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057091295 with entries=137, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057094605
2014-07-10 22:38:14,969 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=397, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/cc40fd4c55644bf384fc107fa6f4e02f
2014-07-10 22:38:23,840 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8734ms
GC pool 'ParNew' had collection(s): count=1 time=116ms
2014-07-10 22:38:23,863 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/cc40fd4c55644bf384fc107fa6f4e02f as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/cc40fd4c55644bf384fc107fa6f4e02f
2014-07-10 22:38:23,936 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/cc40fd4c55644bf384fc107fa6f4e02f, entries=932560, sequenceid=397, filesize=66.4m
2014-07-10 22:38:23,939 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268568080, currentsize=76.0m/79678640 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 32424ms, sequenceid=397, compaction requested=false
2014-07-10 22:38:23,971 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 335.0m
2014-07-10 22:38:27,969 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094814,"queuetimems":0,"class":"HRegionServer","responsesize":164,"method":"Multi"}
2014-07-10 22:38:28,029 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094778,"queuetimems":1,"class":"HRegionServer","responsesize":1949,"method":"Multi"}
2014-07-10 22:38:28,086 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094446,"queuetimems":1,"class":"HRegionServer","responsesize":3492,"method":"Multi"}
2014-07-10 22:38:28,711 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094225,"queuetimems":5,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-10 22:38:28,734 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14357,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094376,"queuetimems":1,"class":"HRegionServer","responsesize":15794,"method":"Multi"}
2014-07-10 22:38:28,734 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094967,"queuetimems":0,"class":"HRegionServer","responsesize":1998,"method":"Multi"}
2014-07-10 22:38:28,735 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13773,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057094960,"queuetimems":1,"class":"HRegionServer","responsesize":1601,"method":"Multi"}
2014-07-10 22:38:29,328 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:38:30,563 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=417, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/bc232a8e876c4cf594365bf7925d9880
2014-07-10 22:38:30,605 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/bc232a8e876c4cf594365bf7925d9880 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/bc232a8e876c4cf594365bf7925d9880
2014-07-10 22:38:30,630 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/bc232a8e876c4cf594365bf7925d9880, entries=932780, sequenceid=417, filesize=66.5m
2014-07-10 22:38:30,631 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.2m/268632640, currentsize=88.0m/92263200 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 37613ms, sequenceid=417, compaction requested=false
2014-07-10 22:38:30,631 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 340.5m
2014-07-10 22:38:31,427 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:38:52,131 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=490, memsize=335.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/fc2da062841a4d14818e04bffc257251
2014-07-10 22:38:52,159 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/fc2da062841a4d14818e04bffc257251 as hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/fc2da062841a4d14818e04bffc257251
2014-07-10 22:38:52,177 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/fc2da062841a4d14818e04bffc257251, entries=1220650, sequenceid=490, filesize=87.0m
2014-07-10 22:38:52,177 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~335.3m/351539120, currentsize=14.1m/14788080 for region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. in 28206ms, sequenceid=490, compaction requested=false
2014-07-10 22:38:52,178 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 293.1m
2014-07-10 22:38:52,512 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:38:54,243 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=507, memsize=344.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/fe2cb07c897d46e698f3e06c900e5490
2014-07-10 22:38:54,295 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/fe2cb07c897d46e698f3e06c900e5490 as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/fe2cb07c897d46e698f3e06c900e5490
2014-07-10 22:38:54,334 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/fe2cb07c897d46e698f3e06c900e5490, entries=1253300, sequenceid=507, filesize=89.3m
2014-07-10 22:38:54,334 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~344.2m/360938320, currentsize=5.5m/5785840 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 23703ms, sequenceid=507, compaction requested=false
2014-07-10 22:39:03,201 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:04,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2287 synced till here 2284
2014-07-10 22:39:04,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057094605 with entries=231, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057143218
2014-07-10 22:39:08,918 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:08,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2586 synced till here 2584
2014-07-10 22:39:08,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057143218 with entries=299, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057148918
2014-07-10 22:39:11,138 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=134, memsize=293.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/89ead8e195fc470596ff5561486f7d89
2014-07-10 22:39:11,165 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/89ead8e195fc470596ff5561486f7d89 as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/89ead8e195fc470596ff5561486f7d89
2014-07-10 22:39:11,225 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/89ead8e195fc470596ff5561486f7d89, entries=1067220, sequenceid=134, filesize=76.0m
2014-07-10 22:39:11,226 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~293.1m/307352640, currentsize=49.4m/51798160 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 19048ms, sequenceid=134, compaction requested=false
2014-07-10 22:39:14,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:14,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2684 synced till here 2671
2014-07-10 22:39:14,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057148918 with entries=98, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057154255
2014-07-10 22:39:14,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405056670674
2014-07-10 22:39:14,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057033119
2014-07-10 22:39:14,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057035133
2014-07-10 22:39:14,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057036965
2014-07-10 22:39:14,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057038506
2014-07-10 22:39:14,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057044242
2014-07-10 22:39:14,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057046298
2014-07-10 22:39:14,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057048442
2014-07-10 22:39:14,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057050426
2014-07-10 22:39:14,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057056880
2014-07-10 22:39:19,116 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:19,263 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2770 synced till here 2763
2014-07-10 22:39:19,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057154255 with entries=86, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057159117
2014-07-10 22:39:22,370 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:22,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2856 synced till here 2842
2014-07-10 22:39:22,711 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057159117 with entries=86, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057162373
2014-07-10 22:39:25,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:25,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2977 synced till here 2956
2014-07-10 22:39:25,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057162373 with entries=121, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057165387
2014-07-10 22:39:28,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:28,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3054 synced till here 3043
2014-07-10 22:39:28,839 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:39:28,842 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 256.8m
2014-07-10 22:39:29,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057165387 with entries=77, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057168777
2014-07-10 22:39:31,797 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:39:34,808 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:39:34,809 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 262.2m
2014-07-10 22:39:36,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:36,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3169 synced till here 3149
2014-07-10 22:39:36,785 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057168777 with entries=115, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057176138
2014-07-10 22:39:36,819 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:39:37,538 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:39:39,553 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:39,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3268 synced till here 3255
2014-07-10 22:39:40,111 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057176138 with entries=99, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057179555
2014-07-10 22:39:45,409 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:39:49,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:49,371 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10034,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057179329,"queuetimems":3,"class":"HRegionServer","responsesize":23807,"method":"Multi"}
2014-07-10 22:39:49,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3389 synced till here 3375
2014-07-10 22:39:50,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057179555 with entries=121, filesize=85.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057189353
2014-07-10 22:39:51,033 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057180775,"queuetimems":0,"class":"HRegionServer","responsesize":15792,"method":"Multi"}
2014-07-10 22:39:51,156 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11264,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057179891,"queuetimems":1,"class":"HRegionServer","responsesize":25600,"method":"Multi"}
2014-07-10 22:39:51,157 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11041,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057180115,"queuetimems":0,"class":"HRegionServer","responsesize":19342,"method":"Multi"}
2014-07-10 22:39:51,157 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11617,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057179540,"queuetimems":12,"class":"HRegionServer","responsesize":19688,"method":"Multi"}
2014-07-10 22:39:51,157 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11509,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057179646,"queuetimems":1,"class":"HRegionServer","responsesize":19786,"method":"Multi"}
2014-07-10 22:39:51,351 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057181067,"queuetimems":3,"class":"HRegionServer","responsesize":26360,"method":"Multi"}
2014-07-10 22:39:51,362 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057180654,"queuetimems":0,"class":"HRegionServer","responsesize":19579,"method":"Multi"}
2014-07-10 22:39:51,572 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:39:51,980 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057181841,"queuetimems":1,"class":"HRegionServer","responsesize":15806,"method":"Multi"}
2014-07-10 22:39:52,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:52,185 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3477 synced till here 3475
2014-07-10 22:39:52,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057189353 with entries=88, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057192158
2014-07-10 22:39:55,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:39:55,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3546 synced till here 3535
2014-07-10 22:39:56,356 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057192158 with entries=69, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057195867
2014-07-10 22:39:58,786 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=692, memsize=264.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/f4af622000614efeacc8c07c1a3a806d
2014-07-10 22:39:58,837 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/f4af622000614efeacc8c07c1a3a806d as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/f4af622000614efeacc8c07c1a3a806d
2014-07-10 22:39:58,858 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/f4af622000614efeacc8c07c1a3a806d, entries=961990, sequenceid=692, filesize=68.6m
2014-07-10 22:39:58,859 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.2m/277044720, currentsize=137.2m/143866080 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 30017ms, sequenceid=692, compaction requested=false
2014-07-10 22:39:58,859 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 370.5m
2014-07-10 22:40:00,753 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:40:01,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:01,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3634 synced till here 3613
2014-07-10 22:40:02,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057195867 with entries=88, filesize=83.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057201413
2014-07-10 22:40:03,468 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=683, memsize=265.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/638df501fda047f189bac9e3249e7eef
2014-07-10 22:40:03,488 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/638df501fda047f189bac9e3249e7eef as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/638df501fda047f189bac9e3249e7eef
2014-07-10 22:40:03,585 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/638df501fda047f189bac9e3249e7eef, entries=967540, sequenceid=683, filesize=69.0m
2014-07-10 22:40:03,585 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.7m/278643360, currentsize=151.6m/158928560 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 28777ms, sequenceid=683, compaction requested=false
2014-07-10 22:40:03,585 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 360.0m
2014-07-10 22:40:04,472 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:40:05,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:05,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3715 synced till here 3705
2014-07-10 22:40:06,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057201413 with entries=81, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057205723
2014-07-10 22:40:06,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057059117
2014-07-10 22:40:06,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057073932
2014-07-10 22:40:06,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057076130
2014-07-10 22:40:06,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057091295
2014-07-10 22:40:10,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:10,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3794 synced till here 3786
2014-07-10 22:40:11,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057205723 with entries=79, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057210652
2014-07-10 22:40:13,180 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:13,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3862 synced till here 3854
2014-07-10 22:40:13,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057210652 with entries=68, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057213180
2014-07-10 22:40:14,901 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:40:15,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:15,539 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:40:15,847 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3933 synced till here 3930
2014-07-10 22:40:16,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057213180 with entries=71, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057215474
2014-07-10 22:40:18,461 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:18,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4012 synced till here 4007
2014-07-10 22:40:18,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057215474 with entries=79, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057218461
2014-07-10 22:40:24,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:24,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4111 synced till here 4107
2014-07-10 22:40:24,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057218461 with entries=99, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057224369
2014-07-10 22:40:27,245 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:27,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4199 synced till here 4195
2014-07-10 22:40:27,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057224369 with entries=88, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057227245
2014-07-10 22:40:30,758 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:30,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4276 synced till here 4272
2014-07-10 22:40:31,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057227245 with entries=77, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057230759
2014-07-10 22:40:34,060 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:34,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4346 synced till here 4344
2014-07-10 22:40:35,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057230759 with entries=70, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057234060
2014-07-10 22:40:37,305 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=748, hits=741, hitRatio=99.06%, , cachingAccesses=745, cachingHits=738, cachingHitsRatio=99.06%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:40:40,120 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=573, memsize=383.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/e97af0fc6ce54ed493168fde9379f59d
2014-07-10 22:40:40,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:40,205 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/e97af0fc6ce54ed493168fde9379f59d as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/e97af0fc6ce54ed493168fde9379f59d
2014-07-10 22:40:40,235 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/e97af0fc6ce54ed493168fde9379f59d, entries=1397590, sequenceid=573, filesize=99.6m
2014-07-10 22:40:40,235 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~383.8m/402493360, currentsize=263.5m/276258160 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 41376ms, sequenceid=573, compaction requested=false
2014-07-10 22:40:40,236 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 587.1m
2014-07-10 22:40:40,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4438 synced till here 4422
2014-07-10 22:40:40,519 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:40:40,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057234060 with entries=92, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057240210
2014-07-10 22:40:41,711 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:40:42,836 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=778, memsize=361.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/1e96b34627084147b4cbac70e7bcd662
2014-07-10 22:40:42,854 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/1e96b34627084147b4cbac70e7bcd662 as hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/1e96b34627084147b4cbac70e7bcd662
2014-07-10 22:40:43,192 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/1e96b34627084147b4cbac70e7bcd662, entries=1314250, sequenceid=778, filesize=93.6m
2014-07-10 22:40:43,193 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~361.0m/378494320, currentsize=261.4m/274057680 for region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. in 39608ms, sequenceid=778, compaction requested=false
2014-07-10 22:40:43,193 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 431.1m
2014-07-10 22:40:43,272 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:40:44,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:44,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4540 synced till here 4531
2014-07-10 22:40:45,038 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057240210 with entries=102, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057244462
2014-07-10 22:40:45,417 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:40:46,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:47,116 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4623 synced till here 4613
2014-07-10 22:40:47,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057244462 with entries=83, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057246961
2014-07-10 22:40:51,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:51,627 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4702 synced till here 4684
2014-07-10 22:40:54,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057246961 with entries=79, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057251189
2014-07-10 22:40:57,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:40:57,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4789 synced till here 4773
2014-07-10 22:40:58,588 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057251189 with entries=87, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057257730
2014-07-10 22:41:01,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:01,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4921 synced till here 4916
2014-07-10 22:41:01,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057257730 with entries=132, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057261196
2014-07-10 22:41:05,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:05,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4989 synced till here 4977
2014-07-10 22:41:06,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057261196 with entries=68, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057265716
2014-07-10 22:41:09,788 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:10,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5107 synced till here 5073
2014-07-10 22:41:10,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057265716 with entries=118, filesize=91.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057269788
2014-07-10 22:41:13,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:13,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5250 synced till here 5208
2014-07-10 22:41:14,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057269788 with entries=143, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057273368
2014-07-10 22:41:17,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:17,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5337 synced till here 5313
2014-07-10 22:41:18,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057273368 with entries=87, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057277037
2014-07-10 22:41:20,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:20,317 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5430 synced till here 5418
2014-07-10 22:41:20,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057277037 with entries=93, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057280281
2014-07-10 22:41:22,765 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:22,786 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5523 synced till here 5518
2014-07-10 22:41:22,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057280281 with entries=93, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057282765
2014-07-10 22:41:40,221 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14879ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=15351ms
2014-07-10 22:41:40,222 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 24925ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:41:40,222 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 24926ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:41:40,223 WARN  [regionserver60020] util.Sleeper: We slept 18158ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 22:41:40,253 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284540,"queuetimems":1,"class":"HRegionServer","responsesize":243,"method":"Multi"}
2014-07-10 22:41:40,263 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057283177,"queuetimems":0,"class":"HRegionServer","responsesize":25902,"method":"Multi"}
2014-07-10 22:41:40,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:40,432 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284557,"queuetimems":0,"class":"HRegionServer","responsesize":3734,"method":"Multi"}
2014-07-10 22:41:40,432 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15892,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284539,"queuetimems":0,"class":"HRegionServer","responsesize":4018,"method":"Multi"}
2014-07-10 22:41:40,433 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15676,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284757,"queuetimems":199,"class":"HRegionServer","responsesize":56,"method":"Multi"}
2014-07-10 22:41:40,433 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284558,"queuetimems":1,"class":"HRegionServer","responsesize":44,"method":"Multi"}
2014-07-10 22:41:40,440 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15887,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284550,"queuetimems":0,"class":"HRegionServer","responsesize":3995,"method":"Multi"}
2014-07-10 22:41:40,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5607 synced till here 5589
2014-07-10 22:41:40,472 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16910,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057283562,"queuetimems":1,"class":"HRegionServer","responsesize":25785,"method":"Multi"}
2014-07-10 22:41:40,522 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16899,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057283622,"queuetimems":1,"class":"HRegionServer","responsesize":25994,"method":"Multi"}
2014-07-10 22:41:40,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057282765 with entries=84, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057300418
2014-07-10 22:41:40,533 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057283799,"queuetimems":1,"class":"HRegionServer","responsesize":25912,"method":"Multi"}
2014-07-10 22:41:40,769 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057283978,"queuetimems":0,"class":"HRegionServer","responsesize":25301,"method":"Multi"}
2014-07-10 22:41:40,769 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16752,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284016,"queuetimems":0,"class":"HRegionServer","responsesize":19791,"method":"Multi"}
2014-07-10 22:41:40,896 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16697,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284198,"queuetimems":0,"class":"HRegionServer","responsesize":25291,"method":"Multi"}
2014-07-10 22:41:41,258 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284533,"queuetimems":0,"class":"HRegionServer","responsesize":26005,"method":"Multi"}
2014-07-10 22:41:41,258 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057284808,"queuetimems":0,"class":"HRegionServer","responsesize":19660,"method":"Multi"}
2014-07-10 22:41:42,431 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:42,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5667 synced till here 5665
2014-07-10 22:41:43,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057300418 with entries=60, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057302441
2014-07-10 22:41:43,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:43,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5746 synced till here 5740
2014-07-10 22:41:43,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057302441 with entries=79, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057303833
2014-07-10 22:41:46,080 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=942, memsize=438.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/8faf1afda3e543b4bad0117188455e6b
2014-07-10 22:41:46,097 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/8faf1afda3e543b4bad0117188455e6b as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/8faf1afda3e543b4bad0117188455e6b
2014-07-10 22:41:46,113 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/8faf1afda3e543b4bad0117188455e6b, entries=1597170, sequenceid=942, filesize=113.7m
2014-07-10 22:41:46,113 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~438.7m/459973360, currentsize=388.6m/407511440 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 62920ms, sequenceid=942, compaction requested=true
2014-07-10 22:41:46,116 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 22:41:46,116 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:41:46,116 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 815.9m
2014-07-10 22:41:46,117 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 260871901 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-10 22:41:46,117 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: 61ae40bb3344e2f026ef21a6bb386de1 - family: Initiating major compaction
2014-07-10 22:41:46,117 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:41:46,118 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp, totalSize=248.8m
2014-07-10 22:41:46,118 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/bc232a8e876c4cf594365bf7925d9880, keycount=93278, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=417, earliestPutTs=1405057031488
2014-07-10 22:41:46,118 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/f4af622000614efeacc8c07c1a3a806d, keycount=96199, bloomtype=ROW, size=68.6m, encoding=NONE, seqNum=692, earliestPutTs=1405057073230
2014-07-10 22:41:46,118 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/8faf1afda3e543b4bad0117188455e6b, keycount=159717, bloomtype=ROW, size=113.7m, encoding=NONE, seqNum=942, earliestPutTs=1405057169135
2014-07-10 22:41:46,120 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:46,121 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:41:46,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5822 synced till here 5819
2014-07-10 22:41:46,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057303833 with entries=76, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057306120
2014-07-10 22:41:46,239 DEBUG [regionserver60020-smallCompactions-1405056675886] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:41:46,835 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:41:46,839 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:41:46,839 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-10 22:41:48,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:48,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5908 synced till here 5905
2014-07-10 22:41:48,258 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057306120 with entries=86, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057308136
2014-07-10 22:41:49,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:49,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5979 synced till here 5974
2014-07-10 22:41:49,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057308136 with entries=71, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057309707
2014-07-10 22:41:50,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:50,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6043 synced till here 6041
2014-07-10 22:41:51,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057309707 with entries=64, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057310942
2014-07-10 22:41:51,164 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=923, memsize=587.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/b585e5e894b8474d85f1011fe22d998b
2014-07-10 22:41:51,179 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/b585e5e894b8474d85f1011fe22d998b as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/b585e5e894b8474d85f1011fe22d998b
2014-07-10 22:41:51,202 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/b585e5e894b8474d85f1011fe22d998b, entries=2137570, sequenceid=923, filesize=152.3m
2014-07-10 22:41:51,202 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~587.1m/615604240, currentsize=490.1m/513926960 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 70966ms, sequenceid=923, compaction requested=false
2014-07-10 22:41:51,203 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 768.3m
2014-07-10 22:41:51,865 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:41:52,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:52,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057310942 with entries=57, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057312326
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057094605
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057143218
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057148918
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057154255
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057159117
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057162373
2014-07-10 22:41:52,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057165387
2014-07-10 22:41:52,399 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:41:53,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:54,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6218 synced till here 6211
2014-07-10 22:41:54,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057312326 with entries=118, filesize=103.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057313666
2014-07-10 22:41:55,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:55,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057313666 with entries=61, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057315818
2014-07-10 22:41:57,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:41:57,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6350 synced till here 6337
2014-07-10 22:41:58,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057315818 with entries=71, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057317360
2014-07-10 22:42:00,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:00,546 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,546 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,554 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,556 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,556 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,559 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,560 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,582 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,645 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,665 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,669 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,670 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,670 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,670 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,671 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,672 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,672 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,675 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,777 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,836 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,838 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,868 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,875 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057317360 with entries=106, filesize=110.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057320176
2014-07-10 22:42:00,904 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,947 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:00,972 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,056 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,057 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,070 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,075 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,076 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,108 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,300 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:01,936 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,005 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,008 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,010 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,044 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,054 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,056 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,059 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,059 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,715 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:03,783 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,199 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,205 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,220 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,354 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,366 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,373 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:04,374 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:05,547 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,550 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-10 22:42:05,555 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,556 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,556 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,559 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,560 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,583 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,645 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,665 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,670 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,670 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,670 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,671 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,671 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,672 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,672 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,675 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,777 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,836 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,838 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,869 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:05,905 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,947 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:05,972 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:06,057 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:06,057 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:06,070 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:06,075 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:06,077 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:06,108 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:06,300 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:06,936 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:08,006 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,009 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,011 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:08,044 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,055 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:08,056 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,059 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,060 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,716 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:08,784 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,199 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,206 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,220 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,354 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,366 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,373 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:09,374 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:10,547 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,550 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-10 22:42:10,555 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,556 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,557 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,560 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,561 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,583 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,645 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,666 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 22:42:10,670 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,671 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,671 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,671 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,671 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,673 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,673 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,676 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,778 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,837 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,839 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:10,869 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,905 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,948 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:10,972 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:11,057 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:11,058 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 22:42:11,071 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:11,075 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:11,077 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:11,108 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:11,300 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:11,936 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,006 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,009 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,011 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,045 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:13,055 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,057 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:13,059 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:13,060 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,716 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:13,784 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:14,200 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:14,206 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:14,221 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:14,354 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:14,367 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 22:42:14,374 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:14,375 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 22:42:15,547 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,551 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15005ms
2014-07-10 22:42:15,556 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:15,557 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:15,557 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,560 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,561 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,583 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,646 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,666 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:15,671 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:15,671 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,671 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,672 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:15,673 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,673 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,674 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,676 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,778 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,837 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,839 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,869 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,905 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,948 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:15,972 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,057 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,058 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:16,071 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,076 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,077 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,109 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,301 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:16,937 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:18,006 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,009 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,012 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:18,045 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,056 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 22:42:18,057 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,060 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,060 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 22:42:18,517 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1111, memsize=823.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/16b6f4356e35446985f2f86b8ab81c8f
2014-07-10 22:42:18,535 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/16b6f4356e35446985f2f86b8ab81c8f as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/16b6f4356e35446985f2f86b8ab81c8f
2014-07-10 22:42:18,550 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/16b6f4356e35446985f2f86b8ab81c8f, entries=2998900, sequenceid=1111, filesize=213.5m
2014-07-10 22:42:18,550 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~823.7m/863661360, currentsize=212.5m/222772960 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 32434ms, sequenceid=1111, compaction requested=true
2014-07-10 22:42:18,551 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 22:42:18,551 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15492ms
2014-07-10 22:42:18,551 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,551 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 891.9m
2014-07-10 22:42:18,551 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15492ms
2014-07-10 22:42:18,551 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,552 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15496ms
2014-07-10 22:42:18,552 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,552 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15498ms
2014-07-10 22:42:18,552 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,563 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15519ms
2014-07-10 22:42:18,563 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,570 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15560ms
2014-07-10 22:42:18,570 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,570 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15562ms
2014-07-10 22:42:18,570 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,570 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15565ms
2014-07-10 22:42:18,570 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,578 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323059,"queuetimems":1,"class":"HRegionServer","responsesize":648,"method":"Multi"}
2014-07-10 22:42:18,579 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16644ms
2014-07-10 22:42:18,579 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,585 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17285ms
2014-07-10 22:42:18,585 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,585 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17477ms
2014-07-10 22:42:18,585 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,586 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17510ms
2014-07-10 22:42:18,586 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,586 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17511ms
2014-07-10 22:42:18,586 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,586 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17516ms
2014-07-10 22:42:18,586 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,597 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17541ms
2014-07-10 22:42:18,597 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,597 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17541ms
2014-07-10 22:42:18,597 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,597 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17626ms
2014-07-10 22:42:18,597 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,598 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323055,"queuetimems":0,"class":"HRegionServer","responsesize":1423,"method":"Multi"}
2014-07-10 22:42:18,598 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15539,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323058,"queuetimems":0,"class":"HRegionServer","responsesize":1622,"method":"Multi"}
2014-07-10 22:42:18,598 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17651ms
2014-07-10 22:42:18,599 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,603 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17699ms
2014-07-10 22:42:18,603 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,603 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17735ms
2014-07-10 22:42:18,604 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,607 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17769ms
2014-07-10 22:42:18,607 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,609 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17773ms
2014-07-10 22:42:18,609 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,609 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17832ms
2014-07-10 22:42:18,609 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,609 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17934ms
2014-07-10 22:42:18,609 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,610 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17937ms
2014-07-10 22:42:18,610 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,610 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17938ms
2014-07-10 22:42:18,610 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,610 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17939ms
2014-07-10 22:42:18,610 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,613 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17943ms
2014-07-10 22:42:18,613 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,613 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17943ms
2014-07-10 22:42:18,613 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,613 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17943ms
2014-07-10 22:42:18,613 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,617 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17948ms
2014-07-10 22:42:18,617 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,617 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17953ms
2014-07-10 22:42:18,617 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,617 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17972ms
2014-07-10 22:42:18,617 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,623 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18041ms
2014-07-10 22:42:18,623 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,623 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18063ms
2014-07-10 22:42:18,623 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,623 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18064ms
2014-07-10 22:42:18,624 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,629 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18073ms
2014-07-10 22:42:18,629 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,629 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18074ms
2014-07-10 22:42:18,629 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,629 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18075ms
2014-07-10 22:42:18,630 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,633 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18087ms
2014-07-10 22:42:18,633 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,633 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18087ms
2014-07-10 22:42:18,633 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,633 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14259ms
2014-07-10 22:42:18,633 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,641 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14268ms
2014-07-10 22:42:18,641 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,641 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14275ms
2014-07-10 22:42:18,641 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,647 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14293ms
2014-07-10 22:42:18,647 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,648 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14427ms
2014-07-10 22:42:18,648 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,648 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14443ms
2014-07-10 22:42:18,648 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,649 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14450ms
2014-07-10 22:42:18,649 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,649 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14866ms
2014-07-10 22:42:18,649 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,650 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14935ms
2014-07-10 22:42:18,650 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:18,708 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323043,"queuetimems":1,"class":"HRegionServer","responsesize":1516,"method":"Multi"}
2014-07-10 22:42:18,709 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323052,"queuetimems":0,"class":"HRegionServer","responsesize":4543,"method":"Multi"}
2014-07-10 22:42:18,818 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323008,"queuetimems":0,"class":"HRegionServer","responsesize":3990,"method":"Multi"}
2014-07-10 22:42:18,923 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15916,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323006,"queuetimems":0,"class":"HRegionServer","responsesize":3935,"method":"Multi"}
2014-07-10 22:42:18,923 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16990,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321933,"queuetimems":1,"class":"HRegionServer","responsesize":4069,"method":"Multi"}
2014-07-10 22:42:18,930 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321073,"queuetimems":1,"class":"HRegionServer","responsesize":3970,"method":"Multi"}
2014-07-10 22:42:18,933 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323003,"queuetimems":0,"class":"HRegionServer","responsesize":4100,"method":"Multi"}
2014-07-10 22:42:18,933 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321075,"queuetimems":0,"class":"HRegionServer","responsesize":1638,"method":"Multi"}
2014-07-10 22:42:18,933 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17868,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321065,"queuetimems":2,"class":"HRegionServer","responsesize":4060,"method":"Multi"}
2014-07-10 22:42:19,278 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20705,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057318572,"queuetimems":0,"class":"HRegionServer","responsesize":25223,"method":"Multi"}
2014-07-10 22:42:19,278 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18506,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320772,"queuetimems":0,"class":"HRegionServer","responsesize":5525,"method":"Multi"}
2014-07-10 22:42:19,279 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17983,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321295,"queuetimems":0,"class":"HRegionServer","responsesize":6391,"method":"Multi"}
2014-07-10 22:42:19,278 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18311,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320967,"queuetimems":0,"class":"HRegionServer","responsesize":6281,"method":"Multi"}
2014-07-10 22:42:19,279 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057318479,"queuetimems":0,"class":"HRegionServer","responsesize":17775,"method":"Multi"}
2014-07-10 22:42:19,280 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14915,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324365,"queuetimems":0,"class":"HRegionServer","responsesize":596,"method":"Multi"}
2014-07-10 22:42:19,278 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320864,"queuetimems":0,"class":"HRegionServer","responsesize":4078,"method":"Multi"}
2014-07-10 22:42:19,285 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320578,"queuetimems":0,"class":"HRegionServer","responsesize":4099,"method":"Multi"}
2014-07-10 22:42:19,287 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321055,"queuetimems":1,"class":"HRegionServer","responsesize":1691,"method":"Multi"}
2014-07-10 22:42:19,293 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324371,"queuetimems":1,"class":"HRegionServer","responsesize":1643,"method":"Multi"}
2014-07-10 22:42:19,297 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320553,"queuetimems":0,"class":"HRegionServer","responsesize":1522,"method":"Multi"}
2014-07-10 22:42:19,301 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18466,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320835,"queuetimems":1,"class":"HRegionServer","responsesize":1509,"method":"Multi"}
2014-07-10 22:42:19,478 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20653,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057318824,"queuetimems":0,"class":"HRegionServer","responsesize":24527,"method":"Multi"}
2014-07-10 22:42:19,479 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15113,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324365,"queuetimems":1,"class":"HRegionServer","responsesize":5999,"method":"Multi"}
2014-07-10 22:42:19,494 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324344,"queuetimems":0,"class":"HRegionServer","responsesize":6880,"method":"Multi"}
2014-07-10 22:42:19,517 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324204,"queuetimems":1,"class":"HRegionServer","responsesize":1772,"method":"Multi"}
2014-07-10 22:42:19,494 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19661,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319832,"queuetimems":715,"class":"HRegionServer","responsesize":24284,"method":"Multi"}
2014-07-10 22:42:19,518 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323781,"queuetimems":0,"class":"HRegionServer","responsesize":4378,"method":"Multi"}
2014-07-10 22:42:19,518 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324218,"queuetimems":1,"class":"HRegionServer","responsesize":3762,"method":"Multi"}
2014-07-10 22:42:19,517 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15803,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057323714,"queuetimems":1,"class":"HRegionServer","responsesize":1671,"method":"Multi"}
2014-07-10 22:42:19,517 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057324198,"queuetimems":0,"class":"HRegionServer","responsesize":208,"method":"Multi"}
2014-07-10 22:42:19,574 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1460, memsize=770.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/15cccd0002de40969d00f966a31d64ee
2014-07-10 22:42:19,619 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new decompressor
2014-07-10 22:42:19,631 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/15cccd0002de40969d00f966a31d64ee as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/15cccd0002de40969d00f966a31d64ee
2014-07-10 22:42:19,634 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:19,636 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:42:19,660 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/15cccd0002de40969d00f966a31d64ee, entries=2804540, sequenceid=1460, filesize=199.8m
2014-07-10 22:42:19,660 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~770.3m/807682960, currentsize=184.5m/193431600 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 28457ms, sequenceid=1460, compaction requested=true
2014-07-10 22:42:19,660 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 22:42:19,661 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 640.3m
2014-07-10 22:42:19,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6571 synced till here 6546
2014-07-10 22:42:19,782 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19814,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319968,"queuetimems":0,"class":"HRegionServer","responsesize":25281,"method":"Multi"}
2014-07-10 22:42:19,784 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319881,"queuetimems":0,"class":"HRegionServer","responsesize":19175,"method":"Multi"}
2014-07-10 22:42:19,784 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19866,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319918,"queuetimems":0,"class":"HRegionServer","responsesize":19217,"method":"Multi"}
2014-07-10 22:42:19,834 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19801,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320033,"queuetimems":0,"class":"HRegionServer","responsesize":24699,"method":"Multi"}
2014-07-10 22:42:19,836 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20928,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057318907,"queuetimems":0,"class":"HRegionServer","responsesize":21958,"method":"Multi"}
2014-07-10 22:42:19,834 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19986,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319848,"queuetimems":1,"class":"HRegionServer","responsesize":24154,"method":"Multi"}
2014-07-10 22:42:19,837 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057318977,"queuetimems":0,"class":"HRegionServer","responsesize":25089,"method":"Multi"}
2014-07-10 22:42:19,837 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20807,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057319030,"queuetimems":1,"class":"HRegionServer","responsesize":25325,"method":"Multi"}
2014-07-10 22:42:19,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057320176 with entries=115, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057339635
2014-07-10 22:42:19,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057168777
2014-07-10 22:42:19,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057176138
2014-07-10 22:42:19,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057179555
2014-07-10 22:42:19,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057189353
2014-07-10 22:42:19,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057192158
2014-07-10 22:42:19,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057195867
2014-07-10 22:42:20,097 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:42:20,154 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321106,"queuetimems":0,"class":"HRegionServer","responsesize":14493,"method":"Multi"}
2014-07-10 22:42:20,154 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19986,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320167,"queuetimems":0,"class":"HRegionServer","responsesize":25418,"method":"Multi"}
2014-07-10 22:42:20,156 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320946,"queuetimems":1,"class":"HRegionServer","responsesize":14237,"method":"Multi"}
2014-07-10 22:42:20,157 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19881,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320275,"queuetimems":0,"class":"HRegionServer","responsesize":24013,"method":"Multi"}
2014-07-10 22:42:20,156 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320902,"queuetimems":1,"class":"HRegionServer","responsesize":13165,"method":"Multi"}
2014-07-10 22:42:20,155 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19106,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057321049,"queuetimems":0,"class":"HRegionServer","responsesize":24599,"method":"Multi"}
2014-07-10 22:42:20,155 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20057,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320098,"queuetimems":0,"class":"HRegionServer","responsesize":24716,"method":"Multi"}
2014-07-10 22:42:20,155 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320642,"queuetimems":1,"class":"HRegionServer","responsesize":15472,"method":"Multi"}
2014-07-10 22:42:21,010 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:42:21,011 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20177,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44579","starttimems":1405057320833,"queuetimems":2,"class":"HRegionServer","responsesize":24542,"method":"Multi"}
2014-07-10 22:42:21,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:21,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6645 synced till here 6639
2014-07-10 22:42:21,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057339635 with entries=74, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057341239
2014-07-10 22:42:23,123 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:23,150 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6702 synced till here 6699
2014-07-10 22:42:23,195 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057341239 with entries=57, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057343123
2014-07-10 22:42:24,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:24,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6758 synced till here 6756
2014-07-10 22:42:24,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057343123 with entries=56, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057344416
2014-07-10 22:42:25,677 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:25,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6835 synced till here 6833
2014-07-10 22:42:26,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057344416 with entries=77, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057345677
2014-07-10 22:42:26,417 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:42:27,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:27,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6915 synced till here 6902
2014-07-10 22:42:27,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057345677 with entries=80, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057347717
2014-07-10 22:42:29,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:29,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6987 synced till here 6985
2014-07-10 22:42:29,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057347717 with entries=72, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057349004
2014-07-10 22:42:30,269 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:30,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057349004 with entries=63, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057350270
2014-07-10 22:42:31,487 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:31,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7119 synced till here 7117
2014-07-10 22:42:31,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057350270 with entries=69, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057351487
2014-07-10 22:42:31,800 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/360ac47753ed4053ba662ff2ae4bba06 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/360ac47753ed4053ba662ff2ae4bba06
2014-07-10 22:42:31,883 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Removing store files after compaction...
2014-07-10 22:42:31,962 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/bc232a8e876c4cf594365bf7925d9880, to hdfs://master:54310/hbase/archive/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/bc232a8e876c4cf594365bf7925d9880
2014-07-10 22:42:31,969 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/f4af622000614efeacc8c07c1a3a806d, to hdfs://master:54310/hbase/archive/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/f4af622000614efeacc8c07c1a3a806d
2014-07-10 22:42:31,980 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/8faf1afda3e543b4bad0117188455e6b, to hdfs://master:54310/hbase/archive/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/8faf1afda3e543b4bad0117188455e6b
2014-07-10 22:42:31,981 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. into 360ac47753ed4053ba662ff2ae4bba06(size=248.7m), total size for store is 248.7m. This selection was in queue for 0sec, and took 45sec to execute.
2014-07-10 22:42:31,981 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., storeName=family, fileCount=3, fileSize=248.8m, priority=17, time=11213544176248; duration=45sec
2014-07-10 22:42:31,981 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 22:42:31,981 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:42:31,981 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-10 22:42:31,981 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 22:42:31,981 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Not compacting usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. because compaction request was cancelled
2014-07-10 22:42:31,982 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 22:42:31,982 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 393643492 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-10 22:42:31,982 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: 620a02e3b6f5bca4f53190d7d83a9113 - family: Initiating major compaction
2014-07-10 22:42:31,982 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:42:31,982 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp, totalSize=375.4m
2014-07-10 22:42:31,982 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/89ead8e195fc470596ff5561486f7d89, keycount=106722, bloomtype=ROW, size=76.0m, encoding=NONE, seqNum=134, earliestPutTs=1405057032457
2014-07-10 22:42:31,983 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/e97af0fc6ce54ed493168fde9379f59d, keycount=139759, bloomtype=ROW, size=99.6m, encoding=NONE, seqNum=573, earliestPutTs=1405057141919
2014-07-10 22:42:31,983 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/15cccd0002de40969d00f966a31d64ee, keycount=280454, bloomtype=ROW, size=199.8m, encoding=NONE, seqNum=1460, earliestPutTs=1405057199257
2014-07-10 22:42:32,048 DEBUG [regionserver60020-smallCompactions-1405056675886] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:42:33,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:33,479 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7203 synced till here 7199
2014-07-10 22:42:33,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057351487 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057353432
2014-07-10 22:42:35,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:35,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7283 synced till here 7279
2014-07-10 22:42:35,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057353432 with entries=80, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057355078
2014-07-10 22:42:37,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:37,642 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,643 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,643 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,647 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,685 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,687 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,710 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,733 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,741 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,760 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,813 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,834 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,897 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,925 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:37,974 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:38,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057355078 with entries=137, filesize=112.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057357088
2014-07-10 22:42:39,710 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:42,062 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:42,644 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:42,644 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:42,644 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-10 22:42:42,647 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,685 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,687 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,710 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,734 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:42,742 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,760 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,814 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,835 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:42,897 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:42,926 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:42,975 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:42:44,253 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,276 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,302 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,328 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,457 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,464 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,485 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,506 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,557 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,629 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,710 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:42:44,807 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,816 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:44,957 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:45,009 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:45,532 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:45,623 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1244, memsize=640.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/4fb70e75a4844cf2a490552af59fd818
2014-07-10 22:42:45,634 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:45,645 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/4fb70e75a4844cf2a490552af59fd818 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/4fb70e75a4844cf2a490552af59fd818
2014-07-10 22:42:45,656 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:42:45,667 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/4fb70e75a4844cf2a490552af59fd818, entries=2331380, sequenceid=1244, filesize=165.9m
2014-07-10 22:42:45,667 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~640.3m/671417680, currentsize=292.6m/306812560 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 26007ms, sequenceid=1244, compaction requested=false
2014-07-10 22:42:45,668 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12ms
2014-07-10 22:42:45,668 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,668 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34ms
2014-07-10 22:42:45,668 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 961.6m
2014-07-10 22:42:45,668 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,668 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 136ms
2014-07-10 22:42:45,668 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,668 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 659ms
2014-07-10 22:42:45,669 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,669 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 713ms
2014-07-10 22:42:45,669 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,670 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 853ms
2014-07-10 22:42:45,670 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,670 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 863ms
2014-07-10 22:42:45,671 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,672 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-10 22:42:45,672 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,673 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1043ms
2014-07-10 22:42:45,673 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,674 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1117ms
2014-07-10 22:42:45,675 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,676 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1169ms
2014-07-10 22:42:45,676 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,681 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1196ms
2014-07-10 22:42:45,682 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,683 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1218ms
2014-07-10 22:42:45,683 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,684 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1226ms
2014-07-10 22:42:45,684 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,685 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1356ms
2014-07-10 22:42:45,685 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,694 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1391ms
2014-07-10 22:42:45,694 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,694 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1418ms
2014-07-10 22:42:45,694 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,695 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1443ms
2014-07-10 22:42:45,695 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,695 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7721ms
2014-07-10 22:42:45,695 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,696 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7770ms
2014-07-10 22:42:45,696 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,697 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7801ms
2014-07-10 22:42:45,697 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,705 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7871ms
2014-07-10 22:42:45,705 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,705 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7892ms
2014-07-10 22:42:45,705 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,706 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7945ms
2014-07-10 22:42:45,706 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,706 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7965ms
2014-07-10 22:42:45,707 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,707 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7974ms
2014-07-10 22:42:45,707 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,707 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7997ms
2014-07-10 22:42:45,707 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,709 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8022ms
2014-07-10 22:42:45,709 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,713 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8028ms
2014-07-10 22:42:45,713 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,714 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8066ms
2014-07-10 22:42:45,714 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,715 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8072ms
2014-07-10 22:42:45,715 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,716 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8072ms
2014-07-10 22:42:45,716 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,725 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8082ms
2014-07-10 22:42:45,725 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,726 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3663ms
2014-07-10 22:42:45,726 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:42:45,780 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:42:46,500 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:42:46,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:47,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7518 synced till here 7507
2014-07-10 22:42:47,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057357088 with entries=98, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057366982
2014-07-10 22:42:49,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:49,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7601 synced till here 7588
2014-07-10 22:42:49,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057366982 with entries=83, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057369266
2014-07-10 22:42:50,282 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:50,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7682 synced till here 7680
2014-07-10 22:42:50,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057369266 with entries=81, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057370282
2014-07-10 22:42:51,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:42:52,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057370282 with entries=272, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057371972
2014-07-10 22:42:54,007 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1231, memsize=891.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/8ff239538c904bd69fc1f2613734c8c6
2014-07-10 22:42:54,022 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/8ff239538c904bd69fc1f2613734c8c6 as hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/8ff239538c904bd69fc1f2613734c8c6
2014-07-10 22:42:54,033 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/8ff239538c904bd69fc1f2613734c8c6, entries=3247290, sequenceid=1231, filesize=231.2m
2014-07-10 22:42:54,033 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~891.9m/935193920, currentsize=416.9m/437200240 for region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. in 35482ms, sequenceid=1231, compaction requested=true
2014-07-10 22:42:54,034 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 22:42:54,034 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 659.0m
2014-07-10 22:42:54,113 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:42:54,509 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:01,908 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:01,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8364 synced till here 8362
2014-07-10 22:43:01,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057371972 with entries=410, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057381909
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057201413
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057205723
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057210652
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057213180
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057215474
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057218461
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057224369
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057227245
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057230759
2014-07-10 22:43:01,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057234060
2014-07-10 22:43:03,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:03,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8441 synced till here 8435
2014-07-10 22:43:04,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057381909 with entries=77, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057383796
2014-07-10 22:43:05,877 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:05,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8524 synced till here 8523
2014-07-10 22:43:05,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057383796 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057385878
2014-07-10 22:43:18,122 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1534, memsize=659.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/2b7ac52565254ea496066771f48de572
2014-07-10 22:43:18,164 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/2b7ac52565254ea496066771f48de572 as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/2b7ac52565254ea496066771f48de572
2014-07-10 22:43:18,182 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/2b7ac52565254ea496066771f48de572, entries=2402860, sequenceid=1534, filesize=171.0m
2014-07-10 22:43:18,182 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~659.9m/692002640, currentsize=77.4m/81136480 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 24148ms, sequenceid=1534, compaction requested=true
2014-07-10 22:43:18,183 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 22:43:18,183 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 583.4m
2014-07-10 22:43:18,864 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:21,504 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1408, memsize=961.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/6f3a134af831438c92d942a9e0bc4ad6
2014-07-10 22:43:21,524 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/6f3a134af831438c92d942a9e0bc4ad6 as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/6f3a134af831438c92d942a9e0bc4ad6
2014-07-10 22:43:21,535 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/6f3a134af831438c92d942a9e0bc4ad6, entries=3501090, sequenceid=1408, filesize=249.1m
2014-07-10 22:43:21,535 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~961.6m/1008282640, currentsize=190.2m/199437760 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 35867ms, sequenceid=1408, compaction requested=true
2014-07-10 22:43:21,536 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:43:21,536 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 483.6m
2014-07-10 22:43:21,847 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:31,202 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/f4c453c6565e4b1a9c1dfd8e0cb88fcc as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/f4c453c6565e4b1a9c1dfd8e0cb88fcc
2014-07-10 22:43:31,219 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Removing store files after compaction...
2014-07-10 22:43:31,237 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/89ead8e195fc470596ff5561486f7d89, to hdfs://master:54310/hbase/archive/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/89ead8e195fc470596ff5561486f7d89
2014-07-10 22:43:31,240 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/e97af0fc6ce54ed493168fde9379f59d, to hdfs://master:54310/hbase/archive/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/e97af0fc6ce54ed493168fde9379f59d
2014-07-10 22:43:31,243 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/15cccd0002de40969d00f966a31d64ee, to hdfs://master:54310/hbase/archive/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/15cccd0002de40969d00f966a31d64ee
2014-07-10 22:43:31,243 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. into f4c453c6565e4b1a9c1dfd8e0cb88fcc(size=375.3m), total size for store is 375.3m. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-10 22:43:31,243 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., storeName=family, fileCount=3, fileSize=375.4m, priority=17, time=11259409141753; duration=59sec
2014-07-10 22:43:31,244 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:43:31,244 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 22:43:31,244 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 545243865 starting at candidate #0 after considering 3 permutations with 2 in ratio
2014-07-10 22:43:31,244 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: 0afa782426206ca7b66634ebb84ca48d - family: Initiating major compaction
2014-07-10 22:43:31,244 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:43:31,245 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp, totalSize=520.0m
2014-07-10 22:43:31,245 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/cc40fd4c55644bf384fc107fa6f4e02f, keycount=93256, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=397, earliestPutTs=1405057032357
2014-07-10 22:43:31,245 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/638df501fda047f189bac9e3249e7eef, keycount=96754, bloomtype=ROW, size=69.0m, encoding=NONE, seqNum=683, earliestPutTs=1405057071528
2014-07-10 22:43:31,245 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/16b6f4356e35446985f2f86b8ab81c8f, keycount=299890, bloomtype=ROW, size=213.5m, encoding=NONE, seqNum=1111, earliestPutTs=1405057174811
2014-07-10 22:43:31,245 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/2b7ac52565254ea496066771f48de572, keycount=240286, bloomtype=ROW, size=171.0m, encoding=NONE, seqNum=1534, earliestPutTs=1405057306182
2014-07-10 22:43:31,332 DEBUG [regionserver60020-smallCompactions-1405056675886] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:34,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:35,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8813 synced till here 8812
2014-07-10 22:43:35,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057385878 with entries=289, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057414998
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057240210
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057244462
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057246961
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057251189
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057257730
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057261196
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057265716
2014-07-10 22:43:35,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057269788
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057273368
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057277037
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057280281
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057282765
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057300418
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057302441
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057303833
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057306120
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057308136
2014-07-10 22:43:35,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057309707
2014-07-10 22:43:37,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:37,353 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8941 synced till here 8938
2014-07-10 22:43:37,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057414998 with entries=128, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057417317
2014-07-10 22:43:38,982 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1702, memsize=483.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/3b44236313374482ab20243ce68cb666
2014-07-10 22:43:39,006 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/3b44236313374482ab20243ce68cb666 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/3b44236313374482ab20243ce68cb666
2014-07-10 22:43:39,019 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/3b44236313374482ab20243ce68cb666, entries=1760820, sequenceid=1702, filesize=125.4m
2014-07-10 22:43:39,020 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~483.6m/507101920, currentsize=47.7m/49975760 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 17484ms, sequenceid=1702, compaction requested=true
2014-07-10 22:43:39,020 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 22:43:39,020 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 542.3m
2014-07-10 22:43:39,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:39,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9056 synced till here 9055
2014-07-10 22:43:39,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057417317 with entries=115, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057419291
2014-07-10 22:43:39,484 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:39,650 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1881, memsize=583.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/2e225b6f11f3470184883074c66ce5d4
2014-07-10 22:43:39,666 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/2e225b6f11f3470184883074c66ce5d4 as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/2e225b6f11f3470184883074c66ce5d4
2014-07-10 22:43:39,682 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/2e225b6f11f3470184883074c66ce5d4, entries=2124320, sequenceid=1881, filesize=151.2m
2014-07-10 22:43:39,683 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~583.4m/611789040, currentsize=66.6m/69851680 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 21500ms, sequenceid=1881, compaction requested=false
2014-07-10 22:43:40,209 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:43:40,210 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 257.8m
2014-07-10 22:43:40,648 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:43:40,951 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:43:40,970 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9199 synced till here 9196
2014-07-10 22:43:40,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057419291 with entries=143, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057420951
2014-07-10 22:43:40,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057310942
2014-07-10 22:43:40,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057312326
2014-07-10 22:43:40,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057313666
2014-07-10 22:43:40,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057315818
2014-07-10 22:43:40,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057317360
2014-07-10 22:43:48,671 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1808, memsize=257.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/99ce3802ac8a424488d5984e1e93d7bd
2014-07-10 22:43:48,687 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/99ce3802ac8a424488d5984e1e93d7bd as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/99ce3802ac8a424488d5984e1e93d7bd
2014-07-10 22:43:48,698 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/99ce3802ac8a424488d5984e1e93d7bd, entries=938770, sequenceid=1808, filesize=66.9m
2014-07-10 22:43:48,699 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.8m/270359520, currentsize=20.4m/21377680 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 8489ms, sequenceid=1808, compaction requested=true
2014-07-10 22:43:48,700 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-10 22:43:57,216 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1791, memsize=543.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/a3db0c1485eb460d8de802994cc0d64f
2014-07-10 22:43:57,235 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/a3db0c1485eb460d8de802994cc0d64f as hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/a3db0c1485eb460d8de802994cc0d64f
2014-07-10 22:43:57,255 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/a3db0c1485eb460d8de802994cc0d64f, entries=1980220, sequenceid=1791, filesize=141.0m
2014-07-10 22:43:57,256 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~543.9m/570286880, currentsize=39.0m/40943200 for region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. in 18236ms, sequenceid=1791, compaction requested=true
2014-07-10 22:43:57,256 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-10 22:44:05,216 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:05,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057420951 with entries=225, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057445216
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057320176
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057339635
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057341239
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057343123
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057344416
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057345677
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057347717
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057349004
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057350270
2014-07-10 22:44:05,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057351487
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057353432
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057355078
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057357088
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057366982
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057369266
2014-07-10 22:44:05,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057370282
2014-07-10 22:44:07,816 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:07,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9508 synced till here 9507
2014-07-10 22:44:07,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057445216 with entries=84, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057447817
2014-07-10 22:44:09,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:09,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9592 synced till here 9584
2014-07-10 22:44:09,318 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057447817 with entries=84, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057449037
2014-07-10 22:44:11,052 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:11,086 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9832 synced till here 9831
2014-07-10 22:44:11,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057449037 with entries=240, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057451052
2014-07-10 22:44:12,520 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:44:12,520 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 256.1m
2014-07-10 22:44:12,673 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:12,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:13,181 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9951 synced till here 9947
2014-07-10 22:44:13,223 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057451052 with entries=119, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057452772
2014-07-10 22:44:15,166 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:15,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10046 synced till here 10044
2014-07-10 22:44:15,220 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057452772 with entries=95, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057455166
2014-07-10 22:44:16,758 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:44:16,759 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 257.6m
2014-07-10 22:44:16,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:16,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10155 synced till here 10152
2014-07-10 22:44:16,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057455166 with entries=109, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057456787
2014-07-10 22:44:16,920 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:17,860 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:44:18,354 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:18,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10316 synced till here 10311
2014-07-10 22:44:18,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057456787 with entries=161, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057458354
2014-07-10 22:44:19,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:19,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10463 synced till here 10454
2014-07-10 22:44:20,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057458354 with entries=147, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057459709
2014-07-10 22:44:21,209 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:44:21,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:21,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10545 synced till here 10544
2014-07-10 22:44:21,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057459709 with entries=82, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057461546
2014-07-10 22:44:22,604 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:44:22,784 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1990, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/4c4f6b79fc66446c833cf557cf291c31
2014-07-10 22:44:22,798 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/4c4f6b79fc66446c833cf557cf291c31 as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/4c4f6b79fc66446c833cf557cf291c31
2014-07-10 22:44:22,836 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/4c4f6b79fc66446c833cf557cf291c31, entries=932460, sequenceid=1990, filesize=66.4m
2014-07-10 22:44:22,836 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268543200, currentsize=148.6m/155786640 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 10316ms, sequenceid=1990, compaction requested=false
2014-07-10 22:44:22,837 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 328.5m
2014-07-10 22:44:23,088 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:24,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:25,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10699 synced till here 10698
2014-07-10 22:44:25,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057461546 with entries=154, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057464328
2014-07-10 22:44:25,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057371972
2014-07-10 22:44:25,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057381909
2014-07-10 22:44:25,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057383796
2014-07-10 22:44:26,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:26,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10808 synced till here 10800
2014-07-10 22:44:26,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057464328 with entries=109, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057466393
2014-07-10 22:44:27,140 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1987, memsize=257.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/aa8034626e344c118db7ce190d066f36
2014-07-10 22:44:27,151 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/aa8034626e344c118db7ce190d066f36 as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/aa8034626e344c118db7ce190d066f36
2014-07-10 22:44:27,162 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/aa8034626e344c118db7ce190d066f36, entries=938050, sequenceid=1987, filesize=66.8m
2014-07-10 22:44:27,163 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.6m/270148720, currentsize=144.9m/151950720 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 10403ms, sequenceid=1987, compaction requested=true
2014-07-10 22:44:27,163 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-10 22:44:27,163 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 325.6m
2014-07-10 22:44:27,405 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:28,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:28,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10899 synced till here 10893
2014-07-10 22:44:28,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057466393 with entries=91, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057468863
2014-07-10 22:44:29,762 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:29,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10983 synced till here 10979
2014-07-10 22:44:30,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057468863 with entries=84, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057469762
2014-07-10 22:44:31,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:31,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11066 synced till here 11064
2014-07-10 22:44:31,501 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057469762 with entries=83, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057471398
2014-07-10 22:44:32,012 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:44:32,841 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:32,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11136 synced till here 11134
2014-07-10 22:44:32,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057471398 with entries=70, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057472842
2014-07-10 22:44:33,781 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:44:34,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:34,270 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11209 synced till here 11204
2014-07-10 22:44:34,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057472842 with entries=73, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057474210
2014-07-10 22:44:35,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:36,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11307 synced till here 11306
2014-07-10 22:44:36,461 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057474210 with entries=98, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057475789
2014-07-10 22:44:36,699 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2153, memsize=328.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/1c058c45db054e4cbea29673fcc11948
2014-07-10 22:44:36,711 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/1c058c45db054e4cbea29673fcc11948 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/1c058c45db054e4cbea29673fcc11948
2014-07-10 22:44:36,720 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/1c058c45db054e4cbea29673fcc11948, entries=1195890, sequenceid=2153, filesize=85.2m
2014-07-10 22:44:36,720 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~328.5m/344407200, currentsize=191.1m/200393200 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 13883ms, sequenceid=2153, compaction requested=true
2014-07-10 22:44:36,720 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-10 22:44:36,720 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 448.1m
2014-07-10 22:44:37,103 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:37,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:37,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11375 synced till here 11374
2014-07-10 22:44:37,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057475789 with entries=68, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057477465
2014-07-10 22:44:37,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057385878
2014-07-10 22:44:37,511 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057414998
2014-07-10 22:44:39,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:39,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11447 synced till here 11444
2014-07-10 22:44:39,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057477465 with entries=72, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057479562
2014-07-10 22:44:40,695 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2204, memsize=327.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/9f81e1104dc54184aeb08ca3fddd5b61
2014-07-10 22:44:40,713 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp/9f81e1104dc54184aeb08ca3fddd5b61 as hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/9f81e1104dc54184aeb08ca3fddd5b61
2014-07-10 22:44:40,738 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/9f81e1104dc54184aeb08ca3fddd5b61, entries=1193660, sequenceid=2204, filesize=85.0m
2014-07-10 22:44:40,738 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~327.8m/343763760, currentsize=201.7m/211501280 for region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. in 13575ms, sequenceid=2204, compaction requested=true
2014-07-10 22:44:40,738 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-10 22:44:40,739 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 391.3m
2014-07-10 22:44:40,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:41,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11527 synced till here 11523
2014-07-10 22:44:41,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057479562 with entries=80, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057480866
2014-07-10 22:44:41,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057417317
2014-07-10 22:44:41,552 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:44:41,580 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:42,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:42,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11602 synced till here 11600
2014-07-10 22:44:42,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057480866 with entries=75, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057482292
2014-07-10 22:44:43,623 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:44:43,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:44,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11671 synced till here 11664
2014-07-10 22:44:44,259 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057482292 with entries=69, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057483660
2014-07-10 22:44:45,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:45,474 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11749 synced till here 11747
2014-07-10 22:44:45,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057483660 with entries=78, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057485005
2014-07-10 22:44:46,214 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:46,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11817 synced till here 11813
2014-07-10 22:44:46,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057485005 with entries=68, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057486215
2014-07-10 22:44:47,539 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:47,554 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11882 synced till here 11881
2014-07-10 22:44:47,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057486215 with entries=65, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057487540
2014-07-10 22:44:48,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:49,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11962 synced till here 11948
2014-07-10 22:44:49,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057487540 with entries=80, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057488695
2014-07-10 22:44:50,249 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:51,166 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12054 synced till here 12048
2014-07-10 22:44:51,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057488695 with entries=92, filesize=94.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057490249
2014-07-10 22:44:52,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:52,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12138 synced till here 12132
2014-07-10 22:44:52,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057490249 with entries=84, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057492402
2014-07-10 22:44:53,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:53,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12204 synced till here 12203
2014-07-10 22:44:53,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057492402 with entries=66, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057493658
2014-07-10 22:44:55,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:55,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12325 synced till here 12291
2014-07-10 22:44:55,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057493658 with entries=121, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057495255
2014-07-10 22:44:56,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:57,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12429 synced till here 12426
2014-07-10 22:44:57,243 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2306, memsize=452.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/503a8299432649148c78f2213eed5d45
2014-07-10 22:44:57,254 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/503a8299432649148c78f2213eed5d45 as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/503a8299432649148c78f2213eed5d45
2014-07-10 22:44:57,266 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/503a8299432649148c78f2213eed5d45, entries=1646560, sequenceid=2306, filesize=117.3m
2014-07-10 22:44:57,266 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~452.2m/474197920, currentsize=355.6m/372860640 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 20546ms, sequenceid=2306, compaction requested=true
2014-07-10 22:44:57,267 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-10 22:44:57,267 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113., current region memstore size 699.9m
2014-07-10 22:44:57,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057495255 with entries=104, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057496924
2014-07-10 22:44:57,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057419291
2014-07-10 22:44:57,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057420951
2014-07-10 22:44:57,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057445216
2014-07-10 22:44:57,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057447817
2014-07-10 22:44:57,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057449037
2014-07-10 22:44:57,336 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061.
2014-07-10 22:44:58,238 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:58,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:58,490 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12506 synced till here 12502
2014-07-10 22:44:58,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057496924 with entries=77, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057498462
2014-07-10 22:44:59,413 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2343, memsize=395.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/d14c9189cfbe4f60ba2c8c29e28f0d78
2014-07-10 22:44:59,434 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/aac578fe95f24d00bf12bb771352d9dc as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/aac578fe95f24d00bf12bb771352d9dc
2014-07-10 22:44:59,443 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/.tmp/d14c9189cfbe4f60ba2c8c29e28f0d78 as hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/d14c9189cfbe4f60ba2c8c29e28f0d78
2014-07-10 22:44:59,456 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/d14c9189cfbe4f60ba2c8c29e28f0d78, entries=1439470, sequenceid=2343, filesize=102.5m
2014-07-10 22:44:59,457 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~395.4m/414556400, currentsize=339.6m/356131120 for region usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. in 18719ms, sequenceid=2343, compaction requested=false
2014-07-10 22:44:59,457 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1., current region memstore size 590.0m
2014-07-10 22:44:59,459 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Removing store files after compaction...
2014-07-10 22:44:59,467 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/cc40fd4c55644bf384fc107fa6f4e02f, to hdfs://master:54310/hbase/archive/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/cc40fd4c55644bf384fc107fa6f4e02f
2014-07-10 22:44:59,469 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/638df501fda047f189bac9e3249e7eef, to hdfs://master:54310/hbase/archive/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/638df501fda047f189bac9e3249e7eef
2014-07-10 22:44:59,472 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/16b6f4356e35446985f2f86b8ab81c8f, to hdfs://master:54310/hbase/archive/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/16b6f4356e35446985f2f86b8ab81c8f
2014-07-10 22:44:59,478 DEBUG [regionserver60020-smallCompactions-1405056675886] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/2b7ac52565254ea496066771f48de572, to hdfs://master:54310/hbase/archive/data/default/usertable/0afa782426206ca7b66634ebb84ca48d/family/2b7ac52565254ea496066771f48de572
2014-07-10 22:44:59,478 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d. into aac578fe95f24d00bf12bb771352d9dc(size=519.9m), total size for store is 688.8m. This selection was in queue for 0sec, and took 1mins, 28sec to execute.
2014-07-10 22:44:59,478 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., storeName=family, fileCount=4, fileSize=520.0m, priority=16, time=11318671531148; duration=1mins, 28sec
2014-07-10 22:44:59,479 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-10 22:44:59,479 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-10 22:44:59,480 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 668781707 starting at candidate #0 after considering 6 permutations with 5 in ratio
2014-07-10 22:44:59,480 DEBUG [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: 5f0ad63c1591a52a494a87192ca35e1f - family: Initiating major compaction
2014-07-10 22:44:59,480 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f.
2014-07-10 22:44:59,481 INFO  [regionserver60020-smallCompactions-1405056675886] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/.tmp, totalSize=637.8m
2014-07-10 22:44:59,481 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/fc2da062841a4d14818e04bffc257251, keycount=122065, bloomtype=ROW, size=87.0m, encoding=NONE, seqNum=490, earliestPutTs=1405057030509
2014-07-10 22:44:59,482 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/1e96b34627084147b4cbac70e7bcd662, keycount=131425, bloomtype=ROW, size=93.6m, encoding=NONE, seqNum=778, earliestPutTs=1405057109320
2014-07-10 22:44:59,482 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/8ff239538c904bd69fc1f2613734c8c6, keycount=324729, bloomtype=ROW, size=231.2m, encoding=NONE, seqNum=1231, earliestPutTs=1405057203796
2014-07-10 22:44:59,482 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/a3db0c1485eb460d8de802994cc0d64f, keycount=198022, bloomtype=ROW, size=141.0m, encoding=NONE, seqNum=1791, earliestPutTs=1405057338585
2014-07-10 22:44:59,483 DEBUG [regionserver60020-smallCompactions-1405056675886] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f0ad63c1591a52a494a87192ca35e1f/family/9f81e1104dc54184aeb08ca3fddd5b61, keycount=119366, bloomtype=ROW, size=85.0m, encoding=NONE, seqNum=2204, earliestPutTs=1405057419071
2014-07-10 22:44:59,495 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d.
2014-07-10 22:44:59,559 DEBUG [regionserver60020-smallCompactions-1405056675886] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:44:59,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:44:59,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12585 synced till here 12582
2014-07-10 22:44:59,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057498462 with entries=79, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057499798
2014-07-10 22:44:59,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057451052
2014-07-10 22:44:59,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057452772
2014-07-10 22:45:00,250 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:45:02,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:02,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12652 synced till here 12650
2014-07-10 22:45:02,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057499798 with entries=67, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057502020
2014-07-10 22:45:03,408 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:03,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12733 synced till here 12729
2014-07-10 22:45:03,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057502020 with entries=81, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057503409
2014-07-10 22:45:04,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:05,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12834 synced till here 12832
2014-07-10 22:45:05,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057503409 with entries=101, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057504879
2014-07-10 22:45:06,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:06,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12902 synced till here 12901
2014-07-10 22:45:06,662 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057504879 with entries=68, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057506580
2014-07-10 22:45:08,213 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:08,447 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13000 synced till here 12995
2014-07-10 22:45:08,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057506580 with entries=98, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057508213
2014-07-10 22:45:09,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:09,827 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13080 synced till here 13078
2014-07-10 22:45:09,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057508213 with entries=80, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057509798
2014-07-10 22:45:11,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:11,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057509798 with entries=82, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057511292
2014-07-10 22:45:12,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:12,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13241 synced till here 13239
2014-07-10 22:45:12,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057511292 with entries=79, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057512704
2014-07-10 22:45:14,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:14,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13329 synced till here 13328
2014-07-10 22:45:14,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057512704 with entries=88, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057514364
2014-07-10 22:45:16,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:16,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13457 synced till here 13456
2014-07-10 22:45:16,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057514364 with entries=128, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057516147
2014-07-10 22:45:18,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 22:45:18,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13530 synced till here 13529
2014-07-10 22:45:18,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057516147 with entries=73, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405056637193/slave1%2C60020%2C1405056637193.1405057518802
2014-07-10 22:45:19,330 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:45:19,332 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405056637193: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 22:45:24,331 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 22:45:24,333 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 22:45:24,364 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2522, memsize=592.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/b9e7022313d845158514e8b98359cee2
2014-07-10 22:45:24,385 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/.tmp/b9e7022313d845158514e8b98359cee2 as hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/b9e7022313d845158514e8b98359cee2
2014-07-10 22:45:24,528 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/61ae40bb3344e2f026ef21a6bb386de1/family/b9e7022313d845158514e8b98359cee2, entries=2157540, sequenceid=2522, filesize=153.6m
2014-07-10 22:45:24,528 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~592.6m/621353200, currentsize=290.9m/305049600 for region usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1. in 25071ms, sequenceid=2522, compaction requested=true
2014-07-10 22:45:24,529 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-10 22:45:24,529 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5197ms
2014-07-10 22:45:24,529 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:45:24,529 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5199ms
2014-07-10 22:45:24,529 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405057014371.5f0ad63c1591a52a494a87192ca35e1f., current region memstore size 834.7m
2014-07-10 22:45:24,529 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405056637193
2014-07-10 22:45:24,951 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405057014371.61ae40bb3344e2f026ef21a6bb386de1.
2014-07-10 22:45:25,190 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:45:26,907 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2459, memsize=699.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/2c9b1a846dd540c685168d2189dd1220
2014-07-10 22:45:26,925 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/.tmp/2c9b1a846dd540c685168d2189dd1220 as hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/2c9b1a846dd540c685168d2189dd1220
2014-07-10 22:45:26,942 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/620a02e3b6f5bca4f53190d7d83a9113/family/2c9b1a846dd540c685168d2189dd1220, entries=2548500, sequenceid=2459, filesize=181.4m
2014-07-10 22:45:26,942 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~699.9m/733949360, currentsize=318.7m/334139680 for region usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113. in 29675ms, sequenceid=2459, compaction requested=true
2014-07-10 22:45:26,942 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-10 22:45:26,943 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061., current region memstore size 701.7m
2014-07-10 22:45:27,073 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405057014372.620a02e3b6f5bca4f53190d7d83a9113.
2014-07-10 22:45:27,393 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 22:45:37,279 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=47421, hits=1699, hitRatio=3.58%, , cachingAccesses=1703, cachingHits=1696, cachingHitsRatio=99.58%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 22:45:49,388 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2650, memsize=701.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/ae60710801914c06a9a68f39fe5ec2b4
2014-07-10 22:45:49,410 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/.tmp/ae60710801914c06a9a68f39fe5ec2b4 as hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/ae60710801914c06a9a68f39fe5ec2b4
2014-07-10 22:45:49,423 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cdb7e3c24ac3c1e2ebe797f67da3b061/family/ae60710801914c06a9a68f39fe5ec2b4, entries=2554870, sequenceid=2650, filesize=181.9m
2014-07-10 22:45:49,423 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~701.7m/735779120, currentsize=4.2m/4426480 for region usertable,user3,1405057014371.cdb7e3c24ac3c1e2ebe797f67da3b061. in 22480ms, sequenceid=2650, compaction requested=true
2014-07-10 22:45:49,423 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-10 22:45:49,424 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405057014371.0afa782426206ca7b66634ebb84ca48d., current region memstore size 651.9m
