Wed Jul  9 14:28:44 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-09 14:28:44,938 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-09 14:28:44,939 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-09 14:28:44,939 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 35115 22
2014-07-09 14:28:45,167 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-09 14:28:45,168 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 35115 9.1.143.59 22
2014-07-09 14:28:45,169 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-09 14:28:45,169 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-09 14:28:45,169 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-09 14:28:45,171 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=292
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-09 14:28:45,172 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-09 14:28:45,174 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-09 14:28:45,175 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-09 14:28:45,399 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-09 14:28:45,788 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-09 14:28:45,890 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-09 14:28:45,903 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-09 14:28:45,964 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-09 14:28:45,966 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-09 14:28:45,966 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-09 14:28:45,972 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-09 14:28:45,977 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-09 14:28:46,065 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-09 14:28:46,066 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-09 14:28:46,070 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-09 14:28:46,073 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-09 14:28:46,148 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-09 14:28:46,206 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-09 14:28:46,217 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-09 14:28:46,219 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-09 14:28:46,219 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-09 14:28:46,219 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-09 14:28:46,536 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-09 14:28:46,585 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-09 14:28:46,588 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 14:28:46,588 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-09 14:28:46,611 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 14:28:46,615 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 14:28:46,619 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-09 14:28:46,639 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x471d07562a0000, negotiated timeout = 90000
2014-07-09 14:29:17,675 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x14100767, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 14:29:17,676 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x14100767 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 14:29:17,676 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 14:29:17,677 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-09 14:29:17,683 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x471d07562a0003, negotiated timeout = 90000
2014-07-09 14:29:17,960 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4beaf267
2014-07-09 14:29:17,965 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-09 14:29:17,971 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-09 14:29:17,988 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-09 14:29:18,025 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-09 14:29:18,032 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-09 14:29:18,036 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-09 14:29:18,054 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1404941325354 with port=60020, startcode=1404941325989
2014-07-09 14:29:18,442 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-09 14:29:18,442 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-09 14:29:18,442 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-09 14:29:18,467 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-09 14:29:18,477 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989
2014-07-09 14:29:18,519 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-09 14:29:18,531 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-09 14:29:18,610 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941358537
2014-07-09 14:29:18,621 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-09 14:29:18,625 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-09 14:29:18,629 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-09 14:29:18,634 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-09 14:29:18,636 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-09 14:29:18,636 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-09 14:29:18,636 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-09 14:29:18,637 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-09 14:29:18,637 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-09 14:29:18,645 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1404941325989, sceplus-vm48.almaden.ibm.com,60020,1404941326960] other RSs: [slave1,60020,1404941325989, sceplus-vm48.almaden.ibm.com,60020,1404941326960]
2014-07-09 14:29:18,666 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-09 14:29:18,669 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x4ade6be1, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 14:29:18,670 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x4ade6be1 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 14:29:18,670 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 14:29:18,671 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-09 14:29:18,675 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x471d07562a0004, negotiated timeout = 90000
2014-07-09 14:29:18,681 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-09 14:29:18,681 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-09 14:29:18,722 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1404941325989, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x471d07562a0000
2014-07-09 14:29:18,722 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1404941325989 starting
2014-07-09 14:29:18,722 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-09 14:29:18,722 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1404941325989
2014-07-09 14:29:18,722 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1404941325989'
2014-07-09 14:29:18,722 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-09 14:29:18,724 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-09 14:29:18,725 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-09 14:29:22,479 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-09 14:29:22,581 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:22,607 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:22,607 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989
2014-07-09 14:29:22,609 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-09 14:29:22,633 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941362613.meta
2014-07-09 14:29:22,651 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-09 14:29:22,672 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-09 14:29:22,679 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-09 14:29:22,682 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-09 14:29:22,686 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-09 14:29:22,687 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-09 14:29:22,687 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-09 14:29:22,759 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-09 14:29:22,796 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-09 14:29:22,852 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c9d4a0cbe3394c898452951eae20b887, isReference=false, isBulkLoadResult=false, seqid=2703, majorCompaction=true
2014-07-09 14:29:22,864 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for d0d5c6ee77134cfaa0fa25aa0b90947b
2014-07-09 14:29:22,864 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d0d5c6ee77134cfaa0fa25aa0b90947b, isReference=false, isBulkLoadResult=false, seqid=2729, majorCompaction=false
2014-07-09 14:29:22,895 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-09 14:29:22,900 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=2730
2014-07-09 14:29:22,901 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-09 14:29:22,904 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-09 14:29:22,905 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1404941325989
2014-07-09 14:29:22,911 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-09 14:29:22,911 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:22,917 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:22,917 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:22,917 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1404941325989
2014-07-09 14:29:23,228 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:23,249 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:23,250 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 49c77d66194dd9403ff50d6bd336794c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,250 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:23,251 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b8d29d40ffb788d9b5928f6477167bfd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,252 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:23,252 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd022dfd5a21ce853009713c7168a2f0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,252 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 14:29:23,259 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:23,267 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 49c77d66194dd9403ff50d6bd336794c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,267 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 49c77d66194dd9403ff50d6bd336794c, NAME => 'usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-09 14:29:23,268 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b8d29d40ffb788d9b5928f6477167bfd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,268 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd022dfd5a21ce853009713c7168a2f0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:23,268 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => b8d29d40ffb788d9b5928f6477167bfd, NAME => 'usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-09 14:29:23,269 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => dd022dfd5a21ce853009713c7168a2f0, NAME => 'usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-09 14:29:23,269 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 49c77d66194dd9403ff50d6bd336794c
2014-07-09 14:29:23,269 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:23,270 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b8d29d40ffb788d9b5928f6477167bfd
2014-07-09 14:29:23,270 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:23,270 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable dd022dfd5a21ce853009713c7168a2f0
2014-07-09 14:29:23,270 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:23,277 INFO  [RS_OPEN_REGION-slave1:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-09 14:29:23,279 INFO  [RS_OPEN_REGION-slave1:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-09 14:29:23,281 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-09 14:29:23,282 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-09 14:29:23,284 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-09 14:29:23,311 INFO  [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:29:23,313 INFO  [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:29:23,315 INFO  [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:29:23,357 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:29:23,359 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/19d093c04473429ea0fde602225a4859, isReference=false, isBulkLoadResult=false, seqid=9535, majorCompaction=false
2014-07-09 14:29:23,452 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:29:23,452 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/003e9e2c7d6d409383067d312a621b8e, isReference=false, isBulkLoadResult=false, seqid=8107, majorCompaction=false
2014-07-09 14:29:23,452 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/0c02fd72c2cb478e8d7ab8af0df76471, isReference=false, isBulkLoadResult=false, seqid=8234, majorCompaction=false
2014-07-09 14:29:23,455 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/41750f8ce6834523862e415d58a5cad9, isReference=false, isBulkLoadResult=false, seqid=2556, majorCompaction=false
2014-07-09 14:29:23,472 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/0fe89da7cbeb428ca03a79a023204c7a, isReference=false, isBulkLoadResult=false, seqid=1079, majorCompaction=false
2014-07-09 14:29:23,473 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/1005d6336efe486893419ed6a1c9c085, isReference=false, isBulkLoadResult=false, seqid=8606, majorCompaction=false
2014-07-09 14:29:23,496 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/10a6bc2fa48245c49e8d97c9db12b10e, isReference=false, isBulkLoadResult=false, seqid=9065, majorCompaction=false
2014-07-09 14:29:23,497 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/50fe5b2831bc49e0b5d9587ca50109a4, isReference=false, isBulkLoadResult=false, seqid=4217, majorCompaction=false
2014-07-09 14:29:23,505 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/1a3cf8776130409eb2dd542807c337dd, isReference=false, isBulkLoadResult=false, seqid=1614, majorCompaction=false
2014-07-09 14:29:23,516 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/1f325f320ce344e399c0c5f8d93893e4, isReference=false, isBulkLoadResult=false, seqid=8898, majorCompaction=false
2014-07-09 14:29:23,520 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/2594c1c4479646dfb99ac611452a05c7, isReference=false, isBulkLoadResult=false, seqid=8939, majorCompaction=false
2014-07-09 14:29:23,565 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/533d981173374e41aa60b12236b6454a, isReference=false, isBulkLoadResult=false, seqid=2390, majorCompaction=false
2014-07-09 14:29:23,570 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/29594ca1c4964cdd9858f13c30717a48, isReference=false, isBulkLoadResult=false, seqid=9660, majorCompaction=false
2014-07-09 14:29:23,581 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/5d6e6c85d4a14733bc57a5f6939183a2, isReference=false, isBulkLoadResult=false, seqid=9661, majorCompaction=false
2014-07-09 14:29:23,622 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/6a209061e8f94e0295493c39e2a017ac, isReference=false, isBulkLoadResult=false, seqid=6441, majorCompaction=false
2014-07-09 14:29:23,635 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/2f7b20d9e94146df9f170bc7bd5cb865, isReference=false, isBulkLoadResult=false, seqid=7900, majorCompaction=false
2014-07-09 14:29:23,639 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/5e2ce759709d41b69fd54fea54b3792a, isReference=false, isBulkLoadResult=false, seqid=9202, majorCompaction=false
2014-07-09 14:29:23,643 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/83ec45084283459bac3023ec43cde798, isReference=false, isBulkLoadResult=false, seqid=9272, majorCompaction=false
2014-07-09 14:29:23,686 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/5a4671a9576f43ed8440f9fec8eec581, isReference=false, isBulkLoadResult=false, seqid=8067, majorCompaction=false
2014-07-09 14:29:23,769 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/8a0dea87ae664a17a292831b42351b77, isReference=false, isBulkLoadResult=false, seqid=5878, majorCompaction=false
2014-07-09 14:29:23,770 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/8d77f8d76ef04b458d5d51c0f408f4db, isReference=false, isBulkLoadResult=false, seqid=8773, majorCompaction=false
2014-07-09 14:29:23,820 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/6acefeaf48c04d369162877c559c935e, isReference=false, isBulkLoadResult=false, seqid=2743, majorCompaction=false
2014-07-09 14:29:23,823 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/9ed84cb5f2794351a3ad78f5449c33e2, isReference=false, isBulkLoadResult=false, seqid=8440, majorCompaction=false
2014-07-09 14:29:23,830 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/a938512c468740e5bf256a52883b3277, isReference=false, isBulkLoadResult=false, seqid=7541, majorCompaction=false
2014-07-09 14:29:23,843 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/8390ce73287c4b8ba68aad057bb26d50, isReference=false, isBulkLoadResult=false, seqid=8732, majorCompaction=false
2014-07-09 14:29:23,846 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/be0602c04a7e445bac23913b8147c3d5, isReference=false, isBulkLoadResult=false, seqid=723, majorCompaction=true
2014-07-09 14:29:23,848 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/a5a6af06cf524721866a580620aa12cf, isReference=false, isBulkLoadResult=false, seqid=1280, majorCompaction=true
2014-07-09 14:29:23,863 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/851ce43bc40c40f8b66c3be366b8d727, isReference=false, isBulkLoadResult=false, seqid=4406, majorCompaction=false
2014-07-09 14:29:23,865 DEBUG [StoreOpener-b8d29d40ffb788d9b5928f6477167bfd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/fffbcfa72a404d9284017d0adde84742, isReference=false, isBulkLoadResult=false, seqid=9369, majorCompaction=false
2014-07-09 14:29:23,866 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/a7aa4fabc72449fbb0b0ffdfa32a6f9d, isReference=false, isBulkLoadResult=false, seqid=1446, majorCompaction=false
2014-07-09 14:29:23,868 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd
2014-07-09 14:29:23,871 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined b8d29d40ffb788d9b5928f6477167bfd; next sequenceid=9662
2014-07-09 14:29:23,871 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b8d29d40ffb788d9b5928f6477167bfd
2014-07-09 14:29:23,876 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/c1599a39e0f24b4585f556ddaf242b0a, isReference=false, isBulkLoadResult=false, seqid=9608, majorCompaction=false
2014-07-09 14:29:23,879 INFO  [PostOpenDeployTasks:b8d29d40ffb788d9b5928f6477167bfd] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:23,880 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/857e7486187a497f937bf0b909b1ae9c, isReference=false, isBulkLoadResult=false, seqid=9231, majorCompaction=false
2014-07-09 14:29:23,881 DEBUG [PostOpenDeployTasks:b8d29d40ffb788d9b5928f6477167bfd] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:29:23,883 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 14:29:23,887 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 4048757783 starting at candidate #0 after considering 36 permutations with 33 in ratio
2014-07-09 14:29:23,889 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/c93a5fc775a742468b4c1e73566e04f5, isReference=false, isBulkLoadResult=false, seqid=9660, majorCompaction=false
2014-07-09 14:29:23,890 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.HStore: b8d29d40ffb788d9b5928f6477167bfd - family: Initiating major compaction
2014-07-09 14:29:23,890 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HRegion: Starting compaction on family in region usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:23,891 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/.tmp, totalSize=3.8g
2014-07-09 14:29:23,891 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/887ba76655a3412fa11b6ae3ac0d0c20, isReference=false, isBulkLoadResult=false, seqid=9564, majorCompaction=false
2014-07-09 14:29:23,892 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/be0602c04a7e445bac23913b8147c3d5, keycount=406082, bloomtype=ROW, size=289.1m, encoding=NONE, seqNum=723, earliestPutTs=1404937968922
2014-07-09 14:29:23,892 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/533d981173374e41aa60b12236b6454a, keycount=936722, bloomtype=ROW, size=667.1m, encoding=NONE, seqNum=2390, earliestPutTs=1404938122610
2014-07-09 14:29:23,892 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/41750f8ce6834523862e415d58a5cad9, keycount=93461, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=2556, earliestPutTs=1404938512979
2014-07-09 14:29:23,893 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/50fe5b2831bc49e0b5d9587ca50109a4, keycount=933295, bloomtype=ROW, size=664.7m, encoding=NONE, seqNum=4217, earliestPutTs=1404938561798
2014-07-09 14:29:23,893 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/8a0dea87ae664a17a292831b42351b77, keycount=933575, bloomtype=ROW, size=664.9m, encoding=NONE, seqNum=5878, earliestPutTs=1404939086545
2014-07-09 14:29:23,893 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/a938512c468740e5bf256a52883b3277, keycount=934509, bloomtype=ROW, size=665.7m, encoding=NONE, seqNum=7541, earliestPutTs=1404939666917
2014-07-09 14:29:23,893 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/5e2ce759709d41b69fd54fea54b3792a, keycount=933429, bloomtype=ROW, size=665.3m, encoding=NONE, seqNum=9202, earliestPutTs=1404940309085
2014-07-09 14:29:23,893 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/fffbcfa72a404d9284017d0adde84742, keycount=93967, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=9369, earliestPutTs=1404941032347
2014-07-09 14:29:23,894 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/19d093c04473429ea0fde602225a4859, keycount=93404, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=9535, earliestPutTs=1404941108836
2014-07-09 14:29:23,894 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b8d29d40ffb788d9b5928f6477167bfd/family/5d6e6c85d4a14733bc57a5f6939183a2, keycount=62063, bloomtype=ROW, size=44.3m, encoding=NONE, seqNum=9661, earliestPutTs=1404941182382
2014-07-09 14:29:23,901 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/cb63bfba3b1d49499ad173dd5bf023a4, isReference=false, isBulkLoadResult=false, seqid=9438, majorCompaction=false
2014-07-09 14:29:23,908 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/8cfd4368815f48eabc660be31e40c44a, isReference=false, isBulkLoadResult=false, seqid=8400, majorCompaction=false
2014-07-09 14:29:23,916 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/d6767bee15204c0b8af9585a184d58ec, isReference=false, isBulkLoadResult=false, seqid=9105, majorCompaction=false
2014-07-09 14:29:23,927 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/b1326c5cd4ea41d1b663336dcaa2657d, isReference=false, isBulkLoadResult=false, seqid=913, majorCompaction=true
2014-07-09 14:29:23,933 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/d683328ac9924f07a690e5f5250a1ae9, isReference=false, isBulkLoadResult=false, seqid=8273, majorCompaction=false
2014-07-09 14:29:23,993 DEBUG [regionserver60020-smallCompactions-1404941363881] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:29:23,993 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/e41a55b4f6294a9da72f06bb46d8d1ca, isReference=false, isBulkLoadResult=false, seqid=6238, majorCompaction=false
2014-07-09 14:29:23,994 DEBUG [StoreOpener-dd022dfd5a21ce853009713c7168a2f0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0/family/f0986cd362634bf8aae78f47bee8e84e, isReference=false, isBulkLoadResult=false, seqid=4777, majorCompaction=false
2014-07-09 14:29:24,000 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/dd022dfd5a21ce853009713c7168a2f0
2014-07-09 14:29:24,003 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined dd022dfd5a21ce853009713c7168a2f0; next sequenceid=9661
2014-07-09 14:29:24,003 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node dd022dfd5a21ce853009713c7168a2f0
2014-07-09 14:29:24,010 INFO  [PostOpenDeployTasks:dd022dfd5a21ce853009713c7168a2f0] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:24,010 DEBUG [PostOpenDeployTasks:dd022dfd5a21ce853009713c7168a2f0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 14:29:24,012 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/ebcd6f8ea41d44098fe500314dd97d7b, isReference=false, isBulkLoadResult=false, seqid=8566, majorCompaction=false
2014-07-09 14:29:24,040 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/f6ed53ece4c14b5090f02a9413d9e737, isReference=false, isBulkLoadResult=false, seqid=6071, majorCompaction=false
2014-07-09 14:29:24,054 DEBUG [StoreOpener-49c77d66194dd9403ff50d6bd336794c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c/family/fbd37a7d68d84e35b4e87bd115dd1251, isReference=false, isBulkLoadResult=false, seqid=9398, majorCompaction=false
2014-07-09 14:29:24,061 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/49c77d66194dd9403ff50d6bd336794c
2014-07-09 14:29:24,065 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 49c77d66194dd9403ff50d6bd336794c; next sequenceid=9661
2014-07-09 14:29:24,065 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 49c77d66194dd9403ff50d6bd336794c
2014-07-09 14:29:24,068 INFO  [PostOpenDeployTasks:49c77d66194dd9403ff50d6bd336794c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:24,068 DEBUG [PostOpenDeployTasks:49c77d66194dd9403ff50d6bd336794c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 14:29:24,084 INFO  [PostOpenDeployTasks:dd022dfd5a21ce853009713c7168a2f0] catalog.MetaEditor: Updated row usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,084 INFO  [PostOpenDeployTasks:b8d29d40ffb788d9b5928f6477167bfd] catalog.MetaEditor: Updated row usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,085 INFO  [PostOpenDeployTasks:dd022dfd5a21ce853009713c7168a2f0] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:24,084 INFO  [PostOpenDeployTasks:49c77d66194dd9403ff50d6bd336794c] catalog.MetaEditor: Updated row usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,085 INFO  [PostOpenDeployTasks:b8d29d40ffb788d9b5928f6477167bfd] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:24,086 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd022dfd5a21ce853009713c7168a2f0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,086 INFO  [PostOpenDeployTasks:49c77d66194dd9403ff50d6bd336794c] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:24,086 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b8d29d40ffb788d9b5928f6477167bfd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,086 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 49c77d66194dd9403ff50d6bd336794c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,092 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd022dfd5a21ce853009713c7168a2f0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,092 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned dd022dfd5a21ce853009713c7168a2f0 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,092 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0. on slave1,60020,1404941325989
2014-07-09 14:29:24,092 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b8d29d40ffb788d9b5928f6477167bfd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,093 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned b8d29d40ffb788d9b5928f6477167bfd to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,093 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 702db18cb43566cbcd7543685d1447c3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,093 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd. on slave1,60020,1404941325989
2014-07-09 14:29:24,093 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 49c77d66194dd9403ff50d6bd336794c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,093 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 49c77d66194dd9403ff50d6bd336794c to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,094 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,094 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c. on slave1,60020,1404941325989
2014-07-09 14:29:24,094 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8388f814719c533a823011bbd7f4c202 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,100 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 702db18cb43566cbcd7543685d1447c3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,101 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 702db18cb43566cbcd7543685d1447c3, NAME => 'usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 702db18cb43566cbcd7543685d1447c3
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8388f814719c533a823011bbd7f4c202 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-09 14:29:24,102 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 8388f814719c533a823011bbd7f4c202, NAME => 'usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-09 14:29:24,103 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-09 14:29:24,103 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 8388f814719c533a823011bbd7f4c202
2014-07-09 14:29:24,103 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 14:29:24,103 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:24,110 INFO  [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:29:24,113 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-09 14:29:24,116 INFO  [StoreOpener-8388f814719c533a823011bbd7f4c202-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:29:24,171 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-09 14:29:24,174 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-09 14:29:24,216 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/065b0ec1c79c48d1a28dc65227fe364d, isReference=false, isBulkLoadResult=false, seqid=3493, majorCompaction=false
2014-07-09 14:29:24,217 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-09 14:29:24,217 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-09 14:29:24,217 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/0948d0687c2645689f2a8dab9ccd18cf, isReference=false, isBulkLoadResult=false, seqid=3847, majorCompaction=false
2014-07-09 14:29:24,220 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 14:29:24,226 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,226 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 14:29:24,227 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,232 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,233 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,233 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1404941325989
2014-07-09 14:29:24,240 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/27ef91318bbe4cc8b3ee3f4f4402cc4e, isReference=false, isBulkLoadResult=false, seqid=8650, majorCompaction=false
2014-07-09 14:29:24,244 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/18a230fdc526496baab488325391abe0, isReference=false, isBulkLoadResult=false, seqid=9173, majorCompaction=false
2014-07-09 14:29:24,255 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/31a4e38595ed4132b8fb0f4cd2353873, isReference=false, isBulkLoadResult=false, seqid=9661, majorCompaction=false
2014-07-09 14:29:24,263 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/3b2d80f435664a9f901fef84273b25a6, isReference=false, isBulkLoadResult=false, seqid=9661, majorCompaction=false
2014-07-09 14:29:24,282 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/35f8821d1eba46d0bf0a2cc2fd3d8c58, isReference=false, isBulkLoadResult=false, seqid=1664, majorCompaction=true
2014-07-09 14:29:24,293 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/508e40a2551746e1aaf2f7ce1b68e8a9, isReference=false, isBulkLoadResult=false, seqid=8509, majorCompaction=false
2014-07-09 14:29:24,307 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/51c5cbd5f0444f638e3c2d8778f35430, isReference=false, isBulkLoadResult=false, seqid=8483, majorCompaction=false
2014-07-09 14:29:24,309 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/9c411d5329bb4fa492a85fa04601e54a, isReference=false, isBulkLoadResult=false, seqid=8675, majorCompaction=false
2014-07-09 14:29:24,363 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/9f12aace19534b519b6f57f2a3a53bdf, isReference=false, isBulkLoadResult=false, seqid=9506, majorCompaction=false
2014-07-09 14:29:24,405 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/5cf21e890d0047dfbb485205ab2d90e8, isReference=false, isBulkLoadResult=false, seqid=6653, majorCompaction=false
2014-07-09 14:29:24,426 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/b3bf0ad87b9c45c29edbd5bf0350d1c1, isReference=false, isBulkLoadResult=false, seqid=9007, majorCompaction=false
2014-07-09 14:29:24,427 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/68e4997d4bde48558e43d395e45ad1b5, isReference=false, isBulkLoadResult=false, seqid=8317, majorCompaction=false
2014-07-09 14:29:24,491 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/cb17e1e3b47d49a6a512c8f0cf76ff4a, isReference=false, isBulkLoadResult=false, seqid=2018, majorCompaction=true
2014-07-09 14:29:24,492 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/6d89a5f512f64a0faf6a8147d4d5b37e, isReference=false, isBulkLoadResult=false, seqid=8816, majorCompaction=false
2014-07-09 14:29:24,510 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/d181ef81dfb242778a157d1c35b8c096, isReference=false, isBulkLoadResult=false, seqid=2185, majorCompaction=false
2014-07-09 14:29:24,525 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/70fd8c3bdfce46e1b4c666d378d438a2, isReference=false, isBulkLoadResult=false, seqid=8982, majorCompaction=false
2014-07-09 14:29:24,540 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/d54e5fcc39cb4bd4bb959f05ecbd6175, isReference=false, isBulkLoadResult=false, seqid=9340, majorCompaction=false
2014-07-09 14:29:24,558 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/71ca2c670aaf4bd6ab178f4c0bf632c6, isReference=false, isBulkLoadResult=false, seqid=9481, majorCompaction=false
2014-07-09 14:29:24,568 DEBUG [StoreOpener-8388f814719c533a823011bbd7f4c202-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202/family/e332869681014470ac6ec46718f0571a, isReference=false, isBulkLoadResult=false, seqid=8841, majorCompaction=false
2014-07-09 14:29:24,615 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/8388f814719c533a823011bbd7f4c202
2014-07-09 14:29:24,615 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/899d668dc1e44bbfa5535da12a06b714, isReference=false, isBulkLoadResult=false, seqid=9315, majorCompaction=false
2014-07-09 14:29:24,618 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 8388f814719c533a823011bbd7f4c202; next sequenceid=9662
2014-07-09 14:29:24,618 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 8388f814719c533a823011bbd7f4c202
2014-07-09 14:29:24,621 INFO  [PostOpenDeployTasks:8388f814719c533a823011bbd7f4c202] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:24,621 DEBUG [PostOpenDeployTasks:8388f814719c533a823011bbd7f4c202] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-09 14:29:24,628 INFO  [PostOpenDeployTasks:8388f814719c533a823011bbd7f4c202] catalog.MetaEditor: Updated row usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,628 INFO  [PostOpenDeployTasks:8388f814719c533a823011bbd7f4c202] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:24,629 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8388f814719c533a823011bbd7f4c202 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,633 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/91bf5c37e8a140aeb460bd5892bba3aa, isReference=false, isBulkLoadResult=false, seqid=1830, majorCompaction=false
2014-07-09 14:29:24,633 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8388f814719c533a823011bbd7f4c202 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,633 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 8388f814719c533a823011bbd7f4c202 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,633 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202. on slave1,60020,1404941325989
2014-07-09 14:29:24,645 DEBUG [StoreOpener-702db18cb43566cbcd7543685d1447c3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3/family/d019dfa6012b43f2b1364276a47df070, isReference=false, isBulkLoadResult=false, seqid=9148, majorCompaction=false
2014-07-09 14:29:24,647 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/702db18cb43566cbcd7543685d1447c3
2014-07-09 14:29:24,649 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 702db18cb43566cbcd7543685d1447c3; next sequenceid=9662
2014-07-09 14:29:24,650 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 702db18cb43566cbcd7543685d1447c3
2014-07-09 14:29:24,652 INFO  [PostOpenDeployTasks:702db18cb43566cbcd7543685d1447c3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:24,652 DEBUG [PostOpenDeployTasks:702db18cb43566cbcd7543685d1447c3] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-09 14:29:24,658 INFO  [PostOpenDeployTasks:702db18cb43566cbcd7543685d1447c3] catalog.MetaEditor: Updated row usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3. with server=slave1,60020,1404941325989
2014-07-09 14:29:24,658 INFO  [PostOpenDeployTasks:702db18cb43566cbcd7543685d1447c3] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:24,659 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 702db18cb43566cbcd7543685d1447c3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,668 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 702db18cb43566cbcd7543685d1447c3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:29:24,668 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 702db18cb43566cbcd7543685d1447c3 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:29:24,668 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3. on slave1,60020,1404941325989
2014-07-09 14:29:28,681 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-09 14:29:28,682 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-09 14:29:28,682 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-09 14:29:28,682 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-09 14:29:52,461 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 49c77d66194dd9403ff50d6bd336794c, via zk=yes, znode version=0, on null
2014-07-09 14:29:52,462 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close b8d29d40ffb788d9b5928f6477167bfd, via zk=yes, znode version=0, on null
2014-07-09 14:29:52,462 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close dd022dfd5a21ce853009713c7168a2f0, via zk=yes, znode version=0, on null
2014-07-09 14:29:52,462 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close 702db18cb43566cbcd7543685d1447c3, via zk=yes, znode version=0, on null
2014-07-09 14:29:52,462 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close 8388f814719c533a823011bbd7f4c202, via zk=yes, znode version=0, on null
2014-07-09 14:29:52,464 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:52,464 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:52,466 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:52,471 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.: disabling compactions & flushes
2014-07-09 14:29:52,471 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.: disabling compactions & flushes
2014-07-09 14:29:52,471 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.: disabling compactions & flushes
2014-07-09 14:29:52,471 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: waiting for 1 compactions to complete for region usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:52,472 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:52,472 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:52,513 INFO  [StoreCloserThread-usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.-1] regionserver.HStore: Closed family
2014-07-09 14:29:52,513 INFO  [StoreCloserThread-usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.-1] regionserver.HStore: Closed family
2014-07-09 14:29:52,516 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:52,516 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:52,516 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dd022dfd5a21ce853009713c7168a2f0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,516 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 49c77d66194dd9403ff50d6bd336794c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dd022dfd5a21ce853009713c7168a2f0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0. on slave1,60020,1404941325989
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0.
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 49c77d66194dd9403ff50d6bd336794c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c. on slave1,60020,1404941325989
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c.
2014-07-09 14:29:52,524 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:52,530 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.: disabling compactions & flushes
2014-07-09 14:29:52,530 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:52,529 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.: disabling compactions & flushes
2014-07-09 14:29:52,530 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:52,533 INFO  [StoreCloserThread-usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.-1] regionserver.HStore: Closed family
2014-07-09 14:29:52,534 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:52,535 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8388f814719c533a823011bbd7f4c202 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,537 INFO  [StoreCloserThread-usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.-1] regionserver.HStore: Closed family
2014-07-09 14:29:52,538 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:52,538 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 702db18cb43566cbcd7543685d1447c3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,542 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8388f814719c533a823011bbd7f4c202 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,542 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202. on slave1,60020,1404941325989
2014-07-09 14:29:52,542 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202.
2014-07-09 14:29:52,545 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 702db18cb43566cbcd7543685d1447c3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,545 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3. on slave1,60020,1404941325989
2014-07-09 14:29:52,545 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3.
2014-07-09 14:29:52,739 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HRegion: compaction interrupted
java.io.InterruptedIOException: Aborting compaction of store family in region usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd. because it was interrupted.
	at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:81)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:109)
	at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1086)
	at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1481)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:475)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 14:29:52,740 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:52,748 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Aborted compaction: Request = regionName=usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd., storeName=family, fileCount=10, fileSize=3.8g (67.0m, 66.6m, 44.3m), priority=10, time=160063308365112; duration=28sec
2014-07-09 14:29:52,748 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-09 14:29:52,748 INFO  [StoreCloserThread-usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.-1] regionserver.HStore: Closed family
2014-07-09 14:29:52,749 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202. because compaction request was cancelled
2014-07-09 14:29:52,749 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:52,749 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404937929187.8388f814719c533a823011bbd7f4c202. because compaction request was cancelled
2014-07-09 14:29:52,749 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b8d29d40ffb788d9b5928f6477167bfd from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,749 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0. because compaction request was cancelled
2014-07-09 14:29:52,749 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404937929187.dd022dfd5a21ce853009713c7168a2f0. because compaction request was cancelled
2014-07-09 14:29:52,750 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c. because compaction request was cancelled
2014-07-09 14:29:52,750 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404937929187.49c77d66194dd9403ff50d6bd336794c. because compaction request was cancelled
2014-07-09 14:29:52,750 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3. because compaction request was cancelled
2014-07-09 14:29:52,750 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404937929187.702db18cb43566cbcd7543685d1447c3. because compaction request was cancelled
2014-07-09 14:29:52,754 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b8d29d40ffb788d9b5928f6477167bfd from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-09 14:29:52,755 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd. on slave1,60020,1404941325989
2014-07-09 14:29:52,755 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user6,1404937929187.b8d29d40ffb788d9b5928f6477167bfd.
2014-07-09 14:29:55,044 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-09 14:29:55,045 DEBUG [Priority.RpcServer.handler=1,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-09 14:29:55,045 DEBUG [Priority.RpcServer.handler=1,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-09 14:29:55,046 DEBUG [Priority.RpcServer.handler=1,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@66a07502; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:29:55,046 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-09 14:29:55,046 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=15.9k
2014-07-09 14:29:55,047 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c9d4a0cbe3394c898452951eae20b887, keycount=71, bloomtype=NONE, size=8.8k, encoding=NONE, seqNum=2703, earliestPutTs=1402645258588
2014-07-09 14:29:55,047 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d0d5c6ee77134cfaa0fa25aa0b90947b, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=2729, earliestPutTs=1404937591096
2014-07-09 14:29:55,051 DEBUG [regionserver60020-smallCompactions-1404941363881] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:29:55,078 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/9d11290e141b4f299e20357845d13956 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/9d11290e141b4f299e20357845d13956
2014-07-09 14:29:55,094 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.HStore: Removing store files after compaction...
2014-07-09 14:29:55,105 DEBUG [regionserver60020-smallCompactions-1404941363881] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c9d4a0cbe3394c898452951eae20b887, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/c9d4a0cbe3394c898452951eae20b887
2014-07-09 14:29:55,108 DEBUG [regionserver60020-smallCompactions-1404941363881] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d0d5c6ee77134cfaa0fa25aa0b90947b, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/d0d5c6ee77134cfaa0fa25aa0b90947b
2014-07-09 14:29:55,108 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 9d11290e141b4f299e20357845d13956(size=8.8k), total size for store is 8.8k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-09 14:29:55,108 INFO  [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=15.9k, priority=1, time=160094464360821; duration=0sec
2014-07-09 14:29:55,109 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:33:46,084 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=6921, hits=55, hitRatio=0.79%, , cachingAccesses=57, cachingHits=53, cachingHitsRatio=92.98%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-09 14:35:01,667 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:35:01,678 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:35:01,678 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 369c8092e5553636aa4ff097e825820a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,678 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:35:01,679 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:35:01,680 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e20ad9e2278dfb99d0d4ac9b665b26ed from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,680 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:35:01,680 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 01d5d06c09b8c415be3f4fdd32569a18 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,690 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 369c8092e5553636aa4ff097e825820a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 369c8092e5553636aa4ff097e825820a, NAME => 'usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e20ad9e2278dfb99d0d4ac9b665b26ed from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 01d5d06c09b8c415be3f4fdd32569a18 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e20ad9e2278dfb99d0d4ac9b665b26ed, NAME => 'usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 369c8092e5553636aa4ff097e825820a
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 01d5d06c09b8c415be3f4fdd32569a18, NAME => 'usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-09 14:35:01,691 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:35:01,692 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 14:35:01,692 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:35:01,692 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 14:35:01,692 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:35:01,701 INFO  [StoreOpener-369c8092e5553636aa4ff097e825820a-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:35:01,703 INFO  [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:35:01,704 INFO  [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:35:01,708 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a
2014-07-09 14:35:01,708 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 14:35:01,709 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 14:35:01,711 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 369c8092e5553636aa4ff097e825820a; next sequenceid=1
2014-07-09 14:35:01,711 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 369c8092e5553636aa4ff097e825820a
2014-07-09 14:35:01,711 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e20ad9e2278dfb99d0d4ac9b665b26ed; next sequenceid=1
2014-07-09 14:35:01,711 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 14:35:01,713 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:35:01,714 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:35:01,727 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] catalog.MetaEditor: Updated row usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. with server=slave1,60020,1404941325989
2014-07-09 14:35:01,727 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:35:01,728 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 369c8092e5553636aa4ff097e825820a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,730 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] catalog.MetaEditor: Updated row usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. with server=slave1,60020,1404941325989
2014-07-09 14:35:01,730 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:35:01,731 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e20ad9e2278dfb99d0d4ac9b665b26ed from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,736 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 369c8092e5553636aa4ff097e825820a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,736 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 369c8092e5553636aa4ff097e825820a to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:35:01,737 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. on slave1,60020,1404941325989
2014-07-09 14:35:01,737 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e20ad9e2278dfb99d0d4ac9b665b26ed from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,737 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ab8fe21463419a7329d4993471fedc73 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,737 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e20ad9e2278dfb99d0d4ac9b665b26ed to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:35:01,738 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. on slave1,60020,1404941325989
2014-07-09 14:35:01,738 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 035ce5d09f7bc593b2c68d83d9f7e1cf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,744 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ab8fe21463419a7329d4993471fedc73 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,744 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => ab8fe21463419a7329d4993471fedc73, NAME => 'usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-09 14:35:01,745 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable ab8fe21463419a7329d4993471fedc73
2014-07-09 14:35:01,745 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:35:01,745 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 035ce5d09f7bc593b2c68d83d9f7e1cf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 14:35:01,746 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 01d5d06c09b8c415be3f4fdd32569a18; next sequenceid=1
2014-07-09 14:35:01,746 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 14:35:01,746 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 035ce5d09f7bc593b2c68d83d9f7e1cf, NAME => 'usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-09 14:35:01,747 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 14:35:01,747 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:35:01,748 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:35:01,755 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] catalog.MetaEditor: Updated row usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. with server=slave1,60020,1404941325989
2014-07-09 14:35:01,755 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:35:01,756 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 01d5d06c09b8c415be3f4fdd32569a18 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,758 INFO  [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:35:01,760 INFO  [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 14:35:01,764 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73
2014-07-09 14:35:01,765 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 14:35:01,766 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 01d5d06c09b8c415be3f4fdd32569a18 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,766 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 01d5d06c09b8c415be3f4fdd32569a18 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:35:01,766 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. on slave1,60020,1404941325989
2014-07-09 14:35:01,767 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined ab8fe21463419a7329d4993471fedc73; next sequenceid=1
2014-07-09 14:35:01,767 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node ab8fe21463419a7329d4993471fedc73
2014-07-09 14:35:01,770 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:35:01,775 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] catalog.MetaEditor: Updated row usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. with server=slave1,60020,1404941325989
2014-07-09 14:35:01,775 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:35:01,777 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ab8fe21463419a7329d4993471fedc73 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,781 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ab8fe21463419a7329d4993471fedc73 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,781 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned ab8fe21463419a7329d4993471fedc73 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:35:01,781 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. on slave1,60020,1404941325989
2014-07-09 14:35:01,806 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 035ce5d09f7bc593b2c68d83d9f7e1cf; next sequenceid=1
2014-07-09 14:35:01,806 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 14:35:01,810 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:35:01,820 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] catalog.MetaEditor: Updated row usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. with server=slave1,60020,1404941325989
2014-07-09 14:35:01,820 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:35:01,821 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 035ce5d09f7bc593b2c68d83d9f7e1cf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,828 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 035ce5d09f7bc593b2c68d83d9f7e1cf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 14:35:01,828 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 035ce5d09f7bc593b2c68d83d9f7e1cf to OPENED in zk on slave1,60020,1404941325989
2014-07-09 14:35:01,828 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. on slave1,60020,1404941325989
2014-07-09 14:35:50,687 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:35:50,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 88 synced till here 85
2014-07-09 14:35:50,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941358537 with entries=88, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941750688
2014-07-09 14:35:57,424 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:35:57,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941750688 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941757425
2014-07-09 14:36:01,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:01,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 256 synced till here 255
2014-07-09 14:36:01,422 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941757425 with entries=85, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941761350
2014-07-09 14:36:04,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:04,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 342 synced till here 340
2014-07-09 14:36:04,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941761350 with entries=86, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941764723
2014-07-09 14:36:08,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:08,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 429 synced till here 427
2014-07-09 14:36:08,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941764723 with entries=87, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941768176
2014-07-09 14:36:10,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:10,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941768176 with entries=84, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941770867
2014-07-09 14:36:13,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:13,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941770867 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941773272
2014-07-09 14:36:15,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:15,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 681 synced till here 680
2014-07-09 14:36:15,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941773272 with entries=84, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941775625
2014-07-09 14:36:18,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:19,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941775625 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941778930
2014-07-09 14:36:21,331 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:36:21,435 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.3m
2014-07-09 14:36:21,500 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:36:21,500 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.0m
2014-07-09 14:36:21,661 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:36:21,761 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:36:21,924 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:36:21,928 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-09 14:36:21,943 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:36:22,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:22,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 849 synced till here 848
2014-07-09 14:36:22,309 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941778930 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941782183
2014-07-09 14:36:25,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:28,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941782183 with entries=125, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941785849
2014-07-09 14:36:31,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:31,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1060 synced till here 1059
2014-07-09 14:36:31,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941785849 with entries=86, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941791289
2014-07-09 14:36:31,411 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=168, memsize=258.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/5558a2883ab14492be041a968ad6f83f
2014-07-09 14:36:31,427 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/5558a2883ab14492be041a968ad6f83f as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5558a2883ab14492be041a968ad6f83f
2014-07-09 14:36:31,445 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5558a2883ab14492be041a968ad6f83f, entries=941550, sequenceid=168, filesize=67.1m
2014-07-09 14:36:31,446 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.6m/271157520, currentsize=73.0m/76571200 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9946ms, sequenceid=168, compaction requested=false
2014-07-09 14:36:31,449 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 330.9m
2014-07-09 14:36:31,551 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=168, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a1ee3936ce224269b0ad70f1101de272
2014-07-09 14:36:31,609 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a1ee3936ce224269b0ad70f1101de272 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a1ee3936ce224269b0ad70f1101de272
2014-07-09 14:36:31,698 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a1ee3936ce224269b0ad70f1101de272, entries=938400, sequenceid=168, filesize=66.9m
2014-07-09 14:36:31,698 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270252720, currentsize=73.0m/76542800 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 10263ms, sequenceid=168, compaction requested=false
2014-07-09 14:36:31,699 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 329.9m
2014-07-09 14:36:31,734 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:36:31,902 INFO  [RpcServer.handler=28,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:36:31,902 INFO  [RpcServer.handler=1,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:36:31,906 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:36:33,877 INFO  [RpcServer.handler=0,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:36:37,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:37,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941791289 with entries=84, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941797054
2014-07-09 14:36:40,480 INFO  [RpcServer.handler=33,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:36:42,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:42,839 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941797054 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941802715
2014-07-09 14:36:43,090 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=215, memsize=330.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/73d606aec1064729bd79aa82371654c8
2014-07-09 14:36:43,091 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=215, memsize=329.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/93f5add43dbd4e44be70c6827e8ee8fa
2014-07-09 14:36:43,108 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/93f5add43dbd4e44be70c6827e8ee8fa as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/93f5add43dbd4e44be70c6827e8ee8fa
2014-07-09 14:36:43,109 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/73d606aec1064729bd79aa82371654c8 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/73d606aec1064729bd79aa82371654c8
2014-07-09 14:36:43,146 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/73d606aec1064729bd79aa82371654c8, entries=1204760, sequenceid=215, filesize=85.8m
2014-07-09 14:36:43,147 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~330.9m/346960640, currentsize=55.9m/58613040 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 11698ms, sequenceid=215, compaction requested=false
2014-07-09 14:36:43,148 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/93f5add43dbd4e44be70c6827e8ee8fa, entries=1201290, sequenceid=215, filesize=85.6m
2014-07-09 14:36:43,148 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~329.9m/345963600, currentsize=56.4m/59138800 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 11449ms, sequenceid=215, compaction requested=false
2014-07-09 14:36:45,068 INFO  [RpcServer.handler=19,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:36:47,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:47,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941802715 with entries=85, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941807624
2014-07-09 14:36:51,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:51,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941807624 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941811051
2014-07-09 14:36:54,758 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:54,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941811051 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941814759
2014-07-09 14:36:59,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:36:59,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941814759 with entries=92, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941819478
2014-07-09 14:37:04,069 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:37:04,070 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.3m
2014-07-09 14:37:04,186 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:37:04,187 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.2m
2014-07-09 14:37:04,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:04,363 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1657 synced till here 1656
2014-07-09 14:37:04,365 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:04,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941819478 with entries=85, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941824287
2014-07-09 14:37:04,527 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:09,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:09,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1741 synced till here 1738
2014-07-09 14:37:09,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941824287 with entries=84, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941829829
2014-07-09 14:37:13,283 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=334, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/be72003e848d424dbffdfcfe14d38bd5
2014-07-09 14:37:13,300 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/be72003e848d424dbffdfcfe14d38bd5 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/be72003e848d424dbffdfcfe14d38bd5
2014-07-09 14:37:13,316 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/be72003e848d424dbffdfcfe14d38bd5, entries=933130, sequenceid=334, filesize=66.5m
2014-07-09 14:37:13,317 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268735280, currentsize=46.6m/48866080 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9247ms, sequenceid=334, compaction requested=false
2014-07-09 14:37:13,547 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=335, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/dd34bdfd00ad4dab8bf4555a4c38fc11
2014-07-09 14:37:13,659 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/dd34bdfd00ad4dab8bf4555a4c38fc11 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/dd34bdfd00ad4dab8bf4555a4c38fc11
2014-07-09 14:37:13,740 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/dd34bdfd00ad4dab8bf4555a4c38fc11, entries=938380, sequenceid=335, filesize=66.9m
2014-07-09 14:37:13,740 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270244640, currentsize=46.4m/48604240 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9553ms, sequenceid=335, compaction requested=false
2014-07-09 14:37:15,418 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:15,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941829829 with entries=84, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941835418
2014-07-09 14:37:18,440 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:37:18,441 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.3m
2014-07-09 14:37:18,506 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:37:18,507 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.1m
2014-07-09 14:37:18,626 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:18,684 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:19,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:19,663 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1910 synced till here 1908
2014-07-09 14:37:19,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941835418 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941839530
2014-07-09 14:37:25,061 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:26,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2015 synced till here 2012
2014-07-09 14:37:27,246 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941839530 with entries=105, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941845062
2014-07-09 14:37:27,951 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=381, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/866a7f45a026429fbcefb476ef0abbeb
2014-07-09 14:37:28,028 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/866a7f45a026429fbcefb476ef0abbeb as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/866a7f45a026429fbcefb476ef0abbeb
2014-07-09 14:37:28,040 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/866a7f45a026429fbcefb476ef0abbeb, entries=933140, sequenceid=381, filesize=66.5m
2014-07-09 14:37:28,041 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268737920, currentsize=52.8m/55352080 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9601ms, sequenceid=381, compaction requested=false
2014-07-09 14:37:28,336 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=381, memsize=257.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4db80c5d4f1b4e90bcfdca2e931c2e92
2014-07-09 14:37:28,385 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4db80c5d4f1b4e90bcfdca2e931c2e92 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4db80c5d4f1b4e90bcfdca2e931c2e92
2014-07-09 14:37:28,398 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4db80c5d4f1b4e90bcfdca2e931c2e92, entries=936240, sequenceid=381, filesize=66.7m
2014-07-09 14:37:28,399 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.1m/269628800, currentsize=55.8m/58539840 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9892ms, sequenceid=381, compaction requested=false
2014-07-09 14:37:29,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:29,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2100 synced till here 2099
2014-07-09 14:37:29,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941845062 with entries=85, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941849595
2014-07-09 14:37:32,713 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:32,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941849595 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941852714
2014-07-09 14:37:36,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:36,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941852714 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941856152
2014-07-09 14:37:39,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:39,985 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2350 synced till here 2349
2014-07-09 14:37:39,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941856152 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941859895
2014-07-09 14:37:43,094 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:43,115 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2436 synced till here 2433
2014-07-09 14:37:43,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941859895 with entries=86, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941863094
2014-07-09 14:37:44,125 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:37:44,125 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.6m
2014-07-09 14:37:44,274 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:44,475 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:37:44,475 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.3m
2014-07-09 14:37:44,703 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:45,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:45,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2521 synced till here 2520
2014-07-09 14:37:45,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941863094 with entries=85, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941865672
2014-07-09 14:37:48,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:48,822 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2608 synced till here 2607
2014-07-09 14:37:48,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941865672 with entries=87, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941868672
2014-07-09 14:37:51,299 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:51,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2692 synced till here 2691
2014-07-09 14:37:51,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941868672 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941871299
2014-07-09 14:37:52,288 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:37:52,424 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:37:53,177 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=500, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/3bd1ba2780ee48468c889ef6ad13a07b
2014-07-09 14:37:53,183 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:37:53,190 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/3bd1ba2780ee48468c889ef6ad13a07b as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3bd1ba2780ee48468c889ef6ad13a07b
2014-07-09 14:37:53,200 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3bd1ba2780ee48468c889ef6ad13a07b, entries=934250, sequenceid=500, filesize=66.6m
2014-07-09 14:37:53,201 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.6m/269056080, currentsize=84.0m/88032400 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9076ms, sequenceid=500, compaction requested=true
2014-07-09 14:37:53,202 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:37:53,202 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-09 14:37:53,203 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-09 14:37:53,203 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 265.8m
2014-07-09 14:37:53,203 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:37:53,203 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:37:53,203 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:37:53,439 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:54,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:54,771 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=502, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a2c23fb613424727a1b1c14c5f0e4e06
2014-07-09 14:37:54,782 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a2c23fb613424727a1b1c14c5f0e4e06 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a2c23fb613424727a1b1c14c5f0e4e06
2014-07-09 14:37:55,426 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a2c23fb613424727a1b1c14c5f0e4e06, entries=936950, sequenceid=502, filesize=66.7m
2014-07-09 14:37:55,427 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269834640, currentsize=96.1m/100789120 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10952ms, sequenceid=502, compaction requested=true
2014-07-09 14:37:55,428 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:37:55,428 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-09 14:37:55,429 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 282.9m
2014-07-09 14:37:55,429 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-09 14:37:55,429 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:37:55,429 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:37:55,429 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:37:55,644 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:37:57,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941871299 with entries=137, filesize=101.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941874181
2014-07-09 14:37:59,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:37:59,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2914 synced till here 2912
2014-07-09 14:37:59,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941874181 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941879716
2014-07-09 14:37:59,803 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 14:38:02,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:02,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941879716 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941882382
2014-07-09 14:38:02,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 14:38:03,752 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=553, memsize=265.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9c0bc9d5660c41adafaf3fa89e8498fc
2014-07-09 14:38:03,767 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9c0bc9d5660c41adafaf3fa89e8498fc as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9c0bc9d5660c41adafaf3fa89e8498fc
2014-07-09 14:38:03,783 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9c0bc9d5660c41adafaf3fa89e8498fc, entries=967820, sequenceid=553, filesize=68.9m
2014-07-09 14:38:03,783 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~265.8m/278723280, currentsize=87.1m/91328400 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10580ms, sequenceid=553, compaction requested=true
2014-07-09 14:38:03,784 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:03,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-09 14:38:03,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-09 14:38:03,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:03,784 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 282.6m
2014-07-09 14:38:03,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:03,784 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:38:04,302 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:05,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:05,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941882382 with entries=85, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941885294
2014-07-09 14:38:06,946 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=564, memsize=282.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/8714aa33d6524622be56b9e3f66d973a
2014-07-09 14:38:06,961 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/8714aa33d6524622be56b9e3f66d973a as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/8714aa33d6524622be56b9e3f66d973a
2014-07-09 14:38:06,973 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/8714aa33d6524622be56b9e3f66d973a, entries=1030130, sequenceid=564, filesize=73.4m
2014-07-09 14:38:06,974 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~282.9m/296668000, currentsize=97.6m/102383520 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 11545ms, sequenceid=564, compaction requested=true
2014-07-09 14:38:06,976 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:06,976 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-09 14:38:06,976 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-09 14:38:06,976 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:06,976 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:06,976 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:38:08,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:08,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3167 synced till here 3165
2014-07-09 14:38:08,563 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941885294 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941888482
2014-07-09 14:38:12,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:12,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3255 synced till here 3254
2014-07-09 14:38:12,170 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941888482 with entries=88, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941892022
2014-07-09 14:38:14,210 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:38:14,210 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 257.3m
2014-07-09 14:38:14,360 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:14,460 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:38:15,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:15,778 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=607, memsize=283.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/3096f05166614353a6260e805185dfc4
2014-07-09 14:38:15,792 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/3096f05166614353a6260e805185dfc4 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3096f05166614353a6260e805185dfc4
2014-07-09 14:38:16,439 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3375 synced till here 3374
2014-07-09 14:38:16,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941892022 with entries=120, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941895498
2014-07-09 14:38:16,514 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3096f05166614353a6260e805185dfc4, entries=1030900, sequenceid=607, filesize=73.4m
2014-07-09 14:38:16,515 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~283.1m/296871440, currentsize=32.1m/33681680 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 12730ms, sequenceid=607, compaction requested=false
2014-07-09 14:38:16,515 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 275.5m
2014-07-09 14:38:16,896 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:19,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:19,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941895498 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941899340
2014-07-09 14:38:19,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941358537
2014-07-09 14:38:19,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941750688
2014-07-09 14:38:19,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941757425
2014-07-09 14:38:19,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941761350
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941764723
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941768176
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941770867
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941773272
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941775625
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941778930
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941782183
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941785849
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941791289
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941797054
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941802715
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941807624
2014-07-09 14:38:19,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941811051
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941814759
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941819478
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941824287
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941829829
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941835418
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941839530
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941845062
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941849595
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941852714
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941856152
2014-07-09 14:38:19,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941859895
2014-07-09 14:38:22,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:22,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941899340 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941902650
2014-07-09 14:38:23,368 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:38:24,832 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=667, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/940f22d2004341eca60101f74ccca96f
2014-07-09 14:38:24,844 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/940f22d2004341eca60101f74ccca96f as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/940f22d2004341eca60101f74ccca96f
2014-07-09 14:38:24,853 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/940f22d2004341eca60101f74ccca96f, entries=936880, sequenceid=667, filesize=66.8m
2014-07-09 14:38:24,854 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269813440, currentsize=91.7m/96160400 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 10643ms, sequenceid=667, compaction requested=true
2014-07-09 14:38:24,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-09 14:38:24,856 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:24,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-09 14:38:24,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:24,857 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:24,857 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:38:24,857 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 267.2m
2014-07-09 14:38:25,095 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:25,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:25,899 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:38:25,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3628 synced till here 3627
2014-07-09 14:38:25,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941902650 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941905899
2014-07-09 14:38:27,175 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=681, memsize=277.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/496540bc85934cf29db67c59937e7772
2014-07-09 14:38:27,190 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/496540bc85934cf29db67c59937e7772 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/496540bc85934cf29db67c59937e7772
2014-07-09 14:38:27,198 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/496540bc85934cf29db67c59937e7772, entries=1008450, sequenceid=681, filesize=71.9m
2014-07-09 14:38:27,199 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~277.0m/290427360, currentsize=90.3m/94696400 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10684ms, sequenceid=681, compaction requested=true
2014-07-09 14:38:27,201 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:27,201 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-09 14:38:27,201 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-09 14:38:27,201 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:27,201 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:27,201 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 268.5m
2014-07-09 14:38:27,201 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:38:27,419 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:29,132 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:29,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941905899 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941909133
2014-07-09 14:38:29,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941863094
2014-07-09 14:38:29,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941865672
2014-07-09 14:38:29,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941868672
2014-07-09 14:38:31,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:33,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3825 synced till here 3824
2014-07-09 14:38:33,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941909133 with entries=114, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941911931
2014-07-09 14:38:34,967 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=726, memsize=267.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/594a2da148e34145aacada934c582d21
2014-07-09 14:38:34,982 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/594a2da148e34145aacada934c582d21 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/594a2da148e34145aacada934c582d21
2014-07-09 14:38:35,025 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/594a2da148e34145aacada934c582d21, entries=972880, sequenceid=726, filesize=69.3m
2014-07-09 14:38:35,025 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~267.2m/280183040, currentsize=84.2m/88246560 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10168ms, sequenceid=726, compaction requested=true
2014-07-09 14:38:35,025 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:35,026 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-09 14:38:35,026 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-09 14:38:35,026 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:35,026 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:35,026 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:38:36,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:36,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941911931 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941916367
2014-07-09 14:38:36,932 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=738, memsize=268.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4b44b3efd7514e68a1b1471898568b72
2014-07-09 14:38:36,944 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4b44b3efd7514e68a1b1471898568b72 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4b44b3efd7514e68a1b1471898568b72
2014-07-09 14:38:36,953 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4b44b3efd7514e68a1b1471898568b72, entries=977450, sequenceid=738, filesize=69.7m
2014-07-09 14:38:36,954 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~268.5m/281496400, currentsize=77.5m/81306240 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9753ms, sequenceid=738, compaction requested=true
2014-07-09 14:38:36,954 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:36,954 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-09 14:38:36,955 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-09 14:38:36,955 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:36,955 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:36,955 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:38:39,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:39,649 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941916367 with entries=83, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941919610
2014-07-09 14:38:39,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941871299
2014-07-09 14:38:39,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941874181
2014-07-09 14:38:39,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941879716
2014-07-09 14:38:42,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:42,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941919610 with entries=83, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941922907
2014-07-09 14:38:45,252 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:38:45,252 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.8m
2014-07-09 14:38:45,524 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.39 GB, free=2.57 GB, max=3.96 GB, blocks=22410, accesses=764127, hits=734725, hitRatio=96.15%, , cachingAccesses=757263, cachingHits=734723, cachingHitsRatio=97.02%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-09 14:38:46,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:46,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941922907 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941926126
2014-07-09 14:38:47,854 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:38:47,854 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.3m
2014-07-09 14:38:48,071 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:49,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:49,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941926126 with entries=85, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941929253
2014-07-09 14:38:52,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:52,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4329 synced till here 4327
2014-07-09 14:38:52,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941929253 with entries=85, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941932365
2014-07-09 14:38:54,894 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=833, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/945d8a0c8bda4d1b9a12d134b7e0f0bb
2014-07-09 14:38:54,906 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/945d8a0c8bda4d1b9a12d134b7e0f0bb as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/945d8a0c8bda4d1b9a12d134b7e0f0bb
2014-07-09 14:38:54,918 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/945d8a0c8bda4d1b9a12d134b7e0f0bb, entries=935030, sequenceid=833, filesize=66.6m
2014-07-09 14:38:54,920 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.8m/269281600, currentsize=85.4m/89554080 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9666ms, sequenceid=833, compaction requested=true
2014-07-09 14:38:54,920 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:54,920 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-09 14:38:54,920 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-09 14:38:54,920 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:54,921 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:54,921 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:38:55,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:55,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941932365 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941935351
2014-07-09 14:38:55,840 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:38:55,841 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.5m
2014-07-09 14:38:56,043 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:38:57,312 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=848, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/7cdd2d9fc3a6450c8492d381d0e5a74c
2014-07-09 14:38:57,327 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/7cdd2d9fc3a6450c8492d381d0e5a74c as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/7cdd2d9fc3a6450c8492d381d0e5a74c
2014-07-09 14:38:57,848 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/7cdd2d9fc3a6450c8492d381d0e5a74c, entries=936920, sequenceid=848, filesize=66.7m
2014-07-09 14:38:57,849 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269824320, currentsize=84.3m/88353040 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9995ms, sequenceid=848, compaction requested=true
2014-07-09 14:38:57,852 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-09 14:38:57,852 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-09 14:38:57,852 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:38:57,852 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:38:57,853 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:38:57,853 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:38:58,317 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:38:58,318 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.9m
2014-07-09 14:38:58,375 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:38:58,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4495 synced till here 4494
2014-07-09 14:38:58,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941935351 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941938376
2014-07-09 14:38:58,557 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:01,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:01,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941938376 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941941324
2014-07-09 14:39:04,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:04,587 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4662 synced till here 4661
2014-07-09 14:39:04,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941941324 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941944571
2014-07-09 14:39:05,952 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=892, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/017c1aa77f0b480db78db62a2f10bcb8
2014-07-09 14:39:05,969 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/017c1aa77f0b480db78db62a2f10bcb8 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/017c1aa77f0b480db78db62a2f10bcb8
2014-07-09 14:39:05,978 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/017c1aa77f0b480db78db62a2f10bcb8, entries=933880, sequenceid=892, filesize=66.5m
2014-07-09 14:39:05,979 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268949840, currentsize=82.3m/86250720 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10138ms, sequenceid=892, compaction requested=true
2014-07-09 14:39:05,979 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:05,980 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-09 14:39:05,980 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-09 14:39:05,980 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:05,980 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:05,980 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:39:07,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:07,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4747 synced till here 4745
2014-07-09 14:39:07,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941944571 with entries=85, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941947673
2014-07-09 14:39:08,119 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=904, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/67a0ae57387641b5813b3d6052058311
2014-07-09 14:39:08,131 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/67a0ae57387641b5813b3d6052058311 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/67a0ae57387641b5813b3d6052058311
2014-07-09 14:39:08,140 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/67a0ae57387641b5813b3d6052058311, entries=935550, sequenceid=904, filesize=66.6m
2014-07-09 14:39:08,140 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.9m/269431280, currentsize=82.4m/86432480 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9822ms, sequenceid=904, compaction requested=true
2014-07-09 14:39:08,141 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:08,141 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-09 14:39:08,141 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-09 14:39:08,141 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:08,141 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:08,141 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:39:11,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:11,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941947673 with entries=85, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941951014
2014-07-09 14:39:14,456 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:15,218 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4935 synced till here 4934
2014-07-09 14:39:15,233 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941951014 with entries=103, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941954456
2014-07-09 14:39:16,156 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:39:16,157 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.6m
2014-07-09 14:39:16,400 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:18,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:18,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941954456 with entries=86, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941958578
2014-07-09 14:39:18,957 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:39:18,957 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.6m
2014-07-09 14:39:19,154 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:21,128 INFO  [RpcServer.handler=39,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:39:21,656 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:21,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941958578 with entries=83, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941961657
2014-07-09 14:39:24,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:24,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941961657 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941964570
2014-07-09 14:39:26,121 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=999, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/738b20154d284d51ab9ae032e459d12d
2014-07-09 14:39:26,130 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/738b20154d284d51ab9ae032e459d12d as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/738b20154d284d51ab9ae032e459d12d
2014-07-09 14:39:26,145 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/738b20154d284d51ab9ae032e459d12d, entries=934440, sequenceid=999, filesize=66.6m
2014-07-09 14:39:26,145 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.6m/269112000, currentsize=83.9m/87924160 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9988ms, sequenceid=999, compaction requested=true
2014-07-09 14:39:26,146 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:26,146 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-09 14:39:26,146 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-09 14:39:26,146 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:26,146 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:26,146 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:39:27,047 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:39:27,048 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.7m
2014-07-09 14:39:27,263 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:27,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:27,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941964570 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941967597
2014-07-09 14:39:28,774 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1014, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/abbe5621b9c64fe192f2e46b42891f71
2014-07-09 14:39:28,790 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/abbe5621b9c64fe192f2e46b42891f71 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/abbe5621b9c64fe192f2e46b42891f71
2014-07-09 14:39:28,799 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/abbe5621b9c64fe192f2e46b42891f71, entries=934340, sequenceid=1014, filesize=66.6m
2014-07-09 14:39:28,799 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.6m/269081360, currentsize=84.7m/88801520 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9842ms, sequenceid=1014, compaction requested=true
2014-07-09 14:39:28,802 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-09 14:39:28,802 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-09 14:39:28,802 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:28,802 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:28,803 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:28,803 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:39:29,469 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:39:29,470 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.3m
2014-07-09 14:39:29,699 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:30,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:32,613 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941967597 with entries=115, filesize=84.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941970705
2014-07-09 14:39:35,642 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:35,658 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5468 synced till here 5467
2014-07-09 14:39:35,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941970705 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941975643
2014-07-09 14:39:37,667 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1058, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9b3ce23d7af3458d936d5c8f96d5b335
2014-07-09 14:39:37,722 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9b3ce23d7af3458d936d5c8f96d5b335 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9b3ce23d7af3458d936d5c8f96d5b335
2014-07-09 14:39:37,735 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9b3ce23d7af3458d936d5c8f96d5b335, entries=934820, sequenceid=1058, filesize=66.6m
2014-07-09 14:39:37,740 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269219840, currentsize=80.4m/84323920 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10692ms, sequenceid=1058, compaction requested=true
2014-07-09 14:39:37,740 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:37,740 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-09 14:39:37,740 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-09 14:39:37,740 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:37,741 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:37,741 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:39:39,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:39,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941975643 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941979287
2014-07-09 14:39:40,063 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1071, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4a11210cc47441fba958eb36297051e6
2014-07-09 14:39:40,075 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4a11210cc47441fba958eb36297051e6 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4a11210cc47441fba958eb36297051e6
2014-07-09 14:39:40,173 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4a11210cc47441fba958eb36297051e6, entries=936830, sequenceid=1071, filesize=66.8m
2014-07-09 14:39:40,174 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.3m/269801360, currentsize=77.7m/81487600 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 10704ms, sequenceid=1071, compaction requested=true
2014-07-09 14:39:40,174 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:39:40,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-09 14:39:40,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-09 14:39:40,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:39:40,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:39:40,175 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:39:42,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:42,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5635 synced till here 5634
2014-07-09 14:39:42,745 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941979287 with entries=83, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941982710
2014-07-09 14:39:45,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:45,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5720 synced till here 5719
2014-07-09 14:39:45,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941982710 with entries=85, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941985569
2014-07-09 14:39:47,747 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:39:47,748 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 256.2m
2014-07-09 14:39:48,084 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:48,113 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:39:48,113 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.0m
2014-07-09 14:39:48,552 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:49,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:50,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5822 synced till here 5821
2014-07-09 14:39:50,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941985569 with entries=102, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941989316
2014-07-09 14:39:51,577 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:39:53,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:53,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941989316 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941993301
2014-07-09 14:39:57,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:39:57,233 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941993301 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941997189
2014-07-09 14:39:59,206 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1156, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/88cf372043b447deb69a5c20225d35a2
2014-07-09 14:39:59,221 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/88cf372043b447deb69a5c20225d35a2 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/88cf372043b447deb69a5c20225d35a2
2014-07-09 14:39:59,233 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/88cf372043b447deb69a5c20225d35a2, entries=932840, sequenceid=1156, filesize=66.4m
2014-07-09 14:39:59,233 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268633280, currentsize=25.1m/26306720 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 11485ms, sequenceid=1156, compaction requested=false
2014-07-09 14:39:59,233 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 313.2m
2014-07-09 14:39:59,615 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:39:59,910 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1165, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a089001dfac24b6fbc30f15310be1d88
2014-07-09 14:39:59,987 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a089001dfac24b6fbc30f15310be1d88 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a089001dfac24b6fbc30f15310be1d88
2014-07-09 14:39:59,999 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a089001dfac24b6fbc30f15310be1d88, entries=932150, sequenceid=1165, filesize=66.4m
2014-07-09 14:39:59,999 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.0m/268451520, currentsize=90.1m/94487360 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 11886ms, sequenceid=1165, compaction requested=true
2014-07-09 14:40:00,000 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:00,000 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-09 14:40:00,000 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-09 14:40:00,001 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:00,001 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:00,001 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:40:00,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:00,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6073 synced till here 6071
2014-07-09 14:40:00,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941997189 with entries=83, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942000118
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941882382
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941885294
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941888482
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941892022
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941895498
2014-07-09 14:40:00,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941899340
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941902650
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941905899
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941909133
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941911931
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941916367
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941919610
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941922907
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941926126
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941929253
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941932365
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941935351
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941938376
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941941324
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941944571
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941947673
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941951014
2014-07-09 14:40:00,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941954456
2014-07-09 14:40:00,265 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:40:00,265 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.1m
2014-07-09 14:40:00,461 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:03,112 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:40:03,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:03,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6161 synced till here 6159
2014-07-09 14:40:03,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942000118 with entries=88, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942003209
2014-07-09 14:40:06,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:07,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942003209 with entries=100, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942006669
2014-07-09 14:40:10,449 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1224, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/3b74b18767784e8da54050e98f1a6662
2014-07-09 14:40:10,463 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/3b74b18767784e8da54050e98f1a6662 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/3b74b18767784e8da54050e98f1a6662
2014-07-09 14:40:10,477 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/3b74b18767784e8da54050e98f1a6662, entries=932470, sequenceid=1224, filesize=66.4m
2014-07-09 14:40:10,477 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268544960, currentsize=80.9m/84848400 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10212ms, sequenceid=1224, compaction requested=true
2014-07-09 14:40:10,477 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:10,477 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-09 14:40:10,478 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 317.5m
2014-07-09 14:40:10,478 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-09 14:40:10,478 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:10,478 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:10,478 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:40:10,567 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:10,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942006669 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942010567
2014-07-09 14:40:10,747 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:11,491 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1217, memsize=314.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e5f47425fdec4e1787653103eada5180
2014-07-09 14:40:11,575 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e5f47425fdec4e1787653103eada5180 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e5f47425fdec4e1787653103eada5180
2014-07-09 14:40:11,587 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e5f47425fdec4e1787653103eada5180, entries=1146130, sequenceid=1217, filesize=81.6m
2014-07-09 14:40:11,587 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~314.8m/330074880, currentsize=100.1m/104990240 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 12354ms, sequenceid=1217, compaction requested=true
2014-07-09 14:40:11,589 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:11,590 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-09 14:40:11,590 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-09 14:40:11,590 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:11,590 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:11,590 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:40:13,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:13,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6431 synced till here 6430
2014-07-09 14:40:13,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942010567 with entries=86, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942013794
2014-07-09 14:40:13,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941958578
2014-07-09 14:40:13,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941961657
2014-07-09 14:40:13,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941964570
2014-07-09 14:40:17,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:17,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6518 synced till here 6516
2014-07-09 14:40:17,690 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942013794 with entries=87, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942017565
2014-07-09 14:40:21,197 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:21,279 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6604 synced till here 6602
2014-07-09 14:40:21,286 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:40:21,287 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.5m
2014-07-09 14:40:21,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942017565 with entries=86, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942021198
2014-07-09 14:40:21,521 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:22,434 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1276, memsize=317.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/506cc662f38d4f21b29f0c0b4d446450
2014-07-09 14:40:22,447 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/506cc662f38d4f21b29f0c0b4d446450 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/506cc662f38d4f21b29f0c0b4d446450
2014-07-09 14:40:22,461 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/506cc662f38d4f21b29f0c0b4d446450, entries=1156010, sequenceid=1276, filesize=82.3m
2014-07-09 14:40:22,474 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~317.5m/332921440, currentsize=90.1m/94441280 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 11996ms, sequenceid=1276, compaction requested=true
2014-07-09 14:40:22,477 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:22,477 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-09 14:40:22,477 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-09 14:40:22,477 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:22,477 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:22,477 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:40:24,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:24,793 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942021198 with entries=82, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942024717
2014-07-09 14:40:24,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941967597
2014-07-09 14:40:24,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941970705
2014-07-09 14:40:24,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941975643
2014-07-09 14:40:24,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941979287
2014-07-09 14:40:24,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941982710
2014-07-09 14:40:27,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:28,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942024717 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942027905
2014-07-09 14:40:31,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:31,038 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942027905 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942031008
2014-07-09 14:40:31,401 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1331, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/e4a331acdaa6440b84facf79fe1a142a
2014-07-09 14:40:31,412 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/e4a331acdaa6440b84facf79fe1a142a as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/e4a331acdaa6440b84facf79fe1a142a
2014-07-09 14:40:31,423 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/e4a331acdaa6440b84facf79fe1a142a, entries=933970, sequenceid=1331, filesize=66.5m
2014-07-09 14:40:31,423 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268976400, currentsize=80.8m/84717760 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 10136ms, sequenceid=1331, compaction requested=true
2014-07-09 14:40:31,424 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:31,424 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-09 14:40:31,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-09 14:40:31,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:31,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:31,425 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:40:31,683 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:40:31,683 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.0m
2014-07-09 14:40:31,896 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:32,878 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:40:32,878 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 257.5m
2014-07-09 14:40:33,125 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:33,985 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:34,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6936 synced till here 6935
2014-07-09 14:40:34,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942031008 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942033986
2014-07-09 14:40:37,245 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:37,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942033986 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942037245
2014-07-09 14:40:40,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:40,702 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942037245 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942040623
2014-07-09 14:40:41,782 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1384, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/9dce6f0a454f4e35a64f215955110def
2014-07-09 14:40:41,822 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/9dce6f0a454f4e35a64f215955110def as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9dce6f0a454f4e35a64f215955110def
2014-07-09 14:40:41,847 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9dce6f0a454f4e35a64f215955110def, entries=935810, sequenceid=1384, filesize=66.7m
2014-07-09 14:40:41,847 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.0m/269506480, currentsize=79.3m/83112640 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10164ms, sequenceid=1384, compaction requested=true
2014-07-09 14:40:41,848 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-09 14:40:41,848 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-09 14:40:41,849 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:41,849 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:41,849 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:40:41,849 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:42,788 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1391, memsize=257.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/473654eddbd948e7a4f768c32ed157cb
2014-07-09 14:40:42,829 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/473654eddbd948e7a4f768c32ed157cb as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/473654eddbd948e7a4f768c32ed157cb
2014-07-09 14:40:42,841 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/473654eddbd948e7a4f768c32ed157cb, entries=937690, sequenceid=1391, filesize=66.8m
2014-07-09 14:40:42,850 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.5m/270046480, currentsize=73.1m/76642800 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9972ms, sequenceid=1391, compaction requested=true
2014-07-09 14:40:42,851 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-09 14:40:42,851 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:42,851 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-09 14:40:42,851 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:42,851 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:42,851 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:40:44,575 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:40:44,576 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.4m
2014-07-09 14:40:44,737 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:45,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:45,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942040623 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942045220
2014-07-09 14:40:48,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:48,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7270 synced till here 7269
2014-07-09 14:40:48,857 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942045220 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942048829
2014-07-09 14:40:52,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:52,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7354 synced till here 7353
2014-07-09 14:40:52,264 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942048829 with entries=84, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942052241
2014-07-09 14:40:54,301 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1442, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c1ec0c2b1a714bbd8355ab24bbb9a4b7
2014-07-09 14:40:54,327 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c1ec0c2b1a714bbd8355ab24bbb9a4b7 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1ec0c2b1a714bbd8355ab24bbb9a4b7
2014-07-09 14:40:54,338 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1ec0c2b1a714bbd8355ab24bbb9a4b7, entries=933680, sequenceid=1442, filesize=66.5m
2014-07-09 14:40:54,339 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268890720, currentsize=74.4m/77999120 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9763ms, sequenceid=1442, compaction requested=true
2014-07-09 14:40:54,339 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:40:54,339 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-09 14:40:54,339 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-09 14:40:54,339 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:40:54,339 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:40:54,339 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:40:55,434 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:40:55,434 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.1m
2014-07-09 14:40:55,698 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:40:55,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:55,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7439 synced till here 7438
2014-07-09 14:40:55,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942052241 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942055710
2014-07-09 14:40:58,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:40:59,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7523 synced till here 7521
2014-07-09 14:40:59,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942055710 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942058907
2014-07-09 14:41:02,129 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:02,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7617 synced till here 7616
2014-07-09 14:41:02,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942058907 with entries=94, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942062129
2014-07-09 14:41:04,871 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1497, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/3cafadf44d2742f2903416c7612ef640
2014-07-09 14:41:04,884 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/3cafadf44d2742f2903416c7612ef640 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3cafadf44d2742f2903416c7612ef640
2014-07-09 14:41:04,893 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3cafadf44d2742f2903416c7612ef640, entries=932450, sequenceid=1497, filesize=66.4m
2014-07-09 14:41:04,920 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268536720, currentsize=72.7m/76274880 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9486ms, sequenceid=1497, compaction requested=true
2014-07-09 14:41:04,923 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:04,923 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-09 14:41:04,923 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-09 14:41:04,923 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:04,923 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:04,924 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:41:05,901 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:41:05,901 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.8m
2014-07-09 14:41:05,975 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:06,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7701 synced till here 7699
2014-07-09 14:41:06,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942062129 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942065975
2014-07-09 14:41:06,116 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:07,063 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:41:07,063 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.7m
2014-07-09 14:41:07,355 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:09,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:09,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7785 synced till here 7784
2014-07-09 14:41:09,541 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942065975 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942069510
2014-07-09 14:41:12,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:13,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942069510 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942072822
2014-07-09 14:41:15,878 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1550, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/f83c5a8e17124d18b70638b6af726628
2014-07-09 14:41:15,891 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/f83c5a8e17124d18b70638b6af726628 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f83c5a8e17124d18b70638b6af726628
2014-07-09 14:41:15,902 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f83c5a8e17124d18b70638b6af726628, entries=935100, sequenceid=1550, filesize=66.6m
2014-07-09 14:41:15,904 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269303200, currentsize=74.8m/78429200 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10003ms, sequenceid=1550, compaction requested=true
2014-07-09 14:41:15,904 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:15,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-09 14:41:15,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-09 14:41:15,905 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:15,905 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:15,905 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:41:16,421 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:16,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7953 synced till here 7952
2014-07-09 14:41:16,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942072822 with entries=83, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942076421
2014-07-09 14:41:17,140 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1557, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/fdda3761a9d44fbe910da9429f808216
2014-07-09 14:41:17,153 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/fdda3761a9d44fbe910da9429f808216 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdda3761a9d44fbe910da9429f808216
2014-07-09 14:41:17,163 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdda3761a9d44fbe910da9429f808216, entries=934520, sequenceid=1557, filesize=66.5m
2014-07-09 14:41:17,163 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269134080, currentsize=73.1m/76674720 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10100ms, sequenceid=1557, compaction requested=true
2014-07-09 14:41:17,164 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:17,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-09 14:41:17,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-09 14:41:17,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:17,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:17,164 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:41:18,663 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:41:18,664 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.4m
2014-07-09 14:41:18,878 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:20,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:20,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942076421 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942080069
2014-07-09 14:41:23,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:23,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942080069 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942083439
2014-07-09 14:41:27,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:27,632 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942083439 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942087557
2014-07-09 14:41:28,152 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1609, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/1095e9a09dac497d870a443bfd5722a1
2014-07-09 14:41:28,167 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/1095e9a09dac497d870a443bfd5722a1 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1095e9a09dac497d870a443bfd5722a1
2014-07-09 14:41:28,187 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1095e9a09dac497d870a443bfd5722a1, entries=937250, sequenceid=1609, filesize=66.8m
2014-07-09 14:41:28,187 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269919760, currentsize=70.0m/73449840 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9524ms, sequenceid=1609, compaction requested=true
2014-07-09 14:41:28,188 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:28,188 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-09 14:41:28,188 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-09 14:41:28,188 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:28,188 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:28,188 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:41:29,335 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:41:29,335 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.2m
2014-07-09 14:41:29,562 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:31,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:31,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942087557 with entries=84, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942091085
2014-07-09 14:41:34,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:34,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942091085 with entries=84, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942094100
2014-07-09 14:41:37,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:38,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942094100 with entries=96, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942097637
2014-07-09 14:41:39,062 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1663, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/698139aafee94466a26a8ec7ade2f81c
2014-07-09 14:41:39,074 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/698139aafee94466a26a8ec7ade2f81c as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/698139aafee94466a26a8ec7ade2f81c
2014-07-09 14:41:39,082 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/698139aafee94466a26a8ec7ade2f81c, entries=932920, sequenceid=1663, filesize=66.5m
2014-07-09 14:41:39,082 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268673520, currentsize=67.1m/70408480 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9747ms, sequenceid=1663, compaction requested=true
2014-07-09 14:41:39,083 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:39,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 14:41:39,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-09 14:41:39,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:39,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:39,083 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:41:40,097 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:41:40,097 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 256.4m
2014-07-09 14:41:40,339 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:40,966 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:41:40,966 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.0m
2014-07-09 14:41:41,187 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:41,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:42,006 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942097637 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942101984
2014-07-09 14:41:42,270 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:41:45,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:45,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942101984 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942105256
2014-07-09 14:41:48,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:50,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942105256 with entries=100, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942108840
2014-07-09 14:41:50,320 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1705, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/5c02c1237d2948e683bff21bdffcfba0
2014-07-09 14:41:50,331 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/5c02c1237d2948e683bff21bdffcfba0 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5c02c1237d2948e683bff21bdffcfba0
2014-07-09 14:41:50,474 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5c02c1237d2948e683bff21bdffcfba0, entries=933610, sequenceid=1705, filesize=66.5m
2014-07-09 14:41:50,475 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268854960, currentsize=23.3m/24422480 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 10378ms, sequenceid=1705, compaction requested=true
2014-07-09 14:41:50,475 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:50,475 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-09 14:41:50,476 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-09 14:41:50,476 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 316.8m
2014-07-09 14:41:50,476 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:50,476 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:50,476 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:41:50,681 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:50,997 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1716, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/87ca59cb96c14d038a95ae4c090a74c1
2014-07-09 14:41:51,015 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/87ca59cb96c14d038a95ae4c090a74c1 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/87ca59cb96c14d038a95ae4c090a74c1
2014-07-09 14:41:51,027 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/87ca59cb96c14d038a95ae4c090a74c1, entries=932240, sequenceid=1716, filesize=66.5m
2014-07-09 14:41:51,028 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268477520, currentsize=74.3m/77933680 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10062ms, sequenceid=1716, compaction requested=true
2014-07-09 14:41:51,031 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:41:51,031 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 14:41:51,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-09 14:41:51,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:41:51,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:41:51,032 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:41:53,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:53,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8819 synced till here 8818
2014-07-09 14:41:53,233 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942108840 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942113204
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941985569
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941989316
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941993301
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941997189
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942000118
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942003209
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942006669
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942010567
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942013794
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942017565
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942021198
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942024717
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942027905
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942031008
2014-07-09 14:41:53,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942033986
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942037245
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942040623
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942045220
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942048829
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942052241
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942055710
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942058907
2014-07-09 14:41:53,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942062129
2014-07-09 14:41:53,268 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:41:53,269 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.1m
2014-07-09 14:41:53,595 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:41:57,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:41:57,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942113204 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942117539
2014-07-09 14:42:01,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:01,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942117539 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942121204
2014-07-09 14:42:02,817 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1762, memsize=316.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/5d2971b8f45e42dbbe64ba6c0a4647fb
2014-07-09 14:42:02,828 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/5d2971b8f45e42dbbe64ba6c0a4647fb as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5d2971b8f45e42dbbe64ba6c0a4647fb
2014-07-09 14:42:02,836 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5d2971b8f45e42dbbe64ba6c0a4647fb, entries=1153310, sequenceid=1762, filesize=82.2m
2014-07-09 14:42:02,837 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~316.8m/332143760, currentsize=87.3m/91490000 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 12361ms, sequenceid=1762, compaction requested=true
2014-07-09 14:42:02,838 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:02,838 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 14:42:02,838 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-09 14:42:02,838 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:02,838 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:02,838 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:42:03,199 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1775, memsize=257.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c7424b6594374a34909f224c11c018c0
2014-07-09 14:42:03,217 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c7424b6594374a34909f224c11c018c0 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c7424b6594374a34909f224c11c018c0
2014-07-09 14:42:03,249 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c7424b6594374a34909f224c11c018c0, entries=936200, sequenceid=1775, filesize=66.7m
2014-07-09 14:42:03,249 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.1m/269618800, currentsize=68.2m/71545440 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9980ms, sequenceid=1775, compaction requested=true
2014-07-09 14:42:03,249 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:03,249 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 14:42:03,250 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-09 14:42:03,250 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:03,250 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:03,250 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:42:04,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:04,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9069 synced till here 9068
2014-07-09 14:42:04,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942121204 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942124495
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942065975
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942069510
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942072822
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942076421
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942080069
2014-07-09 14:42:04,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942083439
2014-07-09 14:42:04,991 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:42:04,991 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 257.1m
2014-07-09 14:42:05,144 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:08,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:08,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942124495 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942128080
2014-07-09 14:42:11,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:12,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942128080 with entries=100, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942131439
2014-07-09 14:42:14,068 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1829, memsize=257.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a2776ed447e04b42b498d7ce6a1dec5d
2014-07-09 14:42:14,081 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/a2776ed447e04b42b498d7ce6a1dec5d as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a2776ed447e04b42b498d7ce6a1dec5d
2014-07-09 14:42:14,092 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a2776ed447e04b42b498d7ce6a1dec5d, entries=936170, sequenceid=1829, filesize=66.7m
2014-07-09 14:42:14,092 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.1m/269610640, currentsize=63.4m/66482880 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9101ms, sequenceid=1829, compaction requested=true
2014-07-09 14:42:14,093 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:14,093 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 20 blocking
2014-07-09 14:42:14,093 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 11 files from compaction candidates
2014-07-09 14:42:14,093 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:14,093 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:14,093 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:42:16,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:16,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942131439 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942136058
2014-07-09 14:42:16,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942087557
2014-07-09 14:42:16,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942091085
2014-07-09 14:42:16,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942094100
2014-07-09 14:42:16,671 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:42:16,671 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.1m
2014-07-09 14:42:16,925 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:19,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:20,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942136058 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942139953
2014-07-09 14:42:25,679 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1882, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/23fc57266e274a1cba3489e47b3a985f
2014-07-09 14:42:25,701 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/23fc57266e274a1cba3489e47b3a985f as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/23fc57266e274a1cba3489e47b3a985f
2014-07-09 14:42:25,709 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/23fc57266e274a1cba3489e47b3a985f, entries=932430, sequenceid=1882, filesize=66.4m
2014-07-09 14:42:25,783 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268530560, currentsize=46.8m/49033200 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9112ms, sequenceid=1882, compaction requested=true
2014-07-09 14:42:25,784 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:25,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 20 blocking
2014-07-09 14:42:25,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 11 files from compaction candidates
2014-07-09 14:42:25,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:25,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:25,784 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:42:25,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:25,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9502 synced till here 9501
2014-07-09 14:42:25,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942139953 with entries=84, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942145885
2014-07-09 14:42:29,094 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:42:29,094 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.3m
2014-07-09 14:42:29,308 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:29,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:29,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942145885 with entries=84, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942149607
2014-07-09 14:42:31,514 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:42:31,514 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.0m
2014-07-09 14:42:31,667 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:32,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:32,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942149607 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942152489
2014-07-09 14:42:36,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:36,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942152489 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942156503
2014-07-09 14:42:39,651 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1928, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/78f1642125214e94ad35e327ed169d09
2014-07-09 14:42:39,666 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/78f1642125214e94ad35e327ed169d09 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78f1642125214e94ad35e327ed169d09
2014-07-09 14:42:39,678 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78f1642125214e94ad35e327ed169d09, entries=933340, sequenceid=1928, filesize=66.5m
2014-07-09 14:42:39,680 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268794880, currentsize=73.4m/76951440 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10586ms, sequenceid=1928, compaction requested=true
2014-07-09 14:42:39,681 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:39,681 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 20 blocking
2014-07-09 14:42:39,681 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 11 files from compaction candidates
2014-07-09 14:42:39,681 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:39,682 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:39,682 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:42:40,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:40,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9835 synced till here 9834
2014-07-09 14:42:40,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942156503 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942160230
2014-07-09 14:42:41,878 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1942, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/af621bc752664213b0072000ac3deae0
2014-07-09 14:42:41,894 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/af621bc752664213b0072000ac3deae0 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/af621bc752664213b0072000ac3deae0
2014-07-09 14:42:41,903 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/af621bc752664213b0072000ac3deae0, entries=935740, sequenceid=1942, filesize=66.7m
2014-07-09 14:42:41,931 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269487120, currentsize=68.5m/71879440 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 10417ms, sequenceid=1942, compaction requested=true
2014-07-09 14:42:41,932 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:41,932 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 20 blocking
2014-07-09 14:42:41,932 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 11 files from compaction candidates
2014-07-09 14:42:41,933 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:41,933 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:41,933 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:42:44,027 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:42:44,028 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.1m
2014-07-09 14:42:44,308 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:44,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:44,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9919 synced till here 9918
2014-07-09 14:42:44,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942160230 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942164350
2014-07-09 14:42:48,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:48,193 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10005 synced till here 10004
2014-07-09 14:42:48,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942164350 with entries=86, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942168169
2014-07-09 14:42:52,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:52,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942168169 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942172186
2014-07-09 14:42:53,532 INFO  [RpcServer.handler=5,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:42:53,532 INFO  [RpcServer.handler=32,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:42:53,532 INFO  [RpcServer.handler=37,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:42:53,532 INFO  [RpcServer.handler=26,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:42:54,217 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1995, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/7c10f75d27dd4889acfd03f5405c9cb9
2014-07-09 14:42:54,239 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/7c10f75d27dd4889acfd03f5405c9cb9 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7c10f75d27dd4889acfd03f5405c9cb9
2014-07-09 14:42:54,250 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7c10f75d27dd4889acfd03f5405c9cb9, entries=932370, sequenceid=1995, filesize=66.5m
2014-07-09 14:42:54,251 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268514880, currentsize=74.6m/78262160 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 10223ms, sequenceid=1995, compaction requested=true
2014-07-09 14:42:54,251 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:42:54,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-09 14:42:54,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 12 files from compaction candidates
2014-07-09 14:42:54,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:42:54,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:42:54,252 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:42:56,233 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:56,233 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:42:56,233 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.2m
2014-07-09 14:42:56,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942172186 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942176233
2014-07-09 14:42:56,441 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:42:59,534 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:42:59,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942176233 with entries=83, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942179535
2014-07-09 14:43:03,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:03,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942179535 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942183190
2014-07-09 14:43:06,169 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2048, memsize=257.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/550d6f2093a34b7eae2f956724a58ad5
2014-07-09 14:43:06,183 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/550d6f2093a34b7eae2f956724a58ad5 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/550d6f2093a34b7eae2f956724a58ad5
2014-07-09 14:43:06,194 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/550d6f2093a34b7eae2f956724a58ad5, entries=936350, sequenceid=2048, filesize=66.7m
2014-07-09 14:43:06,194 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.2m/269660240, currentsize=71.3m/74768960 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9961ms, sequenceid=2048, compaction requested=true
2014-07-09 14:43:06,195 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:43:06,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-09 14:43:06,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 12 files from compaction candidates
2014-07-09 14:43:06,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:43:06,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:43:06,195 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:43:06,211 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:43:06,212 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.8m
2014-07-09 14:43:06,453 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:06,712 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:06,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10421 synced till here 10420
2014-07-09 14:43:06,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942183190 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942186712
2014-07-09 14:43:09,701 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:43:09,702 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.6m
2014-07-09 14:43:09,868 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:11,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:11,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942186712 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942191594
2014-07-09 14:43:15,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:15,663 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10588 synced till here 10587
2014-07-09 14:43:15,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942191594 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942195630
2014-07-09 14:43:16,117 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2094, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/8a6ad8bbdc0a4fa4b7e1b2fe2890249b
2014-07-09 14:43:16,129 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/8a6ad8bbdc0a4fa4b7e1b2fe2890249b as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/8a6ad8bbdc0a4fa4b7e1b2fe2890249b
2014-07-09 14:43:16,174 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/8a6ad8bbdc0a4fa4b7e1b2fe2890249b, entries=935040, sequenceid=2094, filesize=66.6m
2014-07-09 14:43:16,175 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269284240, currentsize=60.6m/63562800 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9964ms, sequenceid=2094, compaction requested=true
2014-07-09 14:43:16,175 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:43:16,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-09 14:43:16,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 12 files from compaction candidates
2014-07-09 14:43:16,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:43:16,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:43:16,175 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:43:19,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:19,994 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2108, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/d8d6e73fcef84af596235bd9c5f27fa8
2014-07-09 14:43:20,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942195630 with entries=87, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942199390
2014-07-09 14:43:20,074 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/d8d6e73fcef84af596235bd9c5f27fa8 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d8d6e73fcef84af596235bd9c5f27fa8
2014-07-09 14:43:20,095 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d8d6e73fcef84af596235bd9c5f27fa8, entries=934390, sequenceid=2108, filesize=66.5m
2014-07-09 14:43:20,095 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.6m/269096400, currentsize=62.2m/65224640 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 10393ms, sequenceid=2108, compaction requested=true
2014-07-09 14:43:20,096 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:43:20,096 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-09 14:43:20,096 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 12 files from compaction candidates
2014-07-09 14:43:20,096 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:43:20,096 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:43:20,096 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:43:22,818 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:43:22,819 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.4m
2014-07-09 14:43:23,061 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:23,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:23,742 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942199390 with entries=82, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942203721
2014-07-09 14:43:28,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:28,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942203721 with entries=83, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942208341
2014-07-09 14:43:32,482 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2161, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/8dc1524666c84b2fbe4c180b6fa27eb2
2014-07-09 14:43:32,496 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/8dc1524666c84b2fbe4c180b6fa27eb2 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8dc1524666c84b2fbe4c180b6fa27eb2
2014-07-09 14:43:32,504 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8dc1524666c84b2fbe4c180b6fa27eb2, entries=933460, sequenceid=2161, filesize=66.5m
2014-07-09 14:43:32,518 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268829840, currentsize=54.3m/56961840 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9700ms, sequenceid=2161, compaction requested=true
2014-07-09 14:43:32,518 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:43:32,518 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-09 14:43:32,518 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-09 14:43:32,518 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:43:32,518 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:43:32,518 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:43:33,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:33,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942208341 with entries=85, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942213156
2014-07-09 14:43:37,087 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:43:37,087 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 257.1m
2014-07-09 14:43:37,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:37,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11010 synced till here 11009
2014-07-09 14:43:37,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942213156 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942217288
2014-07-09 14:43:37,461 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:42,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:42,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11094 synced till here 11093
2014-07-09 14:43:42,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942217288 with entries=84, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942222279
2014-07-09 14:43:46,151 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.82 GB, free=136.09 MB, max=3.96 GB, blocks=61903, accesses=5590647, hits=5498466, hitRatio=98.35%, , cachingAccesses=5583783, cachingHits=5498464, cachingHitsRatio=98.47%, evictions=9, evicted=23115, evictedPerRun=2568.333251953125
2014-07-09 14:43:46,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:46,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942222279 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942226260
2014-07-09 14:43:46,861 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2215, memsize=257.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/c31ca82fa5174080bf5bdc9617a89223
2014-07-09 14:43:46,887 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/c31ca82fa5174080bf5bdc9617a89223 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c31ca82fa5174080bf5bdc9617a89223
2014-07-09 14:43:46,899 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c31ca82fa5174080bf5bdc9617a89223, entries=936100, sequenceid=2215, filesize=66.7m
2014-07-09 14:43:46,900 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.1m/269589440, currentsize=57.6m/60441120 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9813ms, sequenceid=2215, compaction requested=true
2014-07-09 14:43:46,900 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:43:46,900 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-09 14:43:46,900 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-09 14:43:46,900 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:43:46,900 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:43:46,900 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:43:49,162 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:43:49,163 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 257.5m
2014-07-09 14:43:49,417 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:49,704 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:43:49,704 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 256.2m
2014-07-09 14:43:49,964 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:43:50,647 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:50,696 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942226260 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942230647
2014-07-09 14:43:52,927 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:43:55,256 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:43:55,303 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942230647 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942235256
2014-07-09 14:43:59,962 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2261, memsize=257.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/b4c2b14e44b04ebe8ab2f4cd03f479b3
2014-07-09 14:43:59,989 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/b4c2b14e44b04ebe8ab2f4cd03f479b3 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/b4c2b14e44b04ebe8ab2f4cd03f479b3
2014-07-09 14:44:00,012 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/b4c2b14e44b04ebe8ab2f4cd03f479b3, entries=937630, sequenceid=2261, filesize=66.8m
2014-07-09 14:44:00,013 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.5m/270030000, currentsize=59.2m/62048640 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10851ms, sequenceid=2261, compaction requested=true
2014-07-09 14:44:00,013 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:00,014 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-09 14:44:00,014 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-09 14:44:00,014 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:00,014 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:00,014 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 295.6m
2014-07-09 14:44:00,014 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:44:00,207 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:00,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:00,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942235256 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942240322
2014-07-09 14:44:00,819 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2254, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/c34a25bc7b7948728840cef4b261bd8e
2014-07-09 14:44:00,834 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/c34a25bc7b7948728840cef4b261bd8e as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/c34a25bc7b7948728840cef4b261bd8e
2014-07-09 14:44:00,844 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/c34a25bc7b7948728840cef4b261bd8e, entries=932790, sequenceid=2254, filesize=66.4m
2014-07-09 14:44:00,845 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268618160, currentsize=18.1m/18980320 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 11141ms, sequenceid=2254, compaction requested=true
2014-07-09 14:44:00,845 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-09 14:44:00,846 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:00,845 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-09 14:44:00,846 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:00,846 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:00,846 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:44:05,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:05,242 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942240322 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942245211
2014-07-09 14:44:05,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942097637
2014-07-09 14:44:05,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942101984
2014-07-09 14:44:05,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942105256
2014-07-09 14:44:05,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942108840
2014-07-09 14:44:05,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942113204
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942117539
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942121204
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942124495
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942128080
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942131439
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942136058
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942139953
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942145885
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942149607
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942152489
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942156503
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942160230
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942164350
2014-07-09 14:44:05,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942168169
2014-07-09 14:44:05,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942172186
2014-07-09 14:44:05,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942176233
2014-07-09 14:44:05,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942179535
2014-07-09 14:44:05,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942183190
2014-07-09 14:44:07,832 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:44:07,833 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.4m
2014-07-09 14:44:08,040 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:09,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:09,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942245211 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942249759
2014-07-09 14:44:11,615 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2299, memsize=295.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/3149fc5a224343a2b005dab1ac94c314
2014-07-09 14:44:11,631 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/3149fc5a224343a2b005dab1ac94c314 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3149fc5a224343a2b005dab1ac94c314
2014-07-09 14:44:11,650 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3149fc5a224343a2b005dab1ac94c314, entries=1076410, sequenceid=2299, filesize=76.7m
2014-07-09 14:44:11,651 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~295.6m/309996480, currentsize=60.2m/63139040 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 11637ms, sequenceid=2299, compaction requested=true
2014-07-09 14:44:11,652 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:11,652 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-09 14:44:11,652 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-09 14:44:11,652 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:11,652 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:11,653 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:44:14,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:15,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942249759 with entries=99, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942254538
2014-07-09 14:44:15,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942186712
2014-07-09 14:44:15,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942191594
2014-07-09 14:44:15,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942195630
2014-07-09 14:44:18,627 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2327, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/220634410fef40f4a3e5e2b44a459940
2014-07-09 14:44:18,966 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/220634410fef40f4a3e5e2b44a459940 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/220634410fef40f4a3e5e2b44a459940
2014-07-09 14:44:18,978 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/220634410fef40f4a3e5e2b44a459940, entries=933470, sequenceid=2327, filesize=66.5m
2014-07-09 14:44:18,978 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268830400, currentsize=62.0m/64993920 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 11145ms, sequenceid=2327, compaction requested=true
2014-07-09 14:44:18,979 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:18,979 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-09 14:44:18,979 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 14 files from compaction candidates
2014-07-09 14:44:18,979 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:18,979 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:18,979 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:44:20,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:20,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11775 synced till here 11774
2014-07-09 14:44:20,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942254538 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942260073
2014-07-09 14:44:20,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942199390
2014-07-09 14:44:20,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942203721
2014-07-09 14:44:20,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942208341
2014-07-09 14:44:22,663 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:44:22,721 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.5m
2014-07-09 14:44:22,891 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:24,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:24,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11859 synced till here 11858
2014-07-09 14:44:24,341 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942260073 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942264275
2014-07-09 14:44:28,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:28,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942264275 with entries=83, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942268671
2014-07-09 14:44:32,554 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2381, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/3475e54300e64c65b1c4504cc0b2f8a5
2014-07-09 14:44:32,565 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/3475e54300e64c65b1c4504cc0b2f8a5 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/3475e54300e64c65b1c4504cc0b2f8a5
2014-07-09 14:44:32,588 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/3475e54300e64c65b1c4504cc0b2f8a5, entries=934040, sequenceid=2381, filesize=66.6m
2014-07-09 14:44:32,588 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268998480, currentsize=60.9m/63876880 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9924ms, sequenceid=2381, compaction requested=true
2014-07-09 14:44:32,588 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:32,589 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-09 14:44:32,589 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 14 files from compaction candidates
2014-07-09 14:44:32,589 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:32,589 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:32,589 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:44:32,611 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:32,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12027 synced till here 12025
2014-07-09 14:44:32,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942268671 with entries=85, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942272611
2014-07-09 14:44:32,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942213156
2014-07-09 14:44:32,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942217288
2014-07-09 14:44:32,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942222279
2014-07-09 14:44:34,613 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:44:34,613 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.7m
2014-07-09 14:44:34,807 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:37,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:38,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942272611 with entries=94, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942277073
2014-07-09 14:44:43,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:43,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942277073 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942283012
2014-07-09 14:44:45,128 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2427, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/7438d9864c0244f8b3c25c6ad144aa30
2014-07-09 14:44:45,143 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/7438d9864c0244f8b3c25c6ad144aa30 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/7438d9864c0244f8b3c25c6ad144aa30
2014-07-09 14:44:45,155 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/7438d9864c0244f8b3c25c6ad144aa30, entries=934530, sequenceid=2427, filesize=66.6m
2014-07-09 14:44:45,167 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269137120, currentsize=55.8m/58471120 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10554ms, sequenceid=2427, compaction requested=true
2014-07-09 14:44:45,168 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:45,168 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-09 14:44:45,168 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 14 files from compaction candidates
2014-07-09 14:44:45,168 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:45,168 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:45,168 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:44:46,020 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:44:46,020 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 257.3m
2014-07-09 14:44:46,182 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:47,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:47,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942283012 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942287595
2014-07-09 14:44:52,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:52,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942287595 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942292289
2014-07-09 14:44:52,692 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:44:52,693 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 257.4m
2014-07-09 14:44:52,925 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:44:55,836 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2466, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/3a1338eb786a426da2979e82aa0f1e38
2014-07-09 14:44:55,847 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/3a1338eb786a426da2979e82aa0f1e38 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3a1338eb786a426da2979e82aa0f1e38
2014-07-09 14:44:55,859 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3a1338eb786a426da2979e82aa0f1e38, entries=936820, sequenceid=2466, filesize=66.8m
2014-07-09 14:44:55,864 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.3m/269796000, currentsize=56.0m/58670000 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9844ms, sequenceid=2466, compaction requested=true
2014-07-09 14:44:55,867 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:44:55,867 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-09 14:44:55,867 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 14 files from compaction candidates
2014-07-09 14:44:55,867 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:44:55,867 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:44:55,867 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:44:56,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:44:56,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942292289 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942296666
2014-07-09 14:45:00,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:00,911 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942296666 with entries=83, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942300872
2014-07-09 14:45:03,491 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2494, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/7e354200982d45a2beda783790527257
2014-07-09 14:45:03,503 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/7e354200982d45a2beda783790527257 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7e354200982d45a2beda783790527257
2014-07-09 14:45:03,522 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7e354200982d45a2beda783790527257, entries=937140, sequenceid=2494, filesize=66.8m
2014-07-09 14:45:03,526 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269889200, currentsize=59.1m/61979120 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 10834ms, sequenceid=2494, compaction requested=true
2014-07-09 14:45:03,528 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:45:03,528 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-09 14:45:03,528 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-09 14:45:03,528 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:45:03,528 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:45:03,528 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:45:05,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:05,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942300872 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942305747
2014-07-09 14:45:08,393 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:45:08,394 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.6m
2014-07-09 14:45:08,659 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:45:10,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:10,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12704 synced till here 12703
2014-07-09 14:45:10,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942305747 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942310805
2014-07-09 14:45:15,197 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:15,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942310805 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942315198
2014-07-09 14:45:18,717 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2547, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/92574d98e3b54570bdfe0c4d867de3c3
2014-07-09 14:45:18,752 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/92574d98e3b54570bdfe0c4d867de3c3 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/92574d98e3b54570bdfe0c4d867de3c3
2014-07-09 14:45:18,777 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/92574d98e3b54570bdfe0c4d867de3c3, entries=934210, sequenceid=2547, filesize=66.6m
2014-07-09 14:45:18,783 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.6m/269045600, currentsize=62.4m/65402720 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 10389ms, sequenceid=2547, compaction requested=true
2014-07-09 14:45:18,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-09 14:45:18,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-09 14:45:18,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:45:18,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:45:18,785 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:45:18,785 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:45:20,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:20,236 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12872 synced till here 12871
2014-07-09 14:45:20,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942315198 with entries=85, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942320029
2014-07-09 14:45:20,984 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:45:20,985 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.1m
2014-07-09 14:45:21,158 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:45:25,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:25,548 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942320029 with entries=84, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942325502
2014-07-09 14:45:30,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:30,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942325502 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942330079
2014-07-09 14:45:30,540 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2593, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/a9746e2e85ad4d75a7e20f81b7507f29
2014-07-09 14:45:30,567 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/a9746e2e85ad4d75a7e20f81b7507f29 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a9746e2e85ad4d75a7e20f81b7507f29
2014-07-09 14:45:30,575 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a9746e2e85ad4d75a7e20f81b7507f29, entries=932550, sequenceid=2593, filesize=66.5m
2014-07-09 14:45:30,578 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268566960, currentsize=49.2m/51584880 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9593ms, sequenceid=2593, compaction requested=true
2014-07-09 14:45:30,578 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:45:30,578 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-09 14:45:30,578 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-09 14:45:30,578 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:45:30,578 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:45:30,578 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:45:32,249 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:45:32,249 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.8m
2014-07-09 14:45:32,416 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:45:34,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:34,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942330079 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942334628
2014-07-09 14:45:39,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:39,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942334628 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942339040
2014-07-09 14:45:39,844 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:45:39,844 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.4m
2014-07-09 14:45:40,081 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:45:41,871 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2632, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/dd7b32bb51da4a2488864193a80789a7
2014-07-09 14:45:41,887 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/dd7b32bb51da4a2488864193a80789a7 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/dd7b32bb51da4a2488864193a80789a7
2014-07-09 14:45:41,905 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/dd7b32bb51da4a2488864193a80789a7, entries=934860, sequenceid=2632, filesize=66.6m
2014-07-09 14:45:41,906 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269231840, currentsize=54.3m/56896080 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9657ms, sequenceid=2632, compaction requested=true
2014-07-09 14:45:41,906 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:45:41,906 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-09 14:45:41,906 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-09 14:45:41,906 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:45:41,906 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:45:41,907 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:45:43,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:43,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942339040 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942343554
2014-07-09 14:45:47,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:48,605 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942343554 with entries=95, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942347987
2014-07-09 14:45:49,606 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2660, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b25d25c5c5814fcc84900f0ebdbd9eb0
2014-07-09 14:45:49,623 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b25d25c5c5814fcc84900f0ebdbd9eb0 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b25d25c5c5814fcc84900f0ebdbd9eb0
2014-07-09 14:45:49,658 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b25d25c5c5814fcc84900f0ebdbd9eb0, entries=933510, sequenceid=2660, filesize=66.5m
2014-07-09 14:45:49,659 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268843600, currentsize=56.2m/58926000 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9815ms, sequenceid=2660, compaction requested=true
2014-07-09 14:45:49,659 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:45:49,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-09 14:45:49,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-09 14:45:49,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:45:49,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:45:49,660 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:45:53,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:53,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942347987 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942353523
2014-07-09 14:45:54,066 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:45:54,067 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.1m
2014-07-09 14:45:54,250 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:45:58,552 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:45:58,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13551 synced till here 13550
2014-07-09 14:45:58,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942353523 with entries=85, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942358552
2014-07-09 14:46:03,311 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2713, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e9c84ec1f1dd4271a6b0d6644d50bed2
2014-07-09 14:46:03,328 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e9c84ec1f1dd4271a6b0d6644d50bed2 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e9c84ec1f1dd4271a6b0d6644d50bed2
2014-07-09 14:46:03,344 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e9c84ec1f1dd4271a6b0d6644d50bed2, entries=932600, sequenceid=2713, filesize=66.5m
2014-07-09 14:46:03,503 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268580800, currentsize=45.1m/47299520 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9434ms, sequenceid=2713, compaction requested=true
2014-07-09 14:46:03,503 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:03,503 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-09 14:46:03,504 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-09 14:46:03,504 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:03,504 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:03,504 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:46:03,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:03,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942358552 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942363905
2014-07-09 14:46:07,317 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:46:07,318 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.4m
2014-07-09 14:46:07,513 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:08,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:08,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942363905 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942368445
2014-07-09 14:46:13,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:13,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942368445 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942373359
2014-07-09 14:46:17,457 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2759, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/bb5e9d93f30e4a7ea8ab592053ff3c9f
2014-07-09 14:46:17,471 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/bb5e9d93f30e4a7ea8ab592053ff3c9f as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/bb5e9d93f30e4a7ea8ab592053ff3c9f
2014-07-09 14:46:17,487 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/bb5e9d93f30e4a7ea8ab592053ff3c9f, entries=933650, sequenceid=2759, filesize=66.5m
2014-07-09 14:46:17,487 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268882480, currentsize=54.1m/56711200 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 10170ms, sequenceid=2759, compaction requested=true
2014-07-09 14:46:17,488 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:17,488 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-09 14:46:17,488 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-09 14:46:17,488 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:17,488 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:17,488 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:46:17,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:17,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942373359 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942377517
2014-07-09 14:46:19,046 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:46:19,047 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.2m
2014-07-09 14:46:19,201 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:22,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:22,934 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942377517 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942382848
2014-07-09 14:46:22,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 14:46:22,935 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 254.5m
2014-07-09 14:46:23,193 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:23,556 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:46:26,686 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:46:27,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:27,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14054 synced till here 14052
2014-07-09 14:46:27,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942382848 with entries=86, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942387638
2014-07-09 14:46:28,459 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2798, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/962fa5757d8342cfacaf29b328caf2e2
2014-07-09 14:46:28,473 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/962fa5757d8342cfacaf29b328caf2e2 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/962fa5757d8342cfacaf29b328caf2e2
2014-07-09 14:46:28,483 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/962fa5757d8342cfacaf29b328caf2e2, entries=932820, sequenceid=2798, filesize=66.5m
2014-07-09 14:46:28,484 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268646160, currentsize=52.7m/55251520 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9436ms, sequenceid=2798, compaction requested=true
2014-07-09 14:46:28,484 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:28,484 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-09 14:46:28,484 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-09 14:46:28,484 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., flushing=true, writesEnabled=true
2014-07-09 14:46:28,484 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:28,484 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:28,484 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:46:28,485 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 267.6m
2014-07-09 14:46:28,671 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:32,596 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2799, memsize=254.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/6f23e20e29264db7b2733271fe41deb5
2014-07-09 14:46:32,608 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/6f23e20e29264db7b2733271fe41deb5 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6f23e20e29264db7b2733271fe41deb5
2014-07-09 14:46:32,620 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6f23e20e29264db7b2733271fe41deb5, entries=926830, sequenceid=2799, filesize=66.0m
2014-07-09 14:46:32,620 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~254.5m/266901200, currentsize=15.4m/16149680 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9685ms, sequenceid=2799, compaction requested=true
2014-07-09 14:46:32,621 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-09 14:46:32,621 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-09 14:46:32,621 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:32,621 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:32,621 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:32,621 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:46:33,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:33,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942387638 with entries=85, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942393047
2014-07-09 14:46:33,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942226260
2014-07-09 14:46:33,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942230647
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942235256
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942240322
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942245211
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942249759
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942254538
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942260073
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942264275
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942268671
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942272611
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942277073
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942283012
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942287595
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942292289
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942296666
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942300872
2014-07-09 14:46:33,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942305747
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942310805
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942315198
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942320029
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942325502
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942330079
2014-07-09 14:46:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942334628
2014-07-09 14:46:38,156 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2833, memsize=267.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/12480f8bcfa044df94f29ec25df311dd
2014-07-09 14:46:38,171 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/12480f8bcfa044df94f29ec25df311dd as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/12480f8bcfa044df94f29ec25df311dd
2014-07-09 14:46:38,193 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/12480f8bcfa044df94f29ec25df311dd, entries=974170, sequenceid=2833, filesize=69.4m
2014-07-09 14:46:38,194 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~267.6m/280553520, currentsize=43.2m/45350640 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9709ms, sequenceid=2833, compaction requested=true
2014-07-09 14:46:38,194 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:38,194 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-09 14:46:38,194 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-09 14:46:38,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:38,195 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:38,195 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:46:38,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:38,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14223 synced till here 14222
2014-07-09 14:46:38,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942393047 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942398551
2014-07-09 14:46:38,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942339040
2014-07-09 14:46:38,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942343554
2014-07-09 14:46:38,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942347987
2014-07-09 14:46:43,509 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:46:43,510 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.5m
2014-07-09 14:46:43,599 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:43,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942398551 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942403599
2014-07-09 14:46:43,761 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:48,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:48,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14392 synced till here 14391
2014-07-09 14:46:48,983 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942403599 with entries=86, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942408913
2014-07-09 14:46:52,461 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2879, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/fb586941fcd3470ea8421c95bad5ec4c
2014-07-09 14:46:52,474 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/fb586941fcd3470ea8421c95bad5ec4c as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fb586941fcd3470ea8421c95bad5ec4c
2014-07-09 14:46:52,492 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fb586941fcd3470ea8421c95bad5ec4c, entries=933810, sequenceid=2879, filesize=66.5m
2014-07-09 14:46:52,500 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268929360, currentsize=42.1m/44142880 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 8990ms, sequenceid=2879, compaction requested=true
2014-07-09 14:46:52,502 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:46:52,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-09 14:46:52,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-09 14:46:52,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:46:52,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:46:52,502 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:46:54,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:54,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942408913 with entries=86, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942414721
2014-07-09 14:46:54,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942353523
2014-07-09 14:46:54,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942358552
2014-07-09 14:46:58,429 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:46:58,430 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.4m
2014-07-09 14:46:58,584 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:46:59,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:46:59,833 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942414721 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942419791
2014-07-09 14:47:05,042 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:05,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942419791 with entries=95, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942425042
2014-07-09 14:47:08,057 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2925, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/e3f1a09502fa4ddda6bbdd199ff8507e
2014-07-09 14:47:08,072 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/e3f1a09502fa4ddda6bbdd199ff8507e as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/e3f1a09502fa4ddda6bbdd199ff8507e
2014-07-09 14:47:08,086 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/e3f1a09502fa4ddda6bbdd199ff8507e, entries=933480, sequenceid=2925, filesize=66.5m
2014-07-09 14:47:08,086 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268835440, currentsize=52.8m/55392720 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9656ms, sequenceid=2925, compaction requested=true
2014-07-09 14:47:08,087 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:47:08,087 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-09 14:47:08,087 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-09 14:47:08,087 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:47:08,087 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:47:08,087 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:47:09,593 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:47:09,593 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.1m
2014-07-09 14:47:09,813 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:47:10,440 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:10,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942425042 with entries=84, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942430440
2014-07-09 14:47:10,478 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942363905
2014-07-09 14:47:10,478 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942368445
2014-07-09 14:47:10,478 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942373359
2014-07-09 14:47:15,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:15,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942430440 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942435162
2014-07-09 14:47:18,637 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2964, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/70356b511997474182a98d7d4700abad
2014-07-09 14:47:18,673 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/70356b511997474182a98d7d4700abad as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/70356b511997474182a98d7d4700abad
2014-07-09 14:47:18,684 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/70356b511997474182a98d7d4700abad, entries=932470, sequenceid=2964, filesize=66.5m
2014-07-09 14:47:18,685 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268544720, currentsize=46.6m/48860960 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9092ms, sequenceid=2964, compaction requested=true
2014-07-09 14:47:18,685 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:47:18,685 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-09 14:47:18,687 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-09 14:47:18,687 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:47:18,687 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:47:18,687 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:47:19,730 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:47:19,730 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 257.6m
2014-07-09 14:47:19,976 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:19,977 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:47:20,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14912 synced till here 14909
2014-07-09 14:47:20,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942435162 with entries=86, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942439977
2014-07-09 14:47:20,026 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942377517
2014-07-09 14:47:24,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:24,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942439977 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942444620
2014-07-09 14:47:29,152 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3000, memsize=257.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/deec67dadd40487f949a463878e35365
2014-07-09 14:47:29,189 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/deec67dadd40487f949a463878e35365 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/deec67dadd40487f949a463878e35365
2014-07-09 14:47:29,203 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/deec67dadd40487f949a463878e35365, entries=937860, sequenceid=3000, filesize=66.9m
2014-07-09 14:47:29,204 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.6m/270097840, currentsize=50.1m/52509520 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9474ms, sequenceid=3000, compaction requested=true
2014-07-09 14:47:29,204 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:47:29,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-09 14:47:29,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 18 files from compaction candidates
2014-07-09 14:47:29,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:47:29,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:47:29,205 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:47:29,969 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:30,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942444620 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942449969
2014-07-09 14:47:32,992 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:47:32,992 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.3m
2014-07-09 14:47:33,218 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:47:35,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:35,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942449969 with entries=83, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942455242
2014-07-09 14:47:40,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:40,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942455242 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942460495
2014-07-09 14:47:42,515 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3045, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e097fa95a140410fb6bd1c2aa93f8b84
2014-07-09 14:47:42,536 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/e097fa95a140410fb6bd1c2aa93f8b84 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e097fa95a140410fb6bd1c2aa93f8b84
2014-07-09 14:47:42,549 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e097fa95a140410fb6bd1c2aa93f8b84, entries=933210, sequenceid=3045, filesize=66.5m
2014-07-09 14:47:42,631 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268756880, currentsize=54.3m/56938800 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9639ms, sequenceid=3045, compaction requested=true
2014-07-09 14:47:42,634 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:47:42,634 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-09 14:47:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 18 files from compaction candidates
2014-07-09 14:47:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:47:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:47:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:47:44,333 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:44,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942460495 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942464334
2014-07-09 14:47:45,892 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:47:45,892 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.5m
2014-07-09 14:47:46,049 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:47:49,197 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:49,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942464334 with entries=84, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942469197
2014-07-09 14:47:55,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:55,059 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3091, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/605151e95bb2412a932d3ad2950a5a79
2014-07-09 14:47:55,088 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/605151e95bb2412a932d3ad2950a5a79 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/605151e95bb2412a932d3ad2950a5a79
2014-07-09 14:47:55,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942469197 with entries=84, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942475059
2014-07-09 14:47:55,110 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/605151e95bb2412a932d3ad2950a5a79, entries=933840, sequenceid=3091, filesize=66.5m
2014-07-09 14:47:55,110 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268938640, currentsize=43.4m/45496720 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9218ms, sequenceid=3091, compaction requested=true
2014-07-09 14:47:55,110 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:47:55,111 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-09 14:47:55,111 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 18 files from compaction candidates
2014-07-09 14:47:55,111 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:47:55,111 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:47:55,111 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:47:58,533 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:47:58,533 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.3m
2014-07-09 14:47:58,757 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:47:59,476 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:47:59,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942475059 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942479476
2014-07-09 14:48:04,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:04,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15671 synced till here 15669
2014-07-09 14:48:04,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942479476 with entries=88, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942484708
2014-07-09 14:48:07,768 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3130, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c1fc0788e43940778409efaf14423d33
2014-07-09 14:48:07,797 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c1fc0788e43940778409efaf14423d33 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1fc0788e43940778409efaf14423d33
2014-07-09 14:48:07,872 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1fc0788e43940778409efaf14423d33, entries=933310, sequenceid=3130, filesize=66.5m
2014-07-09 14:48:07,883 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268785360, currentsize=51.3m/53840240 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9350ms, sequenceid=3130, compaction requested=true
2014-07-09 14:48:07,884 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:48:07,884 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-09 14:48:07,884 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 18 files from compaction candidates
2014-07-09 14:48:07,884 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:48:07,885 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:48:07,885 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:48:08,307 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:48:08,307 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.9m
2014-07-09 14:48:08,465 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:48:10,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:10,446 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942484708 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942490420
2014-07-09 14:48:15,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:15,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15840 synced till here 15839
2014-07-09 14:48:15,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942490420 with entries=85, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942495240
2014-07-09 14:48:18,044 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3166, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b31da402be464d17b919064e90e4ff88
2014-07-09 14:48:18,055 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b31da402be464d17b919064e90e4ff88 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b31da402be464d17b919064e90e4ff88
2014-07-09 14:48:18,070 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b31da402be464d17b919064e90e4ff88, entries=935450, sequenceid=3166, filesize=66.7m
2014-07-09 14:48:18,071 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.9m/269401840, currentsize=49.5m/51898640 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9764ms, sequenceid=3166, compaction requested=true
2014-07-09 14:48:18,071 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:48:18,071 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-09 14:48:18,071 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-09 14:48:18,071 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:48:18,071 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:48:18,071 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:48:19,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:20,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942495240 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942499984
2014-07-09 14:48:22,242 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:48:22,242 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.3m
2014-07-09 14:48:22,451 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:48:25,180 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:25,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942499984 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942505181
2014-07-09 14:48:30,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:30,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942505181 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942510092
2014-07-09 14:48:31,450 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3211, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/b6fa10283cae4fe6a6c921de50c6556f
2014-07-09 14:48:31,524 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/b6fa10283cae4fe6a6c921de50c6556f as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b6fa10283cae4fe6a6c921de50c6556f
2014-07-09 14:48:31,535 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b6fa10283cae4fe6a6c921de50c6556f, entries=933090, sequenceid=3211, filesize=66.5m
2014-07-09 14:48:31,549 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268722880, currentsize=48.0m/50347120 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9307ms, sequenceid=3211, compaction requested=true
2014-07-09 14:48:31,550 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:48:31,550 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-09 14:48:31,551 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-09 14:48:31,551 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:48:31,551 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:48:31,551 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:48:34,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:34,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942510092 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942514901
2014-07-09 14:48:35,673 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:48:35,674 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.1m
2014-07-09 14:48:35,911 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:48:40,529 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:40,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16257 synced till here 16256
2014-07-09 14:48:40,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942514901 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942520529
2014-07-09 14:48:44,658 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3257, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/c586c4a03f1c482c8a565ce2dd4625a1
2014-07-09 14:48:44,672 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/c586c4a03f1c482c8a565ce2dd4625a1 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c586c4a03f1c482c8a565ce2dd4625a1
2014-07-09 14:48:44,682 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c586c4a03f1c482c8a565ce2dd4625a1, entries=932590, sequenceid=3257, filesize=66.5m
2014-07-09 14:48:44,683 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268578400, currentsize=45.4m/47596400 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9009ms, sequenceid=3257, compaction requested=true
2014-07-09 14:48:44,683 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:48:44,683 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-09 14:48:44,683 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-09 14:48:44,683 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:48:44,684 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:48:44,684 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:48:45,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:45,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942520529 with entries=82, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942525339
2014-07-09 14:48:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.85 GB, free=111.94 MB, max=3.96 GB, blocks=62257, accesses=11333073, hits=11158245, hitRatio=98.45%, , cachingAccesses=11326209, cachingHits=11158243, cachingHitsRatio=98.51%, evictions=41, evicted=105295, evictedPerRun=2568.170654296875
2014-07-09 14:48:47,501 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:48:47,502 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.7m
2014-07-09 14:48:47,647 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:48:50,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:50,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942525339 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942530605
2014-07-09 14:48:55,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:48:55,787 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16507 synced till here 16506
2014-07-09 14:48:55,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942530605 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942535746
2014-07-09 14:48:56,268 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3296, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/cc8e89fc604941b5879893af546fde53
2014-07-09 14:48:56,286 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/cc8e89fc604941b5879893af546fde53 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/cc8e89fc604941b5879893af546fde53
2014-07-09 14:48:56,297 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/cc8e89fc604941b5879893af546fde53, entries=934480, sequenceid=3296, filesize=66.6m
2014-07-09 14:48:56,394 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269121200, currentsize=40.5m/42452480 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 8892ms, sequenceid=3296, compaction requested=true
2014-07-09 14:48:56,396 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:48:56,396 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-09 14:48:56,396 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-09 14:48:56,396 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:48:56,396 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:48:56,396 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:48:58,804 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:48:58,805 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 257.4m
2014-07-09 14:48:58,958 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:00,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:01,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16594 synced till here 16593
2014-07-09 14:49:01,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942535746 with entries=87, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942540754
2014-07-09 14:49:05,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:05,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16679 synced till here 16677
2014-07-09 14:49:05,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942540754 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942545904
2014-07-09 14:49:07,576 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:49:07,576 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 256.3m
2014-07-09 14:49:07,812 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:08,290 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3333, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/053246811ea44861986507fa064763fc
2014-07-09 14:49:08,310 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/053246811ea44861986507fa064763fc as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/053246811ea44861986507fa064763fc
2014-07-09 14:49:08,331 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/053246811ea44861986507fa064763fc, entries=937270, sequenceid=3333, filesize=66.8m
2014-07-09 14:49:08,332 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269924560, currentsize=48.3m/50614400 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9527ms, sequenceid=3333, compaction requested=true
2014-07-09 14:49:08,332 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:08,332 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 14:49:08,332 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 14:49:08,332 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:49:08,333 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:08,333 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:49:11,159 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:11,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942545904 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942551159
2014-07-09 14:49:12,066 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:49:12,066 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.4m
2014-07-09 14:49:12,326 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:16,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:16,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942551159 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942556291
2014-07-09 14:49:17,080 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3348, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/55282ea871d44e6cbf855fd4ae4faf1e
2014-07-09 14:49:17,092 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/55282ea871d44e6cbf855fd4ae4faf1e as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/55282ea871d44e6cbf855fd4ae4faf1e
2014-07-09 14:49:17,115 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/55282ea871d44e6cbf855fd4ae4faf1e, entries=933190, sequenceid=3348, filesize=66.5m
2014-07-09 14:49:17,115 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268735760, currentsize=14.5m/15222080 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9539ms, sequenceid=3348, compaction requested=true
2014-07-09 14:49:17,115 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:17,115 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-09 14:49:17,115 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-09 14:49:17,116 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:49:17,116 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:17,116 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:49:20,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:20,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942556291 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942560778
2014-07-09 14:49:20,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942382848
2014-07-09 14:49:20,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942387638
2014-07-09 14:49:20,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942393047
2014-07-09 14:49:20,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942398551
2014-07-09 14:49:20,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942403599
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942408913
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942414721
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942419791
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942425042
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942430440
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942435162
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942439977
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942444620
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942449969
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942455242
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942460495
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942464334
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942469197
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942475059
2014-07-09 14:49:20,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942479476
2014-07-09 14:49:20,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942484708
2014-07-09 14:49:20,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942490420
2014-07-09 14:49:20,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942495240
2014-07-09 14:49:21,604 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3377, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/df73698b7e134d3bb08f42c73ab6fde6
2014-07-09 14:49:21,616 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/df73698b7e134d3bb08f42c73ab6fde6 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df73698b7e134d3bb08f42c73ab6fde6
2014-07-09 14:49:21,624 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df73698b7e134d3bb08f42c73ab6fde6, entries=933650, sequenceid=3377, filesize=66.5m
2014-07-09 14:49:21,624 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268885200, currentsize=49.5m/51910320 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9558ms, sequenceid=3377, compaction requested=true
2014-07-09 14:49:21,624 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:21,624 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 14:49:21,624 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 14:49:21,625 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:49:21,625 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:21,625 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:49:26,243 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:49:26,244 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.7m
2014-07-09 14:49:26,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:26,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942560778 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942566386
2014-07-09 14:49:26,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942499984
2014-07-09 14:49:26,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942505181
2014-07-09 14:49:26,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942510092
2014-07-09 14:49:26,491 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:31,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:31,467 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942566386 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942571444
2014-07-09 14:49:35,331 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3423, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0046a0d576c249abad89b943ef6da41f
2014-07-09 14:49:35,358 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0046a0d576c249abad89b943ef6da41f as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0046a0d576c249abad89b943ef6da41f
2014-07-09 14:49:35,374 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0046a0d576c249abad89b943ef6da41f, entries=934630, sequenceid=3423, filesize=66.6m
2014-07-09 14:49:35,374 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269166160, currentsize=48.2m/50496880 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 9130ms, sequenceid=3423, compaction requested=true
2014-07-09 14:49:35,375 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:35,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 14:49:35,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 14:49:35,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:49:35,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:35,375 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:49:36,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:36,271 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942571444 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942576248
2014-07-09 14:49:36,271 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942514901
2014-07-09 14:49:36,272 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942520529
2014-07-09 14:49:38,087 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:49:38,087 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.5m
2014-07-09 14:49:38,292 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:41,213 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:41,236 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942576248 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942581214
2014-07-09 14:49:46,764 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:46,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942581214 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942586764
2014-07-09 14:49:47,286 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3462, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/bf2f24f17e0646fcaf6ed406108f9ba9
2014-07-09 14:49:47,300 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/bf2f24f17e0646fcaf6ed406108f9ba9 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf2f24f17e0646fcaf6ed406108f9ba9
2014-07-09 14:49:47,334 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf2f24f17e0646fcaf6ed406108f9ba9, entries=934030, sequenceid=3462, filesize=66.6m
2014-07-09 14:49:47,342 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268992560, currentsize=47.9m/50243120 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9255ms, sequenceid=3462, compaction requested=true
2014-07-09 14:49:47,346 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:47,346 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 14:49:47,347 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 14:49:47,347 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:49:47,347 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:47,347 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:49:48,815 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:49:48,815 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 256.5m
2014-07-09 14:49:49,033 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:49:51,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:51,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942586764 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942591748
2014-07-09 14:49:51,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942525339
2014-07-09 14:49:51,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942530605
2014-07-09 14:49:57,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:49:57,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17515 synced till here 17514
2014-07-09 14:49:57,447 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942591748 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942597413
2014-07-09 14:49:57,966 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3499, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/9a04919087404502bfe6c4eba5bda02a
2014-07-09 14:49:57,983 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/9a04919087404502bfe6c4eba5bda02a as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/9a04919087404502bfe6c4eba5bda02a
2014-07-09 14:49:57,994 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/9a04919087404502bfe6c4eba5bda02a, entries=933880, sequenceid=3499, filesize=66.6m
2014-07-09 14:49:57,994 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.5m/268950000, currentsize=42.0m/44065280 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 9179ms, sequenceid=3499, compaction requested=true
2014-07-09 14:49:57,995 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:49:57,995 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:49:57,995 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:49:57,995 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:49:57,995 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:49:57,995 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:50:02,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:02,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17598 synced till here 17596
2014-07-09 14:50:02,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942597413 with entries=83, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942602882
2014-07-09 14:50:02,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942535746
2014-07-09 14:50:02,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942540754
2014-07-09 14:50:03,048 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:50:03,049 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 256.7m
2014-07-09 14:50:03,293 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:50:07,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:07,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942602882 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942607290
2014-07-09 14:50:12,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:12,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942607290 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942612097
2014-07-09 14:50:12,564 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3543, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/c0e17bb55aa24c1394f627769dc59788
2014-07-09 14:50:12,615 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/c0e17bb55aa24c1394f627769dc59788 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c0e17bb55aa24c1394f627769dc59788
2014-07-09 14:50:12,625 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c0e17bb55aa24c1394f627769dc59788, entries=934750, sequenceid=3543, filesize=66.6m
2014-07-09 14:50:12,625 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269200000, currentsize=54.4m/57022240 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9576ms, sequenceid=3543, compaction requested=true
2014-07-09 14:50:12,627 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:50:12,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:50:12,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:50:12,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:50:12,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:50:12,627 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:50:16,906 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:50:16,907 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 256.3m
2014-07-09 14:50:17,053 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:50:17,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:17,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942612097 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942617818
2014-07-09 14:50:23,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:23,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942617818 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942623729
2014-07-09 14:50:25,722 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3589, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/a6d0dcb3442f424bae08ce3492b43b57
2014-07-09 14:50:25,833 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/a6d0dcb3442f424bae08ce3492b43b57 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a6d0dcb3442f424bae08ce3492b43b57
2014-07-09 14:50:25,855 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a6d0dcb3442f424bae08ce3492b43b57, entries=933040, sequenceid=3589, filesize=66.5m
2014-07-09 14:50:25,856 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268708320, currentsize=40.2m/42199520 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 8949ms, sequenceid=3589, compaction requested=true
2014-07-09 14:50:25,856 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:50:25,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:50:25,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:50:25,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:50:25,856 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:50:25,856 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:50:28,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:28,536 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942623729 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942628475
2014-07-09 14:50:29,226 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:50:29,226 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 256.3m
2014-07-09 14:50:29,410 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:50:34,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:34,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942628475 with entries=85, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942634363
2014-07-09 14:50:38,958 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3628, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/561c77e552b247458d819ee298aed3f9
2014-07-09 14:50:38,978 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/561c77e552b247458d819ee298aed3f9 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/561c77e552b247458d819ee298aed3f9
2014-07-09 14:50:39,183 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/561c77e552b247458d819ee298aed3f9, entries=933330, sequenceid=3628, filesize=66.5m
2014-07-09 14:50:39,197 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268792400, currentsize=43.6m/45681600 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 9971ms, sequenceid=3628, compaction requested=true
2014-07-09 14:50:39,198 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:50:39,198 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:50:39,198 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:50:39,198 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:50:39,200 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:50:39,200 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:50:40,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:40,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18188 synced till here 18186
2014-07-09 14:50:40,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942634363 with entries=85, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942640036
2014-07-09 14:50:40,912 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:50:40,913 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 14:50:40,914 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:50:40,914 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:50:40,914 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:50:40,915 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:50:40,915 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:50:40,915 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:50:44,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:44,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942640036 with entries=84, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942644865
2014-07-09 14:50:50,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:50,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942644865 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942650271
2014-07-09 14:50:54,390 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:50:54,390 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 14:50:54,390 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:50:54,391 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:50:54,391 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:50:54,391 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:50:54,391 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:50:54,391 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:50:55,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:50:55,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942650271 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942655294
2014-07-09 14:51:01,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:01,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942655294 with entries=84, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942661111
2014-07-09 14:51:06,134 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:06,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942661111 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942666134
2014-07-09 14:51:09,609 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:51:09,609 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 14:51:09,610 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:51:09,610 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:51:09,610 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:51:09,610 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:51:09,610 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:51:09,611 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:51:11,361 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:11,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18690 synced till here 18689
2014-07-09 14:51:11,390 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942666134 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942671361
2014-07-09 14:51:16,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:16,797 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942671361 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942676774
2014-07-09 14:51:22,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:22,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942676774 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942682318
2014-07-09 14:51:22,443 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:51:22,443 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 14:51:22,443 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:51:22,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-09 14:51:22,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 21 files from compaction candidates
2014-07-09 14:51:22,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:51:22,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:51:22,444 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:51:28,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:28,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942682318 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942688613
2014-07-09 14:51:33,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:33,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942688613 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942693010
2014-07-09 14:51:38,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:38,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942693010 with entries=84, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942698740
2014-07-09 14:51:44,543 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:44,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19192 synced till here 19191
2014-07-09 14:51:44,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942698740 with entries=85, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942704544
2014-07-09 14:51:49,720 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:49,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942704544 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942709720
2014-07-09 14:51:55,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:51:55,568 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942709720 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942715512
2014-07-09 14:52:00,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:00,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942715512 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942720624
2014-07-09 14:52:00,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 14:52:00,682 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 255.7m
2014-07-09 14:52:00,722 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:52:00,722 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., flushing=true, writesEnabled=true
2014-07-09 14:52:00,926 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:52:06,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:06,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942720624 with entries=86, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942726479
2014-07-09 14:52:09,937 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3896, memsize=255.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/266843fa05534fe987eb70676491ca43
2014-07-09 14:52:10,009 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/266843fa05534fe987eb70676491ca43 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/266843fa05534fe987eb70676491ca43
2014-07-09 14:52:10,025 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/266843fa05534fe987eb70676491ca43, entries=930890, sequenceid=3896, filesize=66.3m
2014-07-09 14:52:10,032 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~255.7m/268072160, currentsize=12.6m/13183360 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9350ms, sequenceid=3896, compaction requested=true
2014-07-09 14:52:10,034 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:52:10,034 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-09 14:52:10,034 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-09 14:52:10,034 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:52:10,034 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:52:10,034 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:52:11,159 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90247ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:52:11,159 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 687.0m
2014-07-09 14:52:11,762 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:52:12,591 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:12,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942726479 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942732592
2014-07-09 14:52:12,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942545904
2014-07-09 14:52:12,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942551159
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942556291
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942560778
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942566386
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942571444
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942576248
2014-07-09 14:52:12,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942581214
2014-07-09 14:52:17,615 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:17,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942732592 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942737615
2014-07-09 14:52:23,016 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:23,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942737615 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942743016
2014-07-09 14:52:24,954 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90565ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:52:24,955 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 680.5m
2014-07-09 14:52:25,630 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:52:29,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:29,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942743016 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942749307
2014-07-09 14:52:35,370 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:35,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942749307 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942755370
2014-07-09 14:52:39,074 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3943, memsize=688.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/c1b3caead681423c82c89715066525fa
2014-07-09 14:52:39,086 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/c1b3caead681423c82c89715066525fa as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/c1b3caead681423c82c89715066525fa
2014-07-09 14:52:39,102 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/c1b3caead681423c82c89715066525fa, entries=2506910, sequenceid=3943, filesize=178.6m
2014-07-09 14:52:39,127 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~688.5m/721971120, currentsize=127.9m/134070800 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 27968ms, sequenceid=3943, compaction requested=true
2014-07-09 14:52:39,131 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:52:39,131 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:52:39,131 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:52:39,131 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:52:39,131 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:52:39,131 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:52:40,031 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90422ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:52:40,032 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 679.0m
2014-07-09 14:52:40,657 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:40,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942755370 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942760657
2014-07-09 14:52:40,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942586764
2014-07-09 14:52:40,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942591748
2014-07-09 14:52:40,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942597413
2014-07-09 14:52:40,688 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:52:46,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:47,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942760657 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942766923
2014-07-09 14:52:52,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:52,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942766923 with entries=84, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942772264
2014-07-09 14:52:53,110 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3982, memsize=680.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/208e3e5e2d404804817262a25615b194
2014-07-09 14:52:53,124 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/208e3e5e2d404804817262a25615b194 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/208e3e5e2d404804817262a25615b194
2014-07-09 14:52:53,149 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/208e3e5e2d404804817262a25615b194, entries=2477610, sequenceid=3982, filesize=176.5m
2014-07-09 14:52:53,149 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~680.5m/713530000, currentsize=129.1m/135365040 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 28194ms, sequenceid=3982, compaction requested=true
2014-07-09 14:52:53,150 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:52:53,150 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:52:53,150 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90708ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:52:53,150 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:52:53,150 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:52:53,150 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:52:53,150 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 677.4m
2014-07-09 14:52:53,150 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:52:53,745 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:52:58,860 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:52:58,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942772264 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942778861
2014-07-09 14:52:58,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942602882
2014-07-09 14:52:58,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942607290
2014-07-09 14:53:04,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:04,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942778861 with entries=85, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942784795
2014-07-09 14:53:08,099 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4027, memsize=679.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/405c9e22ef8c4e10a539d5f3be40d0a9
2014-07-09 14:53:08,123 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/405c9e22ef8c4e10a539d5f3be40d0a9 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/405c9e22ef8c4e10a539d5f3be40d0a9
2014-07-09 14:53:08,133 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/405c9e22ef8c4e10a539d5f3be40d0a9, entries=2472240, sequenceid=4027, filesize=176.1m
2014-07-09 14:53:08,171 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~679.0m/711984480, currentsize=121.5m/127353600 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 28139ms, sequenceid=4027, compaction requested=true
2014-07-09 14:53:08,173 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:08,173 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:08,173 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:08,173 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:08,173 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:08,174 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:53:09,328 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:53:09,328 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 14:53:09,329 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:09,329 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:09,329 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:09,329 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:09,329 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:09,329 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:53:10,912 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:10,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942784795 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942790912
2014-07-09 14:53:10,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942612097
2014-07-09 14:53:10,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942617818
2014-07-09 14:53:10,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942623729
2014-07-09 14:53:18,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:18,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942790912 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942798297
2014-07-09 14:53:20,637 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4065, memsize=677.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/a50b9e861fb84b5191c4b29efaff27ea
2014-07-09 14:53:20,716 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/a50b9e861fb84b5191c4b29efaff27ea as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/a50b9e861fb84b5191c4b29efaff27ea
2014-07-09 14:53:20,725 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/a50b9e861fb84b5191c4b29efaff27ea, entries=2466460, sequenceid=4065, filesize=175.7m
2014-07-09 14:53:20,736 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~677.4m/710322320, currentsize=110.4m/115734880 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 27586ms, sequenceid=4065, compaction requested=true
2014-07-09 14:53:20,738 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:20,738 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:20,738 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:20,738 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:20,738 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:20,738 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:53:24,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:24,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942798297 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942804619
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942628475
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942634363
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942640036
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942644865
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942650271
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942655294
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942661111
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942666134
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942671361
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942676774
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942682318
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942688613
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942693010
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942698740
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942704544
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942709720
2014-07-09 14:53:24,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942715512
2014-07-09 14:53:24,693 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:53:24,693 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 14:53:24,694 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:24,694 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:24,694 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:24,694 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:24,695 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:24,695 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:53:30,297 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:30,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942804619 with entries=83, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942810297
2014-07-09 14:53:31,832 INFO  [RpcServer.handler=6,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 14:53:36,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:36,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20782 synced till here 20781
2014-07-09 14:53:36,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942810297 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942816391
2014-07-09 14:53:41,536 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:53:41,536 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 14:53:41,536 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:41,536 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:41,536 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:41,536 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:41,537 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:41,537 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:53:43,586 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:43,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942816391 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942823586
2014-07-09 14:53:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.89 GB, free=69.6 MB, max=3.96 GB, blocks=62897, accesses=17283596, hits=17020729, hitRatio=98.47%, , cachingAccesses=17276732, cachingHits=17020727, cachingHitsRatio=98.51%, evictions=75, evicted=192622, evictedPerRun=2568.293212890625
2014-07-09 14:53:48,792 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:48,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942823586 with entries=85, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942828793
2014-07-09 14:53:55,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:53:55,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21036 synced till here 21035
2014-07-09 14:53:55,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942828793 with entries=85, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942835008
2014-07-09 14:53:55,221 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:53:55,221 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 14:53:55,221 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:53:55,222 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-09 14:53:55,222 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 22 files from compaction candidates
2014-07-09 14:53:55,222 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:53:55,222 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:53:55,222 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:54:00,712 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:00,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21120 synced till here 21119
2014-07-09 14:54:00,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942835008 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942840713
2014-07-09 14:54:06,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:06,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942840713 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942846563
2014-07-09 14:54:12,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:12,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942846563 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942852231
2014-07-09 14:54:18,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:18,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21370 synced till here 21369
2014-07-09 14:54:18,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942852231 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942858174
2014-07-09 14:54:24,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:24,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942858174 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942864516
2014-07-09 14:54:30,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:30,192 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942864516 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942870165
2014-07-09 14:54:36,491 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:36,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942870165 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942876491
2014-07-09 14:54:39,749 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90421ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:54:39,750 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 641.9m
2014-07-09 14:54:40,361 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:54:43,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:43,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942876491 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942883204
2014-07-09 14:54:49,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:49,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942883204 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942889390
2014-07-09 14:54:55,612 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90919ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:54:55,613 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 643.7m
2014-07-09 14:54:55,722 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:54:55,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942889390 with entries=84, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942895722
2014-07-09 14:54:56,200 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:55:03,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:03,756 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942895722 with entries=84, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942903598
2014-07-09 14:55:05,733 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4357, memsize=641.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/5327801a7d504514b9952473796b17ee
2014-07-09 14:55:05,809 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/5327801a7d504514b9952473796b17ee as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5327801a7d504514b9952473796b17ee
2014-07-09 14:55:05,820 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5327801a7d504514b9952473796b17ee, entries=2336990, sequenceid=4357, filesize=166.5m
2014-07-09 14:55:05,821 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~641.9m/673032880, currentsize=99.3m/104135040 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 26070ms, sequenceid=4357, compaction requested=true
2014-07-09 14:55:05,821 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:05,821 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:05,821 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:05,822 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:05,822 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:05,822 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:55:09,687 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:09,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22042 synced till here 22041
2014-07-09 14:55:10,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942903598 with entries=87, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942909687
2014-07-09 14:55:12,292 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90756ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:55:12,292 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 640.4m
2014-07-09 14:55:12,919 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:55:15,471 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:15,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942909687 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942915648
2014-07-09 14:55:19,036 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:55:21,148 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4398, memsize=645.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/b1e9e459177a4ab9836fef1a9e1261d7
2014-07-09 14:55:21,163 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/b1e9e459177a4ab9836fef1a9e1261d7 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b1e9e459177a4ab9836fef1a9e1261d7
2014-07-09 14:55:21,174 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b1e9e459177a4ab9836fef1a9e1261d7, entries=2348960, sequenceid=4398, filesize=167.3m
2014-07-09 14:55:21,174 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~645.1m/676483040, currentsize=101.9m/106891040 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 25561ms, sequenceid=4398, compaction requested=true
2014-07-09 14:55:21,174 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:21,174 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:21,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:21,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:21,175 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 258.6m
2014-07-09 14:55:21,175 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:21,175 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:55:21,451 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:21,465 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:55:21,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942915648 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942921452
2014-07-09 14:55:27,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:27,823 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942921452 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942927789
2014-07-09 14:55:32,049 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4449, memsize=258.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/19015d7a681d460caffb6177e4e8a220
2014-07-09 14:55:32,062 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/19015d7a681d460caffb6177e4e8a220 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/19015d7a681d460caffb6177e4e8a220
2014-07-09 14:55:32,073 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/19015d7a681d460caffb6177e4e8a220, entries=941510, sequenceid=4449, filesize=67.1m
2014-07-09 14:55:32,078 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.6m/271127840, currentsize=12.7m/13344880 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 10902ms, sequenceid=4449, compaction requested=true
2014-07-09 14:55:32,079 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:32,079 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-09 14:55:32,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-09 14:55:32,080 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 96859ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:55:32,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:55:32,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:32,142 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:55:32,143 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 662.2m
2014-07-09 14:55:32,765 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:55:33,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:33,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22377 synced till here 22376
2014-07-09 14:55:33,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942927789 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942933704
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942720624
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942726479
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942732592
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942737615
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942743016
2014-07-09 14:55:33,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942749307
2014-07-09 14:55:37,556 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4440, memsize=640.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/745daeb873e64f6fbe5ddd254890d8f4
2014-07-09 14:55:37,581 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/745daeb873e64f6fbe5ddd254890d8f4 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/745daeb873e64f6fbe5ddd254890d8f4
2014-07-09 14:55:37,595 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/745daeb873e64f6fbe5ddd254890d8f4, entries=2331630, sequenceid=4440, filesize=166.1m
2014-07-09 14:55:37,595 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~640.4m/671490160, currentsize=107.2m/112429120 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 25303ms, sequenceid=4440, compaction requested=true
2014-07-09 14:55:37,596 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:37,596 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:37,596 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:37,596 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:37,596 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:37,596 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:55:40,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:40,111 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942933704 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942940084
2014-07-09 14:55:40,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942755370
2014-07-09 14:55:40,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942760657
2014-07-09 14:55:40,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942766923
2014-07-09 14:55:41,523 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:55:41,523 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 14:55:41,524 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:41,524 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:41,524 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:41,524 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:41,524 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:41,524 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:55:46,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:46,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942940084 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942946733
2014-07-09 14:55:52,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:53,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942946733 with entries=87, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942952942
2014-07-09 14:55:57,552 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:55:57,552 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 14:55:57,553 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:57,553 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:57,553 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:57,553 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:57,553 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:57,554 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:55:57,812 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4493, memsize=663.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/d267737501f74c688f236345f56875ad
2014-07-09 14:55:57,834 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/d267737501f74c688f236345f56875ad as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d267737501f74c688f236345f56875ad
2014-07-09 14:55:57,857 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d267737501f74c688f236345f56875ad, entries=2416650, sequenceid=4493, filesize=172.2m
2014-07-09 14:55:57,857 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~663.7m/695974080, currentsize=110.1m/115424800 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 25714ms, sequenceid=4493, compaction requested=true
2014-07-09 14:55:57,857 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:55:57,858 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:55:57,858 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:55:57,858 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:55:57,858 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:55:57,858 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:55:59,202 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:55:59,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942952942 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942959202
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942772264
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942778861
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942784795
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942790912
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942798297
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942804619
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942810297
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942816391
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942823586
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942828793
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942835008
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942840713
2014-07-09 14:55:59,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942846563
2014-07-09 14:55:59,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942852231
2014-07-09 14:55:59,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942858174
2014-07-09 14:55:59,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942864516
2014-07-09 14:55:59,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942870165
2014-07-09 14:56:05,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:05,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22799 synced till here 22798
2014-07-09 14:56:05,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942959202 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942965255
2014-07-09 14:56:13,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:13,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22884 synced till here 22883
2014-07-09 14:56:13,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942965255 with entries=85, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942973021
2014-07-09 14:56:14,441 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:56:14,442 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 14:56:14,442 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:56:14,442 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:56:14,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:56:14,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:56:14,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:56:14,443 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:56:20,216 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:20,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942973021 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942980216
2014-07-09 14:56:27,061 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:27,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23051 synced till here 23050
2014-07-09 14:56:27,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942980216 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942987062
2014-07-09 14:56:33,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:33,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942987062 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942993088
2014-07-09 14:56:36,501 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:56:36,501 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 14:56:36,501 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:56:36,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-09 14:56:36,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 23 files from compaction candidates
2014-07-09 14:56:36,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:56:36,502 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:56:36,502 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:56:39,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:39,654 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942993088 with entries=83, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942999565
2014-07-09 14:56:46,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:46,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23302 synced till here 23301
2014-07-09 14:56:46,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942999565 with entries=84, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943006243
2014-07-09 14:56:52,675 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:52,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23386 synced till here 23385
2014-07-09 14:56:52,701 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943006243 with entries=84, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943012676
2014-07-09 14:56:58,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:56:58,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943012676 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943018530
2014-07-09 14:57:05,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:05,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943018530 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943025613
2014-07-09 14:57:11,601 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90078ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:57:11,601 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 608.7m
2014-07-09 14:57:12,213 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:57:12,214 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:12,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943025613 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943032215
2014-07-09 14:57:17,966 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:17,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943032215 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943037967
2014-07-09 14:57:25,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:25,094 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943037967 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943045064
2014-07-09 14:57:28,167 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90615ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:57:28,168 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 607.7m
2014-07-09 14:57:28,729 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:57:32,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:32,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943045064 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943052102
2014-07-09 14:57:36,112 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4751, memsize=610.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/514c2d56a6ba4dd089bb1fa87886d574
2014-07-09 14:57:36,146 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/514c2d56a6ba4dd089bb1fa87886d574 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/514c2d56a6ba4dd089bb1fa87886d574
2014-07-09 14:57:36,163 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/514c2d56a6ba4dd089bb1fa87886d574, entries=2222120, sequenceid=4751, filesize=158.2m
2014-07-09 14:57:36,164 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~610.3m/639954960, currentsize=93.3m/97827840 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 24563ms, sequenceid=4751, compaction requested=true
2014-07-09 14:57:36,164 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:57:36,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:57:36,164 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:57:36,165 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:57:36,165 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:57:36,165 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:57:38,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:38,692 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943052102 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943058654
2014-07-09 14:57:38,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942876491
2014-07-09 14:57:38,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942883204
2014-07-09 14:57:44,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:44,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24052 synced till here 24051
2014-07-09 14:57:44,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943058654 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943064252
2014-07-09 14:57:45,193 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90752ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:57:45,194 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 616.1m
2014-07-09 14:57:45,763 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:57:51,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:51,487 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943064252 with entries=84, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943071460
2014-07-09 14:57:51,869 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4790, memsize=607.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/84299acf06664702861c9f9e62bd688b
2014-07-09 14:57:51,893 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/84299acf06664702861c9f9e62bd688b as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/84299acf06664702861c9f9e62bd688b
2014-07-09 14:57:51,902 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/84299acf06664702861c9f9e62bd688b, entries=2212460, sequenceid=4790, filesize=157.6m
2014-07-09 14:57:51,928 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~607.7m/637169040, currentsize=97.6m/102329440 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 23760ms, sequenceid=4790, compaction requested=true
2014-07-09 14:57:51,929 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:57:51,929 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:57:51,929 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:57:51,929 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:57:51,930 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:57:51,930 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:57:56,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:57:57,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943071460 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943076982
2014-07-09 14:57:57,012 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942889390
2014-07-09 14:57:57,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942895722
2014-07-09 14:57:57,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942903598
2014-07-09 14:58:03,129 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:03,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943076982 with entries=83, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943083129
2014-07-09 14:58:06,589 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90088ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:58:06,589 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 619.5m
2014-07-09 14:58:07,169 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:58:20,560 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 20701ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 14:58:20,560 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 20702ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 14:58:20,561 WARN  [regionserver60020] util.Sleeper: We slept 15757ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 14:58:20,637 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13082ms
GC pool 'ParNew' had collection(s): count=1 time=65ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=13263ms
2014-07-09 14:58:22,542 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4839, memsize=617.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/fdf1ee6c516c41fbaef1b21579cebc48
2014-07-09 14:58:22,561 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/fdf1ee6c516c41fbaef1b21579cebc48 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdf1ee6c516c41fbaef1b21579cebc48
2014-07-09 14:58:22,571 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdf1ee6c516c41fbaef1b21579cebc48, entries=2248460, sequenceid=4839, filesize=160.1m
2014-07-09 14:58:22,572 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~617.5m/647539840, currentsize=85.6m/89775120 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 37378ms, sequenceid=4839, compaction requested=true
2014-07-09 14:58:22,573 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:58:22,573 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:58:22,573 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:58:22,573 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:58:22,573 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:58:22,573 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:58:31,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:31,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943083129 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943111018
2014-07-09 14:58:31,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942909687
2014-07-09 14:58:37,469 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 14:58:37,470 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 14:58:37,470 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:58:37,470 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:58:37,470 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:58:37,471 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:58:37,471 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:58:37,471 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 14:58:38,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:39,032 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943111018 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943118991
2014-07-09 14:58:39,698 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4894, memsize=621.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/f219e2768942423489ca3df22a6d2b1a
2014-07-09 14:58:39,719 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/f219e2768942423489ca3df22a6d2b1a as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/f219e2768942423489ca3df22a6d2b1a
2014-07-09 14:58:39,730 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/f219e2768942423489ca3df22a6d2b1a, entries=2261640, sequenceid=4894, filesize=161.0m
2014-07-09 14:58:39,745 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~621.2m/651335760, currentsize=41.5m/43555600 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 33156ms, sequenceid=4894, compaction requested=true
2014-07-09 14:58:39,746 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:58:39,746 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:58:39,746 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:58:39,746 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:58:39,746 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:58:39,746 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:58:45,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:45,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943118991 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943125519
2014-07-09 14:58:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.78 GB, free=180.7 MB, max=3.96 GB, blocks=61111, accesses=22465570, hits=22122289, hitRatio=98.47%, , cachingAccesses=22458706, cachingHits=22122287, cachingHitsRatio=98.50%, evictions=107, evicted=274803, evictedPerRun=2568.25244140625
2014-07-09 14:58:50,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:51,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943125519 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943130995
2014-07-09 14:58:52,458 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 14:58:52,458 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 14:58:52,458 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:58:52,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:58:52,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:58:52,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:58:52,459 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:58:52,459 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 14:58:57,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:58:57,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943130995 with entries=85, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943137673
2014-07-09 14:59:03,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:03,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943137673 with entries=84, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943143925
2014-07-09 14:59:09,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:09,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943143925 with entries=82, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943149652
2014-07-09 14:59:09,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 14:59:09,704 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 251.0m
2014-07-09 14:59:09,887 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 14:59:09,887 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 14:59:09,887 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:59:09,887 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:59:09,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:59:09,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:59:09,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:59:09,888 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 14:59:09,922 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 14:59:13,788 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 14:59:13,789 DEBUG [MemStoreFlusher.1] regionserver.HRegion: NOT flushing memstore for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., flushing=true, writesEnabled=true
2014-07-09 14:59:16,424 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:16,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943149652 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943156425
2014-07-09 14:59:18,197 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4987, memsize=251.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/0a42f9d104344b4987ec1e659b38f6d6
2014-07-09 14:59:18,230 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/0a42f9d104344b4987ec1e659b38f6d6 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0a42f9d104344b4987ec1e659b38f6d6
2014-07-09 14:59:18,243 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0a42f9d104344b4987ec1e659b38f6d6, entries=914080, sequenceid=4987, filesize=65.1m
2014-07-09 14:59:18,243 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~251.0m/263229520, currentsize=11.1m/11662960 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 8539ms, sequenceid=4987, compaction requested=true
2014-07-09 14:59:18,243 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:59:18,243 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-09 14:59:18,243 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-09 14:59:18,244 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 14:59:18,244 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:59:18,244 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 14:59:21,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:21,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943156425 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943161290
2014-07-09 14:59:21,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942915648
2014-07-09 14:59:21,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942921452
2014-07-09 14:59:21,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942927789
2014-07-09 14:59:21,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942933704
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942940084
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942946733
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942952942
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942959202
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942965255
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942973021
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942980216
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942987062
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942993088
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404942999565
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943006243
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943012676
2014-07-09 14:59:21,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943018530
2014-07-09 14:59:26,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:26,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943161290 with entries=82, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943166295
2014-07-09 14:59:29,217 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 14:59:29,217 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 14:59:29,218 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 14:59:29,218 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 20 blocking
2014-07-09 14:59:29,218 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 24 files from compaction candidates
2014-07-09 14:59:29,218 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 14:59:29,218 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 14:59:29,218 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 14:59:31,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:31,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943166295 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943171455
2014-07-09 14:59:37,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:37,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943171455 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943177917
2014-07-09 14:59:45,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:45,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25386 synced till here 25385
2014-07-09 14:59:45,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943177917 with entries=83, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943185625
2014-07-09 14:59:51,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:51,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943185625 with entries=83, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943191737
2014-07-09 14:59:57,844 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 14:59:57,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943191737 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943197844
2014-07-09 15:00:05,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:05,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943197844 with entries=82, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943205242
2014-07-09 15:00:08,254 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90785ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:00:08,255 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 635.4m
2014-07-09 15:00:08,715 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:00:11,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:11,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25719 synced till here 25718
2014-07-09 15:00:11,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943205242 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943211700
2014-07-09 15:00:17,177 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:17,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25803 synced till here 25802
2014-07-09 15:00:17,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943211700 with entries=84, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943217178
2014-07-09 15:00:22,660 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90202ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:00:22,660 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 638.6m
2014-07-09 15:00:23,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:23,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943217178 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943223258
2014-07-09 15:00:23,537 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:00:28,691 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5161, memsize=635.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/22cb56db51a349078c05e1e5905fcd88
2014-07-09 15:00:28,704 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/22cb56db51a349078c05e1e5905fcd88 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/22cb56db51a349078c05e1e5905fcd88
2014-07-09 15:00:28,715 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/22cb56db51a349078c05e1e5905fcd88, entries=2313400, sequenceid=5161, filesize=164.7m
2014-07-09 15:00:28,715 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~635.4m/666239200, currentsize=87.1m/91295920 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 20460ms, sequenceid=5161, compaction requested=true
2014-07-09 15:00:28,716 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:00:28,716 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:00:28,716 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:00:28,716 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:00:28,716 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:00:28,716 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:00:29,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:29,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25973 synced till here 25972
2014-07-09 15:00:29,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943223258 with entries=85, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943229453
2014-07-09 15:00:29,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943025613
2014-07-09 15:00:29,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943032215
2014-07-09 15:00:29,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943037967
2014-07-09 15:00:36,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:36,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943229453 with entries=83, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943236369
2014-07-09 15:00:39,980 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90093ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:00:39,980 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 636.2m
2014-07-09 15:00:40,398 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:00:43,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:43,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26140 synced till here 26139
2014-07-09 15:00:43,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943236369 with entries=84, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943243154
2014-07-09 15:00:44,084 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5202, memsize=638.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/9c9fc27b1e2743308b0d5b652418ed70
2014-07-09 15:00:44,094 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/9c9fc27b1e2743308b0d5b652418ed70 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9c9fc27b1e2743308b0d5b652418ed70
2014-07-09 15:00:44,103 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9c9fc27b1e2743308b0d5b652418ed70, entries=2324980, sequenceid=5202, filesize=165.5m
2014-07-09 15:00:44,112 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~638.6m/669576400, currentsize=84.0m/88119280 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 21452ms, sequenceid=5202, compaction requested=true
2014-07-09 15:00:44,113 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:00:44,114 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:00:44,114 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:00:44,114 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:00:44,114 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:00:44,114 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:00:49,551 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:49,601 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943243154 with entries=85, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943249551
2014-07-09 15:00:49,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943045064
2014-07-09 15:00:49,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943052102
2014-07-09 15:00:49,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943058654
2014-07-09 15:00:56,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:00:56,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943249551 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943256442
2014-07-09 15:00:59,608 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90391ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:00:59,609 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 619.8m
2014-07-09 15:01:00,099 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:01:00,590 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5249, memsize=636.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/78ef81052ff246eb824ae924968c9f72
2014-07-09 15:01:00,600 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/78ef81052ff246eb824ae924968c9f72 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78ef81052ff246eb824ae924968c9f72
2014-07-09 15:01:00,614 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78ef81052ff246eb824ae924968c9f72, entries=2316520, sequenceid=5249, filesize=164.9m
2014-07-09 15:01:00,614 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~636.2m/667138640, currentsize=77.6m/81329360 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 20634ms, sequenceid=5249, compaction requested=true
2014-07-09 15:01:00,614 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:00,614 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:00,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:00,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:00,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:00,615 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:01:01,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:01,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943256442 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943261708
2014-07-09 15:01:01,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943064252
2014-07-09 15:01:01,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943071460
2014-07-09 15:01:01,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943076982
2014-07-09 15:01:09,136 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:09,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26476 synced till here 26475
2014-07-09 15:01:09,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943261708 with entries=85, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943269136
2014-07-09 15:01:10,384 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:01:10,384 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:01:10,384 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:10,385 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:10,385 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:10,385 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:10,385 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:10,385 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:01:15,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:15,376 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943269136 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943275325
2014-07-09 15:01:20,195 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5296, memsize=623.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/1b6ad9f477044a2d85a2ecbd88052d5e
2014-07-09 15:01:20,223 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/1b6ad9f477044a2d85a2ecbd88052d5e as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1b6ad9f477044a2d85a2ecbd88052d5e
2014-07-09 15:01:20,232 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1b6ad9f477044a2d85a2ecbd88052d5e, entries=2268390, sequenceid=5296, filesize=161.5m
2014-07-09 15:01:20,244 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~623.0m/653277280, currentsize=85.6m/89781520 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 20635ms, sequenceid=5296, compaction requested=true
2014-07-09 15:01:20,247 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:20,247 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:20,247 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:20,247 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:20,247 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:20,247 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:01:22,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:22,189 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26644 synced till here 26642
2014-07-09 15:01:22,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943275325 with entries=84, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943282154
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943083129
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943111018
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943118991
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943125519
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943130995
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943137673
2014-07-09 15:01:22,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943143925
2014-07-09 15:01:26,736 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:01:26,736 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:01:26,736 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:26,737 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:26,737 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:26,737 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:26,737 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:26,737 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:01:27,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:27,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943282154 with entries=85, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943287822
2014-07-09 15:01:33,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:33,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943287822 with entries=83, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943293462
2014-07-09 15:01:39,726 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:39,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943293462 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943299726
2014-07-09 15:01:42,358 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:01:42,359 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:01:42,359 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:42,359 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:42,359 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:42,359 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:42,359 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:42,359 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:01:45,028 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:45,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943299726 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943305028
2014-07-09 15:01:49,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:49,829 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943305028 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943309787
2014-07-09 15:01:54,641 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:54,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943309787 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943314641
2014-07-09 15:01:56,079 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:01:56,079 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:01:56,080 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:01:56,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 25 store files, 0 compacting, 25 eligible, 20 blocking
2014-07-09 15:01:56,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 25 files from compaction candidates
2014-07-09 15:01:56,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:01:56,080 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:01:56,080 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:01:59,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:01:59,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943314641 with entries=84, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943319797
2014-07-09 15:02:05,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:05,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943319797 with entries=83, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943325466
2014-07-09 15:02:05,543 WARN  [RpcServer.handler=26,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/9a04919087404502bfe6c4eba5bda02a for block blk_-5380656709138446664_72702:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,544 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/561c77e552b247458d819ee298aed3f9 for block blk_2019836618988981443_72722:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,544 WARN  [RpcServer.handler=17,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3bd1ba2780ee48468c889ef6ad13a07b for block blk_-8035653478641201660_72214:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,544 WARN  [RpcServer.handler=4,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df73698b7e134d3bb08f42c73ab6fde6 for block blk_-1163501453950111825_72681:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,544 WARN  [RpcServer.handler=40,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/7cdd2d9fc3a6450c8492d381d0e5a74c for block blk_4441403849424846685_72269:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,544 WARN  [RpcServer.handler=29,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/266843fa05534fe987eb70676491ca43 for block blk_-2191501621428455357_72756:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,543 WARN  [RpcServer.handler=27,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d267737501f74c688f236345f56875ad for block blk_4980629182543451671_72842:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,543 WARN  [RpcServer.handler=45,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d8d6e73fcef84af596235bd9c5f27fa8 for block blk_9026683111706699595_72473:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,569 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/8a6ad8bbdc0a4fa4b7e1b2fe2890249b for block blk_7573227044712628116_72470:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,569 WARN  [RpcServer.handler=49,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdf1ee6c516c41fbaef1b21579cebc48 for block blk_902551201217072087_72892:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,584 WARN  [RpcServer.handler=22,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/745daeb873e64f6fbe5ddd254890d8f4 for block blk_-5750841237976971370_72835:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,585 WARN  [RpcServer.handler=9,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5327801a7d504514b9952473796b17ee for block blk_-1781617655838475335_72824:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,600 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a2776ed447e04b42b498d7ce6a1dec5d for block blk_8936414345158854436_72428:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,624 WARN  [RpcServer.handler=15,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a6d0dcb3442f424bae08ce3492b43b57 for block blk_2971658219125601490_72716:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,630 WARN  [RpcServer.handler=46,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9c0bc9d5660c41adafaf3fa89e8498fc for block blk_2732594585480721659_72231:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,640 WARN  [RpcServer.handler=2,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/a50b9e861fb84b5191c4b29efaff27ea for block blk_5411489684844660558_72787:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,648 WARN  [RpcServer.handler=40,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b1e9e459177a4ab9836fef1a9e1261d7 for block blk_-9017907741329407821_72826:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,664 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1b6ad9f477044a2d85a2ecbd88052d5e for block blk_-8247518882060794910_72949:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,664 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/866a7f45a026429fbcefb476ef0abbeb for block blk_-6824969582670643003_72197:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,668 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/deec67dadd40487f949a463878e35365 for block blk_4411665481762554254_72620:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,669 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1ec0c2b1a714bbd8355ab24bbb9a4b7 for block blk_-6958692581220115284_72371:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,675 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4b44b3efd7514e68a1b1471898568b72 for block blk_3899387769297294857_72254:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,675 WARN  [RpcServer.handler=14,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6f23e20e29264db7b2733271fe41deb5 for block blk_-8648780632068958330_72588:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,679 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c31ca82fa5174080bf5bdc9617a89223 for block blk_-7078518225279489250_72490:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,683 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e5f47425fdec4e1787653103eada5180 for block blk_-3761366238131809334_72328:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,690 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/92574d98e3b54570bdfe0c4d867de3c3 for block blk_-1338680024123384107_72544:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,690 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f83c5a8e17124d18b70638b6af726628 for block blk_7956299115050015751_72382:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,690 WARN  [RpcServer.handler=34,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/55282ea871d44e6cbf855fd4ae4faf1e for block blk_647454468663197686_72678:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,692 WARN  [RpcServer.handler=7,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/73d606aec1064729bd79aa82371654c8 for block blk_2356617450193536530_72175:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,695 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1fc0788e43940778409efaf14423d33 for block blk_960508521943371887_72644:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,720 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9c9fc27b1e2743308b0d5b652418ed70 for block blk_5370574816945618736_72939:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,723 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9c9fc27b1e2743308b0d5b652418ed70 for block blk_3937117038966199820_72936:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,733 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9b3ce23d7af3458d936d5c8f96d5b335 for block blk_8816141563885317145_72302:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,748 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b25d25c5c5814fcc84900f0ebdbd9eb0 for block blk_-9164002281011597651_72562:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,748 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/7438d9864c0244f8b3c25c6ad144aa30 for block blk_6514744927838866383_72526:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,752 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/e4a331acdaa6440b84facf79fe1a142a for block blk_-2406235329155619605_72347:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,766 WARN  [RpcServer.handler=48,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/962fa5757d8342cfacaf29b328caf2e2 for block blk_9128343966772957125_72585:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,770 WARN  [RpcServer.handler=7,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c586c4a03f1c482c8a565ce2dd4625a1 for block blk_-5905013568997033124_72661:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,772 WARN  [RpcServer.handler=13,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3a1338eb786a426da2979e82aa0f1e38 for block blk_-8257605464679489125_72531:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,773 WARN  [RpcServer.handler=38,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/605151e95bb2412a932d3ad2950a5a79 for block blk_-3453358980524804271_72634:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,773 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/f219e2768942423489ca3df22a6d2b1a for block blk_-1178345947451322268_72893:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,774 WARN  [RpcServer.handler=45,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdda3761a9d44fbe910da9429f808216 for block blk_-5393812568714511493_72390:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,790 WARN  [RpcServer.handler=33,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/514c2d56a6ba4dd089bb1fa87886d574 for block blk_7407179918964591716_72875:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,790 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/c1b3caead681423c82c89715066525fa for block blk_2499109303709914841_72761:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,793 WARN  [RpcServer.handler=20,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8dc1524666c84b2fbe4c180b6fa27eb2 for block blk_-6722187648731726876_72480:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,795 WARN  [RpcServer.handler=6,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/22cb56db51a349078c05e1e5905fcd88 for block blk_4873358816641282376_72926:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,812 WARN  [RpcServer.handler=37,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/be72003e848d424dbffdfcfe14d38bd5 for block blk_-4977876161206072964_72188:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,826 WARN  [RpcServer.handler=34,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a1ee3936ce224269b0ad70f1101de272 for block blk_4938720411717929712_72162:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,828 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3096f05166614353a6260e805185dfc4 for block blk_6978987564795718685_72232:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,837 WARN  [RpcServer.handler=10,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/cc8e89fc604941b5879893af546fde53 for block blk_1709108305165173038_72666:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,837 WARN  [RpcServer.handler=43,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/496540bc85934cf29db67c59937e7772 for block blk_992384457294022675_72244:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,849 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/594a2da148e34145aacada934c582d21 for block blk_-3772682625107504885_72249:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,902 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78ef81052ff246eb824ae924968c9f72 for block blk_-8580574853660902148_72940:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,902 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/93f5add43dbd4e44be70c6827e8ee8fa for block blk_4857072318873708174_72171:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,908 WARN  [RpcServer.handler=40,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/abbe5621b9c64fe192f2e46b42891f71 for block blk_-3235313784628275328_72297:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,908 WARN  [RpcServer.handler=44,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf2f24f17e0646fcaf6ed406108f9ba9 for block blk_-4660076388959990190_72695:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,908 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a9746e2e85ad4d75a7e20f81b7507f29 for block blk_4041823479210329093_72553:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,912 WARN  [RpcServer.handler=11,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/405c9e22ef8c4e10a539d5f3be40d0a9 for block blk_4020984161569898031_72779:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,927 WARN  [RpcServer.handler=4,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/84299acf06664702861c9f9e62bd688b for block blk_-3950836236353832402_72886:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,931 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/e3f1a09502fa4ddda6bbdd199ff8507e for block blk_-2362189426963923196_72607:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,945 WARN  [RpcServer.handler=49,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/698139aafee94466a26a8ec7ade2f81c for block blk_3098972282003393815_72400:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,953 WARN  [RpcServer.handler=27,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/c34a25bc7b7948728840cef4b261bd8e for block blk_-122929981655340223_72499:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,958 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3cafadf44d2742f2903416c7612ef640 for block blk_4754393934267197926_72373:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,972 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3149fc5a224343a2b005dab1ac94c314 for block blk_8565880344604910679_72510:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,972 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e097fa95a140410fb6bd1c2aa93f8b84 for block blk_942404344791053881_72626:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,974 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/88cf372043b447deb69a5c20225d35a2 for block blk_-1320593065502167208_72319:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,977 WARN  [RpcServer.handler=12,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/3475e54300e64c65b1c4504cc0b2f8a5 for block blk_-8142345960879142572_72523:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:05,983 WARN  [RpcServer.handler=11,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a2c23fb613424727a1b1c14c5f0e4e06 for block blk_168347759112388615_72215:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,007 WARN  [RpcServer.handler=6,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/3b74b18767784e8da54050e98f1a6662 for block blk_7479707977030386671_72330:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,024 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c7424b6594374a34909f224c11c018c0 for block blk_8103992952342203366_72420:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,029 WARN  [RpcServer.handler=15,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5c02c1237d2948e683bff21bdffcfba0 for block blk_-2139473023806694730_72407:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,039 WARN  [RpcServer.handler=2,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/220634410fef40f4a3e5e2b44a459940 for block blk_-7955232017707611608_72508:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,055 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1095e9a09dac497d870a443bfd5722a1 for block blk_1287469377618374889_72392:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,073 WARN  [RpcServer.handler=29,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/473654eddbd948e7a4f768c32ed157cb for block blk_-3945215086558041867_72356:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,075 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/87ca59cb96c14d038a95ae4c090a74c1 for block blk_-7593194114233662040_72409:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,081 WARN  [RpcServer.handler=14,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4db80c5d4f1b4e90bcfdca2e931c2e92 for block blk_1524417663230198738_72198:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,081 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78f1642125214e94ad35e327ed169d09 for block blk_-5793729546851651813_72450:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,091 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7e354200982d45a2beda783790527257 for block blk_4790140315027847971_72535:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,111 WARN  [RpcServer.handler=46,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/dd34bdfd00ad4dab8bf4555a4c38fc11 for block blk_870263101006287802_72189:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,148 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/bb5e9d93f30e4a7ea8ab592053ff3c9f for block blk_-5872037384206918525_72579:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,165 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/208e3e5e2d404804817262a25615b194 for block blk_-3347873440411496058_72767:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,168 WARN  [RpcServer.handler=34,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5d2971b8f45e42dbbe64ba6c0a4647fb for block blk_3205800682647602273_72417:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,172 WARN  [RpcServer.handler=13,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/053246811ea44861986507fa064763fc for block blk_5627484936188605652_72674:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,172 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c0e17bb55aa24c1394f627769dc59788 for block blk_3417102489631922430_72708:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,172 WARN  [RpcServer.handler=18,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/67a0ae57387641b5813b3d6052058311 for block blk_-889103100205649961_72281:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,177 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/af621bc752664213b0072000ac3deae0 for block blk_9097186742484778506_72446:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,214 WARN  [RpcServer.handler=6,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a089001dfac24b6fbc30f15310be1d88 for block blk_-5625131843891268691_72321:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,237 WARN  [RpcServer.handler=44,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0a42f9d104344b4987ec1e659b38f6d6 for block blk_9422168318954671_72907:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,242 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/550d6f2093a34b7eae2f956724a58ad5 for block blk_-1705222166369287513_72463:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,242 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/70356b511997474182a98d7d4700abad for block blk_-1949733642676396205_72612:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,245 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0046a0d576c249abad89b943ef6da41f for block blk_-7520071052153846126_72689:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,308 WARN  [RpcServer.handler=18,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9dce6f0a454f4e35a64f215955110def for block blk_8649051134754241405_72355:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,351 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5558a2883ab14492be041a968ad6f83f for block blk_-4258432104196966352_72163:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,358 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/945d8a0c8bda4d1b9a12d134b7e0f0bb for block blk_-9086814384619411516_72266:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,378 WARN  [RpcServer.handler=47,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b6fa10283cae4fe6a6c921de50c6556f for block blk_-3921883359055747019_72653:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,388 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/738b20154d284d51ab9ae032e459d12d for block blk_7879097684246942881_72293:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,388 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e9c84ec1f1dd4271a6b0d6644d50bed2 for block blk_-4154094196780137778_72571:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,395 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/dd7b32bb51da4a2488864193a80789a7 for block blk_3968993413884129332_72558:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,400 WARN  [RpcServer.handler=18,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7c10f75d27dd4889acfd03f5405c9cb9 for block blk_-3387738210737396615_72460:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,438 WARN  [RpcServer.handler=33,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/940f22d2004341eca60101f74ccca96f for block blk_-2054089343866143432_72241:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,499 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4a11210cc47441fba958eb36297051e6 for block blk_3374647553311462301_72307:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,499 WARN  [RpcServer.handler=22,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/506cc662f38d4f21b29f0c0b4d446450 for block blk_3815214382370574234_72339:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,509 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/8714aa33d6524622be56b9e3f66d973a for block blk_-7633703029182258364_72225:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,852 WARN  [RpcServer.handler=48,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/19015d7a681d460caffb6177e4e8a220 for block blk_1344654027546652089_72835:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,869 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/017c1aa77f0b480db78db62a2f10bcb8 for block blk_5689670951691520258_72276:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:06,989 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b31da402be464d17b919064e90e4ff88 for block blk_4616488624620594093_72646:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:07,002 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fb586941fcd3470ea8421c95bad5ec4c for block blk_6594732840141366898_72599:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:07,064 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/23fc57266e274a1cba3489e47b3a985f for block blk_-6203628382112595586_72436:java.net.BindException: Cannot assign requested address
2014-07-09 15:02:17,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:17,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27398 synced till here 27395
2014-07-09 15:02:17,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943325466 with entries=85, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943337026
2014-07-09 15:02:25,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:25,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943337026 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943345226
2014-07-09 15:02:31,393 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:31,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943345226 with entries=84, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943351393
2014-07-09 15:02:35,871 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:02:35,872 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 256.3m
2014-07-09 15:02:36,035 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:02:36,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:36,901 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943351393 with entries=84, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943356865
2014-07-09 15:02:40,866 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90482ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:02:40,867 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 628.1m
2014-07-09 15:02:41,329 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:02:43,984 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5536, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/3cb7ab78738c43018c2dd00b11c58e52
2014-07-09 15:02:44,007 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/3cb7ab78738c43018c2dd00b11c58e52 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3cb7ab78738c43018c2dd00b11c58e52
2014-07-09 15:02:44,026 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3cb7ab78738c43018c2dd00b11c58e52, entries=933090, sequenceid=5536, filesize=66.4m
2014-07-09 15:02:44,027 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268705040, currentsize=9.1m/9499680 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 8155ms, sequenceid=5536, compaction requested=true
2014-07-09 15:02:44,028 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:02:44,028 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-09 15:02:44,028 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-09 15:02:44,028 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:02:44,028 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:02:44,028 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:02:45,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:45,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943356865 with entries=83, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943365358
2014-07-09 15:02:45,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943149652
2014-07-09 15:02:45,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943156425
2014-07-09 15:02:45,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943161290
2014-07-09 15:02:45,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943166295
2014-07-09 15:02:45,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943171455
2014-07-09 15:02:45,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943177917
2014-07-09 15:02:45,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943185625
2014-07-09 15:02:45,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943191737
2014-07-09 15:02:45,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943197844
2014-07-09 15:02:51,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:51,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943365358 with entries=84, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943371617
2014-07-09 15:02:57,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:02:57,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943371617 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943377366
2014-07-09 15:02:57,532 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90796ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:02:57,532 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 627.4m
2014-07-09 15:02:57,923 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:03:00,738 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5566, memsize=628.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/cb5a3952d9394058be03f1bcc595b9a3
2014-07-09 15:03:00,928 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/cb5a3952d9394058be03f1bcc595b9a3 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/cb5a3952d9394058be03f1bcc595b9a3
2014-07-09 15:03:00,946 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/cb5a3952d9394058be03f1bcc595b9a3, entries=2286900, sequenceid=5566, filesize=162.8m
2014-07-09 15:03:00,963 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~628.1m/658609040, currentsize=72.9m/76450400 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 20096ms, sequenceid=5566, compaction requested=true
2014-07-09 15:03:00,964 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:03:00,964 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:03:00,965 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:03:00,965 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:03:00,965 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:03:00,965 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:03:05,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:05,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27985 synced till here 27984
2014-07-09 15:03:05,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943377366 with entries=85, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943385801
2014-07-09 15:03:05,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943205242
2014-07-09 15:03:05,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943211700
2014-07-09 15:03:12,718 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90360ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:03:12,719 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 602.4m
2014-07-09 15:03:13,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:13,141 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:03:13,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28072 synced till here 28071
2014-07-09 15:03:13,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943385801 with entries=87, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943393118
2014-07-09 15:03:17,134 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5607, memsize=627.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/fa13366e41ae45bc9d9719ff74e4804a
2014-07-09 15:03:17,145 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/fa13366e41ae45bc9d9719ff74e4804a as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fa13366e41ae45bc9d9719ff74e4804a
2014-07-09 15:03:17,154 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fa13366e41ae45bc9d9719ff74e4804a, entries=2284360, sequenceid=5607, filesize=162.6m
2014-07-09 15:03:17,158 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~627.4m/657876640, currentsize=68.4m/71678000 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 19626ms, sequenceid=5607, compaction requested=true
2014-07-09 15:03:17,159 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:03:17,159 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:03:17,159 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:03:17,159 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:03:17,159 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:03:17,159 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:03:22,121 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:22,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28157 synced till here 28156
2014-07-09 15:03:22,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943393118 with entries=85, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943402122
2014-07-09 15:03:22,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943217178
2014-07-09 15:03:22,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943223258
2014-07-09 15:03:22,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943229453
2014-07-09 15:03:26,249 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90170ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:03:26,249 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 575.9m
2014-07-09 15:03:26,641 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:03:29,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:29,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943402122 with entries=84, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943409316
2014-07-09 15:03:32,387 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5638, memsize=602.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/cf167e9308f94c8aae386d9fa415035d
2014-07-09 15:03:32,407 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/cf167e9308f94c8aae386d9fa415035d as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/cf167e9308f94c8aae386d9fa415035d
2014-07-09 15:03:32,424 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/cf167e9308f94c8aae386d9fa415035d, entries=2193440, sequenceid=5638, filesize=156.2m
2014-07-09 15:03:32,424 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~602.4m/631694320, currentsize=74.4m/78043280 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 19705ms, sequenceid=5638, compaction requested=true
2014-07-09 15:03:32,425 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:03:32,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:03:32,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:03:32,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:03:32,425 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:03:32,425 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:03:34,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:34,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28325 synced till here 28324
2014-07-09 15:03:34,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943409316 with entries=84, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943414653
2014-07-09 15:03:34,680 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943236369
2014-07-09 15:03:34,681 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943243154
2014-07-09 15:03:34,681 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943249551
2014-07-09 15:03:41,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:41,446 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943414653 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943421382
2014-07-09 15:03:44,615 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5668, memsize=575.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/197497afa0154e71a6c3aa991576476d
2014-07-09 15:03:44,624 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/197497afa0154e71a6c3aa991576476d as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/197497afa0154e71a6c3aa991576476d
2014-07-09 15:03:44,632 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/197497afa0154e71a6c3aa991576476d, entries=2096980, sequenceid=5668, filesize=149.3m
2014-07-09 15:03:44,649 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~575.9m/603915120, currentsize=71.2m/74664320 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 18400ms, sequenceid=5668, compaction requested=true
2014-07-09 15:03:44,651 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:03:44,651 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:03:44,651 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:03:44,651 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:03:44,651 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:03:44,651 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:03:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.84 GB, free=115.82 MB, max=3.96 GB, blocks=62109, accesses=28433394, hits=27996640, hitRatio=98.46%, , cachingAccesses=28426530, cachingHits=27996638, cachingHitsRatio=98.48%, evictions=143, evicted=367248, evictedPerRun=2568.167724609375
2014-07-09 15:03:50,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:50,447 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28496 synced till here 28494
2014-07-09 15:03:50,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943421382 with entries=87, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943430364
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943256442
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943261708
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943269136
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943275325
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943282154
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943287822
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943293462
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943299726
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943305028
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943309787
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943314641
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943319797
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943325466
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943337026
2014-07-09 15:03:50,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943345226
2014-07-09 15:03:51,626 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:03:51,626 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:03:51,627 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:03:51,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:03:51,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:03:51,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:03:51,627 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:03:51,627 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:03:56,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:03:57,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28582 synced till here 28581
2014-07-09 15:03:57,032 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943430364 with entries=86, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943436973
2014-07-09 15:04:03,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:04:03,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943436973 with entries=84, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943443024
2014-07-09 15:04:08,253 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:04:08,253 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:04:08,254 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:04:08,254 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:04:08,254 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:04:08,254 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:04:08,254 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:04:08,254 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:04:11,641 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:04:11,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28749 synced till here 28748
2014-07-09 15:04:11,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943443024 with entries=83, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943451641
2014-07-09 15:04:18,097 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:04:18,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943451641 with entries=83, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943458098
2014-07-09 15:04:20,691 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:04:20,691 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:04:20,692 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:04:20,692 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:04:20,692 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:04:20,692 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:04:20,692 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:04:20,692 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:05:21,922 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90296ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:05:21,923 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 372.6m
2014-07-09 15:05:22,152 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:05:33,034 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5807, memsize=372.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/d61d55a7a1d54cbfb01b97554ff9e522
2014-07-09 15:05:33,052 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/d61d55a7a1d54cbfb01b97554ff9e522 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/d61d55a7a1d54cbfb01b97554ff9e522
2014-07-09 15:05:33,070 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/d61d55a7a1d54cbfb01b97554ff9e522, entries=1356780, sequenceid=5807, filesize=96.6m
2014-07-09 15:05:33,071 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~372.6m/390742480, currentsize=0.0/0 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 11148ms, sequenceid=5807, compaction requested=true
2014-07-09 15:05:33,072 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:05:33,072 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:05:33,072 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:05:33,072 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:05:33,073 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:05:33,073 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:05:36,127 INFO  [regionserver60020-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404941326960 znode expired, triggering replicatorRemoved event
2014-07-09 15:05:36,473 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:36,484 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:36,567 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943370528
2014-07-09 15:05:36,712 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943370528, length=65758384
2014-07-09 15:05:36,712 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:36,726 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943370528
2014-07-09 15:05:36,751 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943370528 after 25ms
2014-07-09 15:05:36,812 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:36,812 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:36,815 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:36,943 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005585.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:36,968 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005587.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:36,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005587.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:36,999 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005585.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:37,474 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:37,475 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:37,484 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:37,485 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005585.temp
2014-07-09 15:05:37,486 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005585.temp
2014-07-09 15:05:37,487 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005585.temp
2014-07-09 15:05:37,487 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005587.temp
2014-07-09 15:05:37,487 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005585.temp
2014-07-09 15:05:37,487 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005587.temp
2014-07-09 15:05:37,487 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005587.temp
2014-07-09 15:05:37,506 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943362058
2014-07-09 15:05:37,520 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005585.temp (wrote 19 edits in 232ms)
2014-07-09 15:05:37,521 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005585.temp (wrote 18 edits in 225ms)
2014-07-09 15:05:37,522 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005587.temp (wrote 18 edits in 181ms)
2014-07-09 15:05:37,524 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005585.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005603
2014-07-09 15:05:37,524 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005587.temp
2014-07-09 15:05:37,525 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005585.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005602
2014-07-09 15:05:37,528 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005587.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005604
2014-07-09 15:05:37,541 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943362058, length=65575474
2014-07-09 15:05:37,541 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:37,544 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943362058
2014-07-09 15:05:37,546 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005587.temp (wrote 18 edits in 172ms)
2014-07-09 15:05:37,547 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943362058 after 1ms
2014-07-09 15:05:37,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:37,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:37,565 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:37,574 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005587.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005604
2014-07-09 15:05:37,574 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943370528 is corrupted = false progress failed = false
2014-07-09 15:05:37,582 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943370528 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:37,582 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943370528 in 939ms
2014-07-09 15:05:37,588 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005569.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:37,589 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005567.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:37,625 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005567.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:37,626 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005567.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:38,143 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:38,143 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:38,151 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:38,151 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,151 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,151 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,151 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,152 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005569.temp
2014-07-09 15:05:38,152 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,152 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005567.temp
2014-07-09 15:05:38,197 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005567.temp (wrote 18 edits in 226ms)
2014-07-09 15:05:38,197 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005567.temp (wrote 19 edits in 143ms)
2014-07-09 15:05:38,204 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005567.temp (wrote 18 edits in 146ms)
2014-07-09 15:05:38,209 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005567.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005584
2014-07-09 15:05:38,209 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005569.temp
2014-07-09 15:05:38,210 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943376965
2014-07-09 15:05:38,211 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005567.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005586
2014-07-09 15:05:38,213 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005567.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005584
2014-07-09 15:05:38,214 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005569.temp (wrote 18 edits in 148ms)
2014-07-09 15:05:38,232 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943376965, length=63825666
2014-07-09 15:05:38,232 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:38,281 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005569.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005586
2014-07-09 15:05:38,281 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943362058 is corrupted = false progress failed = false
2014-07-09 15:05:38,305 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943376965
2014-07-09 15:05:38,306 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943362058 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:38,307 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943362058 in 799ms
2014-07-09 15:05:38,307 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943376965 after 1ms
2014-07-09 15:05:38,321 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:38,322 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:38,323 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:38,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005603.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:38,389 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005605.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:38,403 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005605.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:38,422 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005604.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:38,509 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90256ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:05:38,509 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 308.9m
2014-07-09 15:05:38,734 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:05:38,932 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943439372
2014-07-09 15:05:38,952 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943439372, length=65379204
2014-07-09 15:05:38,952 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:38,957 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943439372
2014-07-09 15:05:38,958 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943439372 after 1ms
2014-07-09 15:05:38,981 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:38,982 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:38,983 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:39,046 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:39,047 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:39,054 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:39,054 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005603.temp
2014-07-09 15:05:39,054 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005604.temp
2014-07-09 15:05:39,055 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005603.temp
2014-07-09 15:05:39,055 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005605.temp
2014-07-09 15:05:39,055 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005604.temp
2014-07-09 15:05:39,055 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005605.temp
2014-07-09 15:05:39,055 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005605.temp
2014-07-09 15:05:39,131 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005604.temp (wrote 18 edits in 168ms)
2014-07-09 15:05:39,132 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005605.temp (wrote 18 edits in 156ms)
2014-07-09 15:05:39,132 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005603.temp (wrote 17 edits in 170ms)
2014-07-09 15:05:39,133 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005748.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:39,134 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005749.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:39,143 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005604.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005621
2014-07-09 15:05:39,143 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005605.temp
2014-07-09 15:05:39,145 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005603.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005619
2014-07-09 15:05:39,149 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005749.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:39,160 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005605.temp (wrote 18 edits in 146ms)
2014-07-09 15:05:39,172 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005605.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005622
2014-07-09 15:05:39,190 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005605.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005622
2014-07-09 15:05:39,190 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 71 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943376965 is corrupted = false progress failed = false
2014-07-09 15:05:39,196 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943376965 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:39,196 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943376965 in 986ms
2014-07-09 15:05:39,211 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:39,230 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005749.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:39,701 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943416163
2014-07-09 15:05:39,728 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943416163, length=63882286
2014-07-09 15:05:39,728 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:39,732 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943416163
2014-07-09 15:05:39,733 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943416163 after 0ms
2014-07-09 15:05:39,754 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:39,754 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:39,755 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:39,814 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005694.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:39,846 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005695.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:39,847 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005695.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:40,045 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm48.almaden.ibm.com,60020,1404941326960's hlogs to my queue
2014-07-09 15:05:40,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005695.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:40,219 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:40,230 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:41,119 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:41,119 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:41,126 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:41,126 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005694.temp
2014-07-09 15:05:41,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,127 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005694.temp
2014-07-09 15:05:41,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,127 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,128 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,128 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,143 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005694.temp (wrote 18 edits in 456ms)
2014-07-09 15:05:41,148 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005695.temp (wrote 17 edits in 237ms)
2014-07-09 15:05:41,149 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005695.temp (wrote 18 edits in 492ms)
2014-07-09 15:05:41,152 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005694.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005711
2014-07-09 15:05:41,152 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005695.temp
2014-07-09 15:05:41,158 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005695.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005711
2014-07-09 15:05:41,158 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005695.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005712
2014-07-09 15:05:41,197 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005695.temp (wrote 18 edits in 521ms)
2014-07-09 15:05:41,205 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005695.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005712
2014-07-09 15:05:41,205 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 71 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943416163 is corrupted = false progress failed = false
2014-07-09 15:05:41,216 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943416163 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:41,216 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943416163 in 1514ms
2014-07-09 15:05:41,233 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:41,242 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943409944
2014-07-09 15:05:41,262 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943409944, length=65455434
2014-07-09 15:05:41,262 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:41,265 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943409944
2014-07-09 15:05:41,266 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943409944 after 1ms
2014-07-09 15:05:41,283 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:41,283 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:41,284 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:41,305 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005675.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:41,397 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005677.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:41,472 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005677.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:41,505 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005677.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:41,865 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:41,865 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:41,880 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:41,880 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005748.temp
2014-07-09 15:05:41,881 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,881 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005748.temp
2014-07-09 15:05:41,881 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,881 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,882 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,882 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,887 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005748.temp (wrote 18 edits in 299ms)
2014-07-09 15:05:41,889 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005749.temp (wrote 18 edits in 235ms)
2014-07-09 15:05:41,890 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005749.temp (wrote 18 edits in 194ms)
2014-07-09 15:05:41,899 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005748.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005765
2014-07-09 15:05:41,899 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005749.temp
2014-07-09 15:05:41,919 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005749.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005766
2014-07-09 15:05:41,920 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005749.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005766
2014-07-09 15:05:41,957 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005749.temp (wrote 19 edits in 246ms)
2014-07-09 15:05:41,964 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:42,004 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005749.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005767
2014-07-09 15:05:42,005 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943439372 is corrupted = false progress failed = false
2014-07-09 15:05:42,043 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943439372 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:42,043 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943439372 in 3110ms
2014-07-09 15:05:42,064 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:42,071 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943393492
2014-07-09 15:05:42,091 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943393492, length=64605215
2014-07-09 15:05:42,091 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:42,095 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943393492
2014-07-09 15:05:42,105 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943393492 after 10ms
2014-07-09 15:05:42,133 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:42,133 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:42,134 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:42,153 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005638.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:42,187 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005639.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:42,189 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005641.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:42,244 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005641.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:42,373 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:42,373 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:42,384 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:42,384 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005675.temp
2014-07-09 15:05:42,384 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,384 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005675.temp
2014-07-09 15:05:42,384 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,384 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,385 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,385 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,395 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005677.temp (wrote 18 edits in 181ms)
2014-07-09 15:05:42,397 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005675.temp (wrote 19 edits in 182ms)
2014-07-09 15:05:42,397 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005677.temp (wrote 18 edits in 191ms)
2014-07-09 15:05:42,413 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005675.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005693
2014-07-09 15:05:42,414 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005677.temp
2014-07-09 15:05:42,421 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005677.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005694
2014-07-09 15:05:42,423 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005677.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005694
2014-07-09 15:05:42,461 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005677.temp (wrote 18 edits in 167ms)
2014-07-09 15:05:42,475 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005677.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005694
2014-07-09 15:05:42,475 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943409944 is corrupted = false progress failed = false
2014-07-09 15:05:42,608 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943409944 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:42,608 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943409944 in 1366ms
2014-07-09 15:05:42,630 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:42,905 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:42,906 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:42,914 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:42,914 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005638.temp
2014-07-09 15:05:42,914 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005639.temp
2014-07-09 15:05:42,915 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005638.temp
2014-07-09 15:05:42,915 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005641.temp
2014-07-09 15:05:42,915 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005639.temp
2014-07-09 15:05:42,915 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005641.temp
2014-07-09 15:05:42,915 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005641.temp
2014-07-09 15:05:42,921 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005638.temp (wrote 19 edits in 174ms)
2014-07-09 15:05:42,933 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005641.temp (wrote 17 edits in 211ms)
2014-07-09 15:05:42,934 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005639.temp (wrote 18 edits in 224ms)
2014-07-09 15:05:42,947 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005641.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005657
2014-07-09 15:05:42,947 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005641.temp
2014-07-09 15:05:42,949 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005639.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005657
2014-07-09 15:05:42,954 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005638.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005657
2014-07-09 15:05:42,996 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005641.temp (wrote 18 edits in 220ms)
2014-07-09 15:05:43,007 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005641.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005658
2014-07-09 15:05:43,007 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 72 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943393492 is corrupted = false progress failed = false
2014-07-09 15:05:43,011 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943393492 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:43,011 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943393492 in 940ms
2014-07-09 15:05:43,012 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943385629
2014-07-09 15:05:43,034 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943385629, length=63837936
2014-07-09 15:05:43,034 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:43,042 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943385629
2014-07-09 15:05:43,044 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943385629 after 2ms
2014-07-09 15:05:43,062 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:43,062 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:43,063 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:43,089 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005620.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:43,134 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005623.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:43,145 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005623.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:43,186 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005622.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:43,674 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943446771
2014-07-09 15:05:43,706 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943446771, length=63793196
2014-07-09 15:05:43,706 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:43,871 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943446771
2014-07-09 15:05:43,873 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943446771 after 2ms
2014-07-09 15:05:43,941 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:43,941 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:43,941 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:44,050 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005767.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:44,085 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005766.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:44,101 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:44,101 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:44,109 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:44,109 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005620.temp
2014-07-09 15:05:44,110 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005622.temp
2014-07-09 15:05:44,110 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005620.temp
2014-07-09 15:05:44,110 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005623.temp
2014-07-09 15:05:44,110 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005622.temp
2014-07-09 15:05:44,110 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005623.temp
2014-07-09 15:05:44,110 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005623.temp
2014-07-09 15:05:44,127 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005620.temp (wrote 18 edits in 179ms)
2014-07-09 15:05:44,131 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005623.temp (wrote 18 edits in 186ms)
2014-07-09 15:05:44,131 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005622.temp (wrote 17 edits in 253ms)
2014-07-09 15:05:44,134 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005620.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005637
2014-07-09 15:05:44,134 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005623.temp
2014-07-09 15:05:44,136 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005623.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005640
2014-07-09 15:05:44,137 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005768.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:44,155 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005622.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005638
2014-07-09 15:05:44,167 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005623.temp (wrote 18 edits in 166ms)
2014-07-09 15:05:44,172 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005623.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005640
2014-07-09 15:05:44,172 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 71 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943385629 is corrupted = false progress failed = false
2014-07-09 15:05:44,178 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943385629 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:44,178 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943385629 in 1165ms
2014-07-09 15:05:44,212 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005767.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:44,500 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943454557
2014-07-09 15:05:44,521 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943454557, length=64071426
2014-07-09 15:05:44,521 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:44,529 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943454557
2014-07-09 15:05:44,530 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943454557 after 1ms
2014-07-09 15:05:44,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:44,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:44,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:44,587 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005784.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:44,605 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005785.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:44,612 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005785.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:44,635 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005785.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:45,283 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:45,283 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:45,291 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:45,292 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005784.temp
2014-07-09 15:05:45,292 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,292 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005784.temp
2014-07-09 15:05:45,292 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,293 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,293 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,293 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,307 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005784.temp (wrote 18 edits in 259ms)
2014-07-09 15:05:45,309 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005785.temp (wrote 17 edits in 198ms)
2014-07-09 15:05:45,309 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005785.temp (wrote 18 edits in 255ms)
2014-07-09 15:05:45,320 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005784.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005801
2014-07-09 15:05:45,320 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:45,320 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:45,320 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005785.temp
2014-07-09 15:05:45,322 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005785.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005802
2014-07-09 15:05:45,324 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005785.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005801
2014-07-09 15:05:45,327 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:45,327 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005766.temp
2014-07-09 15:05:45,328 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:45,328 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005767.temp
2014-07-09 15:05:45,328 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005766.temp
2014-07-09 15:05:45,328 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005767.temp
2014-07-09 15:05:45,328 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005767.temp
2014-07-09 15:05:45,328 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005768.temp
2014-07-09 15:05:45,328 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005767.temp
2014-07-09 15:05:45,331 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:45,355 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005785.temp (wrote 18 edits in 215ms)
2014-07-09 15:05:45,355 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005767.temp (wrote 18 edits in 308ms)
2014-07-09 15:05:45,355 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005767.temp (wrote 18 edits in 181ms)
2014-07-09 15:05:45,377 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005785.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005802
2014-07-09 15:05:45,377 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 71 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943454557 is corrupted = false progress failed = false
2014-07-09 15:05:45,377 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005767.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005784
2014-07-09 15:05:45,378 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005768.temp
2014-07-09 15:05:45,382 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005767.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005784
2014-07-09 15:05:45,382 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943454557 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:45,382 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943454557 in 881ms
2014-07-09 15:05:45,401 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:45,418 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943432144
2014-07-09 15:05:45,420 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005768.temp (wrote 17 edits in 243ms)
2014-07-09 15:05:45,438 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943432144, length=66055524
2014-07-09 15:05:45,438 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:45,442 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943432144
2014-07-09 15:05:45,445 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943432144 after 3ms
2014-07-09 15:05:45,455 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005768.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005784
2014-07-09 15:05:45,502 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:45,502 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:45,503 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:45,530 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005731.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:45,597 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005730.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:45,620 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005731.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:45,644 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005730.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:45,756 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005766.temp (wrote 18 edits in 202ms)
2014-07-09 15:05:45,761 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005766.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005783
2014-07-09 15:05:45,761 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 71 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943446771 is corrupted = false progress failed = false
2014-07-09 15:05:45,767 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943446771 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:45,767 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943446771 in 2092ms
2014-07-09 15:05:45,791 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:46,262 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943424724
2014-07-09 15:05:46,280 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943424724, length=64732105
2014-07-09 15:05:46,281 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:46,284 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943424724
2014-07-09 15:05:46,285 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943424724 after 1ms
2014-07-09 15:05:46,295 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:46,295 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:46,296 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:46,367 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005712.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:46,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005713.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:46,528 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005712.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:46,640 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005713.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:47,142 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:47,144 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:47,385 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:47,385 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:47,396 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:47,396 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005730.temp
2014-07-09 15:05:47,396 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005730.temp
2014-07-09 15:05:47,396 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005730.temp
2014-07-09 15:05:47,397 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005731.temp
2014-07-09 15:05:47,397 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005731.temp
2014-07-09 15:05:47,397 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005730.temp
2014-07-09 15:05:47,397 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005731.temp
2014-07-09 15:05:47,409 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005730.temp (wrote 18 edits in 203ms)
2014-07-09 15:05:47,413 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005731.temp (wrote 18 edits in 165ms)
2014-07-09 15:05:47,478 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005730.temp (wrote 19 edits in 187ms)
2014-07-09 15:05:47,489 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005730.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005747
2014-07-09 15:05:47,490 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005731.temp
2014-07-09 15:05:47,497 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005731.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005748
2014-07-09 15:05:47,501 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005731.temp (wrote 18 edits in 184ms)
2014-07-09 15:05:47,505 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005730.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005748
2014-07-09 15:05:47,551 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005731.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005748
2014-07-09 15:05:47,551 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943432144 is corrupted = false progress failed = false
2014-07-09 15:05:47,556 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943432144 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:47,556 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943432144 in 2138ms
2014-07-09 15:05:47,570 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:47,584 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943461009
2014-07-09 15:05:47,606 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009, length=0
2014-07-09 15:05:47,606 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:47,610 WARN  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: File hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009 might be still open, length is 0
2014-07-09 15:05:47,610 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009
2014-07-09 15:05:47,793 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009 after 183ms
2014-07-09 15:05:47,873 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5807, memsize=308.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/49180e1a5f25478f9d72d9d3515f732d
2014-07-09 15:05:47,889 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/49180e1a5f25478f9d72d9d3515f732d as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/49180e1a5f25478f9d72d9d3515f732d
2014-07-09 15:05:47,898 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/49180e1a5f25478f9d72d9d3515f732d, entries=1124710, sequenceid=5807, filesize=80.1m
2014-07-09 15:05:47,898 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~308.9m/323906720, currentsize=0.0/0 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 9389ms, sequenceid=5807, compaction requested=true
2014-07-09 15:05:47,899 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:05:47,899 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:05:47,899 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:05:47,899 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:05:47,899 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:05:47,899 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:05:48,520 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 2 tasks in progress and can't take more.
2014-07-09 15:05:48,528 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:48,528 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:48,534 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:48,535 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005712.temp
2014-07-09 15:05:48,535 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005712.temp
2014-07-09 15:05:48,535 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005712.temp
2014-07-09 15:05:48,535 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005713.temp
2014-07-09 15:05:48,535 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005712.temp
2014-07-09 15:05:48,535 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005713.temp
2014-07-09 15:05:48,535 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005713.temp
2014-07-09 15:05:48,546 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005712.temp (wrote 18 edits in 213ms)
2014-07-09 15:05:48,547 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005713.temp (wrote 18 edits in 141ms)
2014-07-09 15:05:48,548 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005712.temp (wrote 18 edits in 133ms)
2014-07-09 15:05:48,555 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005712.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005729
2014-07-09 15:05:48,555 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005713.temp
2014-07-09 15:05:48,555 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005713.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005730
2014-07-09 15:05:48,557 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005712.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005729
2014-07-09 15:05:48,597 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005713.temp (wrote 18 edits in 152ms)
2014-07-09 15:05:48,608 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005713.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005730
2014-07-09 15:05:48,608 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 72 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943424724 is corrupted = false progress failed = false
2014-07-09 15:05:48,613 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943424724 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:48,613 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943424724 in 2351ms
2014-07-09 15:05:48,630 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:48,662 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: worker slave1,60020,1404941325989 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943402098
2014-07-09 15:05:48,678 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943402098, length=65839874
2014-07-09 15:05:48,678 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-09 15:05:48,681 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943402098
2014-07-09 15:05:48,688 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943402098 after 7ms
2014-07-09 15:05:48,702 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-09 15:05:48,702 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-09 15:05:48,702 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-09 15:05:48,719 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005658.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:48,742 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005658.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:48,750 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005658.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:48,771 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005659.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:49,232 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:49,232 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:49,242 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:49,243 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,243 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,243 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,243 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,243 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,243 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005659.temp
2014-07-09 15:05:49,244 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005658.temp
2014-07-09 15:05:49,248 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005658.temp (wrote 19 edits in 225ms)
2014-07-09 15:05:49,254 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005658.temp (wrote 17 edits in 149ms)
2014-07-09 15:05:49,257 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005658.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005676
2014-07-09 15:05:49,257 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005659.temp
2014-07-09 15:05:49,258 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005658.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005674
2014-07-09 15:05:49,276 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005658.temp (wrote 19 edits in 264ms)
2014-07-09 15:05:49,277 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005659.temp (wrote 18 edits in 307ms)
2014-07-09 15:05:49,287 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005658.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005676
2014-07-09 15:05:49,291 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005659.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005676
2014-07-09 15:05:49,291 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 73 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943402098 is corrupted = false progress failed = false
2014-07-09 15:05:49,296 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943402098 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:49,296 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943402098 in 634ms
2014-07-09 15:05:49,306 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:49,595 DEBUG [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: Current region server slave1,60020,1404941325989 has 1 tasks in progress and can't take more.
2014-07-09 15:05:50,846 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90155ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:05:50,846 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 260.9m
2014-07-09 15:05:50,992 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:05:51,795 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009 after 4185ms
2014-07-09 15:05:51,820 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-09 15:05:51,820 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-09 15:05:51,822 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-09 15:05:51,845 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005802.temp region=0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:51,855 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005803.temp region=fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:51,869 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005802.temp region=0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:05:51,906 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-09 15:05:51,906 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-09 15:05:51,918 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005803.temp region=aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:51,966 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-09 15:05:51,967 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005802.temp
2014-07-09 15:05:51,967 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005802.temp
2014-07-09 15:05:51,967 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005802.temp
2014-07-09 15:05:51,967 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005803.temp
2014-07-09 15:05:51,967 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005802.temp
2014-07-09 15:05:51,967 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005803.temp
2014-07-09 15:05:51,968 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005803.temp
2014-07-09 15:05:51,971 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005802.temp (wrote 3 edits in 75ms)
2014-07-09 15:05:51,978 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005802.temp (wrote 4 edits in 78ms)
2014-07-09 15:05:51,978 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005803.temp (wrote 3 edits in 101ms)
2014-07-09 15:05:51,980 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005802.temp to hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005804
2014-07-09 15:05:51,980 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005803.temp
2014-07-09 15:05:51,981 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005802.temp to hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005805
2014-07-09 15:05:51,989 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005803.temp to hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005805
2014-07-09 15:05:52,432 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005803.temp (wrote 3 edits in 42ms)
2014-07-09 15:05:52,435 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005803.temp to hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005805
2014-07-09 15:05:52,435 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 13 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404941326960-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960.1404943461009 is corrupted = false progress failed = false
2014-07-09 15:05:52,439 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943461009 to final state DONE slave1,60020,1404941325989
2014-07-09 15:05:52,439 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404941325989 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404941326960-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404941326960.1404943461009 in 4854ms
2014-07-09 15:05:52,448 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-09 15:05:52,494 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Open usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:05:52,496 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Open usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:05:52,496 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Open usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:05:52,496 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Open usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:05:52,497 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Open usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:05:52,505 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 967e1d7e4e4a9cd6ca99d66bdf70a02a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,506 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,507 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning aba5d255d2a2118b681bca61272578b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 967e1d7e4e4a9cd6ca99d66bdf70a02a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node aba5d255d2a2118b681bca61272578b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 967e1d7e4e4a9cd6ca99d66bdf70a02a, NAME => 'usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => aba5d255d2a2118b681bca61272578b4, NAME => 'usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-09 15:05:52,512 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => fa2ab9ffb0b5a85ad4c1c3400a6b6d39, NAME => 'usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:05:52,513 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:05:52,519 INFO  [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:05:52,520 INFO  [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:05:52,521 INFO  [StoreOpener-967e1d7e4e4a9cd6ca99d66bdf70a02a-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:05:52,552 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:05:52,563 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 967e1d7e4e4a9cd6ca99d66bdf70a02a; next sequenceid=1
2014-07-09 15:05:52,563 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:05:52,565 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:05:52,600 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/03943dd7f0f6421a89c520c21a929949, isReference=false, isBulkLoadResult=false, seqid=2165, majorCompaction=false
2014-07-09 15:05:52,602 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/0ec098d23b4f4555842e70d3395bdfc1, isReference=false, isBulkLoadResult=false, seqid=4352, majorCompaction=false
2014-07-09 15:05:52,611 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] catalog.MetaEditor: Updated row usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a. with server=slave1,60020,1404941325989
2014-07-09 15:05:52,611 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] regionserver.HRegionServer: Finished post open deploy task for usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:05:52,612 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 967e1d7e4e4a9cd6ca99d66bdf70a02a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:05:52,616 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 967e1d7e4e4a9cd6ca99d66bdf70a02a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:05:52,616 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 967e1d7e4e4a9cd6ca99d66bdf70a02a to OPENED in zk on slave1,60020,1404941325989
2014-07-09 15:05:52,616 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a. on slave1,60020,1404941325989
2014-07-09 15:05:52,616 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e294e1cc84fff4243a9d24c11e9bc8d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,620 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e294e1cc84fff4243a9d24c11e9bc8d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:05:52,621 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 0e294e1cc84fff4243a9d24c11e9bc8d, NAME => 'usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-09 15:05:52,622 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:52,622 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:05:52,625 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/37762d54f1424a2895b1afa471272ff3, isReference=false, isBulkLoadResult=false, seqid=1000, majorCompaction=false
2014-07-09 15:05:52,642 INFO  [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:05:52,645 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/10935ab4a53e42dc885881592b602f1f, isReference=false, isBulkLoadResult=false, seqid=832, majorCompaction=false
2014-07-09 15:05:52,666 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/123fc3e0dc304d828b4b4abc14bb296e, isReference=false, isBulkLoadResult=false, seqid=5568, majorCompaction=false
2014-07-09 15:05:52,680 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/145320010f5b4bcd9618548529be4182, isReference=false, isBulkLoadResult=false, seqid=899, majorCompaction=false
2014-07-09 15:05:52,685 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/12c02592515f4088887d1165fc858ee1, isReference=false, isBulkLoadResult=false, seqid=2830, majorCompaction=false
2014-07-09 15:05:52,686 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/3c8638ebd260448a9d141e3ae81f58ce, isReference=false, isBulkLoadResult=false, seqid=2497, majorCompaction=false
2014-07-09 15:05:52,698 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/1b892d24e3c74062a20887e8d31e39d6, isReference=false, isBulkLoadResult=false, seqid=3395, majorCompaction=false
2014-07-09 15:05:52,702 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/18484b4efc324c8eaffbab14f560d908, isReference=false, isBulkLoadResult=false, seqid=2164, majorCompaction=false
2014-07-09 15:05:52,710 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2320846854e948b69bf4207e997a7b58, isReference=false, isBulkLoadResult=false, seqid=5654, majorCompaction=false
2014-07-09 15:05:52,711 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/49c3ac6d115a4e39bb6eb20cc3f5eaa9, isReference=false, isBulkLoadResult=false, seqid=5165, majorCompaction=false
2014-07-09 15:05:52,722 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/2444d8abe5cc4d54bea8a0284398b0a3, isReference=false, isBulkLoadResult=false, seqid=3939, majorCompaction=false
2014-07-09 15:05:52,726 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/37489b3288ec4f25b9dd65f05e12d580, isReference=false, isBulkLoadResult=false, seqid=4030, majorCompaction=false
2014-07-09 15:05:52,741 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/288de302ea5d4f25ab4c0deca74c10ab, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-09 15:05:52,748 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/3c2a84c716224d27bb6cdc27534c8162, isReference=false, isBulkLoadResult=false, seqid=2497, majorCompaction=false
2014-07-09 15:05:52,749 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3fc3f22db77a406794ea1f1e23032122, isReference=false, isBulkLoadResult=false, seqid=2564, majorCompaction=false
2014-07-09 15:05:52,760 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/5c8598ea061942b1928f8848199f9c39, isReference=false, isBulkLoadResult=false, seqid=2997, majorCompaction=false
2014-07-09 15:05:52,763 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/59bfdce46e444c9dad821b0ddab4230d, isReference=false, isBulkLoadResult=false, seqid=5162, majorCompaction=false
2014-07-09 15:05:52,768 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4a9891ae591b41f6ac22141b3043a279, isReference=false, isBulkLoadResult=false, seqid=212, majorCompaction=false
2014-07-09 15:05:52,782 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6b632d2e6a214852b3d0d153f830674d, isReference=false, isBulkLoadResult=false, seqid=2665, majorCompaction=false
2014-07-09 15:05:52,785 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/657c2a33be164d9ebd181bcf678ba480, isReference=false, isBulkLoadResult=false, seqid=3328, majorCompaction=false
2014-07-09 15:05:52,797 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4b035fb94d1b4330892f0dc7dde7caad, isReference=false, isBulkLoadResult=false, seqid=566, majorCompaction=false
2014-07-09 15:05:52,799 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/710403c5744a49dba8a85b9a95115101, isReference=false, isBulkLoadResult=false, seqid=666, majorCompaction=false
2014-07-09 15:05:52,813 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6f1a2a76241841ac88cd4b0e0256a0a3, isReference=false, isBulkLoadResult=false, seqid=665, majorCompaction=false
2014-07-09 15:05:52,827 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7548f4182b884ddea62d8abd638180e6, isReference=false, isBulkLoadResult=false, seqid=1498, majorCompaction=false
2014-07-09 15:05:52,837 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/54fdb51e719942e9a47bf6e6747ca012, isReference=false, isBulkLoadResult=false, seqid=2065, majorCompaction=false
2014-07-09 15:05:52,858 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/77cf201cfbea4af3a3095547a81dd73e, isReference=false, isBulkLoadResult=false, seqid=1330, majorCompaction=false
2014-07-09 15:05:52,875 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/77dd2d11972b4a3fa96682a1a208bda7, isReference=false, isBulkLoadResult=false, seqid=2831, majorCompaction=false
2014-07-09 15:05:52,888 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/555a8566d5a341bcb52667d0ec20096d, isReference=false, isBulkLoadResult=false, seqid=3561, majorCompaction=false
2014-07-09 15:05:52,902 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/7bde56a2a0ce46f882739ed119a3399f, isReference=false, isBulkLoadResult=false, seqid=499, majorCompaction=false
2014-07-09 15:05:52,905 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7b68ba0ed05845c4861702ba44c0fdd3, isReference=false, isBulkLoadResult=false, seqid=1166, majorCompaction=false
2014-07-09 15:05:52,912 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/56125172ed8e4654af81eea1c2f167a8, isReference=false, isBulkLoadResult=false, seqid=2397, majorCompaction=false
2014-07-09 15:05:52,920 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7e85b0ece7f34954baf6230f4d52857e, isReference=false, isBulkLoadResult=false, seqid=333, majorCompaction=false
2014-07-09 15:05:52,924 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/87884ad8125f429681cc865847b5a422, isReference=false, isBulkLoadResult=false, seqid=3494, majorCompaction=false
2014-07-09 15:05:52,938 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9bd713b234394c0dbe374350e17d5eb3, isReference=false, isBulkLoadResult=false, seqid=1998, majorCompaction=false
2014-07-09 15:05:52,939 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/5e24a4c19a434c8f99a97ccb0a822972, isReference=false, isBulkLoadResult=false, seqid=1731, majorCompaction=false
2014-07-09 15:05:52,964 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/a8cf6f7dfc6f4724b4e13fa1c7f0e1bb, isReference=false, isBulkLoadResult=false, seqid=1332, majorCompaction=false
2014-07-09 15:05:52,967 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/65122adbecee4e3da9fb501c11e54a62, isReference=false, isBulkLoadResult=false, seqid=3063, majorCompaction=false
2014-07-09 15:05:52,968 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8ae555f5c532416089c4a0230a62351c, isReference=false, isBulkLoadResult=false, seqid=1497, majorCompaction=false
2014-07-09 15:05:52,989 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ab6f1f93c904477183599a8b59aca50c, isReference=false, isBulkLoadResult=false, seqid=4752, majorCompaction=false
2014-07-09 15:05:52,991 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b117166eee847d6a2597f23d985eb44, isReference=false, isBulkLoadResult=false, seqid=1829, majorCompaction=false
2014-07-09 15:05:53,007 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6bb2975734be48c788829f5f3d80579b, isReference=false, isBulkLoadResult=false, seqid=3229, majorCompaction=false
2014-07-09 15:05:53,009 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ace63e71a2ec41e384ba55aed5bd9f97, isReference=false, isBulkLoadResult=false, seqid=5571, majorCompaction=false
2014-07-09 15:05:53,022 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/a436d8f631f24d8c960fe458ee5df15d, isReference=false, isBulkLoadResult=false, seqid=4750, majorCompaction=false
2014-07-09 15:05:53,041 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/be28ed9c7dec408fbfdc0fe9ae002cac, isReference=false, isBulkLoadResult=false, seqid=3329, majorCompaction=false
2014-07-09 15:05:53,058 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/79fddfe53a954baa9bb5ca10b733f0ba, isReference=false, isBulkLoadResult=false, seqid=2730, majorCompaction=false
2014-07-09 15:05:53,060 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b011fea696be4bb396d715d650e5f74b, isReference=false, isBulkLoadResult=false, seqid=2331, majorCompaction=false
2014-07-09 15:05:53,088 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d01cd96ad164f6c832e895adb799023, isReference=false, isBulkLoadResult=false, seqid=733, majorCompaction=false
2014-07-09 15:05:53,090 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b2982f11829642ac84c1a3ea9952d43c, isReference=false, isBulkLoadResult=false, seqid=1997, majorCompaction=false
2014-07-09 15:05:53,107 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/beca9b70e6ee445ea25d73c755388298, isReference=false, isBulkLoadResult=false, seqid=3940, majorCompaction=false
2014-07-09 15:05:53,120 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d7f1e3f355f49039c98eaa8058a2b8d, isReference=false, isBulkLoadResult=false, seqid=2896, majorCompaction=false
2014-07-09 15:05:53,133 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/bda669f73afd43208c395c2d7e851db1, isReference=false, isBulkLoadResult=false, seqid=2996, majorCompaction=false
2014-07-09 15:05:53,135 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/c9a0e09b4db24628a5e1c395cd782a76, isReference=false, isBulkLoadResult=false, seqid=834, majorCompaction=false
2014-07-09 15:05:53,162 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/cebfc0ca2ddf48ddb06f54bf4609e7ce, isReference=false, isBulkLoadResult=false, seqid=2663, majorCompaction=false
2014-07-09 15:05:53,163 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8902cd057abd48e694f3a996b18f7b9f, isReference=false, isBulkLoadResult=false, seqid=4442, majorCompaction=false
2014-07-09 15:05:53,164 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ccced78695f84d3690c3e35010e69639, isReference=false, isBulkLoadResult=false, seqid=3495, majorCompaction=false
2014-07-09 15:05:53,314 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/cd257740e02048a7b094e5b555a99da9, isReference=false, isBulkLoadResult=false, seqid=4356, majorCompaction=false
2014-07-09 15:05:53,331 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/da3421c8de464cf9b5225d4cabce8ee4, isReference=false, isBulkLoadResult=false, seqid=1164, majorCompaction=false
2014-07-09 15:05:53,339 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8925e9a02f9840918f538ba86e5596b3, isReference=false, isBulkLoadResult=false, seqid=1399, majorCompaction=false
2014-07-09 15:05:53,357 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/db253cb0944c40b0b1425e1ab348e6f9, isReference=false, isBulkLoadResult=false, seqid=3162, majorCompaction=false
2014-07-09 15:05:53,394 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8fc5148433834b48b819d036f4a7eda3, isReference=false, isBulkLoadResult=false, seqid=1067, majorCompaction=false
2014-07-09 15:05:53,403 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d34e3ad8633249edae470500cc66f3c2, isReference=false, isBulkLoadResult=false, seqid=1664, majorCompaction=false
2014-07-09 15:05:53,411 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/9692cd2b28ac4d97bb900ab0ef083648, isReference=false, isBulkLoadResult=false, seqid=2231, majorCompaction=false
2014-07-09 15:05:53,437 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/efe6eab791f74c879347c461e577c962, isReference=false, isBulkLoadResult=false, seqid=998, majorCompaction=false
2014-07-09 15:05:53,467 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d364bc312adb45fca0136b9dc28d9cc3, isReference=false, isBulkLoadResult=false, seqid=500, majorCompaction=false
2014-07-09 15:05:53,472 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a044a2cd564048ff9f9a630a6eaed6fe, isReference=false, isBulkLoadResult=false, seqid=5248, majorCompaction=false
2014-07-09 15:05:53,475 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/f0eaf6a98e8d4cb7a725fa3051acc44f, isReference=false, isBulkLoadResult=false, seqid=1663, majorCompaction=false
2014-07-09 15:05:53,492 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d679777569084c3cb81ea37d4c24f3a4, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-09 15:05:53,492 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a83d9bb773f04f48b63b7a494ef0bd2e, isReference=false, isBulkLoadResult=false, seqid=378, majorCompaction=false
2014-07-09 15:05:53,512 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fe45bc84abd946ce841fceb4d2a3ca61, isReference=false, isBulkLoadResult=false, seqid=333, majorCompaction=false
2014-07-09 15:05:53,515 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d67ddca54aa64393a75a1607309e8f5e, isReference=false, isBulkLoadResult=false, seqid=2331, majorCompaction=false
2014-07-09 15:05:53,516 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/bca7b238a3a1436aaeb4d80c71bc8660, isReference=false, isBulkLoadResult=false, seqid=1898, majorCompaction=false
2014-07-09 15:05:53,526 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c9f581396fed4e62a6636bd9ad2e4247, isReference=false, isBulkLoadResult=false, seqid=1233, majorCompaction=false
2014-07-09 15:05:53,526 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/da8f56c9f94444d69163b9c854f6e271, isReference=false, isBulkLoadResult=false, seqid=3163, majorCompaction=false
2014-07-09 15:05:53,541 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/d5cec43e8cf04b7e817011371193affd, isReference=false, isBulkLoadResult=false, seqid=1565, majorCompaction=false
2014-07-09 15:05:53,564 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/f19f26ee11164aacae079c3d6a3eb703, isReference=false, isBulkLoadResult=false, seqid=1832, majorCompaction=false
2014-07-09 15:05:53,569 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ddb165bca89f49618a3f293263cee171, isReference=false, isBulkLoadResult=false, seqid=4840, majorCompaction=false
2014-07-09 15:05:53,569 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 14 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:53,572 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005586
2014-07-09 15:05:53,580 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 14 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:53,582 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005586
2014-07-09 15:05:53,632 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 14 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:53,633 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5584 and minimum sequenceid for the region is 5654, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005584
2014-07-09 15:05:53,635 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5603 and minimum sequenceid for the region is 5654, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005603
2014-07-09 15:05:53,636 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5621 and minimum sequenceid for the region is 5654, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005621
2014-07-09 15:05:53,638 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5638 and minimum sequenceid for the region is 5654, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005638
2014-07-09 15:05:53,639 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005657
2014-07-09 15:05:53,870 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:53,873 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 17320, skipped 84280, firstSequenceidInLog=5639, maxSequenceidInLog=5657, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005657
2014-07-09 15:05:53,875 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005676
2014-07-09 15:05:54,230 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:54,233 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101450, skipped 0, firstSequenceidInLog=5569, maxSequenceidInLog=5586, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005586
2014-07-09 15:05:54,241 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:54,242 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 86150, skipped 22350, firstSequenceidInLog=5567, maxSequenceidInLog=5586, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005586
2014-07-09 15:05:54,254 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005604
2014-07-09 15:05:54,254 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005604
2014-07-09 15:05:54,420 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:54,422 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 106850, skipped 0, firstSequenceidInLog=5658, maxSequenceidInLog=5676, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005676
2014-07-09 15:05:54,425 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005694
2014-07-09 15:05:54,815 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:54,818 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 102140, skipped 0, firstSequenceidInLog=5587, maxSequenceidInLog=5604, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005604
2014-07-09 15:05:54,820 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005622
2014-07-09 15:05:54,823 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:54,825 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 102200, skipped 0, firstSequenceidInLog=5587, maxSequenceidInLog=5604, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005604
2014-07-09 15:05:54,826 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005622
2014-07-09 15:05:55,464 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:55,467 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101220, skipped 0, firstSequenceidInLog=5677, maxSequenceidInLog=5694, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005694
2014-07-09 15:05:55,469 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005711
2014-07-09 15:05:55,791 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:55,793 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101860, skipped 0, firstSequenceidInLog=5605, maxSequenceidInLog=5622, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005622
2014-07-09 15:05:55,795 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005640
2014-07-09 15:05:55,879 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:55,881 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101860, skipped 0, firstSequenceidInLog=5605, maxSequenceidInLog=5622, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005622
2014-07-09 15:05:55,883 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005640
2014-07-09 15:05:56,112 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:56,114 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 96550, skipped 0, firstSequenceidInLog=5695, maxSequenceidInLog=5711, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005711
2014-07-09 15:05:56,116 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005729
2014-07-09 15:05:56,387 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:56,390 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 102020, skipped 0, firstSequenceidInLog=5623, maxSequenceidInLog=5640, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005640
2014-07-09 15:05:56,392 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005657
2014-07-09 15:05:56,471 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:56,473 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101520, skipped 0, firstSequenceidInLog=5623, maxSequenceidInLog=5640, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005640
2014-07-09 15:05:56,475 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005658
2014-07-09 15:05:56,678 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:56,681 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101860, skipped 0, firstSequenceidInLog=5712, maxSequenceidInLog=5729, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005729
2014-07-09 15:05:56,683 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005748
2014-07-09 15:05:56,998 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:57,000 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 95300, skipped 0, firstSequenceidInLog=5641, maxSequenceidInLog=5657, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005657
2014-07-09 15:05:57,002 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005676
2014-07-09 15:05:57,104 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:57,106 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101440, skipped 0, firstSequenceidInLog=5641, maxSequenceidInLog=5658, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005658
2014-07-09 15:05:57,116 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005676
2014-07-09 15:05:57,350 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:57,353 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 108090, skipped 0, firstSequenceidInLog=5730, maxSequenceidInLog=5748, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005748
2014-07-09 15:05:57,358 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005766
2014-07-09 15:05:57,728 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:05:57,731 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 108640, skipped 0, firstSequenceidInLog=5658, maxSequenceidInLog=5676, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005676
2014-07-09 15:05:57,733 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005694
2014-07-09 15:05:57,770 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:05:57,772 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 102300, skipped 0, firstSequenceidInLog=5659, maxSequenceidInLog=5676, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005676
2014-07-09 15:05:57,773 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005694
2014-07-09 15:05:58,112 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:05:58,114 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102200, skipped 0, firstSequenceidInLog=5749, maxSequenceidInLog=5766, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005766
2014-07-09 15:05:58,116 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005784
2014-07-09 15:06:09,153 WARN  [regionserver60020] util.Sleeper: We slept 13072ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:06:09,153 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10874ms
GC pool 'ParNew' had collection(s): count=1 time=1560ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=9356ms
2014-07-09 15:06:09,425 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:09,428 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 102090, skipped 0, firstSequenceidInLog=5677, maxSequenceidInLog=5694, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005694
2014-07-09 15:06:09,430 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005712
2014-07-09 15:06:09,444 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:09,446 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101410, skipped 0, firstSequenceidInLog=5677, maxSequenceidInLog=5694, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005694
2014-07-09 15:06:09,448 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005712
2014-07-09 15:06:09,779 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:06:09,781 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101930, skipped 0, firstSequenceidInLog=5767, maxSequenceidInLog=5784, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005784
2014-07-09 15:06:09,808 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5807, memsize=260.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0e2b09e890e148078d1ec7be92599674
2014-07-09 15:06:09,817 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005801
2014-07-09 15:06:09,825 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0e2b09e890e148078d1ec7be92599674 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0e2b09e890e148078d1ec7be92599674
2014-07-09 15:06:09,834 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0e2b09e890e148078d1ec7be92599674, entries=949930, sequenceid=5807, filesize=67.7m
2014-07-09 15:06:09,834 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.9m/273572480, currentsize=0.0/0 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 18988ms, sequenceid=5807, compaction requested=true
2014-07-09 15:06:09,835 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:09,835 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:06:09,835 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:06:09,835 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:09,835 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:09,835 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:06:10,168 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:10,171 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101760, skipped 0, firstSequenceidInLog=5695, maxSequenceidInLog=5712, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005712
2014-07-09 15:06:10,173 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005730
2014-07-09 15:06:10,230 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:10,232 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101310, skipped 0, firstSequenceidInLog=5695, maxSequenceidInLog=5712, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005712
2014-07-09 15:06:10,233 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005730
2014-07-09 15:06:10,618 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:06:10,621 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 97080, skipped 0, firstSequenceidInLog=5785, maxSequenceidInLog=5801, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005801
2014-07-09 15:06:10,623 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005805
2014-07-09 15:06:10,791 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:06:10,793 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 22440, skipped 0, firstSequenceidInLog=5802, maxSequenceidInLog=5805, path=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005805
2014-07-09 15:06:10,794 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 235.0m; wal is null, using passed sequenceid=5805
2014-07-09 15:06:10,868 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:10,871 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101580, skipped 0, firstSequenceidInLog=5713, maxSequenceidInLog=5730, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005730
2014-07-09 15:06:10,874 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005748
2014-07-09 15:06:10,924 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:11,001 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 256.4m; wal is null, using passed sequenceid=5733
2014-07-09 15:06:11,021 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:11,035 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 102460, skipped 0, firstSequenceidInLog=5713, maxSequenceidInLog=5730, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005730
2014-07-09 15:06:11,037 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005748
2014-07-09 15:06:11,161 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:11,317 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 256.7m; wal is null, using passed sequenceid=5736
2014-07-09 15:06:11,482 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:11,489 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-09 15:06:11,490 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-09 15:06:17,977 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5805, memsize=235.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/6a74f989ead6472ab8afbcc0c2773897
2014-07-09 15:06:17,991 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/6a74f989ead6472ab8afbcc0c2773897 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6a74f989ead6472ab8afbcc0c2773897
2014-07-09 15:06:17,999 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6a74f989ead6472ab8afbcc0c2773897, entries=855540, sequenceid=5805, filesize=60.9m
2014-07-09 15:06:18,000 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~235.0m/246388400, currentsize=0.0/0 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 7206ms, sequenceid=5805, compaction requested=true; wal=null
2014-07-09 15:06:18,001 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005584
2014-07-09 15:06:18,002 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005603
2014-07-09 15:06:18,003 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005621
2014-07-09 15:06:18,005 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005638
2014-07-09 15:06:18,006 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005657
2014-07-09 15:06:18,008 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005676
2014-07-09 15:06:18,009 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005694
2014-07-09 15:06:18,010 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005711
2014-07-09 15:06:18,014 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005729
2014-07-09 15:06:18,015 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005748
2014-07-09 15:06:18,017 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005766
2014-07-09 15:06:18,018 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005784
2014-07-09 15:06:18,019 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005801
2014-07-09 15:06:18,020 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/recovered.edits/0000000000000005805
2014-07-09 15:06:18,022 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 0e294e1cc84fff4243a9d24c11e9bc8d; next sequenceid=5806
2014-07-09 15:06:18,022 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:06:18,025 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:06:18,026 DEBUG [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:18,031 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:06:18,031 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:06:18,031 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:18,031 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:18,031 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:06:18,054 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] catalog.MetaEditor: Updated row usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. with server=slave1,60020,1404941325989
2014-07-09 15:06:18,054 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:06:18,054 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e294e1cc84fff4243a9d24c11e9bc8d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:18,061 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e294e1cc84fff4243a9d24c11e9bc8d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:18,061 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 0e294e1cc84fff4243a9d24c11e9bc8d to OPENED in zk on slave1,60020,1404941325989
2014-07-09 15:06:18,061 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. on slave1,60020,1404941325989
2014-07-09 15:06:18,061 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0cec477330d16ea60f6b986e45ac1516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:06:18,067 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0cec477330d16ea60f6b986e45ac1516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:06:18,068 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 0cec477330d16ea60f6b986e45ac1516, NAME => 'usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-09 15:06:18,068 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:18,068 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:06:18,075 INFO  [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:06:18,115 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0a25622458054959a24e179ec17bb2bb, isReference=false, isBulkLoadResult=false, seqid=4439, majorCompaction=false
2014-07-09 15:06:18,161 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0d8950a81c4245ee9ba5aaab15bc4b21, isReference=false, isBulkLoadResult=false, seqid=2397, majorCompaction=false
2014-07-09 15:06:18,179 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0e3d19f2250c460aac5a0fba103d05f7, isReference=false, isBulkLoadResult=false, seqid=1733, majorCompaction=false
2014-07-09 15:06:18,203 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/268853e99d764e48bfedb502a6d41194, isReference=false, isBulkLoadResult=false, seqid=2564, majorCompaction=false
2014-07-09 15:06:18,217 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/297a60cb4e1a4045830c9ed086b915ce, isReference=false, isBulkLoadResult=false, seqid=3063, majorCompaction=false
2014-07-09 15:06:18,232 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/2dde80329a6f4e618a3bf2ff69f29022, isReference=false, isBulkLoadResult=false, seqid=5245, majorCompaction=false
2014-07-09 15:06:18,253 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3cc067d0b142437aa75e89dfb00e55b2, isReference=false, isBulkLoadResult=false, seqid=4833, majorCompaction=false
2014-07-09 15:06:18,266 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/4d198ec64f36457b9764754c4522a9ca, isReference=false, isBulkLoadResult=false, seqid=566, majorCompaction=false
2014-07-09 15:06:18,283 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/55428f9c1fc3432885ec04830c0333fb, isReference=false, isBulkLoadResult=false, seqid=1067, majorCompaction=false
2014-07-09 15:06:18,298 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/5c61223c852f41688ed3fff756af1031, isReference=false, isBulkLoadResult=false, seqid=3229, majorCompaction=false
2014-07-09 15:06:18,308 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/6b2180b7e3544748ae4605a98b81c53b, isReference=false, isBulkLoadResult=false, seqid=5651, majorCompaction=false
2014-07-09 15:06:18,319 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/833a91bdc2174f04ae7b755e5e64a5dd, isReference=false, isBulkLoadResult=false, seqid=734, majorCompaction=false
2014-07-09 15:06:18,346 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8ad0dc2af3af433f863684719cc06d25, isReference=false, isBulkLoadResult=false, seqid=4027, majorCompaction=false
2014-07-09 15:06:18,378 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8e1209b9d3234aebb76c7915ac86db95, isReference=false, isBulkLoadResult=false, seqid=1899, majorCompaction=false
2014-07-09 15:06:18,408 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/94c061ab697e4f93b3e4ca04a5c84756, isReference=false, isBulkLoadResult=false, seqid=3395, majorCompaction=false
2014-07-09 15:06:18,431 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9f49ae5942054f8485081121898a4bd0, isReference=false, isBulkLoadResult=false, seqid=1399, majorCompaction=false
2014-07-09 15:06:18,456 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a0bdf14cb65746b4a5a0f6948ffdc2f7, isReference=false, isBulkLoadResult=false, seqid=2896, majorCompaction=false
2014-07-09 15:06:18,467 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ba2d8b719658485ca38e1da3fe86609e, isReference=false, isBulkLoadResult=false, seqid=3561, majorCompaction=false
2014-07-09 15:06:18,479 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c0bfdf08816d46dd957d841cbeacd6fb, isReference=false, isBulkLoadResult=false, seqid=379, majorCompaction=false
2014-07-09 15:06:18,493 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d1065a17cb6146029c9892551b99aa36, isReference=false, isBulkLoadResult=false, seqid=900, majorCompaction=false
2014-07-09 15:06:18,510 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d13d5b12f70041769320253668fdb779, isReference=false, isBulkLoadResult=false, seqid=1233, majorCompaction=false
2014-07-09 15:06:18,523 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7dac0168b4345e2ae9fd5479ce29eeb, isReference=false, isBulkLoadResult=false, seqid=2730, majorCompaction=false
2014-07-09 15:06:18,547 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ddc365707e424dce958d47b0be4edf9f, isReference=false, isBulkLoadResult=false, seqid=2231, majorCompaction=false
2014-07-09 15:06:18,564 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/edd46d224132482d83ac6e6d19349497, isReference=false, isBulkLoadResult=false, seqid=2065, majorCompaction=false
2014-07-09 15:06:18,602 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/fbf0a16fee7d44b4a6ed61d2e176b36b, isReference=false, isBulkLoadResult=false, seqid=213, majorCompaction=false
2014-07-09 15:06:18,626 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ff7b3788d1904946957d76d07ce88df1, isReference=false, isBulkLoadResult=false, seqid=1567, majorCompaction=false
2014-07-09 15:06:18,641 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 14 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:18,642 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5584 and minimum sequenceid for the region is 5651, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005584
2014-07-09 15:06:18,644 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5602 and minimum sequenceid for the region is 5651, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005602
2014-07-09 15:06:18,645 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5619 and minimum sequenceid for the region is 5651, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005619
2014-07-09 15:06:18,647 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 5637 and minimum sequenceid for the region is 5651, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005637
2014-07-09 15:06:18,649 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005657
2014-07-09 15:06:18,775 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5733, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/fdd2d29a2e204552bba925cd65283725
2014-07-09 15:06:18,798 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/fdd2d29a2e204552bba925cd65283725 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fdd2d29a2e204552bba925cd65283725
2014-07-09 15:06:18,809 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fdd2d29a2e204552bba925cd65283725, entries=933560, sequenceid=5733, filesize=66.5m
2014-07-09 15:06:18,809 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~256.4m/268856800, currentsize=0.0/0 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 7808ms, sequenceid=5733, compaction requested=true; wal=null
2014-07-09 15:06:19,184 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:19,186 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 102060, skipped 0, firstSequenceidInLog=5731, maxSequenceidInLog=5748, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005748
2014-07-09 15:06:19,188 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005767
2014-07-09 15:06:19,373 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5736, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/eed6e63c8b564094a4a591ff671ad457
2014-07-09 15:06:19,381 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/eed6e63c8b564094a4a591ff671ad457 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/eed6e63c8b564094a4a591ff671ad457
2014-07-09 15:06:19,387 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:19,389 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 34310, skipped 73930, firstSequenceidInLog=5638, maxSequenceidInLog=5657, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005657
2014-07-09 15:06:19,391 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005674
2014-07-09 15:06:19,395 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/eed6e63c8b564094a4a591ff671ad457, entries=934810, sequenceid=5736, filesize=66.6m
2014-07-09 15:06:19,395 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~256.7m/269217840, currentsize=0.0/0 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 8078ms, sequenceid=5736, compaction requested=true; wal=null
2014-07-09 15:06:19,721 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:19,724 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 102860, skipped 0, firstSequenceidInLog=5731, maxSequenceidInLog=5748, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005748
2014-07-09 15:06:19,726 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005766
2014-07-09 15:06:19,867 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:19,870 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 96560, skipped 0, firstSequenceidInLog=5658, maxSequenceidInLog=5674, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005674
2014-07-09 15:06:19,872 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005693
2014-07-09 15:06:20,227 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:20,230 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 106880, skipped 0, firstSequenceidInLog=5749, maxSequenceidInLog=5767, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005767
2014-07-09 15:06:20,232 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005784
2014-07-09 15:06:20,401 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:20,404 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 100110, skipped 0, firstSequenceidInLog=5749, maxSequenceidInLog=5766, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005766
2014-07-09 15:06:20,406 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005784
2014-07-09 15:06:20,527 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:20,530 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 107210, skipped 0, firstSequenceidInLog=5675, maxSequenceidInLog=5693, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005693
2014-07-09 15:06:20,531 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005711
2014-07-09 15:06:21,242 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:21,245 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 96440, skipped 0, firstSequenceidInLog=5768, maxSequenceidInLog=5784, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005784
2014-07-09 15:06:21,248 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005802
2014-07-09 15:06:21,442 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:21,445 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101230, skipped 0, firstSequenceidInLog=5767, maxSequenceidInLog=5784, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005784
2014-07-09 15:06:21,451 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005802
2014-07-09 15:06:21,558 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:21,560 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102410, skipped 0, firstSequenceidInLog=5694, maxSequenceidInLog=5711, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005711
2014-07-09 15:06:21,562 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005729
2014-07-09 15:06:21,871 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:21,874 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 102370, skipped 0, firstSequenceidInLog=5785, maxSequenceidInLog=5802, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005802
2014-07-09 15:06:21,876 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005805
2014-07-09 15:06:22,003 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:22,005 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 16720, skipped 0, firstSequenceidInLog=5803, maxSequenceidInLog=5805, path=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005805
2014-07-09 15:06:22,005 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 111.8m; wal is null, using passed sequenceid=5805
2014-07-09 15:06:22,052 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:22,125 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:22,127 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 102360, skipped 0, firstSequenceidInLog=5785, maxSequenceidInLog=5802, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005802
2014-07-09 15:06:22,129 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005805
2014-07-09 15:06:22,334 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:22,336 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 16360, skipped 0, firstSequenceidInLog=5803, maxSequenceidInLog=5805, path=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005805
2014-07-09 15:06:22,337 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 106.9m; wal is null, using passed sequenceid=5805
2014-07-09 15:06:22,357 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:22,359 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101480, skipped 0, firstSequenceidInLog=5712, maxSequenceidInLog=5729, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005729
2014-07-09 15:06:22,361 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005747
2014-07-09 15:06:22,404 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:23,131 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:23,134 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102700, skipped 0, firstSequenceidInLog=5730, maxSequenceidInLog=5747, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005747
2014-07-09 15:06:23,136 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005765
2014-07-09 15:06:23,829 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:23,831 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102260, skipped 0, firstSequenceidInLog=5748, maxSequenceidInLog=5765, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005765
2014-07-09 15:06:23,839 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005783
2014-07-09 15:06:24,500 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:24,502 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101870, skipped 0, firstSequenceidInLog=5766, maxSequenceidInLog=5783, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005783
2014-07-09 15:06:24,506 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005801
2014-07-09 15:06:25,205 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5805, memsize=111.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/d6dd5e52b85842bcb74373bc4a90dfaa
2014-07-09 15:06:25,219 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/d6dd5e52b85842bcb74373bc4a90dfaa as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d6dd5e52b85842bcb74373bc4a90dfaa
2014-07-09 15:06:25,227 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d6dd5e52b85842bcb74373bc4a90dfaa, entries=407110, sequenceid=5805, filesize=29.0m
2014-07-09 15:06:25,228 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~111.8m/117244640, currentsize=0.0/0 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 3222ms, sequenceid=5805, compaction requested=true; wal=null
2014-07-09 15:06:25,229 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005586
2014-07-09 15:06:25,230 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005604
2014-07-09 15:06:25,240 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005622
2014-07-09 15:06:25,242 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005640
2014-07-09 15:06:25,243 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005658
2014-07-09 15:06:25,305 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005676
2014-07-09 15:06:25,310 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005694
2014-07-09 15:06:25,311 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005712
2014-07-09 15:06:25,313 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005730
2014-07-09 15:06:25,314 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005748
2014-07-09 15:06:25,316 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005767
2014-07-09 15:06:25,317 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005784
2014-07-09 15:06:25,319 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005802
2014-07-09 15:06:25,324 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/recovered.edits/0000000000000005805
2014-07-09 15:06:25,326 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined fa2ab9ffb0b5a85ad4c1c3400a6b6d39; next sequenceid=5806
2014-07-09 15:06:25,326 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:06:25,328 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:25,330 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:06:25,330 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101410, skipped 0, firstSequenceidInLog=5784, maxSequenceidInLog=5801, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005801
2014-07-09 15:06:25,330 DEBUG [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:25,331 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:06:25,331 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:06:25,331 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:25,332 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:25,332 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:06:25,333 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005804
2014-07-09 15:06:25,342 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] catalog.MetaEditor: Updated row usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. with server=slave1,60020,1404941325989
2014-07-09 15:06:25,342 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:06:25,343 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:25,347 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:25,347 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned fa2ab9ffb0b5a85ad4c1c3400a6b6d39 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 15:06:25,347 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. on slave1,60020,1404941325989
2014-07-09 15:06:25,377 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5805, memsize=106.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/e633845284bb453bb5014dc55a5ef078
2014-07-09 15:06:25,389 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/e633845284bb453bb5014dc55a5ef078 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/e633845284bb453bb5014dc55a5ef078
2014-07-09 15:06:25,409 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/e633845284bb453bb5014dc55a5ef078, entries=389400, sequenceid=5805, filesize=27.8m
2014-07-09 15:06:25,409 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~106.9m/112143440, currentsize=0.0/0 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 3072ms, sequenceid=5805, compaction requested=true; wal=null
2014-07-09 15:06:25,411 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005586
2014-07-09 15:06:25,413 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005604
2014-07-09 15:06:25,421 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005622
2014-07-09 15:06:25,424 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005640
2014-07-09 15:06:25,426 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005657
2014-07-09 15:06:25,427 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005676
2014-07-09 15:06:25,428 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005694
2014-07-09 15:06:25,443 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005712
2014-07-09 15:06:25,444 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005730
2014-07-09 15:06:25,446 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005748
2014-07-09 15:06:25,448 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005766
2014-07-09 15:06:25,450 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005784
2014-07-09 15:06:25,452 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005802
2014-07-09 15:06:25,453 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/recovered.edits/0000000000000005805
2014-07-09 15:06:25,459 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined aba5d255d2a2118b681bca61272578b4; next sequenceid=5806
2014-07-09 15:06:25,459 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:06:25,461 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:06:25,461 DEBUG [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:25,462 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:06:25,462 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:06:25,462 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:25,462 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:25,462 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:06:25,467 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] catalog.MetaEditor: Updated row usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. with server=slave1,60020,1404941325989
2014-07-09 15:06:25,467 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:06:25,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning aba5d255d2a2118b681bca61272578b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:25,471 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node aba5d255d2a2118b681bca61272578b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:25,472 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned aba5d255d2a2118b681bca61272578b4 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 15:06:25,472 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. on slave1,60020,1404941325989
2014-07-09 15:06:25,509 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:25,514 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 17280, skipped 0, firstSequenceidInLog=5802, maxSequenceidInLog=5804, path=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005804
2014-07-09 15:06:25,514 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 238.3m; wal is null, using passed sequenceid=5804
2014-07-09 15:06:25,752 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:06:32,783 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5804, memsize=238.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/c7f068cc31ce450a88e42978112c6686
2014-07-09 15:06:32,794 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/c7f068cc31ce450a88e42978112c6686 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c7f068cc31ce450a88e42978112c6686
2014-07-09 15:06:32,809 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c7f068cc31ce450a88e42978112c6686, entries=867490, sequenceid=5804, filesize=61.8m
2014-07-09 15:06:32,809 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~238.3m/249830000, currentsize=0.0/0 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 7295ms, sequenceid=5804, compaction requested=true; wal=null
2014-07-09 15:06:32,811 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005584
2014-07-09 15:06:32,813 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005602
2014-07-09 15:06:32,824 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005619
2014-07-09 15:06:32,832 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005637
2014-07-09 15:06:32,833 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005657
2014-07-09 15:06:32,835 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005674
2014-07-09 15:06:32,836 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005693
2014-07-09 15:06:32,837 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005711
2014-07-09 15:06:32,839 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005729
2014-07-09 15:06:32,847 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005747
2014-07-09 15:06:32,848 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005765
2014-07-09 15:06:32,849 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005783
2014-07-09 15:06:32,850 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005801
2014-07-09 15:06:32,853 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/recovered.edits/0000000000000005804
2014-07-09 15:06:32,855 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 0cec477330d16ea60f6b986e45ac1516; next sequenceid=5805
2014-07-09 15:06:32,855 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:06:32,858 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:06:32,859 DEBUG [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:32,865 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:06:32,866 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:06:32,866 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:32,866 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:32,866 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:06:32,877 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] catalog.MetaEditor: Updated row usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. with server=slave1,60020,1404941325989
2014-07-09 15:06:32,877 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:06:32,878 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0cec477330d16ea60f6b986e45ac1516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:32,882 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x471d07562a0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0cec477330d16ea60f6b986e45ac1516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:06:32,882 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 0cec477330d16ea60f6b986e45ac1516 to OPENED in zk on slave1,60020,1404941325989
2014-07-09 15:06:32,882 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. on slave1,60020,1404941325989
2014-07-09 15:06:34,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:34,595 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943458098 with entries=82, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943594555
2014-07-09 15:06:41,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:41,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943594555 with entries=77, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943601503
2014-07-09 15:06:44,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:44,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29071 synced till here 29070
2014-07-09 15:06:44,924 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943601503 with entries=80, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943604866
2014-07-09 15:06:48,121 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:06:48,121 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:06:48,122 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:06:48,122 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 20 blocking
2014-07-09 15:06:48,122 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 26 files from compaction candidates
2014-07-09 15:06:48,122 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:06:48,122 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:06:48,122 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:06:48,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:48,243 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943604866 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943608224
2014-07-09 15:06:52,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:52,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29228 synced till here 29227
2014-07-09 15:06:52,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943608224 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943612444
2014-07-09 15:06:55,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:55,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29306 synced till here 29305
2014-07-09 15:06:55,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943612444 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943615439
2014-07-09 15:06:59,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:06:59,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943615439 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943619661
2014-07-09 15:07:02,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:02,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29463 synced till here 29462
2014-07-09 15:07:02,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943619661 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943622439
2014-07-09 15:07:06,801 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:06,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943622439 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943626802
2014-07-09 15:07:09,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:09,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943626802 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943629608
2014-07-09 15:07:14,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:14,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29698 synced till here 29697
2014-07-09 15:07:14,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943629608 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943634733
2014-07-09 15:07:18,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:18,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943634733 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943638119
2014-07-09 15:07:21,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:21,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943638119 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943641058
2014-07-09 15:07:26,019 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:26,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943641058 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943646019
2014-07-09 15:07:29,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:29,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943646019 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943649106
2014-07-09 15:07:32,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:32,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943649106 with entries=78, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943652714
2014-07-09 15:07:35,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:35,548 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943652714 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943655515
2014-07-09 15:07:39,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:39,562 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943655515 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943659517
2014-07-09 15:07:39,563 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:07:39,564 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 188.7m
2014-07-09 15:07:39,691 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:07:41,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:41,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30327 synced till here 30326
2014-07-09 15:07:41,873 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943659517 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943661808
2014-07-09 15:07:43,345 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:07:43,345 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:43,346 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:43,346 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:07:43,346 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:07:43,346 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:43,346 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:43,346 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:07:43,444 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:07:43,444 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:43,444 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:43,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:07:43,445 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:07:43,445 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:43,445 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:43,445 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:07:43,545 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:07:43,545 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:43,545 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:43,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:07:43,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:07:43,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:43,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:43,546 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:07:43,997 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:07:43,998 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:43,998 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:43,998 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:07:43,998 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:07:43,998 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:43,998 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:43,998 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:07:44,099 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:07:44,099 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:44,100 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:44,100 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:07:44,100 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:07:44,100 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:44,100 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:44,100 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:07:44,181 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:07:44,181 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:44,181 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:44,181 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:07:44,181 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:07:44,181 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:44,181 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:44,181 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:07:44,207 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:07:44,207 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:07:44,208 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:44,208 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:07:44,208 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:07:44,208 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:07:44,208 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:44,208 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:07:45,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:45,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943661808 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943665175
2014-07-09 15:07:45,374 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5940, memsize=188.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/ba8b7bde18aa4ffebc555765bf66f030
2014-07-09 15:07:45,384 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/ba8b7bde18aa4ffebc555765bf66f030 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ba8b7bde18aa4ffebc555765bf66f030
2014-07-09 15:07:45,414 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ba8b7bde18aa4ffebc555765bf66f030, entries=686980, sequenceid=5940, filesize=48.9m
2014-07-09 15:07:45,415 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~188.7m/197830800, currentsize=8.3m/8736960 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 5851ms, sequenceid=5940, compaction requested=true
2014-07-09 15:07:45,415 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:07:45,415 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 20 blocking
2014-07-09 15:07:45,415 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 11 files from compaction candidates
2014-07-09 15:07:45,415 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:07:45,415 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:07:45,415 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:07:48,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:48,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30483 synced till here 30482
2014-07-09 15:07:48,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943665175 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943668448
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943351393
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943356865
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943365358
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943371617
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943377366
2014-07-09 15:07:48,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943385801
2014-07-09 15:07:48,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943393118
2014-07-09 15:07:51,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:51,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943668448 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943671710
2014-07-09 15:07:54,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:54,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943671710 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943674873
2014-07-09 15:07:57,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:07:57,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943674873 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943677273
2014-07-09 15:08:01,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:01,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30799 synced till here 30797
2014-07-09 15:08:01,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943677273 with entries=82, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943681287
2014-07-09 15:08:01,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:03,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:03,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943681287 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943683821
2014-07-09 15:08:03,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:07,487 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:07,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30955 synced till here 30954
2014-07-09 15:08:07,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943683821 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943687488
2014-07-09 15:08:07,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:09,785 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:09,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943687488 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943689785
2014-07-09 15:08:09,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:10,888 WARN  [RpcServer.handler=46,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/5c61223c852f41688ed3fff756af1031 for block blk_5850272144817460738_72657:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,890 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8fc5148433834b48b819d036f4a7eda3 for block blk_-3282930300260751890_72305:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,891 WARN  [RpcServer.handler=10,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/3c8638ebd260448a9d141e3ae81f58ce for block blk_2160928512249096643_72537:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,892 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d01cd96ad164f6c832e895adb799023 for block blk_-4841494377182575379_72252:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,897 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ccced78695f84d3690c3e35010e69639 for block blk_1216346043145585869_72700:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,897 WARN  [RpcServer.handler=30,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/beca9b70e6ee445ea25d73c755388298 for block blk_-7514055387319644882_72770:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,897 WARN  [RpcServer.handler=7,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0a25622458054959a24e179ec17bb2bb for block blk_-4774479203196950448_72840:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,897 WARN  [RpcServer.handler=45,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ab6f1f93c904477183599a8b59aca50c for block blk_-6699272717243074638_72879:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,899 WARN  [RpcServer.handler=38,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/d5cec43e8cf04b7e817011371193affd for block blk_5670057164566047438_72384:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,906 WARN  [RpcServer.handler=17,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/da3421c8de464cf9b5225d4cabce8ee4 for block blk_5015695371089212597_72318:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,912 WARN  [RpcServer.handler=27,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7b68ba0ed05845c4861702ba44c0fdd3 for block blk_-4975721979176631804_72320:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,916 WARN  [RpcServer.handler=24,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7548f4182b884ddea62d8abd638180e6 for block blk_-7767489416517774816_72375:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,935 WARN  [RpcServer.handler=44,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/0ec098d23b4f4555842e70d3395bdfc1 for block blk_-1466691561934522469_72821:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,935 WARN  [RpcServer.handler=0,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3cc067d0b142437aa75e89dfb00e55b2 for block blk_5211005625009358838_72889:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,938 WARN  [RpcServer.handler=33,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/77dd2d11972b4a3fa96682a1a208bda7 for block blk_6125602699264031839_72592:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,939 WARN  [RpcServer.handler=4,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/49180e1a5f25478f9d72d9d3515f732d for block blk_-5895069841806099409_73030:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,940 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/4d198ec64f36457b9764754c4522a9ca for block blk_8443034361274716467_72234:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,943 WARN  [RpcServer.handler=47,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ace63e71a2ec41e384ba55aed5bd9f97 for block blk_7235025327039978497_72988:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,949 WARN  [RpcServer.handler=19,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/710403c5744a49dba8a85b9a95115101 for block blk_-5631913784300669943_72241:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,949 WARN  [RpcServer.handler=9,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7dac0168b4345e2ae9fd5479ce29eeb for block blk_3511570665676518491_72575:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,951 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/49c3ac6d115a4e39bb6eb20cc3f5eaa9 for block blk_-5510022713104917547_72928:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,952 WARN  [RpcServer.handler=10,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d67ddca54aa64393a75a1607309e8f5e for block blk_5846178504718518246_72510:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,959 WARN  [RpcServer.handler=42,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/fbf0a16fee7d44b4a6ed61d2e176b36b for block blk_6314903404599292395_72172:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,963 WARN  [RpcServer.handler=15,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fa13366e41ae45bc9d9719ff74e4804a for block blk_7329188995976640593_72991:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,967 WARN  [RpcServer.handler=12,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b011fea696be4bb396d715d650e5f74b for block blk_9162250255021269610_72509:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,968 WARN  [RpcServer.handler=18,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/b4c2b14e44b04ebe8ab2f4cd03f479b3 for block blk_-5989126035182107547_72497:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,968 WARN  [RpcServer.handler=20,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d7f1e3f355f49039c98eaa8058a2b8d for block blk_4221183717857927520_72602:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,970 WARN  [RpcServer.handler=30,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6a74f989ead6472ab8afbcc0c2773897 for block blk_1047163332731946956_73077:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,975 WARN  [RpcServer.handler=14,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/555a8566d5a341bcb52667d0ec20096d for block blk_4586078093438096628_72711:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,977 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/a436d8f631f24d8c960fe458ee5df15d for block blk_3737675881115537077_72875:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,978 WARN  [RpcServer.handler=7,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/03943dd7f0f6421a89c520c21a929949 for block blk_5267702120755697532_72482:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,978 WARN  [RpcServer.handler=37,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ba2d8b719658485ca38e1da3fe86609e for block blk_-5353458530257842794_72712:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,990 WARN  [RpcServer.handler=47,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/56125172ed8e4654af81eea1c2f167a8 for block blk_4519947170680572649_72520:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,997 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a0bdf14cb65746b4a5a0f6948ffdc2f7 for block blk_6095589733353125441_72603:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,999 WARN  [RpcServer.handler=38,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/12c02592515f4088887d1165fc858ee1 for block blk_-3445992759979549059_72591:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:10,999 WARN  [RpcServer.handler=44,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/f0eaf6a98e8d4cb7a725fa3051acc44f for block blk_4213433832195500587_72399:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,004 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/cd257740e02048a7b094e5b555a99da9 for block blk_8140658189731370314_72826:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,009 WARN  [RpcServer.handler=19,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/cf167e9308f94c8aae386d9fa415035d for block blk_44773500611151001_72997:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,010 WARN  [RpcServer.handler=13,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/cebfc0ca2ddf48ddb06f54bf4609e7ce for block blk_1286288382495954395_72564:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,011 WARN  [RpcServer.handler=47,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d1065a17cb6146029c9892551b99aa36 for block blk_2458900725394473368_72278:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,013 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4a9891ae591b41f6ac22141b3043a279 for block blk_-4655848237286252572_72169:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,014 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/59bfdce46e444c9dad821b0ddab4230d for block blk_5881740377672070212_72927:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,023 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/37489b3288ec4f25b9dd65f05e12d580 for block blk_3744312642660849364_72784:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,035 WARN  [RpcServer.handler=17,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/833a91bdc2174f04ae7b755e5e64a5dd for block blk_-6246584725564340705_72253:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,044 WARN  [RpcServer.handler=45,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/c9a0e09b4db24628a5e1c395cd782a76 for block blk_-2199086763689467315_72267:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,046 WARN  [RpcServer.handler=7,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/9692cd2b28ac4d97bb900ab0ef083648 for block blk_-6946688525314251911_72492:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,047 WARN  [RpcServer.handler=37,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8ae555f5c532416089c4a0230a62351c for block blk_-9197858484871407938_72372:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,047 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0e2b09e890e148078d1ec7be92599674 for block blk_-3854061033442243218_73072:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,047 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/da8f56c9f94444d69163b9c854f6e271 for block blk_7488432766631313579_72650:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,050 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/1b892d24e3c74062a20887e8d31e39d6 for block blk_-5486591215524497788_72684:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,060 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0e3d19f2250c460aac5a0fba103d05f7 for block blk_4353011681274819254_72413:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,060 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2320846854e948b69bf4207e997a7b58 for block blk_8326780390154237681_73002:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,068 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/77cf201cfbea4af3a3095547a81dd73e for block blk_-1929616499492100039_72346:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,084 WARN  [RpcServer.handler=4,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3cb7ab78738c43018c2dd00b11c58e52 for block blk_-1391805405888931147_72979:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,087 WARN  [RpcServer.handler=15,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/bda669f73afd43208c395c2d7e851db1 for block blk_8374467557423007053_72617:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,088 WARN  [RpcServer.handler=36,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/123fc3e0dc304d828b4b4abc14bb296e for block blk_-7850280251495542990_72983:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,093 WARN  [RpcServer.handler=16,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c9f581396fed4e62a6636bd9ad2e4247 for block blk_-6121914468737669463_72332:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,108 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/2444d8abe5cc4d54bea8a0284398b0a3 for block blk_2681325570166534995_72759:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,108 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/3c2a84c716224d27bb6cdc27534c8162 for block blk_-9014160819601660483_72537:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,238 WARN  [RpcServer.handler=13,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/bca7b238a3a1436aaeb4d80c71bc8660 for block blk_6334581554221641113_72438:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,238 WARN  [RpcServer.handler=22,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/efe6eab791f74c879347c461e577c962 for block blk_-1651360758416208389_72292:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,238 WARN  [RpcServer.handler=24,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/d61d55a7a1d54cbfb01b97554ff9e522 for block blk_8022127883535831844_73017:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,239 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/d61d55a7a1d54cbfb01b97554ff9e522 for block blk_-7716052986437604221_73017:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,246 WARN  [RpcServer.handler=17,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b2982f11829642ac84c1a3ea9952d43c for block blk_-1639406270936651102_72453:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,247 WARN  [RpcServer.handler=11,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/a8cf6f7dfc6f4724b4e13fa1c7f0e1bb for block blk_-4563045342932757304_72348:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,250 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a83d9bb773f04f48b63b7a494ef0bd2e for block blk_-342841195570465589_72195:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,251 WARN  [RpcServer.handler=18,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/cb5a3952d9394058be03f1bcc595b9a3 for block blk_9001184615483424852_72981:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,251 WARN  [RpcServer.handler=46,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8ad0dc2af3af433f863684719cc06d25 for block blk_-1221122859198963534_72775:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,252 WARN  [RpcServer.handler=9,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7e85b0ece7f34954baf6230f4d52857e for block blk_-5693541465242893799_72186:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,252 WARN  [RpcServer.handler=19,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/6b2180b7e3544748ae4605a98b81c53b for block blk_-5963551837274096022_72996:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,264 WARN  [RpcServer.handler=2,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/79fddfe53a954baa9bb5ca10b733f0ba for block blk_2662119235473415916_72575:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,286 WARN  [RpcServer.handler=8,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8925e9a02f9840918f538ba86e5596b3 for block blk_-5075266691552012502_72359:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,288 WARN  [RpcServer.handler=32,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/55428f9c1fc3432885ec04830c0333fb for block blk_-1056339466352149882_72306:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,289 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0d8950a81c4245ee9ba5aaab15bc4b21 for block blk_-8503424506363918905_72521:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,289 WARN  [RpcServer.handler=25,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ff7b3788d1904946957d76d07ce88df1 for block blk_-4874673739904021264_72387:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,289 WARN  [RpcServer.handler=40,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8902cd057abd48e694f3a996b18f7b9f for block blk_4219923656802382255_72831:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,294 WARN  [RpcServer.handler=29,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/94c061ab697e4f93b3e4ca04a5c84756 for block blk_8905386948760744162_72685:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,313 WARN  [RpcServer.handler=5,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9bd713b234394c0dbe374350e17d5eb3 for block blk_-6353590750851216670_72456:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,313 WARN  [RpcServer.handler=23,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ba8b7bde18aa4ffebc555765bf66f030 for block blk_-8994169223753429682_73103:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,326 WARN  [RpcServer.handler=11,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a044a2cd564048ff9f9a630a6eaed6fe for block blk_-8151346939384514478_72942:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,327 WARN  [RpcServer.handler=22,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4b035fb94d1b4330892f0dc7dde7caad for block blk_-1042465142051730885_72226:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,328 WARN  [RpcServer.handler=46,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/18484b4efc324c8eaffbab14f560d908 for block blk_5229710956373165642_72481:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,329 WARN  [RpcServer.handler=35,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fdd2d29a2e204552bba925cd65283725 for block blk_2650172537738681222_73078:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,330 WARN  [RpcServer.handler=6,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ddb165bca89f49618a3f293263cee171 for block blk_1673482255143137272_72890:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,338 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d364bc312adb45fca0136b9dc28d9cc3 for block blk_1141796742499992094_72214:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,344 WARN  [RpcServer.handler=12,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d13d5b12f70041769320253668fdb779 for block blk_7544303441852089041_72333:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,365 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6b632d2e6a214852b3d0d153f830674d for block blk_-6262387778775892074_72565:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,492 WARN  [RpcServer.handler=49,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/37762d54f1424a2895b1afa471272ff3 for block blk_8639816315243788632_72294:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,494 WARN  [RpcServer.handler=45,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fe45bc84abd946ce841fceb4d2a3ca61 for block blk_-113524371603559432_72185:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,515 WARN  [RpcServer.handler=21,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/65122adbecee4e3da9fb501c11e54a62 for block blk_-2211514806111125773_72630:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,518 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8e1209b9d3234aebb76c7915ac86db95 for block blk_7877985147183437013_72440:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,518 WARN  [RpcServer.handler=49,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/f19f26ee11164aacae079c3d6a3eb703 for block blk_5078160050352818_72429:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,522 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6bb2975734be48c788829f5f3d80579b for block blk_-3659605349904912523_72657:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,541 WARN  [RpcServer.handler=47,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/2dde80329a6f4e618a3bf2ff69f29022 for block blk_911083379879703638_72941:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,561 WARN  [RpcServer.handler=13,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/eed6e63c8b564094a4a591ff671ad457 for block blk_203392597495535881_73079:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,561 WARN  [RpcServer.handler=29,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/e633845284bb453bb5014dc55a5ef078 for block blk_8164221348802414095_73081:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,573 WARN  [RpcServer.handler=20,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c0bfdf08816d46dd957d841cbeacd6fb for block blk_-5847058831191865817_72196:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,573 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ddc365707e424dce958d47b0be4edf9f for block blk_8311604636487534637_72493:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,588 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/87884ad8125f429681cc865847b5a422 for block blk_1585416839266091994_72699:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,619 WARN  [RpcServer.handler=26,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/297a60cb4e1a4045830c9ed086b915ce for block blk_6840112083955385399_72630:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,656 WARN  [RpcServer.handler=42,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/5c8598ea061942b1928f8848199f9c39 for block blk_172572304482736944_72618:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,656 WARN  [RpcServer.handler=38,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d679777569084c3cb81ea37d4c24f3a4 for block blk_-7261381662642595722_72161:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,656 WARN  [RpcServer.handler=1,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/7bde56a2a0ce46f882739ed119a3399f for block blk_1943738196880325069_72212:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,656 WARN  [RpcServer.handler=43,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b117166eee847d6a2597f23d985eb44 for block blk_-220096014152016776_72427:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,665 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3fc3f22db77a406794ea1f1e23032122 for block blk_-2284636989878761204_72547:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,768 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d34e3ad8633249edae470500cc66f3c2 for block blk_3585148234015267860_72401:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,768 WARN  [RpcServer.handler=24,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/657c2a33be164d9ebd181bcf678ba480 for block blk_8518370631651165783_72671:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,768 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c7f068cc31ce450a88e42978112c6686 for block blk_-288403551994384440_73082:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,822 WARN  [RpcServer.handler=2,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/10935ab4a53e42dc885881592b602f1f for block blk_-4046222518157800200_72265:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,825 WARN  [RpcServer.handler=49,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9f49ae5942054f8485081121898a4bd0 for block blk_1000972985868006651_72360:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,866 WARN  [RpcServer.handler=39,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/197497afa0154e71a6c3aa991576476d for block blk_-458229164382756278_73000:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,866 WARN  [RpcServer.handler=41,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/12480f8bcfa044df94f29ec25df311dd for block blk_-5934952392375114633_72593:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,866 WARN  [RpcServer.handler=31,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/edd46d224132482d83ac6e6d19349497 for block blk_-1182960011087914409_72467:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,978 WARN  [RpcServer.handler=12,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/288de302ea5d4f25ab4c0deca74c10ab for block blk_3892800646392444827_72160:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,980 WARN  [RpcServer.handler=9,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6f1a2a76241841ac88cd4b0e0256a0a3 for block blk_-5449707322111424856_72248:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,986 WARN  [RpcServer.handler=20,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/145320010f5b4bcd9618548529be4182 for block blk_-146144529959117801_72278:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:11,990 WARN  [RpcServer.handler=0,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6f1a2a76241841ac88cd4b0e0256a0a3 for block blk_-2161146076776704045_72241:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:12,022 WARN  [RpcServer.handler=28,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/db253cb0944c40b0b1425e1ab348e6f9 for block blk_-5963935904089894841_72644:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:12,067 WARN  [RpcServer.handler=42,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/be28ed9c7dec408fbfdc0fe9ae002cac for block blk_6524640516033548824_72672:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:12,092 WARN  [RpcServer.handler=24,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/54fdb51e719942e9a47bf6e6747ca012 for block blk_-2534917609955843765_72466:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:12,119 WARN  [RpcServer.handler=3,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d6dd5e52b85842bcb74373bc4a90dfaa for block blk_5652389586858878221_73080:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:12,316 WARN  [RpcServer.handler=24,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/268853e99d764e48bfedb502a6d41194 for block blk_8280676390614105670_72548:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:13,143 WARN  [RpcServer.handler=14,port=60020] hdfs.DFSClient: Failed to connect to /9.1.143.59:50010 for file /hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/5e24a4c19a434c8f99a97ccb0a822972 for block blk_-2236527797958103043_72412:java.net.BindException: Cannot assign requested address
2014-07-09 15:08:14,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:14,135 INFO  [Thread-1381] hdfs.DFSClient: Exception in createBlockOutputStream 9.1.143.59:50010 java.net.BindException: Cannot assign requested address
2014-07-09 15:08:14,135 INFO  [Thread-1381] hdfs.DFSClient: Abandoning blk_2949479791432224234_73114
2014-07-09 15:08:14,230 INFO  [Thread-1381] hdfs.DFSClient: Excluding datanode 9.1.143.59:50010
2014-07-09 15:08:14,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943689785 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694112
2014-07-09 15:08:14,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:14,309 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-09 15:08:14,309 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:14,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694112 with entries=1, filesize=895.3k; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694309
2014-07-09 15:08:14,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:17,572 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:17,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31194 synced till here 31193
2014-07-09 15:08:17,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694309 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943697573
2014-07-09 15:08:17,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:08:18,834 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90713ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:08:18,834 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 612.6m
2014-07-09 15:08:19,258 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:08:20,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:20,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943697573 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943700446
2014-07-09 15:08:24,006 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:24,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943700446 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943704006
2014-07-09 15:08:26,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:27,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943704006 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943706987
2014-07-09 15:08:29,505 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:08:29,569 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files, but is 448.8m vs best flushable region's 64.1m. Choosing the bigger.
2014-07-09 15:08:29,569 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. due to global heap pressure
2014-07-09 15:08:29,570 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 448.8m
2014-07-09 15:08:30,377 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:08:30,894 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:30,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943706987 with entries=78, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943710894
2014-07-09 15:08:34,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:34,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31588 synced till here 31587
2014-07-09 15:08:34,855 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943710894 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943714489
2014-07-09 15:08:35,885 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:35,905 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:35,978 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:36,545 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:36,891 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:38,267 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:38,448 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:38,549 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:38,947 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:39,288 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:39,747 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:08:40,790 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6063, memsize=612.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/2208afad86744ef0babdfbc61054d31e
2014-07-09 15:08:40,801 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/2208afad86744ef0babdfbc61054d31e as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2208afad86744ef0babdfbc61054d31e
2014-07-09 15:08:40,816 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2208afad86744ef0babdfbc61054d31e, entries=2230610, sequenceid=6063, filesize=158.8m
2014-07-09 15:08:40,817 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~612.6m/642396880, currentsize=69.7m/73060640 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 21983ms, sequenceid=6063, compaction requested=true
2014-07-09 15:08:40,817 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:08:40,817 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:08:40,817 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1070ms
2014-07-09 15:08:40,817 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:08:40,818 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,818 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:08:40,818 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:08:40,818 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1530ms
2014-07-09 15:08:40,818 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,818 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:08:40,818 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1871ms
2014-07-09 15:08:40,818 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,818 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2269ms
2014-07-09 15:08:40,818 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,818 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2370ms
2014-07-09 15:08:40,818 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,819 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2552ms
2014-07-09 15:08:40,819 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,819 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3928ms
2014-07-09 15:08:40,819 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,819 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4274ms
2014-07-09 15:08:40,819 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,820 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4843ms
2014-07-09 15:08:40,820 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,825 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4921ms
2014-07-09 15:08:40,825 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:40,825 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4941ms
2014-07-09 15:08:40,825 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:08:41,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:41,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31665 synced till here 31662
2014-07-09 15:08:41,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943714489 with entries=77, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943721252
2014-07-09 15:08:41,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943402122
2014-07-09 15:08:41,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943409316
2014-07-09 15:08:41,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943414653
2014-07-09 15:08:41,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943421382
2014-07-09 15:08:41,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943430364
2014-07-09 15:08:41,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943436973
2014-07-09 15:08:41,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943443024
2014-07-09 15:08:41,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943451641
2014-07-09 15:08:41,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:42,816 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:42,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31747 synced till here 31746
2014-07-09 15:08:42,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943721252 with entries=82, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943722816
2014-07-09 15:08:42,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:45,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:45,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943722816 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943725221
2014-07-09 15:08:45,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.9 GB, free=61.81 MB, max=3.96 GB, blocks=62792, accesses=34082369, hits=33534089, hitRatio=98.39%, , cachingAccesses=34075505, cachingHits=33534087, cachingHitsRatio=98.41%, evictions=186, evicted=477678, evictedPerRun=2568.161376953125
2014-07-09 15:08:46,981 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6096, memsize=448.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/902b3939e642492d912edc5de686439b
2014-07-09 15:08:47,024 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/902b3939e642492d912edc5de686439b as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/902b3939e642492d912edc5de686439b
2014-07-09 15:08:47,041 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/902b3939e642492d912edc5de686439b, entries=1634030, sequenceid=6096, filesize=116.3m
2014-07-09 15:08:47,041 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~448.8m/470588720, currentsize=64.0m/67147840 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 17471ms, sequenceid=6096, compaction requested=true
2014-07-09 15:08:47,042 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:08:47,042 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:08:47,042 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:08:47,042 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:08:47,042 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:08:47,042 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:08:49,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:49,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943725221 with entries=80, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943729069
2014-07-09 15:08:49,128 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:52,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:52,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31983 synced till here 31982
2014-07-09 15:08:52,078 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943729069 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943732043
2014-07-09 15:08:52,078 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:55,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:55,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943732043 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943735253
2014-07-09 15:08:55,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:08:57,949 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:08:57,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943735253 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943737949
2014-07-09 15:08:57,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:01,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:01,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943737949 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943741607
2014-07-09 15:09:01,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 6 regions(s): aba5d255d2a2118b681bca61272578b4, e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:01,724 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:09:01,725 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files, but is 576.4m vs best flushable region's 101.6m. Choosing the bigger.
2014-07-09 15:09:01,725 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. due to global heap pressure
2014-07-09 15:09:01,725 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 576.4m
2014-07-09 15:09:01,766 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:09:01,767 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files, but is 576.2m vs best flushable region's 101.6m. Choosing the bigger.
2014-07-09 15:09:01,767 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. due to global heap pressure
2014-07-09 15:09:01,767 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 576.2m
2014-07-09 15:09:02,207 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:02,246 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:04,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:04,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32296 synced till here 32295
2014-07-09 15:09:04,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943741607 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943744273
2014-07-09 15:09:04,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 4 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:06,620 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:07,216 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:07,612 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:07,758 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:08,137 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:08,278 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:09,034 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:09,149 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:09,317 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:11,012 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:11,111 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:11,284 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:11,553 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:11,620 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:12,023 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:12,216 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:12,477 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:12,612 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:12,659 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:12,748 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:12,758 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:12,887 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:13,138 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:13,174 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:13,848 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5569ms
2014-07-09 15:09:14,034 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:14,074 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:09:14,149 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:14,318 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:16,013 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:16,111 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:16,284 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:16,554 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:16,621 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:17,137 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5114ms
2014-07-09 15:09:17,217 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:09:17,477 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:17,613 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:17,660 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:17,749 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:17,759 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:17,888 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:18,138 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:18,174 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:09:18,848 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10570ms
2014-07-09 15:09:19,035 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:19,074 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:09:19,150 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:19,318 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:21,013 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:21,111 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:21,285 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:21,554 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:09:21,621 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-09 15:09:22,067 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6178, memsize=576.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/950865660c4c446a832a492e0840177f
2014-07-09 15:09:22,092 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/950865660c4c446a832a492e0840177f as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/950865660c4c446a832a492e0840177f
2014-07-09 15:09:22,104 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/950865660c4c446a832a492e0840177f, entries=2098700, sequenceid=6178, filesize=149.4m
2014-07-09 15:09:22,105 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~576.4m/604410960, currentsize=22.5m/23554880 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 20380ms, sequenceid=6178, compaction requested=true
2014-07-09 15:09:22,106 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:09:22,106 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:09:22,106 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15487ms
2014-07-09 15:09:22,106 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 98662ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:09:22,106 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,106 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:09:22,106 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10553ms
2014-07-09 15:09:22,106 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:09:22,106 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 22.5m
2014-07-09 15:09:22,106 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:09:22,106 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,107 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:09:22,109 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10825ms
2014-07-09 15:09:22,109 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,109 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10999ms
2014-07-09 15:09:22,109 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,109 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11097ms
2014-07-09 15:09:22,109 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,110 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12793ms
2014-07-09 15:09:22,110 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,110 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12961ms
2014-07-09 15:09:22,110 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,110 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8037ms
2014-07-09 15:09:22,110 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,110 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13076ms
2014-07-09 15:09:22,110 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,113 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13835ms
2014-07-09 15:09:22,113 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,119 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:22,121 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8947ms
2014-07-09 15:09:22,125 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,125 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13988ms
2014-07-09 15:09:22,125 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,125 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9238ms
2014-07-09 15:09:22,126 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,126 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14369ms
2014-07-09 15:09:22,126 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,126 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9378ms
2014-07-09 15:09:22,126 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,126 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9467ms
2014-07-09 15:09:22,126 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,127 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14514ms
2014-07-09 15:09:22,127 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,137 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9652ms
2014-07-09 15:09:22,137 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,138 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10114ms
2014-07-09 15:09:22,138 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,141 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14925ms
2014-07-09 15:09:22,141 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:09:22,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:22,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32384 synced till here 32381
2014-07-09 15:09:22,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943744273 with entries=88, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943762385
2014-07-09 15:09:22,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 4 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 01d5d06c09b8c415be3f4fdd32569a18, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:22,760 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6178, memsize=576.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/ad9cdc44209d499c9a02dc535887266c
2014-07-09 15:09:22,995 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/ad9cdc44209d499c9a02dc535887266c as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ad9cdc44209d499c9a02dc535887266c
2014-07-09 15:09:23,016 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6194, memsize=22.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/8271ba93a5d241528cf75694a3c094eb
2014-07-09 15:09:23,027 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/8271ba93a5d241528cf75694a3c094eb as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8271ba93a5d241528cf75694a3c094eb
2014-07-09 15:09:23,039 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ad9cdc44209d499c9a02dc535887266c, entries=2098040, sequenceid=6178, filesize=149.4m
2014-07-09 15:09:23,039 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~576.2m/604218000, currentsize=24.7m/25930560 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 21272ms, sequenceid=6178, compaction requested=true
2014-07-09 15:09:23,040 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:09:23,040 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 99695ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:09:23,040 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:09:23,040 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 181.7m
2014-07-09 15:09:23,040 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:09:23,040 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:09:23,041 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:09:23,041 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:09:23,042 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8271ba93a5d241528cf75694a3c094eb, entries=81790, sequenceid=6194, filesize=5.8m
2014-07-09 15:09:23,042 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~22.5m/23554880, currentsize=1.5m/1615680 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 936ms, sequenceid=6194, compaction requested=true
2014-07-09 15:09:23,053 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:09:23,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:09:23,053 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 99056ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:09:23,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:09:23,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:09:23,053 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 627.9m
2014-07-09 15:09:23,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:09:23,054 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:09:23,105 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943746413,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:23,182 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:23,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:23,570 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32465 synced till here 32458
2014-07-09 15:09:23,610 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:23,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943762385 with entries=81, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943763513
2014-07-09 15:09:23,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 3 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:23,950 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14805,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943749144,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,144 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943754072,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,144 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943751008,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,145 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943747214,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,204 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15174,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943749030,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,277 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943747610,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,277 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943752474,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,277 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13167,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943751109,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,285 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16150,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943748134,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,285 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13002,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943751282,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,779 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943752020,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,779 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13228,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943751550,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,779 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943748276,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,779 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943747755,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,780 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15465,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943749314,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,780 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12122,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943752657,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,783 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12037,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943752746,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,783 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11898,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943752885,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,783 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11612,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943753171,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:09:24,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:24,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943763513 with entries=86, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943764818
2014-07-09 15:09:24,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 3 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:25,589 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:26,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32635 synced till here 32631
2014-07-09 15:09:26,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943764818 with entries=84, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943765589
2014-07-09 15:09:26,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 3 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:27,048 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:09:27,193 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:27,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943765589 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943767193
2014-07-09 15:09:27,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 3 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed, 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:46,324 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18950,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767373,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,324 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 27032ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:09:46,325 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 27034ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:09:46,325 WARN  [regionserver60020] util.Sleeper: We slept 20155ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:09:46,325 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18696ms
GC pool 'ParNew' had collection(s): count=1 time=712ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=18225ms
2014-07-09 15:09:46,327 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18961,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767366,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,329 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18950,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767378,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,331 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18949,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767381,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,331 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18957,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767374,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,331 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18954,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767377,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,332 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18957,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767374,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,332 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18954,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767378,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,333 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18955,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767377,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,333 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18954,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767379,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,333 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18964,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767369,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,337 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18964,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767373,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,337 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18969,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767368,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,337 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18960,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767377,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,338 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18956,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767381,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:46,347 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18970,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55428","starttimems":1404943767376,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:09:48,434 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6214, memsize=181.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/d3f9a07a816441af8b949b3acd48d6df
2014-07-09 15:09:48,453 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/d3f9a07a816441af8b949b3acd48d6df as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d3f9a07a816441af8b949b3acd48d6df
2014-07-09 15:09:48,462 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d3f9a07a816441af8b949b3acd48d6df, entries=661620, sequenceid=6214, filesize=47.2m
2014-07-09 15:09:48,464 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~181.7m/190540720, currentsize=31.2m/32718320 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 25424ms, sequenceid=6214, compaction requested=true
2014-07-09 15:09:48,464 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:09:48,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:09:48,464 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 124365ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:09:48,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:09:48,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:09:48,465 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:09:48,465 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 658.8m
2014-07-09 15:09:48,465 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:09:49,139 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:09:51,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:51,324 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32800 synced till here 32798
2014-07-09 15:09:51,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943767193 with entries=86, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943791205
2014-07-09 15:09:51,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 2 regions(s): 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:52,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:52,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943791205 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943792704
2014-07-09 15:09:52,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 2 regions(s): 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:57,766 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:57,787 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32959 synced till here 32958
2014-07-09 15:09:57,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943792704 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943797767
2014-07-09 15:09:57,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 2 regions(s): 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:09:59,372 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:09:59,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33040 synced till here 33038
2014-07-09 15:09:59,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943797767 with entries=81, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943799373
2014-07-09 15:09:59,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 2 regions(s): 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:04,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:04,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33120 synced till here 33119
2014-07-09 15:10:04,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943799373 with entries=80, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943804805
2014-07-09 15:10:04,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 2 regions(s): 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:05,354 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6212, memsize=627.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/03ac59eb0cea4cb182d0b5c104e679ec
2014-07-09 15:10:05,397 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/03ac59eb0cea4cb182d0b5c104e679ec as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03ac59eb0cea4cb182d0b5c104e679ec
2014-07-09 15:10:05,433 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03ac59eb0cea4cb182d0b5c104e679ec, entries=2286330, sequenceid=6212, filesize=162.7m
2014-07-09 15:10:05,434 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~627.9m/658444480, currentsize=107.2m/112429280 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 42381ms, sequenceid=6212, compaction requested=true
2014-07-09 15:10:05,434 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:05,434 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:05,434 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 141227ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:10:05,435 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:05,435 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:05,435 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:05,435 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 733.8m
2014-07-09 15:10:05,435 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:10:06,002 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:10:06,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:06,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33199 synced till here 33197
2014-07-09 15:10:06,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943804805 with entries=79, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943806684
2014-07-09 15:10:06,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:11,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:11,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943806684 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943811403
2014-07-09 15:10:11,458 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:12,878 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6232, memsize=658.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/22c2050298454f028a2869fdd84f396d
2014-07-09 15:10:12,893 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/22c2050298454f028a2869fdd84f396d as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/22c2050298454f028a2869fdd84f396d
2014-07-09 15:10:12,904 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/22c2050298454f028a2869fdd84f396d, entries=2398770, sequenceid=6232, filesize=170.7m
2014-07-09 15:10:12,915 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~658.8m/690829440, currentsize=108.8m/114095760 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 24450ms, sequenceid=6232, compaction requested=true
2014-07-09 15:10:12,916 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:12,916 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:12,916 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 27 store files, 0 compacting, 27 eligible, 20 blocking
2014-07-09 15:10:12,916 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 27 files from compaction candidates
2014-07-09 15:10:12,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:12,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:12,917 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:10:13,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:13,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33359 synced till here 33358
2014-07-09 15:10:13,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943811403 with entries=80, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943813150
2014-07-09 15:10:13,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:14,975 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:15,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943813150 with entries=78, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943814975
2014-07-09 15:10:15,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:19,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:19,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943814975 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943819834
2014-07-09 15:10:19,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:21,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:21,919 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943819834 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943821897
2014-07-09 15:10:21,920 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:26,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:26,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943821897 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943826506
2014-07-09 15:10:26,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:27,278 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:10:27,278 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:27,279 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:27,279 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:27,279 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:27,279 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:27,279 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:27,279 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:10:28,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:28,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943826506 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943828325
2014-07-09 15:10:28,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:32,896 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6280, memsize=733.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/2a8706097f0e4bbcb4d2a9f142d51b53
2014-07-09 15:10:32,927 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/2a8706097f0e4bbcb4d2a9f142d51b53 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/2a8706097f0e4bbcb4d2a9f142d51b53
2014-07-09 15:10:32,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:33,024 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/2a8706097f0e4bbcb4d2a9f142d51b53, entries=2671660, sequenceid=6280, filesize=190.1m
2014-07-09 15:10:33,025 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~733.8m/769415600, currentsize=116.7m/122327760 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 27590ms, sequenceid=6280, compaction requested=true
2014-07-09 15:10:33,025 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:33,025 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:33,025 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:33,025 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:33,025 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:33,025 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:10:33,064 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943828325 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943832981
2014-07-09 15:10:33,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:33,250 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:10:33,250 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:33,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:10:33,251 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:33,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:10:33,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:33,251 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:33,251 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:10:34,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:34,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33909 synced till here 33908
2014-07-09 15:10:34,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943832981 with entries=79, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943834882
2014-07-09 15:10:34,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:39,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:39,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943834882 with entries=79, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943839179
2014-07-09 15:10:39,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:40,152 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:10:40,152 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:40,152 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:40,152 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:40,153 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:40,153 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:40,153 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:40,153 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:10:40,204 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:10:40,204 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:40,204 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:40,204 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:10:40,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:10:40,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:40,205 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:40,205 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:10:41,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:41,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34067 synced till here 34066
2014-07-09 15:10:41,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943839179 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943841661
2014-07-09 15:10:41,739 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:44,090 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:44,111 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943841661 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943844091
2014-07-09 15:10:44,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:47,804 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:10:47,804 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:10:47,805 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:10:47,805 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:10:47,805 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:10:47,805 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:10:47,805 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:10:47,805 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:10:48,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:48,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34223 synced till here 34222
2014-07-09 15:10:48,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943844091 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943848340
2014-07-09 15:10:48,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:50,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:50,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34305 synced till here 34303
2014-07-09 15:10:50,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943848340 with entries=82, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943850602
2014-07-09 15:10:50,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=70, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:55,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:55,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34386 synced till here 34385
2014-07-09 15:10:55,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943850602 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943855490
2014-07-09 15:10:55,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=71, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:10:57,431 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90383ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:10:57,432 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 556.1m
2014-07-09 15:10:57,826 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:10:58,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:10:58,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34465 synced till here 34464
2014-07-09 15:10:58,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943855490 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943858042
2014-07-09 15:10:58,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=72, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:11:02,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:02,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34544 synced till here 34543
2014-07-09 15:11:02,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943858042 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943862772
2014-07-09 15:11:02,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=73, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:11:03,792 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:11:03,792 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files, but is 980.0m vs best flushable region's 224.3m. Choosing the bigger.
2014-07-09 15:11:03,792 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. due to global heap pressure
2014-07-09 15:11:03,792 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 980.0m
2014-07-09 15:11:04,569 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:11:04,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:05,029 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34624 synced till here 34623
2014-07-09 15:11:05,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943862772 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943865000
2014-07-09 15:11:05,192 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:11:07,544 INFO  [RpcServer.handler=8,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:11:08,247 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:08,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943865000 with entries=78, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943868247
2014-07-09 15:11:09,303 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:09,312 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:09,326 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:09,490 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:10,055 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:10,405 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:10,702 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:10,837 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:11,064 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:11,330 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:11,498 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:11,688 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:11,858 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:12,366 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:12,496 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:13,563 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:13,658 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:13,812 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:14,042 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:14,303 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:14,312 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:14,327 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:14,491 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:15,056 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:15,317 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:15,406 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:15,703 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:16,243 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5178ms
2014-07-09 15:11:16,244 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5408ms
2014-07-09 15:11:16,330 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:16,499 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:16,689 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:16,858 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:17,367 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:17,497 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:18,511 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6422, memsize=556.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/2dd575800bac45a8a6dd274584100dd4
2014-07-09 15:11:18,532 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/2dd575800bac45a8a6dd274584100dd4 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2dd575800bac45a8a6dd274584100dd4
2014-07-09 15:11:18,546 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2dd575800bac45a8a6dd274584100dd4, entries=2024790, sequenceid=6422, filesize=144.2m
2014-07-09 15:11:18,546 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~556.1m/583123680, currentsize=48.2m/50542080 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 21114ms, sequenceid=6422, compaction requested=true
2014-07-09 15:11:18,546 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:11:18,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:11:18,546 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6050ms
2014-07-09 15:11:18,547 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:11:18,546 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:11:18,547 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:11:18,547 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,547 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:11:18,547 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6181ms
2014-07-09 15:11:18,547 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:11:18,547 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,547 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:11:18,547 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6689ms
2014-07-09 15:11:18,547 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:11:18,547 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,547 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:11:18,548 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6860ms
2014-07-09 15:11:18,548 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,548 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:11:18,548 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:11:18,548 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7050ms
2014-07-09 15:11:18,548 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,548 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:11:18,553 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7223ms
2014-07-09 15:11:18,553 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,554 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7718ms
2014-07-09 15:11:18,554 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,554 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7490ms
2014-07-09 15:11:18,554 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,555 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7853ms
2014-07-09 15:11:18,555 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,555 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8150ms
2014-07-09 15:11:18,555 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,555 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3238ms
2014-07-09 15:11:18,555 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,557 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8502ms
2014-07-09 15:11:18,557 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,557 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9067ms
2014-07-09 15:11:18,557 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,563 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:18,563 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,567 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9241ms
2014-07-09 15:11:18,568 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,568 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9256ms
2014-07-09 15:11:18,568 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,569 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9266ms
2014-07-09 15:11:18,569 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,569 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4527ms
2014-07-09 15:11:18,569 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,569 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4757ms
2014-07-09 15:11:18,569 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:18,570 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4911ms
2014-07-09 15:11:18,570 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:19,421 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:19,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34791 synced till here 34780
2014-07-09 15:11:19,495 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943869042,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:19,504 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943868247 with entries=89, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943879421
2014-07-09 15:11:19,910 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943869201,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:20,156 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:20,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34879 synced till here 34867
2014-07-09 15:11:20,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943879421 with entries=88, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943880156
2014-07-09 15:11:21,180 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943870833,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:21,180 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10481,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943870698,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:21,180 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943870400,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:21,181 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943871060,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:21,181 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11692,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943869488,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:21,256 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943870053,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:11:22,121 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:11:22,122 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. due to global heap pressure
2014-07-09 15:11:22,122 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 243.9m
2014-07-09 15:11:22,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:22,195 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34972 synced till here 34969
2014-07-09 15:11:22,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943880156 with entries=93, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943882140
2014-07-09 15:11:22,347 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:11:23,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:23,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35054 synced till here 35052
2014-07-09 15:11:23,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943882140 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943883692
2014-07-09 15:11:28,242 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,258 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,270 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,290 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,303 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,504 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,594 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:28,716 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:29,497 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:29,576 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:29,733 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:29,843 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:30,252 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:30,402 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:30,594 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:30,914 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:31,105 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:31,987 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6463, memsize=243.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/ffcf02b1c34a468fa4d9e97b554427d8
2014-07-09 15:11:32,027 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/ffcf02b1c34a468fa4d9e97b554427d8 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ffcf02b1c34a468fa4d9e97b554427d8
2014-07-09 15:11:32,071 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ffcf02b1c34a468fa4d9e97b554427d8, entries=888100, sequenceid=6463, filesize=63.2m
2014-07-09 15:11:32,083 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~243.9m/255748800, currentsize=8.1m/8524000 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9961ms, sequenceid=6463, compaction requested=true
2014-07-09 15:11:32,083 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:11:32,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-09 15:11:32,083 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 978ms
2014-07-09 15:11:32,083 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 12 files from compaction candidates
2014-07-09 15:11:32,083 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,084 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:11:32,084 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1170ms
2014-07-09 15:11:32,084 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:11:32,084 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,084 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:11:32,084 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1491ms
2014-07-09 15:11:32,084 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,085 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1683ms
2014-07-09 15:11:32,085 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,085 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1834ms
2014-07-09 15:11:32,085 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,086 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2243ms
2014-07-09 15:11:32,086 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,086 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2353ms
2014-07-09 15:11:32,087 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,087 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2511ms
2014-07-09 15:11:32,087 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,096 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2599ms
2014-07-09 15:11:32,096 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,097 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3381ms
2014-07-09 15:11:32,097 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,098 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3504ms
2014-07-09 15:11:32,098 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,098 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3594ms
2014-07-09 15:11:32,098 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,098 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3795ms
2014-07-09 15:11:32,099 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,106 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3815ms
2014-07-09 15:11:32,106 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,106 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3837ms
2014-07-09 15:11:32,106 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,107 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3848ms
2014-07-09 15:11:32,107 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:32,107 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3866ms
2014-07-09 15:11:32,107 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:33,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:33,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35140 synced till here 35133
2014-07-09 15:11:33,383 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:11:33,383 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files, but is 498.4m vs best flushable region's 8.6m. Choosing the bigger.
2014-07-09 15:11:33,383 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. due to global heap pressure
2014-07-09 15:11:33,383 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 498.4m
2014-07-09 15:11:33,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943883692 with entries=86, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943893229
2014-07-09 15:11:33,782 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:11:34,639 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:34,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35229 synced till here 35218
2014-07-09 15:11:34,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943893229 with entries=89, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943894640
2014-07-09 15:11:36,117 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:36,129 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:36,528 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:36,704 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:36,845 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:36,948 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:37,726 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:37,930 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:38,113 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:38,230 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:38,308 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:38,647 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:38,756 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:39,006 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:39,239 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:39,369 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:40,408 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:40,838 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:11:41,117 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:41,130 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:41,528 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:41,704 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:41,845 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:11:41,948 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:11:42,582 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6438, memsize=981.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/a93fe9c5cd01477ea5e3ce5147e4ebe1
2014-07-09 15:11:42,605 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/a93fe9c5cd01477ea5e3ce5147e4ebe1 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a93fe9c5cd01477ea5e3ce5147e4ebe1
2014-07-09 15:11:42,614 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a93fe9c5cd01477ea5e3ce5147e4ebe1, entries=3573950, sequenceid=6438, filesize=254.3m
2014-07-09 15:11:42,614 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~981.6m/1029269200, currentsize=120.9m/126743120 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 38822ms, sequenceid=6438, compaction requested=true
2014-07-09 15:11:42,615 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:11:42,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:11:42,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:11:42,615 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5667ms
2014-07-09 15:11:42,615 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:11:42,615 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:11:42,615 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5771ms
2014-07-09 15:11:42,615 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,615 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:11:42,616 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5913ms
2014-07-09 15:11:42,616 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,616 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6088ms
2014-07-09 15:11:42,616 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,616 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6487ms
2014-07-09 15:11:42,616 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,616 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6499ms
2014-07-09 15:11:42,616 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,617 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1779ms
2014-07-09 15:11:42,617 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,617 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2209ms
2014-07-09 15:11:42,617 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,618 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3249ms
2014-07-09 15:11:42,618 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,618 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3379ms
2014-07-09 15:11:42,618 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,618 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3613ms
2014-07-09 15:11:42,618 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,621 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3865ms
2014-07-09 15:11:42,621 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,621 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3974ms
2014-07-09 15:11:42,621 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,623 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4315ms
2014-07-09 15:11:42,623 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,623 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4393ms
2014-07-09 15:11:42,623 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,624 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4511ms
2014-07-09 15:11:42,624 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,625 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4695ms
2014-07-09 15:11:42,625 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:42,625 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4899ms
2014-07-09 15:11:42,625 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:11:43,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:43,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35322 synced till here 35318
2014-07-09 15:11:43,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943894640 with entries=93, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943903321
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943458098
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943594555
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943601503
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943604866
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943608224
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943612444
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943615439
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943619661
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943622439
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943626802
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943629608
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943634733
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943638119
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943641058
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943646019
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943649106
2014-07-09 15:11:43,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943652714
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943655515
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943659517
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943661808
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943665175
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943668448
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943671710
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943674873
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943677273
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943681287
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943683821
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943687488
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943689785
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694112
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943694309
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943697573
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943700446
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943704006
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943706987
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943710894
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943714489
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943721252
2014-07-09 15:11:43,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943722816
2014-07-09 15:11:43,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943725221
2014-07-09 15:11:43,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943729069
2014-07-09 15:11:43,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943732043
2014-07-09 15:11:43,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943735253
2014-07-09 15:11:43,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943737949
2014-07-09 15:11:44,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:44,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35405 synced till here 35397
2014-07-09 15:11:44,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943903321 with entries=83, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943904796
2014-07-09 15:11:46,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:46,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943904796 with entries=87, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943906290
2014-07-09 15:11:48,228 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:48,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943906290 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943908229
2014-07-09 15:11:52,471 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6500, memsize=498.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/3deae42579344e45b925af14c4749f22
2014-07-09 15:11:52,495 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/3deae42579344e45b925af14c4749f22 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3deae42579344e45b925af14c4749f22
2014-07-09 15:11:52,507 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3deae42579344e45b925af14c4749f22, entries=1814590, sequenceid=6500, filesize=129.2m
2014-07-09 15:11:52,529 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~498.4m/522589360, currentsize=88.7m/92957840 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 19146ms, sequenceid=6500, compaction requested=true
2014-07-09 15:11:52,530 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:11:52,530 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:11:52,530 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:11:52,530 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:11:52,530 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:11:52,530 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:11:53,002 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:53,466 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943908229 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943913002
2014-07-09 15:11:53,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943741607
2014-07-09 15:11:53,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:11:54,422 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:54,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943913002 with entries=78, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943914422
2014-07-09 15:11:54,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:11:57,536 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90258ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:11:57,537 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 116.6m
2014-07-09 15:11:57,607 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:11:59,760 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:11:59,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35806 synced till here 35805
2014-07-09 15:11:59,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943914422 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943919760
2014-07-09 15:11:59,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:01,247 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6576, memsize=116.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/4d1d4a6bcc384af68343b2ec10023c1f
2014-07-09 15:12:01,272 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/4d1d4a6bcc384af68343b2ec10023c1f as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4d1d4a6bcc384af68343b2ec10023c1f
2014-07-09 15:12:01,283 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4d1d4a6bcc384af68343b2ec10023c1f, entries=424550, sequenceid=6576, filesize=30.3m
2014-07-09 15:12:01,283 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~116.6m/122267040, currentsize=15.6m/16366640 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 3746ms, sequenceid=6576, compaction requested=true
2014-07-09 15:12:01,284 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:01,284 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:12:01,284 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:12:01,284 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:01,284 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:01,284 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:12:01,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:01,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35884 synced till here 35883
2014-07-09 15:12:01,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943919760 with entries=78, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943921327
2014-07-09 15:12:01,366 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:02,259 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:12:02,259 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:12:02,259 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:02,260 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:12:02,260 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:12:02,260 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:02,260 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:02,260 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:12:03,948 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:03,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943921327 with entries=79, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943923949
2014-07-09 15:12:03,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:07,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:08,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36047 synced till here 36042
2014-07-09 15:12:08,090 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943923949 with entries=84, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943927964
2014-07-09 15:12:08,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:08,378 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:12:08,378 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:12:08,379 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:08,379 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 28 store files, 0 compacting, 28 eligible, 20 blocking
2014-07-09 15:12:08,379 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 28 files from compaction candidates
2014-07-09 15:12:08,379 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:08,379 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:08,379 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:12:10,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:10,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943927964 with entries=79, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943930490
2014-07-09 15:12:10,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:10,699 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90547ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:12:10,699 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90495ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:12:10,700 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 623.3m
2014-07-09 15:12:10,700 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 621.6m
2014-07-09 15:12:11,590 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:12:11,613 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:12:14,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:14,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943930490 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943934719
2014-07-09 15:12:14,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:16,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:17,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36287 synced till here 36286
2014-07-09 15:12:17,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943934719 with entries=82, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943936775
2014-07-09 15:12:17,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:21,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:21,644 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36366 synced till here 36364
2014-07-09 15:12:21,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943936775 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943941595
2014-07-09 15:12:21,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:22,241 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:22,264 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:22,275 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:22,504 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:22,595 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:22,910 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:23,028 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:23,339 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:23,623 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:25,289 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:25,466 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:25,703 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:26,072 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:26,200 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:27,241 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:27,265 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:27,275 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:27,504 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:27,863 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5267ms
2014-07-09 15:12:27,911 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:28,029 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:28,093 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:28,339 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:28,489 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:28,577 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:28,623 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:29,080 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:29,349 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:29,522 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:12:30,289 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:30,779 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5076ms
2014-07-09 15:12:30,779 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5313ms
2014-07-09 15:12:31,072 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:31,201 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:32,242 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:32,265 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:32,276 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:32,504 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:32,863 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10268ms
2014-07-09 15:12:32,911 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:33,029 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:33,093 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:33,340 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:33,490 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:33,578 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:12:33,624 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:12:34,080 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:12:34,197 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6614, memsize=623.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/03c4b9ae15824886bae3000d621d8ddf
2014-07-09 15:12:34,226 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/03c4b9ae15824886bae3000d621d8ddf as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03c4b9ae15824886bae3000d621d8ddf
2014-07-09 15:12:34,242 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03c4b9ae15824886bae3000d621d8ddf, entries=2269330, sequenceid=6614, filesize=161.6m
2014-07-09 15:12:34,243 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~623.3m/653550560, currentsize=44.5m/46651520 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 23543ms, sequenceid=6614, compaction requested=true
2014-07-09 15:12:34,243 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:34,243 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:12:34,244 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5164ms
2014-07-09 15:12:34,244 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:12:34,244 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,244 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 106440ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:12:34,244 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10621ms
2014-07-09 15:12:34,244 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,244 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:34,244 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 635.6m
2014-07-09 15:12:34,244 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:34,244 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:12:34,245 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5668ms
2014-07-09 15:12:34,245 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,249 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5760ms
2014-07-09 15:12:34,249 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,249 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10911ms
2014-07-09 15:12:34,249 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,249 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6156ms
2014-07-09 15:12:34,249 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,249 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11221ms
2014-07-09 15:12:34,249 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,253 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11343ms
2014-07-09 15:12:34,253 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,262 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11666ms
2014-07-09 15:12:34,262 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,262 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11759ms
2014-07-09 15:12:34,262 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,263 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11988ms
2014-07-09 15:12:34,263 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,263 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11999ms
2014-07-09 15:12:34,263 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,263 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12022ms
2014-07-09 15:12:34,263 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,263 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8063ms
2014-07-09 15:12:34,263 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,264 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8192ms
2014-07-09 15:12:34,264 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,265 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8798ms
2014-07-09 15:12:34,265 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,265 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8562ms
2014-07-09 15:12:34,265 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,272 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8983ms
2014-07-09 15:12:34,272 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,273 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4750ms
2014-07-09 15:12:34,273 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,273 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4924ms
2014-07-09 15:12:34,273 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:12:34,516 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12658,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943941857,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:34,520 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6616, memsize=623.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/ae7b7e6df4134a15858a02046cf99c03
2014-07-09 15:12:34,561 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/ae7b7e6df4134a15858a02046cf99c03 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/ae7b7e6df4134a15858a02046cf99c03
2014-07-09 15:12:34,570 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/ae7b7e6df4134a15858a02046cf99c03, entries=2268780, sequenceid=6616, filesize=161.5m
2014-07-09 15:12:34,571 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.1m/653388000, currentsize=45.2m/47409040 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 23871ms, sequenceid=6616, compaction requested=true
2014-07-09 15:12:34,572 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:34,572 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:12:34,572 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:12:34,572 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:34,572 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:34,572 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:12:35,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:35,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36445 synced till here 36440
2014-07-09 15:12:35,230 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:12:35,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943941595 with entries=79, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955186
2014-07-09 15:12:35,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:35,274 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943942095,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:35,403 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943942161,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:35,472 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90280ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:12:35,473 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 564.1m
2014-07-09 15:12:35,975 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:12:35,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:36,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36536 synced till here 36522
2014-07-09 15:12:36,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955186 with entries=91, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955978
2014-07-09 15:12:36,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:37,186 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14277,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943942908,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,186 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943942593,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,196 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943946064,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,211 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943943336,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,227 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14726,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943942501,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,227 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11941,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943945286,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,228 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943945697,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,228 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943943620,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,228 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943945461,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,235 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404943943026,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:12:37,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:37,631 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36625 synced till here 36623
2014-07-09 15:12:37,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955978 with entries=89, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943957601
2014-07-09 15:12:37,690 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:39,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36705 synced till here 36701
2014-07-09 15:12:40,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943957601 with entries=80, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943959557
2014-07-09 15:12:40,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:45,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:45,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943959557 with entries=82, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943965054
2014-07-09 15:12:45,121 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:46,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:47,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943965054 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943966795
2014-07-09 15:12:47,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:52,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:52,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943966795 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943972371
2014-07-09 15:12:52,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:54,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:54,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943972371 with entries=78, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943974146
2014-07-09 15:12:54,219 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:56,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:12:56,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37099 synced till here 37098
2014-07-09 15:12:56,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943974146 with entries=79, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943976460
2014-07-09 15:12:56,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:12:58,669 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6645, memsize=565.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/f03be7260d494ad6a2f185fa05498c9a
2014-07-09 15:12:58,703 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/f03be7260d494ad6a2f185fa05498c9a as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/f03be7260d494ad6a2f185fa05498c9a
2014-07-09 15:12:58,776 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/f03be7260d494ad6a2f185fa05498c9a, entries=2059720, sequenceid=6645, filesize=146.7m
2014-07-09 15:12:58,776 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~565.7m/593182160, currentsize=116.6m/122267040 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 23303ms, sequenceid=6645, compaction requested=true
2014-07-09 15:12:58,777 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:12:58,777 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:12:58,777 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:12:58,777 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:12:58,777 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:12:58,777 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:13:00,723 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6642, memsize=635.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/de5f50185780423680ea0cd4ac5ffe7b
2014-07-09 15:13:00,779 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/de5f50185780423680ea0cd4ac5ffe7b as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/de5f50185780423680ea0cd4ac5ffe7b
2014-07-09 15:13:00,796 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/de5f50185780423680ea0cd4ac5ffe7b, entries=2314090, sequenceid=6642, filesize=164.7m
2014-07-09 15:13:00,796 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~635.6m/666437360, currentsize=132.0m/138423600 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 26552ms, sequenceid=6642, compaction requested=true
2014-07-09 15:13:00,796 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:00,796 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:13:00,797 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:13:00,797 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:00,797 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:00,797 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:13:01,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:01,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37178 synced till here 37177
2014-07-09 15:13:01,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943976460 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943981367
2014-07-09 15:13:01,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:03,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:03,679 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37257 synced till here 37256
2014-07-09 15:13:03,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943981367 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943983637
2014-07-09 15:13:03,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:03,886 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:13:03,887 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:13:03,888 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:03,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:13:03,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:13:03,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:03,888 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:03,888 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:13:08,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37339 synced till here 37337
2014-07-09 15:13:08,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943983637 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943988315
2014-07-09 15:13:08,388 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:10,977 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:11,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37420 synced till here 37419
2014-07-09 15:13:11,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943988315 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943990978
2014-07-09 15:13:11,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:15,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:15,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37498 synced till here 37497
2014-07-09 15:13:15,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943990978 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943995459
2014-07-09 15:13:15,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:18,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:18,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37578 synced till here 37576
2014-07-09 15:13:18,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943995459 with entries=80, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943998173
2014-07-09 15:13:18,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:19,310 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:13:19,311 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:13:19,311 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:19,311 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:13:19,311 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:13:19,312 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:19,312 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:19,312 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:13:19,379 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:13:19,379 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:13:19,380 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:19,380 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:13:19,380 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:13:19,380 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:19,380 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:19,380 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:13:22,342 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:22,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943998173 with entries=79, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944002342
2014-07-09 15:13:22,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:24,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:24,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37736 synced till here 37735
2014-07-09 15:13:24,579 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944002342 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944004497
2014-07-09 15:13:24,580 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:28,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:28,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944004497 with entries=78, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944008120
2014-07-09 15:13:28,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:31,377 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:13:31,377 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:13:31,377 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:31,378 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:13:31,378 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:13:31,378 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:31,378 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:31,378 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:13:31,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:31,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944008120 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944011872
2014-07-09 15:13:31,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:13:32,190 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:13:32,190 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:13:32,191 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:32,191 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:13:32,191 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:13:32,191 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:32,191 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:32,191 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:13:32,925 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90666ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:13:32,926 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 599.9m
2014-07-09 15:13:33,449 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:13:33,734 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:13:33,734 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files, but is 966.4m vs best flushable region's 156.2m. Choosing the bigger.
2014-07-09 15:13:33,734 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. due to global heap pressure
2014-07-09 15:13:33,734 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 966.4m
2014-07-09 15:13:34,264 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:34,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944011872 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944014264
2014-07-09 15:13:34,598 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:13:38,686 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:38,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38051 synced till here 38048
2014-07-09 15:13:38,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944014264 with entries=81, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944018687
2014-07-09 15:13:40,120 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,144 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,159 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,189 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,448 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,555 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,688 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:40,879 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:41,290 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:42,582 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:43,471 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:44,241 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:44,431 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:45,254 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5066ms
2014-07-09 15:13:45,254 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5134ms
2014-07-09 15:13:45,255 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5111ms
2014-07-09 15:13:45,255 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5096ms
2014-07-09 15:13:45,319 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:45,423 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:45,448 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:45,493 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:45,556 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:45,621 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:45,688 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:45,879 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:45,976 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.9 GB, free=61.07 MB, max=3.96 GB, blocks=62756, accesses=45256374, hits=44494937, hitRatio=98.31%, , cachingAccesses=45249510, cachingHits=44494935, cachingHitsRatio=98.33%, evictions=269, evicted=690825, evictedPerRun=2568.12255859375
2014-07-09 15:13:46,193 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:46,290 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:46,717 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:13:47,583 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:48,472 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:49,353 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5112ms
2014-07-09 15:13:49,431 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:50,255 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10067ms
2014-07-09 15:13:50,255 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10135ms
2014-07-09 15:13:50,255 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10111ms
2014-07-09 15:13:50,256 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10097ms
2014-07-09 15:13:50,319 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:50,423 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:50,449 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:50,493 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:50,556 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:50,621 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:50,689 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:50,879 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:50,976 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:13:51,193 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:51,291 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:13:51,717 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:13:52,583 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:53,473 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:54,353 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10112ms
2014-07-09 15:13:54,432 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:13:55,005 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6810, memsize=601.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/154d2021577d455f96054beecac8e33d
2014-07-09 15:13:55,040 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/154d2021577d455f96054beecac8e33d as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/154d2021577d455f96054beecac8e33d
2014-07-09 15:13:55,060 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/154d2021577d455f96054beecac8e33d, entries=2189830, sequenceid=6810, filesize=155.9m
2014-07-09 15:13:55,061 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~601.4m/630653360, currentsize=30.9m/32373120 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 22135ms, sequenceid=6810, compaction requested=true
2014-07-09 15:13:55,061 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:13:55,061 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:13:55,061 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:13:55,061 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10630ms
2014-07-09 15:13:55,062 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,062 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:13:55,061 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 106683ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:13:55,062 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:13:55,062 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:13:55,062 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10821ms
2014-07-09 15:13:55,062 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 607.6m
2014-07-09 15:13:55,062 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,065 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11594ms
2014-07-09 15:13:55,065 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,069 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12487ms
2014-07-09 15:13:55,069 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,069 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8352ms
2014-07-09 15:13:55,069 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,069 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13780ms
2014-07-09 15:13:55,069 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,070 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8876ms
2014-07-09 15:13:55,070 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,073 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9098ms
2014-07-09 15:13:55,073 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,073 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14195ms
2014-07-09 15:13:55,073 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,074 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14385ms
2014-07-09 15:13:55,074 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,079 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9457ms
2014-07-09 15:13:55,079 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,079 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14524ms
2014-07-09 15:13:55,080 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,080 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9587ms
2014-07-09 15:13:55,080 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,080 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14633ms
2014-07-09 15:13:55,080 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,081 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9658ms
2014-07-09 15:13:55,081 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,081 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9762ms
2014-07-09 15:13:55,081 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,082 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14923ms
2014-07-09 15:13:55,082 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,083 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14938ms
2014-07-09 15:13:55,083 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,083 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14963ms
2014-07-09 15:13:55,084 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,084 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14896ms
2014-07-09 15:13:55,085 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:13:55,111 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16030,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944019080,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:55,563 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15751,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944019810,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:55,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:55,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38140 synced till here 38132
2014-07-09 15:13:55,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944018687 with entries=89, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944035610
2014-07-09 15:13:55,916 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:13:56,198 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16237,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944019960,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:56,344 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:56,345 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16275,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944020070,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:56,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38222 synced till here 38213
2014-07-09 15:13:56,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944035610 with entries=82, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944036345
2014-07-09 15:13:57,480 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13245,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944024234,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,511 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944025489,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,511 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16635,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944020876,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,511 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10796,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944026715,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,511 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944024427,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,512 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944023465,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,512 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11893,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944025618,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,531 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12213,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944025317,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,531 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16845,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944020686,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,531 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11557,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944025974,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,532 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944025421,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,556 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944020552,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,556 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14976,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944022580,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,556 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944020445,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,556 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16269,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944021287,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,556 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944026191,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:13:57,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:13:57,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38310 synced till here 38309
2014-07-09 15:13:57,911 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944036345 with entries=88, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944037869
2014-07-09 15:15:10,115 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 72708ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:15:10,115 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 72708ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:15:10,115 WARN  [regionserver60020] util.Sleeper: We slept 72487ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:15:10,147 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 71532ms
GC pool 'ParNew' had collection(s): count=1 time=1141ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=70786ms
2014-07-09 15:15:10,182 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 83476ms for sessionid 0x471d07562a0000, closing socket connection and attempting reconnect
2014-07-09 15:15:10,182 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 83552ms for sessionid 0x471d07562a0003, closing socket connection and attempting reconnect
2014-07-09 15:15:10,182 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 77932ms for sessionid 0x471d07562a0004, closing socket connection and attempting reconnect
2014-07-09 15:15:10,448 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581276 service: ClientService methodName: Get size: 124.0 connection: 9.1.143.58:55428: output error
2014-07-09 15:15:10,468 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:10,468 WARN  [ResponseProcessor for block blk_6990183236877891907_73221] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_6990183236877891907_73221java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.59:45925 remote=/9.1.143.59:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-09 15:15:10,468 WARN  [ResponseProcessor for block blk_-5760616768399969328_72127] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_-5760616768399969328_72127java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.59:43234 remote=/9.1.143.59:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-09 15:15:10,468 WARN  [ResponseProcessor for block blk_1262593702170038949_73223] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_1262593702170038949_73223java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.59:46010 remote=/9.1.143.59:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-09 15:15:10,503 WARN  [DataStreamer for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/66d4bbac260b41bea450fbff446c779c block blk_6990183236877891907_73221] hdfs.DFSClient: Error Recovery for blk_6990183236877891907_73221 bad datanode[0] 9.1.143.59:50010
2014-07-09 15:15:10,518 WARN  [DataStreamer for file /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941362613.meta block blk_-5760616768399969328_72127] hdfs.DFSClient: Error Recovery for blk_-5760616768399969328_72127 bad datanode[0] 9.1.143.59:50010
2014-07-09 15:15:10,532 WARN  [DataStreamer for file /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941362613.meta block blk_-5760616768399969328_72127] hdfs.DFSClient: Error Recovery for block blk_-5760616768399969328_72127 in pipeline 9.1.143.59:50010, 9.1.143.58:50010: bad datanode 9.1.143.59:50010
2014-07-09 15:15:10,532 WARN  [DataStreamer for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7a9f200b5324c47a2163d4acb877962 block blk_1262593702170038949_73223] hdfs.DFSClient: Error Recovery for blk_1262593702170038949_73223 bad datanode[0] 9.1.143.59:50010
2014-07-09 15:15:10,532 WARN  [DataStreamer for file /hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7a9f200b5324c47a2163d4acb877962 block blk_1262593702170038949_73223] hdfs.DFSClient: Error Recovery for block blk_1262593702170038949_73223 in pipeline 9.1.143.59:50010, 9.1.143.58:50010: bad datanode 9.1.143.59:50010
2014-07-09 15:15:10,533 WARN  [DataStreamer for file /hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/66d4bbac260b41bea450fbff446c779c block blk_6990183236877891907_73221] hdfs.DFSClient: Error Recovery for block blk_6990183236877891907_73221 in pipeline 9.1.143.59:50010, 9.1.143.58:50010: bad datanode 9.1.143.59:50010
2014-07-09 15:15:10,564 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:15:10,564 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-09 15:15:10,606 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x471d07562a0003, negotiated timeout = 90000
2014-07-09 15:15:11,028 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:15:11,028 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-09 15:15:11,048 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:15:11,059 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x471d07562a0004, negotiated timeout = 90000
2014-07-09 15:15:11,089 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-09 15:15:11,096 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581275 service: ClientService methodName: Get size: 124.0 connection: 9.1.143.58:55428: output error
2014-07-09 15:15:11,096 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:11,252 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x471d07562a0000, negotiated timeout = 90000
2014-07-09 15:15:13,582 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":75930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037643,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:13,582 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581265 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:13,583 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:13,802 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":76081,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037712,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:13,803 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581263 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:13,803 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:15,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:15,222 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38391 synced till here 38384
2014-07-09 15:15:15,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944037869 with entries=81, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944115164
2014-07-09 15:15:17,830 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1674ms
GC pool 'ParNew' had collection(s): count=1 time=2018ms
2014-07-09 15:15:18,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:18,909 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":80998,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037910,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:18,909 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581281 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:18,909 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:18,910 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":81120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037786,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:18,910 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581259 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:18,910 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:18,911 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":81065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037845,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:18,912 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581258 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:18,912 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:18,936 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":80926,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944037981,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:18,936 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581280 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:18,936 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:18,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38500 synced till here 38490
2014-07-09 15:15:19,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944115164 with entries=109, filesize=90.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944118698
2014-07-09 15:15:19,093 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581277 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:19,093 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:19,100 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":81052,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944038047,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:19,100 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":80979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55428","starttimems":1404944038120,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:19,100 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581279 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:19,100 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:19,100 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3581278 service: ClientService methodName: Multi size: 5.7m connection: 9.1.143.58:55428: output error
2014-07-09 15:15:19,101 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-09 15:15:19,100 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:19,145 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:21,709 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:21,873 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:23,171 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:23,473 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:23,836 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,008 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,094 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,101 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:24,145 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:24,240 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,448 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,568 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,703 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,864 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:24,948 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:25,033 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:25,113 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:25,417 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:26,453 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:26,710 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:26,802 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:15:26,873 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:28,171 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:28,473 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:28,836 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:29,219 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10033ms
2014-07-09 15:15:29,220 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5126ms
2014-07-09 15:15:29,222 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5213ms
2014-07-09 15:15:29,222 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10122ms
2014-07-09 15:15:29,241 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:29,448 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:29,569 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:29,704 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:29,864 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:29,949 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:30,034 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:30,114 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:30,418 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:31,453 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:15:31,711 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:15:31,803 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:15:31,874 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:15:33,171 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:15:33,474 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:15:33,606 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6818, memsize=967.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/66d4bbac260b41bea450fbff446c779c
2014-07-09 15:15:33,640 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/66d4bbac260b41bea450fbff446c779c as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/66d4bbac260b41bea450fbff446c779c
2014-07-09 15:15:33,659 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/66d4bbac260b41bea450fbff446c779c, entries=3524100, sequenceid=6818, filesize=250.8m
2014-07-09 15:15:33,659 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~967.9m/1014910720, currentsize=96.9m/101598480 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 119925ms, sequenceid=6818, compaction requested=true
2014-07-09 15:15:33,660 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:15:33,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:15:33,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:15:33,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:15:33,660 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 134281ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:15:33,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:15:33,660 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:15:33,661 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10187ms
2014-07-09 15:15:33,661 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 410.4m
2014-07-09 15:15:33,661 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,661 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10491ms
2014-07-09 15:15:33,661 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,661 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11788ms
2014-07-09 15:15:33,661 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,669 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6866ms
2014-07-09 15:15:33,669 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,669 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11960ms
2014-07-09 15:15:33,669 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,669 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7216ms
2014-07-09 15:15:33,669 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,669 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8252ms
2014-07-09 15:15:33,669 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,670 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8557ms
2014-07-09 15:15:33,670 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,673 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8640ms
2014-07-09 15:15:33,673 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,673 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8725ms
2014-07-09 15:15:33,673 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,674 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8810ms
2014-07-09 15:15:33,674 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,675 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8971ms
2014-07-09 15:15:33,675 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,675 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9107ms
2014-07-09 15:15:33,675 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,676 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9227ms
2014-07-09 15:15:33,676 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,676 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9437ms
2014-07-09 15:15:33,676 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,686 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14585ms
2014-07-09 15:15:33,686 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,686 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9678ms
2014-07-09 15:15:33,686 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,686 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9592ms
2014-07-09 15:15:33,686 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,689 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14545ms
2014-07-09 15:15:33,689 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,689 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9854ms
2014-07-09 15:15:33,689 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:15:33,729 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18459,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944115269,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:33,946 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18841,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944115104,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:34,084 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:15:34,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:34,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38595 synced till here 38591
2014-07-09 15:15:34,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944118698 with entries=95, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944134760
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943744273
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943762385
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943763513
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943764818
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943765589
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943767193
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943791205
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943792704
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943797767
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943799373
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943804805
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943806684
2014-07-09 15:15:34,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943811403
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943813150
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943814975
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943819834
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943821897
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943826506
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943828325
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943832981
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943834882
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943839179
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943841661
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943844091
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943848340
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943850602
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943855490
2014-07-09 15:15:34,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943858042
2014-07-09 15:15:35,438 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944123470,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:36,144 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38687 synced till here 38672
2014-07-09 15:15:36,171 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944121703,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,171 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944121870,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,171 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124861,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,172 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944123168,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,172 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11062,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944125110,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,171 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12081,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124089,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,172 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124946,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,179 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10764,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944125414,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,199 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944134760 with entries=92, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944136104
2014-07-09 15:15:36,313 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11613,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124699,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,313 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944125029,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,313 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944123833,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,318 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11871,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124446,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,318 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124004,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,322 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124235,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:36,322 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11757,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944124564,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:15:37,019 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:37,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38771 synced till here 38770
2014-07-09 15:15:37,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944136104 with entries=84, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944137019
2014-07-09 15:15:38,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:38,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944137019 with entries=79, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944138324
2014-07-09 15:15:40,110 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6830, memsize=607.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7a9f200b5324c47a2163d4acb877962
2014-07-09 15:15:40,131 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7a9f200b5324c47a2163d4acb877962 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7a9f200b5324c47a2163d4acb877962
2014-07-09 15:15:40,140 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7a9f200b5324c47a2163d4acb877962, entries=2212270, sequenceid=6830, filesize=157.5m
2014-07-09 15:15:40,177 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~607.6m/637114960, currentsize=133.2m/139637840 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 105115ms, sequenceid=6830, compaction requested=true
2014-07-09 15:15:40,177 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:15:40,177 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 140867ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:15:40,177 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:15:40,178 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:15:40,178 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 469.2m
2014-07-09 15:15:40,178 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:15:40,178 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:15:40,178 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:15:40,581 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:15:44,300 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:44,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944138324 with entries=80, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944144301
2014-07-09 15:15:44,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943862772
2014-07-09 15:15:44,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943865000
2014-07-09 15:15:44,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943868247
2014-07-09 15:15:44,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943879421
2014-07-09 15:15:44,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943880156
2014-07-09 15:15:44,372 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:15:46,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:46,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944144301 with entries=78, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944146078
2014-07-09 15:15:46,117 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:15:49,454 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6881, memsize=396.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/694566863ec34c48b3f3bbd3abd8c6d3
2014-07-09 15:15:49,474 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/694566863ec34c48b3f3bbd3abd8c6d3 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/694566863ec34c48b3f3bbd3abd8c6d3
2014-07-09 15:15:49,523 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/694566863ec34c48b3f3bbd3abd8c6d3, entries=1443300, sequenceid=6881, filesize=102.8m
2014-07-09 15:15:49,539 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~410.4m/430312880, currentsize=93.1m/97591840 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 15878ms, sequenceid=6881, compaction requested=true
2014-07-09 15:15:49,540 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:15:49,540 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:15:49,540 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:15:49,541 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:15:49,541 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:15:49,541 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:15:49,541 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 165655ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:15:49,541 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 562.6m
2014-07-09 15:15:50,325 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:15:50,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:51,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944146078 with entries=115, filesize=90.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944150796
2014-07-09 15:15:51,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:15:54,297 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:54,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944150796 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944154298
2014-07-09 15:15:54,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:15:57,012 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6917, memsize=455.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/59902211b8d14c6c8c2eac24916bbce9
2014-07-09 15:15:57,040 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/59902211b8d14c6c8c2eac24916bbce9 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/59902211b8d14c6c8c2eac24916bbce9
2014-07-09 15:15:57,064 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/59902211b8d14c6c8c2eac24916bbce9, entries=1657080, sequenceid=6917, filesize=118.0m
2014-07-09 15:15:57,065 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~469.2m/491967520, currentsize=61.8m/64830160 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 16887ms, sequenceid=6917, compaction requested=true
2014-07-09 15:15:57,065 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:15:57,065 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:15:57,065 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 144875ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:15:57,066 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:15:57,066 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:15:57,066 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 483.4m
2014-07-09 15:15:57,066 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:15:57,066 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:15:57,492 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:15:59,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:15:59,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39282 synced till here 39281
2014-07-09 15:15:59,337 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944154298 with entries=80, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944159258
2014-07-09 15:15:59,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:16:01,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:01,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39362 synced till here 39361
2014-07-09 15:16:01,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944159258 with entries=80, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944161271
2014-07-09 15:16:01,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:16:02,427 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:16:06,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:06,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944161271 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944166187
2014-07-09 15:16:06,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:16:06,226 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:16:08,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:08,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39520 synced till here 39519
2014-07-09 15:16:08,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944166187 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944168562
2014-07-09 15:16:08,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:16:10,125 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:16:10,720 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6939, memsize=548.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/c605b0d2f3614b53bab4f11a857d576b
2014-07-09 15:16:10,742 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/c605b0d2f3614b53bab4f11a857d576b as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c605b0d2f3614b53bab4f11a857d576b
2014-07-09 15:16:10,772 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c605b0d2f3614b53bab4f11a857d576b, entries=1996960, sequenceid=6939, filesize=142.2m
2014-07-09 15:16:10,782 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~562.6m/589973760, currentsize=93.0m/97530800 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 21241ms, sequenceid=6939, compaction requested=true
2014-07-09 15:16:10,783 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:16:10,783 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:16:10,783 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:10,783 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:10,783 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:16:10,783 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:10,783 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 159406ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:16:10,783 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 550.4m
2014-07-09 15:16:11,231 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:16:12,850 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:12,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944168562 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944172851
2014-07-09 15:16:12,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:16:14,631 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6957, memsize=469.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/abbf8e35ed474552a196b03dead3eb67
2014-07-09 15:16:14,647 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/abbf8e35ed474552a196b03dead3eb67 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/abbf8e35ed474552a196b03dead3eb67
2014-07-09 15:16:14,671 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/abbf8e35ed474552a196b03dead3eb67, entries=1709200, sequenceid=6957, filesize=121.7m
2014-07-09 15:16:14,671 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~483.4m/506911920, currentsize=76.3m/80008000 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 17605ms, sequenceid=6957, compaction requested=true
2014-07-09 15:16:14,671 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:14,672 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:16:14,672 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 245.4m
2014-07-09 15:16:14,672 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:16:14,672 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:14,672 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:14,672 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:16:15,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:15,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39676 synced till here 39675
2014-07-09 15:16:15,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944172851 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944175054
2014-07-09 15:16:15,158 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:16:17,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:17,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944175054 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944177504
2014-07-09 15:16:22,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:22,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944177504 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944182668
2014-07-09 15:16:23,267 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6988, memsize=241.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/b6cf60e71a52470a858f6581279a1ad2
2014-07-09 15:16:23,300 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/b6cf60e71a52470a858f6581279a1ad2 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/b6cf60e71a52470a858f6581279a1ad2
2014-07-09 15:16:23,317 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/b6cf60e71a52470a858f6581279a1ad2, entries=877910, sequenceid=6988, filesize=62.5m
2014-07-09 15:16:23,317 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~245.4m/257293120, currentsize=10.0m/10447680 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 8645ms, sequenceid=6988, compaction requested=true
2014-07-09 15:16:23,317 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:23,317 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-09 15:16:23,317 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:23,317 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-09 15:16:23,317 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:16:23,317 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:16:23,318 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:23,318 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:16:23,318 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:16:23,318 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:16:23,318 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 29 store files, 0 compacting, 29 eligible, 20 blocking
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 29 files from compaction candidates
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:23,319 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:16:24,801 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:24,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944182668 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944184801
2014-07-09 15:16:24,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943882140
2014-07-09 15:16:24,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943883692
2014-07-09 15:16:24,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943893229
2014-07-09 15:16:24,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943894640
2014-07-09 15:16:24,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943903321
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943904796
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943906290
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943908229
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943913002
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943914422
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943919760
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943921327
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943923949
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943927964
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943930490
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943934719
2014-07-09 15:16:24,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943936775
2014-07-09 15:16:28,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:28,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39991 synced till here 39990
2014-07-09 15:16:28,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944184801 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944188904
2014-07-09 15:16:29,052 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:29,052 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:16:29,053 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:29,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:16:29,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:16:29,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:29,053 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:29,053 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:16:30,645 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6997, memsize=536.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/f5643379e02549b6bf7a58c1649fd7b0
2014-07-09 15:16:30,665 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/f5643379e02549b6bf7a58c1649fd7b0 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f5643379e02549b6bf7a58c1649fd7b0
2014-07-09 15:16:30,695 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f5643379e02549b6bf7a58c1649fd7b0, entries=1953640, sequenceid=6997, filesize=139.1m
2014-07-09 15:16:30,695 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~550.4m/577096480, currentsize=80.6m/84559920 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 19912ms, sequenceid=6997, compaction requested=true
2014-07-09 15:16:30,696 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:30,696 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:16:30,696 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:16:30,696 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:30,696 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:30,696 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:16:31,256 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:31,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944188904 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944191257
2014-07-09 15:16:31,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943941595
2014-07-09 15:16:31,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955186
2014-07-09 15:16:31,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943955978
2014-07-09 15:16:31,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943957601
2014-07-09 15:16:31,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943959557
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943965054
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943966795
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943972371
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943974146
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943976460
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943981367
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943983637
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943988315
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943990978
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943995459
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404943998173
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944002342
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944004497
2014-07-09 15:16:31,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944008120
2014-07-09 15:16:35,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:35,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40149 synced till here 40147
2014-07-09 15:16:35,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944191257 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944195660
2014-07-09 15:16:38,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:38,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40227 synced till here 40226
2014-07-09 15:16:38,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944195660 with entries=78, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944198013
2014-07-09 15:16:41,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:41,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944198013 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944201318
2014-07-09 15:16:42,835 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:16:42,835 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:42,836 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:42,836 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:16:42,836 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:16:42,836 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:42,836 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:42,836 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:16:44,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:44,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40385 synced till here 40384
2014-07-09 15:16:44,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944201318 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944204114
2014-07-09 15:16:47,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:47,197 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944204114 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944207176
2014-07-09 15:16:50,406 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:16:50,407 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:50,408 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:50,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:16:50,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:16:50,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:50,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:50,409 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:16:51,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:51,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40541 synced till here 40540
2014-07-09 15:16:51,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944207176 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944211071
2014-07-09 15:16:53,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:53,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944211071 with entries=77, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944213124
2014-07-09 15:16:53,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:16:57,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:57,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944213124 with entries=79, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944217251
2014-07-09 15:16:57,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:16:57,449 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:16:57,450 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:16:57,450 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:16:57,450 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:16:57,450 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:16:57,450 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:16:57,450 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:16:57,450 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:16:59,468 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:16:59,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944217251 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944219468
2014-07-09 15:16:59,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:03,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:03,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944219468 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944223023
2014-07-09 15:17:03,071 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:05,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:05,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40932 synced till here 40931
2014-07-09 15:17:05,794 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944223023 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944225739
2014-07-09 15:17:05,794 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:09,250 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:09,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944225739 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944229251
2014-07-09 15:17:09,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:11,903 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:17:11,903 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:17:11,904 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:17:11,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:17:11,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:17:11,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:17:11,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:17:11,904 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:17:12,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:12,430 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944229251 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944232398
2014-07-09 15:17:12,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:14,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:14,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944232398 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944234695
2014-07-09 15:17:14,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:18,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:18,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41245 synced till here 41244
2014-07-09 15:17:18,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944234695 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944238681
2014-07-09 15:17:18,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:20,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:20,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944238681 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944240935
2014-07-09 15:17:20,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:17:22,726 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:17:22,727 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files, but is 598.0m vs best flushable region's 88.7m. Choosing the bigger.
2014-07-09 15:17:22,727 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. due to global heap pressure
2014-07-09 15:17:22,727 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 598.0m
2014-07-09 15:17:23,208 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:17:23,387 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:17:23,387 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files, but is 589.7m vs best flushable region's 89.2m. Choosing the bigger.
2014-07-09 15:17:23,387 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. due to global heap pressure
2014-07-09 15:17:23,387 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 589.7m
2014-07-09 15:17:23,821 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:17:24,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:24,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41402 synced till here 41401
2014-07-09 15:17:24,349 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944240935 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944244307
2014-07-09 15:17:27,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:27,235 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944244307 with entries=80, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944247176
2014-07-09 15:17:28,808 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:28,810 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:28,835 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:28,838 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:28,847 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:29,219 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:30,066 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:30,601 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:30,845 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:31,660 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:31,790 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:32,310 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:32,529 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:32,693 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:33,062 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:33,455 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:33,619 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:33,808 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:33,810 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:33,835 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:33,838 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:33,847 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:34,512 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5293ms
2014-07-09 15:17:34,651 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:34,818 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:34,934 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:17:35,066 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:17:35,601 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:35,845 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:36,660 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:36,791 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:17:37,310 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:37,766 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5073ms
2014-07-09 15:17:37,767 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5238ms
2014-07-09 15:17:38,062 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:17:38,455 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:38,620 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:17:38,809 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:38,811 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:38,836 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:17:38,838 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:17:38,847 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:17:39,513 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10294ms
2014-07-09 15:17:39,651 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:39,818 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:17:39,935 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:17:40,066 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:40,602 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:40,846 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:41,661 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:41,791 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:42,311 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:17:42,587 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7196, memsize=584.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/791444f716504dcba7cf3daf7a7fddbf
2014-07-09 15:17:42,604 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/791444f716504dcba7cf3daf7a7fddbf as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/791444f716504dcba7cf3daf7a7fddbf
2014-07-09 15:17:42,634 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/791444f716504dcba7cf3daf7a7fddbf, entries=2127190, sequenceid=7196, filesize=151.4m
2014-07-09 15:17:42,634 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~598.0m/627094480, currentsize=21.5m/22587280 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 19907ms, sequenceid=7196, compaction requested=true
2014-07-09 15:17:42,635 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:17:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:17:42,635 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:17:42,635 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10325ms
2014-07-09 15:17:42,636 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:17:42,636 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:17:42,635 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 100208ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:17:42,636 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:17:42,636 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,636 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10846ms
2014-07-09 15:17:42,637 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,636 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 21.5m
2014-07-09 15:17:42,637 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10977ms
2014-07-09 15:17:42,637 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,637 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11792ms
2014-07-09 15:17:42,638 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,641 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12040ms
2014-07-09 15:17:42,641 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,642 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12576ms
2014-07-09 15:17:42,642 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,642 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7708ms
2014-07-09 15:17:42,642 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,649 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:17:42,657 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7839ms
2014-07-09 15:17:42,657 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,657 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8006ms
2014-07-09 15:17:42,657 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,658 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13438ms
2014-07-09 15:17:42,658 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,658 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13811ms
2014-07-09 15:17:42,658 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,659 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13821ms
2014-07-09 15:17:42,659 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,659 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13824ms
2014-07-09 15:17:42,659 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,659 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13849ms
2014-07-09 15:17:42,659 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,661 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13853ms
2014-07-09 15:17:42,661 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,665 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9046ms
2014-07-09 15:17:42,665 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,666 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9210ms
2014-07-09 15:17:42,666 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,667 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9605ms
2014-07-09 15:17:42,667 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,667 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10138ms
2014-07-09 15:17:42,667 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,668 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9974ms
2014-07-09 15:17:42,668 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:17:42,730 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14863,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944247866,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:42,747 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7198, memsize=575.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/6aa0d3baa1c54f95b658abb84b0e2aa1
2014-07-09 15:17:42,768 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/6aa0d3baa1c54f95b658abb84b0e2aa1 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6aa0d3baa1c54f95b658abb84b0e2aa1
2014-07-09 15:17:42,792 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6aa0d3baa1c54f95b658abb84b0e2aa1, entries=2096090, sequenceid=7198, filesize=149.2m
2014-07-09 15:17:42,792 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~589.7m/618312720, currentsize=24.8m/26000080 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 19405ms, sequenceid=7198, compaction requested=true
2014-07-09 15:17:42,793 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:17:42,793 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:17:42,793 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 96568ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:17:42,793 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:17:42,793 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 24.8m
2014-07-09 15:17:42,793 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:17:42,793 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:17:42,793 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:17:42,957 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:17:43,030 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944247983,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:43,331 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:43,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41573 synced till here 41559
2014-07-09 15:17:43,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944247176 with entries=91, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944263332
2014-07-09 15:17:43,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944011872
2014-07-09 15:17:43,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944014264
2014-07-09 15:17:43,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:17:43,617 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7211, memsize=21.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/0d74dd1562e84da1941f0b5c30c3319b
2014-07-09 15:17:43,632 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/0d74dd1562e84da1941f0b5c30c3319b as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/0d74dd1562e84da1941f0b5c30c3319b
2014-07-09 15:17:43,658 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/0d74dd1562e84da1941f0b5c30c3319b, entries=78430, sequenceid=7211, filesize=5.6m
2014-07-09 15:17:43,658 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~21.5m/22587280, currentsize=3.1m/3254320 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 1022ms, sequenceid=7211, compaction requested=true
2014-07-09 15:17:43,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:17:43,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:17:43,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:17:43,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:17:43,659 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:17:43,659 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:17:43,659 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 93534ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:17:43,660 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 592.3m
2014-07-09 15:17:43,946 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944248159,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:43,993 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944248245,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,008 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7216, memsize=26.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/dcd2782001f34a1a9f19c458548bbbc5
2014-07-09 15:17:44,019 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/dcd2782001f34a1a9f19c458548bbbc5 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/dcd2782001f34a1a9f19c458548bbbc5
2014-07-09 15:17:44,031 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/dcd2782001f34a1a9f19c458548bbbc5, entries=95700, sequenceid=7216, filesize=6.8m
2014-07-09 15:17:44,032 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~26.3m/27561040, currentsize=29.8m/31299200 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 1238ms, sequenceid=7216, compaction requested=true
2014-07-09 15:17:44,032 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:17:44,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:17:44,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:17:44,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:17:44,032 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:17:44,032 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:17:44,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:44,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41659 synced till here 41647
2014-07-09 15:17:44,138 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944251789,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,139 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12480,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944251658,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944263332 with entries=86, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944264050
2014-07-09 15:17:44,875 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:17:44,979 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944250839,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,979 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10049,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944254930,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,979 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944250596,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,981 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14919,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944250062,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,982 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944252308,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,999 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944249216,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,999 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944248804,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,999 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12472,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944252527,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:44,999 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11941,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944253058,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:45,000 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944253453,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:45,016 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12323,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944252692,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:45,040 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11421,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944253618,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:45,041 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10391,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944254649,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:17:45,399 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:45,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41746 synced till here 41745
2014-07-09 15:17:45,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944264050 with entries=87, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944265399
2014-07-09 15:17:47,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:17:47,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41825 synced till here 41824
2014-07-09 15:17:47,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944265399 with entries=79, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944267023
2014-07-09 15:18:09,234 WARN  [regionserver60020] util.Sleeper: We slept 20869ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:18:09,235 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 28867ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:18:09,235 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 28868ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:18:09,237 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20624ms
GC pool 'ParNew' had collection(s): count=1 time=638ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20096ms
2014-07-09 15:18:09,239 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20744,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268495,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,239 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20744,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268494,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,239 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20748,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268491,"queuetimems":0,"class":"HRegionServer","responsesize":1533,"method":"Get"}
2014-07-09 15:18:09,239 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20746,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268492,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,240 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20765,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268475,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,241 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20745,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268495,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,241 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20772,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268469,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,241 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20746,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268495,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,241 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20789,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268452,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,241 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20790,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268451,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,239 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20751,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268488,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,242 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20791,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268451,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,244 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20747,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268497,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,244 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20784,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268460,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,246 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20784,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268462,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:18:09,274 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20780,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944268494,"queuetimems":0,"class":"HRegionServer","responsesize":1543,"method":"Get"}
2014-07-09 15:18:12,839 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90004ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:18:12,839 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 526.6m
2014-07-09 15:18:12,888 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:12,924 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41907 synced till here 41904
2014-07-09 15:18:12,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944267023 with entries=82, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944292888
2014-07-09 15:18:13,621 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:18:14,233 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:14,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41986 synced till here 41983
2014-07-09 15:18:14,268 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944292888 with entries=79, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944294234
2014-07-09 15:18:18,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:18,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944294234 with entries=80, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944298491
2014-07-09 15:18:20,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:20,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944298491 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944300129
2014-07-09 15:18:22,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:22,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944300129 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944302601
2014-07-09 15:18:25,634 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7214, memsize=581.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/8fb1da8b7a984ff9b7c65b9c123ca682
2014-07-09 15:18:25,656 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/8fb1da8b7a984ff9b7c65b9c123ca682 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8fb1da8b7a984ff9b7c65b9c123ca682
2014-07-09 15:18:25,677 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8fb1da8b7a984ff9b7c65b9c123ca682, entries=2116140, sequenceid=7214, filesize=150.7m
2014-07-09 15:18:25,678 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~595.2m/624130800, currentsize=122.7m/128617680 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 42018ms, sequenceid=7214, compaction requested=true
2014-07-09 15:18:25,678 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:18:25,679 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:18:25,679 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:25,679 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:25,679 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:25,679 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 95273ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:18:25,679 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:18:25,679 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 555.0m
2014-07-09 15:18:26,422 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:18:26,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:26,728 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42300 synced till here 42299
2014-07-09 15:18:26,744 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944302601 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944306701
2014-07-09 15:18:26,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944018687
2014-07-09 15:18:26,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944035610
2014-07-09 15:18:26,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944036345
2014-07-09 15:18:26,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944037869
2014-07-09 15:18:26,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944115164
2014-07-09 15:18:26,793 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:28,852 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:28,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42378 synced till here 42377
2014-07-09 15:18:28,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944306701 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944308852
2014-07-09 15:18:28,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:31,432 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7258, memsize=528.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b7fc7496c0ac4b9aa6908fb0d9325be3
2014-07-09 15:18:31,449 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/b7fc7496c0ac4b9aa6908fb0d9325be3 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b7fc7496c0ac4b9aa6908fb0d9325be3
2014-07-09 15:18:31,460 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b7fc7496c0ac4b9aa6908fb0d9325be3, entries=1922790, sequenceid=7258, filesize=136.9m
2014-07-09 15:18:31,468 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~528.1m/553749440, currentsize=83.9m/87955760 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 18629ms, sequenceid=7258, compaction requested=true
2014-07-09 15:18:31,468 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:31,468 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 94019ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:18:31,469 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:18:31,469 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 547.9m
2014-07-09 15:18:31,469 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:18:31,469 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:31,469 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:31,469 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:18:31,858 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:18:33,149 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:33,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944308852 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944313149
2014-07-09 15:18:33,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:34,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:34,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42535 synced till here 42533
2014-07-09 15:18:34,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944313149 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944314711
2014-07-09 15:18:34,771 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:39,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:39,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944314711 with entries=81, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944319395
2014-07-09 15:18:39,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:42,717 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:43,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42716 synced till here 42715
2014-07-09 15:18:43,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944319395 with entries=100, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944322717
2014-07-09 15:18:43,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:45,347 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7297, memsize=555.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/a849b34e14334ba185c2ca77a03a1298
2014-07-09 15:18:45,358 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/a849b34e14334ba185c2ca77a03a1298 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a849b34e14334ba185c2ca77a03a1298
2014-07-09 15:18:45,368 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a849b34e14334ba185c2ca77a03a1298, entries=2020630, sequenceid=7297, filesize=143.9m
2014-07-09 15:18:45,368 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~555.0m/581925360, currentsize=85.1m/89234400 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 19689ms, sequenceid=7297, compaction requested=true
2014-07-09 15:18:45,369 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:45,369 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:18:45,369 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:18:45,369 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:45,369 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:45,369 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:18:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.85 GB, free=113.4 MB, max=3.96 GB, blocks=61884, accesses=53435875, hits=52521195, hitRatio=98.28%, , cachingAccesses=53429036, cachingHits=52521216, cachingHitsRatio=98.30%, evictions=329, evicted=844908, evictedPerRun=2568.109375
2014-07-09 15:18:47,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:48,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944322717 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944327992
2014-07-09 15:18:48,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:50,349 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7311, memsize=547.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/5fc30253b5d14f63ab7bbc6810435bb4
2014-07-09 15:18:50,363 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/5fc30253b5d14f63ab7bbc6810435bb4 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5fc30253b5d14f63ab7bbc6810435bb4
2014-07-09 15:18:50,374 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5fc30253b5d14f63ab7bbc6810435bb4, entries=1994980, sequenceid=7311, filesize=142.0m
2014-07-09 15:18:50,374 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~547.9m/574538560, currentsize=79.4m/83215680 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 18905ms, sequenceid=7311, compaction requested=true
2014-07-09 15:18:50,375 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:50,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:18:50,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:18:50,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:50,375 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:50,375 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:18:50,493 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:50,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42872 synced till here 42871
2014-07-09 15:18:50,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944327992 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944330493
2014-07-09 15:18:50,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:54,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:54,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944330493 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944334115
2014-07-09 15:18:54,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:55,443 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:18:55,443 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:18:55,443 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:55,443 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:18:55,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:18:55,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:55,444 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:55,444 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:18:56,481 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:18:56,481 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:18:56,481 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:56,481 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:18:56,481 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:18:56,482 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:56,482 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:56,482 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:18:56,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:56,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43030 synced till here 43029
2014-07-09 15:18:56,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944334115 with entries=80, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944336915
2014-07-09 15:18:56,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:18:57,101 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:18:57,101 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:18:57,102 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:18:57,102 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 30 store files, 0 compacting, 30 eligible, 20 blocking
2014-07-09 15:18:57,102 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 30 files from compaction candidates
2014-07-09 15:18:57,102 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:18:57,102 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:18:57,102 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:18:59,140 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:18:59,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43108 synced till here 43107
2014-07-09 15:18:59,177 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944336915 with entries=78, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944339140
2014-07-09 15:18:59,178 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:03,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:03,316 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944339140 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944343284
2014-07-09 15:19:03,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:05,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:05,351 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43264 synced till here 43263
2014-07-09 15:19:05,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944343284 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944345321
2014-07-09 15:19:05,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:08,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:08,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944345321 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944348429
2014-07-09 15:19:08,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:11,074 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:19:11,074 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:19:11,075 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:19:11,075 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:19:11,075 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:19:11,075 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:19:11,075 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:19:11,075 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:19:11,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:11,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43420 synced till here 43419
2014-07-09 15:19:11,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944348429 with entries=78, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944351373
2014-07-09 15:19:11,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:13,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:14,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43514 synced till here 43513
2014-07-09 15:19:14,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944351373 with entries=94, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944353960
2014-07-09 15:19:14,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:17,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:17,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43594 synced till here 43593
2014-07-09 15:19:17,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944353960 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944357790
2014-07-09 15:19:17,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:21,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:21,440 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944357790 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944361402
2014-07-09 15:19:21,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:24,767 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:19:24,767 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:19:24,767 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:19:24,767 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:19:24,767 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:19:24,767 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:19:24,767 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:19:24,768 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:19:25,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:25,214 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43751 synced till here 43750
2014-07-09 15:19:25,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944361402 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944365200
2014-07-09 15:19:25,229 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:19:25,934 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:19:25,934 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files, but is 910.7m vs best flushable region's 213.6m. Choosing the bigger.
2014-07-09 15:19:25,934 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. due to global heap pressure
2014-07-09 15:19:25,934 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 910.7m
2014-07-09 15:19:26,325 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:19:26,325 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files, but is 730.5m vs best flushable region's 215.1m. Choosing the bigger.
2014-07-09 15:19:26,325 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. due to global heap pressure
2014-07-09 15:19:26,326 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 730.5m
2014-07-09 15:19:26,995 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:27,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944365200 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944366995
2014-07-09 15:19:27,075 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:19:27,445 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:19:29,644 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:19:30,911 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:30,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944366995 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944370911
2014-07-09 15:19:31,834 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:31,851 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:31,900 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:32,313 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:32,430 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:32,587 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:32,745 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:32,904 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:33,758 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:34,160 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:34,363 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:35,162 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:35,315 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:35,746 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:36,625 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:36,835 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:36,852 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:36,871 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:36,901 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:37,035 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:37,314 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:37,430 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:37,588 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:37,746 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:37,768 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:37,904 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:37,945 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:38,049 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:19:38,758 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:39,225 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5065ms
2014-07-09 15:19:39,363 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:40,163 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:40,315 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:40,746 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:41,625 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:41,835 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:41,852 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:41,871 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:41,901 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:42,035 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:42,314 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:42,431 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:42,588 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:42,746 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:42,768 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:19:42,905 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:42,945 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:43,050 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:19:43,759 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:44,261 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10101ms
2014-07-09 15:19:44,364 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:45,164 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:45,415 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10100ms
2014-07-09 15:19:45,747 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:46,626 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:46,836 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:46,852 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:46,871 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:46,901 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,036 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:19:47,314 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,431 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,588 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,746 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,768 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:19:47,905 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:47,945 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:48,050 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:19:48,759 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:49,262 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15101ms
2014-07-09 15:19:49,364 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:50,164 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-09 15:19:50,416 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15101ms
2014-07-09 15:19:50,747 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:51,621 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7469, memsize=732.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/68e4007c0c33452baa619be755cddd23
2014-07-09 15:19:51,626 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:19:51,632 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/68e4007c0c33452baa619be755cddd23 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/68e4007c0c33452baa619be755cddd23
2014-07-09 15:19:51,658 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/68e4007c0c33452baa619be755cddd23, entries=2665520, sequenceid=7469, filesize=189.7m
2014-07-09 15:19:51,658 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~732.1m/767648240, currentsize=20.0m/20922400 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 25332ms, sequenceid=7469, compaction requested=true
2014-07-09 15:19:51,659 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:19:51,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:19:51,659 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15034ms
2014-07-09 15:19:51,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:19:51,659 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:19:51,659 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:19:51,659 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15913ms
2014-07-09 15:19:51,660 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:19:51,659 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:19:51,660 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:19:51,660 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16345ms
2014-07-09 15:19:51,660 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:19:51,660 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:19:51,660 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16498ms
2014-07-09 15:19:51,661 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,661 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17298ms
2014-07-09 15:19:51,661 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,661 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17501ms
2014-07-09 15:19:51,661 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,664 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17906ms
2014-07-09 15:19:51,664 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,664 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13615ms
2014-07-09 15:19:51,664 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,665 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13721ms
2014-07-09 15:19:51,665 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,666 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18761ms
2014-07-09 15:19:51,666 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,666 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13898ms
2014-07-09 15:19:51,666 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,666 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18921ms
2014-07-09 15:19:51,667 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,667 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19080ms
2014-07-09 15:19:51,667 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,667 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19237ms
2014-07-09 15:19:51,667 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,668 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19354ms
2014-07-09 15:19:51,668 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,668 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14634ms
2014-07-09 15:19:51,668 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,668 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19768ms
2014-07-09 15:19:51,668 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,669 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14798ms
2014-07-09 15:19:51,669 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,670 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19818ms
2014-07-09 15:19:51,670 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,670 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19836ms
2014-07-09 15:19:51,670 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:19:51,995 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20483,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944371511,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:52,219 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944371685,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:52,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:52,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43997 synced till here 43984
2014-07-09 15:19:52,575 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944370911 with entries=90, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944392447
2014-07-09 15:19:53,250 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16219,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944377031,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:53,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:53,318 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20576,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944372741,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:53,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44079 synced till here 44072
2014-07-09 15:19:53,380 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944375159,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:53,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944392447 with entries=82, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944393288
2014-07-09 15:19:53,520 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15473,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944378046,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:53,520 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16652,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944376867,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:53,546 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21696,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944371849,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,107 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19949,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944374158,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,107 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944377765,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,248 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21821,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944372426,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20516,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944373756,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18528,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944375744,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944372584,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944372309,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,273 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17652,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944376621,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18961,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944375311,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,272 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944374359,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,273 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16331,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944377942,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,274 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21373,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944372900,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:19:54,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:54,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44172 synced till here 44166
2014-07-09 15:19:54,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944393288 with entries=93, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944394536
2014-07-09 15:19:56,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:19:56,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44253 synced till here 44249
2014-07-09 15:19:56,171 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944394536 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944396096
2014-07-09 15:19:58,380 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7469, memsize=912.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/aaeae62a56124ec1b485f5045e3eea75
2014-07-09 15:19:58,390 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/aaeae62a56124ec1b485f5045e3eea75 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/aaeae62a56124ec1b485f5045e3eea75
2014-07-09 15:19:58,461 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/aaeae62a56124ec1b485f5045e3eea75, entries=3321310, sequenceid=7469, filesize=236.3m
2014-07-09 15:19:58,463 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~912.2m/956511680, currentsize=82.3m/86258400 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 32529ms, sequenceid=7469, compaction requested=true
2014-07-09 15:19:58,463 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:19:58,463 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:19:58,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:19:58,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:19:58,464 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:19:58,464 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:20:01,336 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:01,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944396096 with entries=81, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944401336
2014-07-09 15:20:01,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944118698
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944134760
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944136104
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944137019
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944138324
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944144301
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944146078
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944150796
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944154298
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944159258
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944161271
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944166187
2014-07-09 15:20:01,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944168562
2014-07-09 15:20:01,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:20:01,451 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 242.9m
2014-07-09 15:20:01,838 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:20:03,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:04,408 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944401336 with entries=111, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944403286
2014-07-09 15:20:09,521 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:09,543 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44522 synced till here 44521
2014-07-09 15:20:09,557 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944403286 with entries=77, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944409522
2014-07-09 15:20:10,382 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7508, memsize=242.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/0f7e9767690046e3a32191a27235e860
2014-07-09 15:20:10,469 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/0f7e9767690046e3a32191a27235e860 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0f7e9767690046e3a32191a27235e860
2014-07-09 15:20:10,495 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0f7e9767690046e3a32191a27235e860, entries=884300, sequenceid=7508, filesize=62.9m
2014-07-09 15:20:10,495 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~242.9m/254655600, currentsize=11.4m/11991200 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9044ms, sequenceid=7508, compaction requested=true
2014-07-09 15:20:10,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:20:10,496 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-09 15:20:10,496 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 14 files from compaction candidates
2014-07-09 15:20:10,496 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:20:10,496 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:20:10,496 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:20:11,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:11,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44602 synced till here 44599
2014-07-09 15:20:11,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944409522 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944411423
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944172851
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944175054
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944177504
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944182668
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944184801
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944188904
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944191257
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944195660
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944198013
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944201318
2014-07-09 15:20:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944204114
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944207176
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944211071
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944213124
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944217251
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944219468
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944223023
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944225739
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944229251
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944232398
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944234695
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944238681
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944240935
2014-07-09 15:20:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944244307
2014-07-09 15:20:11,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:20:15,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:15,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944411423 with entries=81, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944415835
2014-07-09 15:20:15,860 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:20:17,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:17,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44761 synced till here 44760
2014-07-09 15:20:17,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944415835 with entries=78, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944417750
2014-07-09 15:20:17,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:20:22,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:22,694 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944417750 with entries=81, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944422506
2014-07-09 15:20:22,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:20:24,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:24,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44920 synced till here 44918
2014-07-09 15:20:24,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944422506 with entries=78, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944424561
2014-07-09 15:20:24,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 2 regions(s): aba5d255d2a2118b681bca61272578b4, 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:20:26,220 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90777ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:20:26,220 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 598.4m
2014-07-09 15:20:26,667 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:20:27,193 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90092ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:20:27,193 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 596.4m
2014-07-09 15:20:27,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:27,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944424561 with entries=78, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944427200
2014-07-09 15:20:27,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:20:27,685 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:20:30,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:30,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45077 synced till here 45076
2014-07-09 15:20:30,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944427200 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944430671
2014-07-09 15:20:30,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:20:32,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:32,823 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944430671 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944432783
2014-07-09 15:20:32,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:20:37,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:38,211 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,238 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,263 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,281 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,330 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,563 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,652 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:38,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944432783 with entries=96, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944437842
2014-07-09 15:20:38,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): aba5d255d2a2118b681bca61272578b4
2014-07-09 15:20:39,058 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:39,166 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:39,356 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:40,348 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:40,684 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:40,770 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:41,131 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:42,346 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:43,289 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-09 15:20:43,289 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5051ms
2014-07-09 15:20:43,289 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-09 15:20:43,290 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5027ms
2014-07-09 15:20:43,330 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:20:43,564 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:20:43,653 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:20:43,734 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:44,058 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:20:44,167 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:20:44,357 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:20:44,689 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:44,811 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:45,135 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:45,348 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:20:45,652 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:20:45,684 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:20:45,770 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:20:46,571 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5440ms
2014-07-09 15:20:47,346 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:20:48,289 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-09 15:20:48,290 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10052ms
2014-07-09 15:20:48,290 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10079ms
2014-07-09 15:20:48,291 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10028ms
2014-07-09 15:20:48,331 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:20:48,546 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7598, memsize=599.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/ff3c72fb64ed45059c9fd44d5696f9a9
2014-07-09 15:20:48,557 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/ff3c72fb64ed45059c9fd44d5696f9a9 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/ff3c72fb64ed45059c9fd44d5696f9a9
2014-07-09 15:20:48,565 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:20:48,565 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/ff3c72fb64ed45059c9fd44d5696f9a9, entries=2184160, sequenceid=7598, filesize=155.4m
2014-07-09 15:20:48,566 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~599.9m/629021040, currentsize=44.9m/47112800 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 22346ms, sequenceid=7598, compaction requested=true
2014-07-09 15:20:48,566 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:20:48,566 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:20:48,566 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-09 15:20:48,566 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 112085ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:20:48,566 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,566 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:20:48,567 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 643.3m
2014-07-09 15:20:48,566 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10236ms
2014-07-09 15:20:48,567 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,567 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:20:48,567 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10304ms
2014-07-09 15:20:48,567 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,567 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:20:48,567 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:20:48,567 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10356ms
2014-07-09 15:20:48,567 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,573 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10335ms
2014-07-09 15:20:48,573 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,576 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10295ms
2014-07-09 15:20:48,576 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,577 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6231ms
2014-07-09 15:20:48,577 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,578 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7448ms
2014-07-09 15:20:48,578 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,578 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7808ms
2014-07-09 15:20:48,578 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,578 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7895ms
2014-07-09 15:20:48,578 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,581 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2929ms
2014-07-09 15:20:48,581 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,581 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8233ms
2014-07-09 15:20:48,581 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,585 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3450ms
2014-07-09 15:20:48,585 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,590 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3778ms
2014-07-09 15:20:48,590 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,590 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3901ms
2014-07-09 15:20:48,590 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,591 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9234ms
2014-07-09 15:20:48,591 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,591 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9425ms
2014-07-09 15:20:48,591 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,594 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9536ms
2014-07-09 15:20:48,594 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,594 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4860ms
2014-07-09 15:20:48,594 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,595 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9943ms
2014-07-09 15:20:48,595 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:20:48,882 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:20:48,883 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944437768,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:48,928 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11025,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944437902,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:49,121 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7599, memsize=596.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/9739cc28317b431a87dec6a49b6d6362
2014-07-09 15:20:49,122 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:20:49,137 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/9739cc28317b431a87dec6a49b6d6362 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9739cc28317b431a87dec6a49b6d6362
2014-07-09 15:20:49,157 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9739cc28317b431a87dec6a49b6d6362, entries=2171650, sequenceid=7599, filesize=154.5m
2014-07-09 15:20:49,158 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~596.4m/625420400, currentsize=45.4m/47586880 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 21965ms, sequenceid=7599, compaction requested=true
2014-07-09 15:20:49,158 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:20:49,158 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:20:49,158 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 98084ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:20:49,158 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:20:49,158 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:20:49,159 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:20:49,159 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 602.8m
2014-07-09 15:20:49,159 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:20:49,161 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:20:49,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:49,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45337 synced till here 45330
2014-07-09 15:20:49,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944437842 with entries=85, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944449796
2014-07-09 15:20:49,888 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944438104,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,054 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11868,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944438185,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,200 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:20:50,335 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12006,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944438328,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,336 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11775,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944438561,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,491 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944439164,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,527 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:50,543 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45425 synced till here 45414
2014-07-09 15:20:50,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944449796 with entries=88, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944450527
2014-07-09 15:20:50,665 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12014,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944438650,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,735 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944440346,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,735 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944439354,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:50,735 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944439056,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:20:52,120 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:52,135 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45513 synced till here 45510
2014-07-09 15:20:52,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944450527 with entries=88, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944452120
2014-07-09 15:20:55,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:55,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944452120 with entries=79, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944455367
2014-07-09 15:20:59,177 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:20:59,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45670 synced till here 45669
2014-07-09 15:20:59,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944455367 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944459178
2014-07-09 15:21:18,425 WARN  [regionserver60020] util.Sleeper: We slept 19260ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:21:18,427 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18036,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460390,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,429 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17772ms
GC pool 'ParNew' had collection(s): count=1 time=696ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=17323ms
2014-07-09 15:21:18,430 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18032,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460398,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,431 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18071,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460360,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,431 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18033,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460398,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,432 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18030,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460401,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,434 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18032,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460401,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,435 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18039,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460396,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,436 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18049,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460387,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,436 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18036,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460400,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,436 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18035,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460401,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,436 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18036,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460400,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,441 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18047,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460393,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,440 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18040,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460400,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,441 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18051,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460390,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,442 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18050,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460391,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,442 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18045,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460397,"queuetimems":1,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,442 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18074,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:55483","starttimems":1404944460368,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-09 15:21:18,560 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18574,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944459986,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:21:18,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:18,875 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944459178 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944478846
2014-07-09 15:21:18,985 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944460359,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:21:23,097 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:23,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45827 synced till here 45826
2014-07-09 15:21:23,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944478846 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944483098
2014-07-09 15:21:24,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:25,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944483098 with entries=92, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944484665
2014-07-09 15:21:29,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:29,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45997 synced till here 45995
2014-07-09 15:21:29,718 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7648, memsize=604.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/ca222c477df44470bdacb98aa6abff3e
2014-07-09 15:21:29,729 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944484665 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944489680
2014-07-09 15:21:29,731 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/ca222c477df44470bdacb98aa6abff3e as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/ca222c477df44470bdacb98aa6abff3e
2014-07-09 15:21:29,741 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/ca222c477df44470bdacb98aa6abff3e, entries=2200490, sequenceid=7648, filesize=156.6m
2014-07-09 15:21:29,741 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~604.4m/633723280, currentsize=101.1m/106004320 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 40582ms, sequenceid=7648, compaction requested=true
2014-07-09 15:21:29,742 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:21:29,742 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:21:29,742 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:21:29,742 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:21:29,742 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:21:29,742 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:29,742 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:29,742 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:21:29,742 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:21:29,743 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:21:29,743 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 120099ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:29,743 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 619.4m
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:29,743 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:21:30,644 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:21:31,060 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7631, memsize=643.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/63c2cdad2bfd455ba712a760537b7ed2
2014-07-09 15:21:31,070 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/63c2cdad2bfd455ba712a760537b7ed2 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/63c2cdad2bfd455ba712a760537b7ed2
2014-07-09 15:21:31,086 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/63c2cdad2bfd455ba712a760537b7ed2, entries=2342380, sequenceid=7631, filesize=166.7m
2014-07-09 15:21:31,106 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~643.3m/674586160, currentsize=136.9m/143509920 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 42539ms, sequenceid=7631, compaction requested=true
2014-07-09 15:21:31,107 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:21:31,107 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:21:31,107 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 126340ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:21:31,107 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:21:31,107 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:31,107 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:31,107 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 654.2m
2014-07-09 15:21:31,107 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:21:31,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:31,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46076 synced till here 46075
2014-07-09 15:21:31,564 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944489680 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944491532
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944247176
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944263332
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944264050
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944265399
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944267023
2014-07-09 15:21:31,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944292888
2014-07-09 15:21:31,565 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944294234
2014-07-09 15:21:31,565 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944298491
2014-07-09 15:21:31,565 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944300129
2014-07-09 15:21:31,602 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:21:36,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:36,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46155 synced till here 46154
2014-07-09 15:21:36,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944491532 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944496460
2014-07-09 15:21:38,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:38,593 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46235 synced till here 46232
2014-07-09 15:21:38,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944496460 with entries=80, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944498567
2014-07-09 15:21:41,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:41,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944498567 with entries=79, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944501276
2014-07-09 15:21:45,559 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:45,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944501276 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944505560
2014-07-09 15:21:47,718 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:21:47,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:47,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944505560 with entries=78, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944507719
2014-07-09 15:21:48,029 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:21:52,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:53,659 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7712, memsize=620.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/c2c3e6421ff04830b8a19fa80a587602
2014-07-09 15:21:53,669 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/c2c3e6421ff04830b8a19fa80a587602 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c2c3e6421ff04830b8a19fa80a587602
2014-07-09 15:21:53,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944507719 with entries=111, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944512159
2014-07-09 15:21:54,314 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c2c3e6421ff04830b8a19fa80a587602, entries=2260810, sequenceid=7712, filesize=160.9m
2014-07-09 15:21:54,339 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~620.9m/651094560, currentsize=104.5m/109546320 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 24596ms, sequenceid=7712, compaction requested=true
2014-07-09 15:21:54,340 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:21:54,340 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:21:54,340 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:54,340 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:54,340 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:21:54,340 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 31 store files, 0 compacting, 31 eligible, 20 blocking
2014-07-09 15:21:54,341 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 31 files from compaction candidates
2014-07-09 15:21:54,341 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:54,341 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:54,341 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:21:55,518 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7719, memsize=654.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/a486fbf37db644c3a9a0aa035876a3a3
2014-07-09 15:21:55,527 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/a486fbf37db644c3a9a0aa035876a3a3 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a486fbf37db644c3a9a0aa035876a3a3
2014-07-09 15:21:55,534 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a486fbf37db644c3a9a0aa035876a3a3, entries=2381920, sequenceid=7719, filesize=169.5m
2014-07-09 15:21:55,548 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~654.2m/685973680, currentsize=100.9m/105767120 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 24441ms, sequenceid=7719, compaction requested=true
2014-07-09 15:21:55,549 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:21:55,549 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:21:55,549 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:21:55,549 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:21:55,549 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:21:55,549 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:21:56,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:21:56,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944512159 with entries=77, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944516319
2014-07-09 15:21:56,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944302601
2014-07-09 15:21:56,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944306701
2014-07-09 15:21:56,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944308852
2014-07-09 15:21:56,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944313149
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944314711
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944319395
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944322717
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944327992
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944330493
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944334115
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944336915
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944339140
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944343284
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944345321
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944348429
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944351373
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944353960
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944357790
2014-07-09 15:21:56,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944361402
2014-07-09 15:21:56,448 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:00,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:00,340 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:22:00,340 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:22:00,341 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:00,341 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:22:00,342 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:22:00,342 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:00,342 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:00,342 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:22:00,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944516319 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944520340
2014-07-09 15:22:00,372 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:02,482 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:02,499 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46814 synced till here 46813
2014-07-09 15:22:02,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944520340 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944522482
2014-07-09 15:22:02,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:06,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:06,872 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:22:06,872 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:22:06,872 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:06,872 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:22:06,872 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:22:06,872 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:06,872 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:06,872 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:22:06,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944522482 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944526872
2014-07-09 15:22:06,915 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:08,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:08,785 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46972 synced till here 46970
2014-07-09 15:22:08,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944526872 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944528756
2014-07-09 15:22:08,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:12,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:12,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944528756 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944532960
2014-07-09 15:22:12,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:14,934 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:14,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47129 synced till here 47128
2014-07-09 15:22:14,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944532960 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944534934
2014-07-09 15:22:14,960 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:17,631 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:17,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944534934 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944537631
2014-07-09 15:22:17,654 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:22:18,994 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90112ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:22:18,995 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 590.3m
2014-07-09 15:22:19,730 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:22:19,895 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90734ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:22:19,895 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 590.2m
2014-07-09 15:22:20,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:20,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47286 synced till here 47284
2014-07-09 15:22:20,447 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944537631 with entries=78, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944540394
2014-07-09 15:22:20,455 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:22:23,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:23,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944540394 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944543319
2014-07-09 15:22:27,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:27,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944543319 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944547614
2014-07-09 15:22:28,565 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:22:29,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:29,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944547614 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944549875
2014-07-09 15:22:30,296 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:22:32,498 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1469ms
GC pool 'ParNew' had collection(s): count=1 time=1494ms
2014-07-09 15:22:35,422 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:35,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47600 synced till here 47599
2014-07-09 15:22:35,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944549875 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944555422
2014-07-09 15:22:37,869 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:37,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47678 synced till here 47677
2014-07-09 15:22:37,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944555422 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944557869
2014-07-09 15:22:41,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:41,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944557869 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944561581
2014-07-09 15:22:42,785 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7850, memsize=590.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/8f8061df76324276b04e0ab3c797e8b8
2014-07-09 15:22:42,796 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/8f8061df76324276b04e0ab3c797e8b8 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8f8061df76324276b04e0ab3c797e8b8
2014-07-09 15:22:42,805 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8f8061df76324276b04e0ab3c797e8b8, entries=2149400, sequenceid=7850, filesize=153.0m
2014-07-09 15:22:42,812 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~590.3m/619009120, currentsize=98.2m/103012320 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 23817ms, sequenceid=7850, compaction requested=true
2014-07-09 15:22:42,813 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:22:42,813 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:42,813 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:42,814 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:22:42,813 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:22:42,815 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:22:42,815 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:22:42,815 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:22:42,815 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:42,815 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:42,815 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:42,815 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:22:43,487 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7851, memsize=591.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a1bd9b1daefb4437ba965c402dd278d2
2014-07-09 15:22:43,496 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a1bd9b1daefb4437ba965c402dd278d2 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a1bd9b1daefb4437ba965c402dd278d2
2014-07-09 15:22:43,504 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a1bd9b1daefb4437ba965c402dd278d2, entries=2154620, sequenceid=7851, filesize=153.4m
2014-07-09 15:22:43,520 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~591.8m/620512160, currentsize=95.8m/100480400 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 23625ms, sequenceid=7851, compaction requested=true
2014-07-09 15:22:43,520 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:43,520 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:22:43,520 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:22:43,520 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:22:43,521 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:43,521 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:22:44,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:44,247 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944561581 with entries=77, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944564187
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944365200
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944366995
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944370911
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944392447
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944393288
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944394536
2014-07-09 15:22:44,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944396096
2014-07-09 15:22:44,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:22:44,289 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 181.1m
2014-07-09 15:22:44,435 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:22:47,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:47,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944564187 with entries=79, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944567826
2014-07-09 15:22:50,119 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7898, memsize=181.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/18125a1b6d904111ba4966b0682878e9
2014-07-09 15:22:50,130 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/18125a1b6d904111ba4966b0682878e9 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/18125a1b6d904111ba4966b0682878e9
2014-07-09 15:22:50,138 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/18125a1b6d904111ba4966b0682878e9, entries=661430, sequenceid=7898, filesize=47.1m
2014-07-09 15:22:50,138 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~181.7m/190474080, currentsize=6.8m/7101520 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 5849ms, sequenceid=7898, compaction requested=true
2014-07-09 15:22:50,139 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:22:50,139 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-09 15:22:50,139 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-09 15:22:50,139 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:22:50,139 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:22:50,139 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:22:51,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:51,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47990 synced till here 47989
2014-07-09 15:22:51,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944567826 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944571054
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944401336
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944403286
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944409522
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944411423
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944415835
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944417750
2014-07-09 15:22:51,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944422506
2014-07-09 15:22:51,130 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:22:53,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:54,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944571054 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944573991
2014-07-09 15:22:54,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:22:57,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:57,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48146 synced till here 48145
2014-07-09 15:22:57,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944573991 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944577321
2014-07-09 15:22:57,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:22:59,647 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:22:59,666 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944577321 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944579647
2014-07-09 15:22:59,666 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:02,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:02,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944579647 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944582747
2014-07-09 15:23:02,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:05,803 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:06,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944582747 with entries=98, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944585803
2014-07-09 15:23:06,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:10,506 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:10,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944585803 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944590506
2014-07-09 15:23:10,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:13,314 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:13,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944590506 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944593315
2014-07-09 15:23:13,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:16,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:16,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944593315 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944596291
2014-07-09 15:23:16,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:23:17,777 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90059ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:23:17,778 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 634.2m
2014-07-09 15:23:18,279 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:23:18,291 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:23:18,292 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files, but is 630.6m vs best flushable region's 42.7m. Choosing the bigger.
2014-07-09 15:23:18,292 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. due to global heap pressure
2014-07-09 15:23:18,292 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 630.6m
2014-07-09 15:23:18,896 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:23:19,745 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:23:20,120 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:20,241 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944596291 with entries=78, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944600121
2014-07-09 15:23:21,387 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:23:22,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:22,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944600121 with entries=77, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944602930
2014-07-09 15:23:23,214 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:23,215 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:23,240 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:23,667 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:24,295 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:24,483 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:24,695 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:24,760 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:25,901 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:26,148 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:26,656 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:26,921 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:27,243 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:27,341 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:27,666 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:28,466 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5226ms
2014-07-09 15:23:28,466 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5252ms
2014-07-09 15:23:28,466 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5251ms
2014-07-09 15:23:28,479 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:28,667 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:28,697 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:28,784 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:29,160 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:29,233 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:23:29,295 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:29,483 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:29,695 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:29,761 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:30,901 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:31,363 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5215ms
2014-07-09 15:23:31,657 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:31,922 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:32,244 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:32,342 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:32,666 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:33,466 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10226ms
2014-07-09 15:23:33,466 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10251ms
2014-07-09 15:23:33,467 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10253ms
2014-07-09 15:23:33,479 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:33,668 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:23:33,697 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:33,784 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:23:34,161 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:34,234 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:23:34,296 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:23:34,484 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:23:34,695 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:23:34,761 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:35,902 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:36,364 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10216ms
2014-07-09 15:23:36,657 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:36,922 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:37,244 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:37,342 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:37,666 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:38,467 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15227ms
2014-07-09 15:23:38,467 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15252ms
2014-07-09 15:23:38,467 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15253ms
2014-07-09 15:23:38,480 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:38,668 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:23:38,697 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:38,785 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:23:39,161 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:39,234 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:23:39,296 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-09 15:23:39,459 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8007, memsize=634.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/bf6575b4a0b943149b664b2cfc44d1f7
2014-07-09 15:23:39,469 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/bf6575b4a0b943149b664b2cfc44d1f7 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf6575b4a0b943149b664b2cfc44d1f7
2014-07-09 15:23:39,478 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf6575b4a0b943149b664b2cfc44d1f7, entries=2309230, sequenceid=8007, filesize=164.4m
2014-07-09 15:23:39,478 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~634.2m/665039680, currentsize=24.7m/25930880 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 21700ms, sequenceid=8007, compaction requested=true
2014-07-09 15:23:39,479 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:23:39,479 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:23:39,480 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:23:39,480 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 99140ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:23:39,480 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:23:39,480 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15184ms
2014-07-09 15:23:39,480 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:23:39,480 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 611.0m
2014-07-09 15:23:39,480 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,480 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:23:39,481 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10248ms
2014-07-09 15:23:39,481 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,481 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10321ms
2014-07-09 15:23:39,481 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,485 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10701ms
2014-07-09 15:23:39,485 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,485 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10789ms
2014-07-09 15:23:39,485 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,486 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15819ms
2014-07-09 15:23:39,486 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,486 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11007ms
2014-07-09 15:23:39,486 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,487 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16272ms
2014-07-09 15:23:39,487 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,488 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16272ms
2014-07-09 15:23:39,488 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,493 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16253ms
2014-07-09 15:23:39,493 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,493 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11828ms
2014-07-09 15:23:39,493 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,494 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12153ms
2014-07-09 15:23:39,494 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,494 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12251ms
2014-07-09 15:23:39,494 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,494 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12573ms
2014-07-09 15:23:39,494 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,508 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12852ms
2014-07-09 15:23:39,508 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,509 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13361ms
2014-07-09 15:23:39,509 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,509 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13608ms
2014-07-09 15:23:39,509 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,509 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14749ms
2014-07-09 15:23:39,509 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,512 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14817ms
2014-07-09 15:23:39,512 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:39,517 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15035ms
2014-07-09 15:23:39,517 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:23:40,013 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:23:40,042 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944603008,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:40,202 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:40,203 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944603071,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:40,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48876 synced till here 48867
2014-07-09 15:23:40,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944602930 with entries=87, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944620202
2014-07-09 15:23:40,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944424561
2014-07-09 15:23:40,339 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8007, memsize=632.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/8f583897e5e944d196d02fa8ee260d14
2014-07-09 15:23:40,347 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/8f583897e5e944d196d02fa8ee260d14 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8f583897e5e944d196d02fa8ee260d14
2014-07-09 15:23:40,355 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8f583897e5e944d196d02fa8ee260d14, entries=2301990, sequenceid=8007, filesize=163.9m
2014-07-09 15:23:40,355 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~632.2m/662954960, currentsize=26.5m/27751040 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 22063ms, sequenceid=8007, compaction requested=true
2014-07-09 15:23:40,356 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:23:40,356 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:23:40,356 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93485ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:23:40,356 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:23:40,356 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:23:40,356 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:23:40,356 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 613.4m
2014-07-09 15:23:40,356 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:23:41,162 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944608782,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,162 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944608476,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,162 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944609158,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:41,206 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15309,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944605897,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,225 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48963 synced till here 48952
2014-07-09 15:23:41,272 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12577,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944608695,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,306 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944606917,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944620202 with entries=87, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944621205
2014-07-09 15:23:41,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944427200
2014-07-09 15:23:41,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944430671
2014-07-09 15:23:41,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944432783
2014-07-09 15:23:41,375 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944607241,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,375 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14722,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944606652,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,375 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18136,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944603238,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,376 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14039,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944607337,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,377 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944603665,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,378 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16689,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944604688,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,398 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:23:41,420 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944604293,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,422 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944609231,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,422 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13757,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944607664,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,422 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15277,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944606144,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,431 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944604757,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:41,446 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16966,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944604480,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:23:42,685 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:42,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49053 synced till here 49049
2014-07-09 15:23:42,761 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944621205 with entries=90, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944622685
2014-07-09 15:23:44,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:44,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49135 synced till here 49132
2014-07-09 15:23:44,092 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944622685 with entries=82, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944624000
2014-07-09 15:23:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.88 GB, free=80.93 MB, max=3.96 GB, blocks=62346, accesses=65829137, hits=64690543, hitRatio=98.27%, , cachingAccesses=65822273, cachingHits=64690541, cachingHitsRatio=98.28%, evictions=416, evicted=1068339, evictedPerRun=2568.12255859375
2014-07-09 15:23:49,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:50,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49240 synced till here 49237
2014-07-09 15:23:50,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944624000 with entries=105, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944629349
2014-07-09 15:23:52,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:52,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944629349 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944632192
2014-07-09 15:23:57,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:57,267 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49401 synced till here 49400
2014-07-09 15:23:57,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944632192 with entries=81, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944637232
2014-07-09 15:23:59,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:23:59,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49481 synced till here 49480
2014-07-09 15:23:59,311 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944637232 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944639279
2014-07-09 15:24:02,887 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8025, memsize=611.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/d4c193d361914d3f8af9778ec13bc4f0
2014-07-09 15:24:02,898 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/d4c193d361914d3f8af9778ec13bc4f0 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d4c193d361914d3f8af9778ec13bc4f0
2014-07-09 15:24:02,908 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d4c193d361914d3f8af9778ec13bc4f0, entries=2224750, sequenceid=8025, filesize=158.4m
2014-07-09 15:24:02,911 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~611.0m/640712000, currentsize=125.4m/131542480 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 23431ms, sequenceid=8025, compaction requested=true
2014-07-09 15:24:02,912 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:02,912 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:24:02,912 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 134883ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:24:02,912 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:24:02,912 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:02,912 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:02,912 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 149.1m
2014-07-09 15:24:02,912 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:24:02,978 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:24:04,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:04,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49562 synced till here 49560
2014-07-09 15:24:04,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944639279 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944644181
2014-07-09 15:24:04,323 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8045, memsize=615.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/28853f4a806046a697c970d61fb6f496
2014-07-09 15:24:04,333 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/28853f4a806046a697c970d61fb6f496 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/28853f4a806046a697c970d61fb6f496
2014-07-09 15:24:04,634 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/28853f4a806046a697c970d61fb6f496, entries=2239130, sequenceid=8045, filesize=159.4m
2014-07-09 15:24:04,635 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~615.0m/644851920, currentsize=102.9m/107934320 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 24279ms, sequenceid=8045, compaction requested=true
2014-07-09 15:24:04,636 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:24:04,636 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:04,636 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:24:04,637 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:24:04,637 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:04,637 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:04,638 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:04,638 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:24:04,638 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:24:04,638 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:04,638 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 32 store files, 0 compacting, 32 eligible, 20 blocking
2014-07-09 15:24:04,638 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 96073ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:24:04,639 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 32 files from compaction candidates
2014-07-09 15:24:04,639 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:04,639 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:04,639 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:24:04,639 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 615.9m
2014-07-09 15:24:05,281 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:24:05,898 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:05,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49640 synced till here 49639
2014-07-09 15:24:05,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944644181 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944645898
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944437842
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944449796
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944450527
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944452120
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944455367
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944459178
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944478846
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944483098
2014-07-09 15:24:05,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944484665
2014-07-09 15:24:06,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:07,935 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8104, memsize=149.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/3b64f5264df2402a8fa40e5757c87f67
2014-07-09 15:24:07,945 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/3b64f5264df2402a8fa40e5757c87f67 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3b64f5264df2402a8fa40e5757c87f67
2014-07-09 15:24:07,953 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3b64f5264df2402a8fa40e5757c87f67, entries=542920, sequenceid=8104, filesize=38.7m
2014-07-09 15:24:07,969 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~149.1m/156356160, currentsize=28.2m/29585280 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 5057ms, sequenceid=8104, compaction requested=true
2014-07-09 15:24:07,970 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:07,970 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:24:07,970 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:24:07,970 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:07,970 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:07,970 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:24:10,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:11,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944645898 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944650992
2014-07-09 15:24:11,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:13,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:13,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944650992 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944653390
2014-07-09 15:24:13,421 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:15,974 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:15,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944653390 with entries=78, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944655974
2014-07-09 15:24:16,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:20,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:20,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944655974 with entries=76, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944660343
2014-07-09 15:24:20,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:22,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:23,462 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944660343 with entries=95, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944662432
2014-07-09 15:24:23,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:26,853 INFO  [RpcServer.handler=44,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:24:26,929 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8109, memsize=615.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/146cab6d1e454ae8aaf01b7ee0de447c
2014-07-09 15:24:26,943 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/146cab6d1e454ae8aaf01b7ee0de447c as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/146cab6d1e454ae8aaf01b7ee0de447c
2014-07-09 15:24:26,950 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/146cab6d1e454ae8aaf01b7ee0de447c, entries=2242440, sequenceid=8109, filesize=159.6m
2014-07-09 15:24:26,973 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~615.9m/645805200, currentsize=90.0m/94415200 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 22334ms, sequenceid=8109, compaction requested=true
2014-07-09 15:24:26,974 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:26,974 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:24:26,974 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:24:26,974 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:26,974 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:26,974 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:24:28,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:28,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50122 synced till here 50121
2014-07-09 15:24:28,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944662432 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944668618
2014-07-09 15:24:28,654 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:29,003 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:24:29,003 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:24:29,003 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:29,003 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:24:29,003 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:24:29,004 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:29,004 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:29,004 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:24:30,451 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:30,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50200 synced till here 50199
2014-07-09 15:24:30,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944668618 with entries=78, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944670451
2014-07-09 15:24:30,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:35,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:35,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50280 synced till here 50279
2014-07-09 15:24:35,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944670451 with entries=80, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944675291
2014-07-09 15:24:35,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:35,380 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:24:35,380 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:24:35,381 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:35,381 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:24:35,381 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:24:35,381 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:35,381 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:35,381 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:24:37,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:37,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944675291 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944677328
2014-07-09 15:24:37,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:41,892 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:41,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944677328 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944681893
2014-07-09 15:24:41,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:42,325 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:24:42,326 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:24:42,326 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:24:42,327 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:24:42,327 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:24:42,327 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:24:42,327 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:24:42,328 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:24:43,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:43,837 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944681893 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944683818
2014-07-09 15:24:43,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:47,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:47,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944683818 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944687532
2014-07-09 15:24:47,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:49,814 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90069ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:24:49,815 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 591.4m
2014-07-09 15:24:50,892 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:50,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50673 synced till here 50672
2014-07-09 15:24:50,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944687532 with entries=78, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944690892
2014-07-09 15:24:50,936 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:50,967 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:24:51,615 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90227ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:24:51,615 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 596.8m
2014-07-09 15:24:52,161 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:24:53,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:53,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944690892 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944693281
2014-07-09 15:24:53,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:57,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:57,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944693281 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944697610
2014-07-09 15:24:57,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:24:59,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:24:59,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944697610 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944699932
2014-07-09 15:24:59,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:04,586 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:04,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50985 synced till here 50984
2014-07-09 15:25:04,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944699932 with entries=78, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944704586
2014-07-09 15:25:04,610 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:05,657 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:25:06,378 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:25:07,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:07,113 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51064 synced till here 51063
2014-07-09 15:25:07,126 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944704586 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944707098
2014-07-09 15:25:07,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:07,204 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:07,219 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:07,228 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:07,247 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:07,267 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:08,001 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:08,360 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:08,541 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:08,776 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:10,743 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:11,180 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:11,804 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:11,974 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:12,205 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:12,219 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:12,229 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:12,248 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:12,267 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:12,509 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:12,670 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8232, memsize=591.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/fec684da12284bb78bc7eb985c6c400f
2014-07-09 15:25:12,681 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/fec684da12284bb78bc7eb985c6c400f as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fec684da12284bb78bc7eb985c6c400f
2014-07-09 15:25:12,783 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fec684da12284bb78bc7eb985c6c400f, entries=2153340, sequenceid=8232, filesize=153.3m
2014-07-09 15:25:12,783 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~591.4m/620144640, currentsize=75.2m/78817920 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 22969ms, sequenceid=8232, compaction requested=true
2014-07-09 15:25:12,783 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:25:12,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:25:12,784 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 275ms
2014-07-09 15:25:12,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:25:12,784 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:25:12,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:12,784 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:25:12,784 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,784 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:25:12,784 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:12,784 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:25:12,784 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:25:12,784 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5517ms
2014-07-09 15:25:12,785 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:25:12,785 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5538ms
2014-07-09 15:25:12,785 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:25:12,785 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5557ms
2014-07-09 15:25:12,785 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:25:12,785 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:12,786 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:12,786 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:25:12,786 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5568ms
2014-07-09 15:25:12,786 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,786 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5582ms
2014-07-09 15:25:12,786 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,786 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 812ms
2014-07-09 15:25:12,786 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,786 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 982ms
2014-07-09 15:25:12,786 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,787 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1607ms
2014-07-09 15:25:12,787 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,787 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2044ms
2014-07-09 15:25:12,787 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,793 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4016ms
2014-07-09 15:25:12,793 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,793 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4252ms
2014-07-09 15:25:12,793 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,793 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4433ms
2014-07-09 15:25:12,793 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:12,793 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4792ms
2014-07-09 15:25:12,794 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:13,576 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8236, memsize=596.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/5585f20c9f4747c28568ee5dc68c2eea
2014-07-09 15:25:13,586 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/5585f20c9f4747c28568ee5dc68c2eea as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5585f20c9f4747c28568ee5dc68c2eea
2014-07-09 15:25:13,594 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5585f20c9f4747c28568ee5dc68c2eea, entries=2172860, sequenceid=8236, filesize=154.7m
2014-07-09 15:25:13,606 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~596.8m/625765360, currentsize=66.3m/69544560 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 21990ms, sequenceid=8236, compaction requested=true
2014-07-09 15:25:13,606 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:25:13,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:25:13,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:25:13,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:13,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:13,606 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:25:13,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:13,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51144 synced till here 51138
2014-07-09 15:25:13,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944707098 with entries=80, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944713905
2014-07-09 15:25:13,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:15,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:15,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51226 synced till here 51225
2014-07-09 15:25:15,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944713905 with entries=82, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944715357
2014-07-09 15:25:15,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:18,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:18,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944715357 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944718039
2014-07-09 15:25:18,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:22,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:22,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51383 synced till here 51382
2014-07-09 15:25:22,307 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944718039 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944722266
2014-07-09 15:25:22,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:24,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:24,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944722266 with entries=84, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944724557
2014-07-09 15:25:24,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:28,918 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:28,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944724557 with entries=77, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944728919
2014-07-09 15:25:28,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:30,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:30,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944728919 with entries=78, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944730932
2014-07-09 15:25:30,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=70, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:35,122 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:35,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944730932 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944735122
2014-07-09 15:25:35,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=71, maxlogs=32; forcing flush of 1 regions(s): 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:25:36,563 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:25:36,563 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files, but is 983.6m vs best flushable region's 203.1m. Choosing the bigger.
2014-07-09 15:25:36,563 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. due to global heap pressure
2014-07-09 15:25:36,564 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 983.6m
2014-07-09 15:25:36,719 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:25:36,719 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files, but is 534.0m vs best flushable region's 203.6m. Choosing the bigger.
2014-07-09 15:25:36,720 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. due to global heap pressure
2014-07-09 15:25:36,720 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 534.0m
2014-07-09 15:25:36,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:36,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944735122 with entries=78, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944736879
2014-07-09 15:25:37,542 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:25:37,764 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:25:41,308 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:41,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944736879 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944741308
2014-07-09 15:25:42,661 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:42,680 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:42,739 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:42,780 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:42,915 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:43,081 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:43,188 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:43,411 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:43,520 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:44,665 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:44,925 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:45,874 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:46,380 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:46,528 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:47,508 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:47,661 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:47,680 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:47,714 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:47,739 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:47,780 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:47,916 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:48,081 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:48,188 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:48,411 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:48,521 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:49,665 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:49,843 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:49,925 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:49,959 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:50,565 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:50,875 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:50,980 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:25:51,380 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:51,528 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:52,508 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:52,662 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:52,681 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:25:52,714 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:52,740 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:25:52,780 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:52,916 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:53,081 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-09 15:25:53,189 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:53,411 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:53,521 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:54,666 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:54,843 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:25:54,926 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-09 15:25:54,959 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:55,566 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:25:55,875 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-09 15:25:55,905 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8354, memsize=537.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/42b687d5ca39443db5d219fe1de51773
2014-07-09 15:25:55,915 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/42b687d5ca39443db5d219fe1de51773 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/42b687d5ca39443db5d219fe1de51773
2014-07-09 15:25:55,928 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/42b687d5ca39443db5d219fe1de51773, entries=1956120, sequenceid=8354, filesize=139.3m
2014-07-09 15:25:55,942 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~537.2m/563345760, currentsize=21.7m/22722400 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 19222ms, sequenceid=8354, compaction requested=true
2014-07-09 15:25:55,942 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:25:55,943 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:25:55,943 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10069ms
2014-07-09 15:25:55,943 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,943 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:25:55,943 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5378ms
2014-07-09 15:25:55,943 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,943 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:55,943 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5985ms
2014-07-09 15:25:55,943 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,943 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11019ms
2014-07-09 15:25:55,943 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,943 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6100ms
2014-07-09 15:25:55,943 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,944 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11279ms
2014-07-09 15:25:55,944 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,944 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12424ms
2014-07-09 15:25:55,944 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,944 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12534ms
2014-07-09 15:25:55,944 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,944 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12756ms
2014-07-09 15:25:55,944 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,945 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12864ms
2014-07-09 15:25:55,945 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,945 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13030ms
2014-07-09 15:25:55,945 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,945 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13166ms
2014-07-09 15:25:55,945 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,943 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:55,949 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:25:55,952 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13213ms
2014-07-09 15:25:55,952 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,953 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8239ms
2014-07-09 15:25:55,953 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,953 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13273ms
2014-07-09 15:25:55,953 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,954 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13292ms
2014-07-09 15:25:55,954 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,955 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8447ms
2014-07-09 15:25:55,955 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,956 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9427ms
2014-07-09 15:25:55,956 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,965 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9585ms
2014-07-09 15:25:55,965 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:55,965 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4985ms
2014-07-09 15:25:55,965 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:25:56,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:56,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51936 synced till here 51930
2014-07-09 15:25:56,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944741308 with entries=81, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944756279
2014-07-09 15:25:56,450 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14212,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944742237,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:56,478 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14067,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944742410,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:56,686 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14176,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944742510,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:57,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:57,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52024 synced till here 52014
2014-07-09 15:25:57,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944756279 with entries=88, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944757691
2014-07-09 15:25:57,881 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12008,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944745872,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,205 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10699,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944747505,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,206 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944742774,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,205 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944746526,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,206 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11827,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944746378,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,209 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13287,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944744922,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,256 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15343,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944742912,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,256 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944743184,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,304 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944747712,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,354 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944743514,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,355 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14948,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944743407,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,355 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15280,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944743075,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,356 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944744663,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:25:58,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:25:58,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944757691 with entries=87, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944758469
2014-07-09 15:25:58,592 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:25:58,593 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:25:58,594 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:25:58,594 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:25:58,594 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:25:58,594 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:25:58,594 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:25:58,594 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:25:59,476 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:25:59,476 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files, but is 577.9m vs best flushable region's 222.2m. Choosing the bigger.
2014-07-09 15:25:59,476 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. due to global heap pressure
2014-07-09 15:25:59,477 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 577.9m
2014-07-09 15:26:00,001 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:26:00,017 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:26:00,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:00,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52195 synced till here 52190
2014-07-09 15:26:00,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944758469 with entries=84, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944760205
2014-07-09 15:26:08,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:08,382 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52275 synced till here 52273
2014-07-09 15:26:08,402 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944760205 with entries=80, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944768379
2014-07-09 15:26:08,435 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,457 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,504 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,725 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,794 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:08,922 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,109 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,181 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,313 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,491 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,569 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,747 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,835 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:09,934 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:10,018 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:11,310 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:13,383 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:13,402 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:13,435 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:13,457 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:13,504 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:14,082 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5160ms
2014-07-09 15:26:14,082 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5288ms
2014-07-09 15:26:14,083 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5358ms
2014-07-09 15:26:14,110 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:14,182 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:14,314 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:14,491 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:14,570 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:14,747 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:14,836 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:14,917 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:14,934 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:26:15,019 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:26:15,209 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:26:15,432 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8354, memsize=985.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/2c0e2931c5854a0ea95762b39392e87e
2014-07-09 15:26:15,442 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/2c0e2931c5854a0ea95762b39392e87e as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2c0e2931c5854a0ea95762b39392e87e
2014-07-09 15:26:15,449 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2c0e2931c5854a0ea95762b39392e87e, entries=3586770, sequenceid=8354, filesize=255.3m
2014-07-09 15:26:15,457 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~985.1m/1032958960, currentsize=90.3m/94697280 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 38893ms, sequenceid=8354, compaction requested=true
2014-07-09 15:26:15,458 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:26:15,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:26:15,458 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 249ms
2014-07-09 15:26:15,458 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 106455ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:26:15,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:26:15,458 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,458 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 86.6m
2014-07-09 15:26:15,458 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5440ms
2014-07-09 15:26:15,458 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:15,458 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5524ms
2014-07-09 15:26:15,458 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,458 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:15,459 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:26:15,459 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 543ms
2014-07-09 15:26:15,459 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,459 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5624ms
2014-07-09 15:26:15,459 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,459 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5712ms
2014-07-09 15:26:15,459 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,459 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5890ms
2014-07-09 15:26:15,459 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,460 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5969ms
2014-07-09 15:26:15,460 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,461 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6148ms
2014-07-09 15:26:15,461 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,468 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6287ms
2014-07-09 15:26:15,468 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,469 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6360ms
2014-07-09 15:26:15,469 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,471 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6746ms
2014-07-09 15:26:15,471 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,471 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6677ms
2014-07-09 15:26:15,471 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,471 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6549ms
2014-07-09 15:26:15,471 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,477 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6974ms
2014-07-09 15:26:15,477 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,477 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7020ms
2014-07-09 15:26:15,477 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,477 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7042ms
2014-07-09 15:26:15,478 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,480 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7078ms
2014-07-09 15:26:15,480 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,481 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7098ms
2014-07-09 15:26:15,481 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,489 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4179ms
2014-07-09 15:26:15,489 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:26:15,518 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:26:16,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:16,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52353 synced till here 52349
2014-07-09 15:26:16,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944768379 with entries=78, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944776768
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944489680
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944491532
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944496460
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944498567
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944501276
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944505560
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944507719
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944512159
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944516319
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944520340
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944522482
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944526872
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944528756
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944532960
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944534934
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944537631
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944540394
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944543319
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944547614
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944549875
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944555422
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944557869
2014-07-09 15:26:16,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944561581
2014-07-09 15:26:16,964 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:26:17,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:18,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52442 synced till here 52435
2014-07-09 15:26:18,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944776768 with entries=89, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944777997
2014-07-09 15:26:18,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:26:19,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:19,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944777997 with entries=84, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944779529
2014-07-09 15:26:19,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:26:19,562 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8411, memsize=86.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/746cbd3cb1ea4c46bfbcbbd537222525
2014-07-09 15:26:19,572 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/746cbd3cb1ea4c46bfbcbbd537222525 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/746cbd3cb1ea4c46bfbcbbd537222525
2014-07-09 15:26:19,583 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/746cbd3cb1ea4c46bfbcbbd537222525, entries=315380, sequenceid=8411, filesize=22.5m
2014-07-09 15:26:19,584 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~86.6m/90826640, currentsize=42.5m/44575360 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 4126ms, sequenceid=8411, compaction requested=true
2014-07-09 15:26:19,585 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:26:19,585 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:26:19,585 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:26:19,585 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:26:19,585 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:26:19,585 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:19,585 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 33 store files, 0 compacting, 33 eligible, 20 blocking
2014-07-09 15:26:19,586 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 242.8m
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 33 files from compaction candidates
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:19,586 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:26:19,866 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:26:21,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:21,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944779529 with entries=79, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944781323
2014-07-09 15:26:23,247 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8398, memsize=577.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/7a896ae50a7149a8bc850b4040f067fa
2014-07-09 15:26:23,257 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/7a896ae50a7149a8bc850b4040f067fa as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7a896ae50a7149a8bc850b4040f067fa
2014-07-09 15:26:23,266 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7a896ae50a7149a8bc850b4040f067fa, entries=2104040, sequenceid=8398, filesize=149.8m
2014-07-09 15:26:23,267 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~577.9m/605946720, currentsize=80.5m/84416320 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 23790ms, sequenceid=8398, compaction requested=true
2014-07-09 15:26:23,267 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:26:23,267 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:26:23,267 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:26:23,267 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:23,267 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:23,267 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:26:27,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:27,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944781323 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944787072
2014-07-09 15:26:28,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:28,729 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944787072 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944788689
2014-07-09 15:26:28,751 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:26:28,752 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., flushing=true, writesEnabled=true
2014-07-09 15:26:28,765 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8419, memsize=243.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/47d2bb06ea704f79bf21a6fe2de516bf
2014-07-09 15:26:28,777 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/47d2bb06ea704f79bf21a6fe2de516bf as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/47d2bb06ea704f79bf21a6fe2de516bf
2014-07-09 15:26:28,787 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/47d2bb06ea704f79bf21a6fe2de516bf, entries=885760, sequenceid=8419, filesize=63.1m
2014-07-09 15:26:28,787 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~243.3m/255074480, currentsize=13.1m/13733600 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 9201ms, sequenceid=8419, compaction requested=true
2014-07-09 15:26:28,788 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:26:28,788 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-09 15:26:28,788 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-09 15:26:28,788 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:26:28,788 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:28,788 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:26:33,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:33,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944788689 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944793484
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944564187
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944567826
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944571054
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944573991
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944577321
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944579647
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944582747
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944585803
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944590506
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944593315
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944596291
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944600121
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944602930
2014-07-09 15:26:33,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944620202
2014-07-09 15:26:33,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:35,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:35,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52918 synced till here 52917
2014-07-09 15:26:35,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944793484 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944795306
2014-07-09 15:26:35,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:35,974 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90317ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:26:35,974 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 591.9m
2014-07-09 15:26:36,467 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:26:37,125 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90747ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:26:37,125 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 587.6m
2014-07-09 15:26:38,036 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:26:40,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:40,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52997 synced till here 52996
2014-07-09 15:26:40,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944795306 with entries=79, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944800275
2014-07-09 15:26:40,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:42,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:43,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944800275 with entries=80, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944802905
2014-07-09 15:26:43,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:47,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:47,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944802905 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944807373
2014-07-09 15:26:47,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:50,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:50,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944807373 with entries=77, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944810104
2014-07-09 15:26:50,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:50,738 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:26:52,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:52,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944810104 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944812936
2014-07-09 15:26:52,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:57,908 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:26:57,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53389 synced till here 53387
2014-07-09 15:26:57,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944812936 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944817908
2014-07-09 15:26:57,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:26:59,454 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8487, memsize=593.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7b4b53f7a764473be2834e024a254c1
2014-07-09 15:26:59,466 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d7b4b53f7a764473be2834e024a254c1 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7b4b53f7a764473be2834e024a254c1
2014-07-09 15:26:59,478 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7b4b53f7a764473be2834e024a254c1, entries=2160740, sequenceid=8487, filesize=153.8m
2014-07-09 15:26:59,514 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~593.4m/622276160, currentsize=80.7m/84586080 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 23540ms, sequenceid=8487, compaction requested=true
2014-07-09 15:26:59,515 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:26:59,515 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:26:59,515 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:26:59,515 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:26:59,516 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:26:59,516 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:26:59,516 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:26:59,516 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:27:00,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:00,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944817908 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944820036
2014-07-09 15:27:00,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:00,169 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8488, memsize=587.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/6d661e525ba64eab82eebb69ae69e147
2014-07-09 15:27:00,178 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/6d661e525ba64eab82eebb69ae69e147 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/6d661e525ba64eab82eebb69ae69e147
2014-07-09 15:27:00,189 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/6d661e525ba64eab82eebb69ae69e147, entries=2139600, sequenceid=8488, filesize=152.3m
2014-07-09 15:27:00,189 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~587.6m/616186560, currentsize=86.8m/91040240 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 23064ms, sequenceid=8488, compaction requested=true
2014-07-09 15:27:00,190 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:00,190 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:27:00,190 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:27:00,190 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:00,190 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:00,190 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:27:04,859 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:04,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53545 synced till here 53544
2014-07-09 15:27:04,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944820036 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944824860
2014-07-09 15:27:04,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:07,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:07,057 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:27:07,057 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:27:07,058 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:07,058 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:27:07,058 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:27:07,058 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:07,058 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:07,058 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:27:07,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944824860 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944827057
2014-07-09 15:27:07,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:10,669 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:10,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944827057 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944830669
2014-07-09 15:27:10,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:13,228 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:27:13,228 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:27:13,229 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:13,229 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:27:13,229 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:27:13,229 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:13,229 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:13,229 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:27:14,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:14,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944830669 with entries=83, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944834105
2014-07-09 15:27:14,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:17,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:17,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944834105 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944837071
2014-07-09 15:27:17,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:21,109 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:21,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944837071 with entries=76, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944841109
2014-07-09 15:27:21,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:23,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:23,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944841109 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944843960
2014-07-09 15:27:23,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:28,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:28,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944843960 with entries=78, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944848199
2014-07-09 15:27:28,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:29,127 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90535ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:27:29,128 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 598.5m
2014-07-09 15:27:29,622 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:27:30,028 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90011ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:27:30,028 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 595.6m
2014-07-09 15:27:30,800 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:27:30,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:30,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54174 synced till here 54173
2014-07-09 15:27:30,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944848199 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944850806
2014-07-09 15:27:30,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:34,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:34,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944850806 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944854233
2014-07-09 15:27:34,258 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:37,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:37,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54331 synced till here 54330
2014-07-09 15:27:37,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944854233 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944857259
2014-07-09 15:27:37,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:40,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:40,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944857259 with entries=78, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944860481
2014-07-09 15:27:40,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:41,528 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:41,541 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:41,658 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:41,883 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:42,668 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:42,762 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:42,924 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:43,807 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:44,147 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:44,513 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:44,614 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:44,898 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:44,980 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:45,456 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:45,706 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:46,107 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:46,836 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5178ms
2014-07-09 15:27:46,837 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5296ms
2014-07-09 15:27:46,837 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5309ms
2014-07-09 15:27:46,883 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:47,015 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:47,270 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:47,478 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:47,668 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:27:47,762 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:47,847 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:27:47,925 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:27:48,807 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:27:49,148 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:27:49,800 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5185ms
2014-07-09 15:27:49,838 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5325ms
2014-07-09 15:27:49,899 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:49,981 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:50,457 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:50,706 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:27:51,108 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:27:51,384 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8618, memsize=598.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/af16ecb87beb4253af11e41c5c744e85
2014-07-09 15:27:51,394 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/af16ecb87beb4253af11e41c5c744e85 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/af16ecb87beb4253af11e41c5c744e85
2014-07-09 15:27:51,402 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/af16ecb87beb4253af11e41c5c744e85, entries=2178980, sequenceid=8618, filesize=155.1m
2014-07-09 15:27:51,408 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~598.5m/627529520, currentsize=53.0m/55548160 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 22279ms, sequenceid=8618, compaction requested=true
2014-07-09 15:27:51,408 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:51,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:27:51,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5301ms
2014-07-09 15:27:51,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:27:51,408 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:51,408 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5702ms
2014-07-09 15:27:51,409 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,408 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:51,409 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:27:51,409 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5953ms
2014-07-09 15:27:51,409 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,414 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6434ms
2014-07-09 15:27:51,414 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,414 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6516ms
2014-07-09 15:27:51,414 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,414 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6901ms
2014-07-09 15:27:51,414 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,414 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6800ms
2014-07-09 15:27:51,415 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,415 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7268ms
2014-07-09 15:27:51,415 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,417 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7611ms
2014-07-09 15:27:51,417 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,417 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8493ms
2014-07-09 15:27:51,417 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,417 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3570ms
2014-07-09 15:27:51,417 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,417 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8655ms
2014-07-09 15:27:51,418 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,425 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8758ms
2014-07-09 15:27:51,425 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,425 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3948ms
2014-07-09 15:27:51,425 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,425 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4155ms
2014-07-09 15:27:51,425 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,426 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4411ms
2014-07-09 15:27:51,426 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,426 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9543ms
2014-07-09 15:27:51,426 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,431 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9903ms
2014-07-09 15:27:51,431 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,432 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9890ms
2014-07-09 15:27:51,432 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,434 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9775ms
2014-07-09 15:27:51,434 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:27:51,709 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944861053,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:52,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:52,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54497 synced till here 54487
2014-07-09 15:27:52,653 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:27:52,653 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:27:52,654 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:52,654 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11288,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944861365,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:52,654 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:27:52,654 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:27:52,654 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:52,654 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:52,654 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:27:52,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944860481 with entries=88, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944872570
2014-07-09 15:27:52,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:52,883 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8621, memsize=595.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/74c2830e285c48d29fb7420af60f9696
2014-07-09 15:27:52,895 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/74c2830e285c48d29fb7420af60f9696 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/74c2830e285c48d29fb7420af60f9696
2014-07-09 15:27:52,903 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/74c2830e285c48d29fb7420af60f9696, entries=2168560, sequenceid=8621, filesize=154.4m
2014-07-09 15:27:52,904 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~595.6m/624527760, currentsize=74.7m/78299280 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 22875ms, sequenceid=8621, compaction requested=true
2014-07-09 15:27:52,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:27:52,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:27:52,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:52,904 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:52,904 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:27:52,904 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:53,017 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:27:53,017 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:27:53,018 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:27:53,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:27:53,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:27:53,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:27:53,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:27:53,018 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:27:53,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:27:53,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54588 synced till here 54570
2014-07-09 15:27:53,493 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11825,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944861655,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:53,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944872570 with entries=91, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944873294
2014-07-09 15:27:53,528 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=70, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:27:53,589 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10925,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944862663,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:53,682 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10761,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944862920,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:53,682 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944862759,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:53,682 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944861881,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:27:55,126 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:17,088 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 27253ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:28:17,088 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 27253ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:28:17,089 WARN  [regionserver60020] util.Sleeper: We slept 22535ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:28:17,090 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21125ms
GC pool 'ParNew' had collection(s): count=1 time=1389ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=20229ms
2014-07-09 15:28:17,095 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54708 synced till here 54706
2014-07-09 15:28:17,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944873294 with entries=120, filesize=92.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944875126
2014-07-09 15:28:17,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=71, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:17,370 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944874837,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,477 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944874950,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,477 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22577,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944874900,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,603 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875010,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,682 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875091,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,725 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22586,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875138,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,786 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22569,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875216,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,791 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22493,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875297,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,807 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22460,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875346,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:17,878 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404944875407,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:28:21,591 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90853ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:28:21,592 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 522.0m
2014-07-09 15:28:22,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:22,148 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54790 synced till here 54789
2014-07-09 15:28:22,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944875126 with entries=82, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944902117
2014-07-09 15:28:22,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=72, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:22,266 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:28:23,355 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:23,708 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944902117 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944903355
2014-07-09 15:28:23,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=73, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:24,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:25,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944903355 with entries=78, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944904916
2014-07-09 15:28:25,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=74, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:30,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:30,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55024 synced till here 55023
2014-07-09 15:28:30,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944904916 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944910152
2014-07-09 15:28:30,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=75, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:31,925 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:31,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944910152 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944911925
2014-07-09 15:28:31,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=76, maxlogs=32; forcing flush of 1 regions(s): 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:28:32,058 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-09 15:28:32,058 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files, but is 1.0g vs best flushable region's 134.1m. Choosing the bigger.
2014-07-09 15:28:32,058 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. due to global heap pressure
2014-07-09 15:28:32,058 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 1.0g
2014-07-09 15:28:32,904 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:28:36,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:36,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944911925 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944916651
2014-07-09 15:28:38,023 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,031 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,051 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,057 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,060 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,195 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,519 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:38,937 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:40,414 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8691, memsize=522.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/c5e62a29a925476d8d2722e5ae93fbf1
2014-07-09 15:28:40,425 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/c5e62a29a925476d8d2722e5ae93fbf1 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c5e62a29a925476d8d2722e5ae93fbf1
2014-07-09 15:28:40,433 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c5e62a29a925476d8d2722e5ae93fbf1, entries=1900480, sequenceid=8691, filesize=135.3m
2014-07-09 15:28:40,436 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~522.0m/547323600, currentsize=80.5m/84418960 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 18844ms, sequenceid=8691, compaction requested=true
2014-07-09 15:28:40,437 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:28:40,437 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:28:40,437 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1501ms
2014-07-09 15:28:40,437 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:28:40,437 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:28:40,437 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:28:40,437 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:28:40,437 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93380ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:28:40,437 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,438 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 537.7m
2014-07-09 15:28:40,438 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1919ms
2014-07-09 15:28:40,438 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,438 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2244ms
2014-07-09 15:28:40,438 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,438 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2378ms
2014-07-09 15:28:40,438 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,439 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2382ms
2014-07-09 15:28:40,439 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,439 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2388ms
2014-07-09 15:28:40,439 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,442 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2411ms
2014-07-09 15:28:40,442 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,442 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2419ms
2014-07-09 15:28:40,442 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:28:40,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:40,619 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55264 synced till here 55261
2014-07-09 15:28:40,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944916651 with entries=81, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944920574
2014-07-09 15:28:40,867 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:28:43,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:43,171 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944920574 with entries=80, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944923143
2014-07-09 15:28:45,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:45,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55423 synced till here 55422
2014-07-09 15:28:45,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944923143 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944925185
2014-07-09 15:28:46,082 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.9 GB, free=56.06 MB, max=3.96 GB, blocks=62691, accesses=78703388, hits=77338454, hitRatio=98.26%, , cachingAccesses=78696546, cachingHits=77338473, cachingHitsRatio=98.27%, evictions=504, evicted=1294327, evictedPerRun=2568.109130859375
2014-07-09 15:28:50,599 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:50,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55514 synced till here 55512
2014-07-09 15:28:51,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944925185 with entries=91, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944930599
2014-07-09 15:28:53,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:28:53,864 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:28:53,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944930599 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944933864
2014-07-09 15:28:55,407 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,423 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,424 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,454 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,455 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,749 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:55,989 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:56,231 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:58,617 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:58,989 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:59,250 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:59,755 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:28:59,900 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:00,123 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:00,209 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:00,328 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:00,959 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5168ms
2014-07-09 15:29:00,959 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5505ms
2014-07-09 15:29:00,960 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5504ms
2014-07-09 15:29:00,960 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5553ms
2014-07-09 15:29:00,960 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5537ms
2014-07-09 15:29:00,960 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5537ms
2014-07-09 15:29:00,990 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-09 15:29:01,218 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:01,232 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-09 15:29:01,596 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:01,816 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:01,916 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:02,348 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8745, memsize=537.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/d60be0a9b3fa469dac33073d252570cc
2014-07-09 15:29:02,358 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/d60be0a9b3fa469dac33073d252570cc as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d60be0a9b3fa469dac33073d252570cc
2014-07-09 15:29:02,365 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d60be0a9b3fa469dac33073d252570cc, entries=1957920, sequenceid=8745, filesize=139.4m
2014-07-09 15:29:02,366 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~537.7m/563864560, currentsize=63.9m/67047440 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 21928ms, sequenceid=8745, compaction requested=true
2014-07-09 15:29:02,366 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:02,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:29:02,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:29:02,367 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 109139ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:29:02,367 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 451ms
2014-07-09 15:29:02,367 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:02,367 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 576.7m
2014-07-09 15:29:02,367 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,367 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:02,367 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:29:02,368 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 552ms
2014-07-09 15:29:02,368 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,368 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 772ms
2014-07-09 15:29:02,368 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,369 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6137ms
2014-07-09 15:29:02,369 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,370 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1152ms
2014-07-09 15:29:02,370 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,371 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6381ms
2014-07-09 15:29:02,371 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,372 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6948ms
2014-07-09 15:29:02,372 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,382 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6958ms
2014-07-09 15:29:02,382 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,382 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6975ms
2014-07-09 15:29:02,382 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,383 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6927ms
2014-07-09 15:29:02,383 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,389 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6935ms
2014-07-09 15:29:02,389 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,389 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6640ms
2014-07-09 15:29:02,389 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,390 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-09 15:29:02,390 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,393 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2183ms
2014-07-09 15:29:02,393 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,393 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2270ms
2014-07-09 15:29:02,393 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,396 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2496ms
2014-07-09 15:29:02,396 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,401 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2646ms
2014-07-09 15:29:02,401 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,402 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3153ms
2014-07-09 15:29:02,402 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,403 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3414ms
2014-07-09 15:29:02,403 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,405 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3787ms
2014-07-09 15:29:02,405 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:02,845 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:29:02,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:02,886 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:29:03,578 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55676 synced till here 55667
2014-07-09 15:29:03,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944933864 with entries=85, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944942874
2014-07-09 15:29:04,393 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:04,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55764 synced till here 55751
2014-07-09 15:29:04,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944942874 with entries=88, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944944393
2014-07-09 15:29:06,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:06,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944944393 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944946965
2014-07-09 15:29:09,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:09,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944946965 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944949611
2014-07-09 15:29:12,186 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:12,271 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:12,836 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:12,940 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:13,207 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:13,905 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:29:14,173 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8728, memsize=1.0g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/5deb9b38aed84dd680a561897e1ce6c2
2014-07-09 15:29:14,198 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/5deb9b38aed84dd680a561897e1ce6c2 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5deb9b38aed84dd680a561897e1ce6c2
2014-07-09 15:29:14,206 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5deb9b38aed84dd680a561897e1ce6c2, entries=3856490, sequenceid=8728, filesize=274.5m
2014-07-09 15:29:14,236 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1110639120, currentsize=150.9m/158184240 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 42178ms, sequenceid=8728, compaction requested=true
2014-07-09 15:29:14,236 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:14,236 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:29:14,236 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 332ms
2014-07-09 15:29:14,236 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:29:14,236 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,237 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:29:14,237 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1030ms
2014-07-09 15:29:14,237 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:14,237 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:29:14,237 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,237 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:29:14,237 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1297ms
2014-07-09 15:29:14,237 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:14,237 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,237 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:29:14,237 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1401ms
2014-07-09 15:29:14,238 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,237 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:14,238 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:29:14,238 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2035ms
2014-07-09 15:29:14,238 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,239 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2054ms
2014-07-09 15:29:14,239 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:29:14,451 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:14,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944949611 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944954451
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944621205
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944622685
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944624000
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944629349
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944632192
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944637232
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944639279
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944644181
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944645898
2014-07-09 15:29:14,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944650992
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944653390
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944655974
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944660343
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944662432
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944668618
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944670451
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944675291
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944677328
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944681893
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944683818
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944687532
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944690892
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944693281
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944697610
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944699932
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944704586
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944707098
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944713905
2014-07-09 15:29:14,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944715357
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944718039
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944722266
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944724557
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944728919
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944730932
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944735122
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944736879
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944741308
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944756279
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944757691
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944758469
2014-07-09 15:29:14,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944760205
2014-07-09 15:29:16,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:16,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944954451 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944956583
2014-07-09 15:29:20,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:20,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56164 synced till here 56163
2014-07-09 15:29:20,438 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944956583 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944960416
2014-07-09 15:29:23,547 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90530ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:29:23,547 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 563.7m
2014-07-09 15:29:23,999 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:29:24,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:24,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944960416 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944964593
2014-07-09 15:29:25,081 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:29:25,709 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8783, memsize=576.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c6f6d0fc881f413e9154e19bbe0de7e1
2014-07-09 15:29:25,720 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/c6f6d0fc881f413e9154e19bbe0de7e1 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c6f6d0fc881f413e9154e19bbe0de7e1
2014-07-09 15:29:26,208 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c6f6d0fc881f413e9154e19bbe0de7e1, entries=2099850, sequenceid=8783, filesize=149.5m
2014-07-09 15:29:26,227 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~576.7m/604739600, currentsize=116.3m/121950560 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 23860ms, sequenceid=8783, compaction requested=true
2014-07-09 15:29:26,228 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:26,228 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:29:26,228 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93575ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:29:26,228 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:29:26,228 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:26,228 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:26,228 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 571.9m
2014-07-09 15:29:26,228 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:29:26,740 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:29:27,203 DEBUG [RS_OPEN_META-slave1:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2014-07-09 15:29:27,207 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 12949
2014-07-09 15:29:27,246 INFO  [RS_OPEN_META-slave1:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404941362613.meta with entries=29, filesize=12.4k; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944967205.meta
2014-07-09 15:29:28,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:28,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56322 synced till here 56321
2014-07-09 15:29:28,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944964593 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944968205
2014-07-09 15:29:28,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944768379
2014-07-09 15:29:28,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944776768
2014-07-09 15:29:28,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944777997
2014-07-09 15:29:28,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:31,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:31,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944968205 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944971446
2014-07-09 15:29:31,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:34,892 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:35,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944971446 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944974892
2014-07-09 15:29:35,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:37,203 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 10205
2014-07-09 15:29:37,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:37,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56558 synced till here 56557
2014-07-09 15:29:37,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944974892 with entries=80, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944977453
2014-07-09 15:29:37,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:39,806 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:29:41,304 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:41,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944977453 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944981304
2014-07-09 15:29:41,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:44,059 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:44,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56717 synced till here 56716
2014-07-09 15:29:44,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944981304 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944984060
2014-07-09 15:29:44,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:29:44,445 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8851, memsize=563.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/65c75ae746c745268f84090007c18129
2014-07-09 15:29:44,456 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/65c75ae746c745268f84090007c18129 as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/65c75ae746c745268f84090007c18129
2014-07-09 15:29:44,464 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/65c75ae746c745268f84090007c18129, entries=2052300, sequenceid=8851, filesize=146.1m
2014-07-09 15:29:44,465 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~563.7m/591046160, currentsize=86.1m/90262080 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 20918ms, sequenceid=8851, compaction requested=true
2014-07-09 15:29:44,465 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:29:44,466 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:29:44,466 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:29:44,466 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 218.8m
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:44,466 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:29:44,628 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:29:45,195 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:29:47,204 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 8652
2014-07-09 15:29:47,438 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8857, memsize=571.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0624a799b6e342eda4ed22202a24154b
2014-07-09 15:29:47,447 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/0624a799b6e342eda4ed22202a24154b as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0624a799b6e342eda4ed22202a24154b
2014-07-09 15:29:47,456 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0624a799b6e342eda4ed22202a24154b, entries=2082290, sequenceid=8857, filesize=148.3m
2014-07-09 15:29:47,471 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~571.9m/599683840, currentsize=86.9m/91077520 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 21243ms, sequenceid=8857, compaction requested=true
2014-07-09 15:29:47,471 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:47,471 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:29:47,471 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:29:47,471 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:29:47,471 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:29:47,471 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:29:47,472 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 23.3k
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:47,472 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:29:47,473 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:29:47,493 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2760, memsize=16.1k, hasBloomFilter=false, into tmp file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/42f24efe7ce44c6297fdb152220bfaad
2014-07-09 15:29:47,499 INFO  [MemStoreFlusher.1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for 42f24efe7ce44c6297fdb152220bfaad
2014-07-09 15:29:47,501 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/42f24efe7ce44c6297fdb152220bfaad as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/42f24efe7ce44c6297fdb152220bfaad
2014-07-09 15:29:47,509 INFO  [MemStoreFlusher.1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for 42f24efe7ce44c6297fdb152220bfaad
2014-07-09 15:29:47,509 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/42f24efe7ce44c6297fdb152220bfaad, entries=68, sequenceid=2760, filesize=8.6k
2014-07-09 15:29:47,509 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~23.3k/23816, currentsize=0.0/0 for region hbase:meta,,1.1588230740 in 37ms, sequenceid=2760, compaction requested=false
2014-07-09 15:29:47,509 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:29:47,509 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:47,510 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:29:47,510 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:29:47,510 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:29:47,510 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:47,510 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:29:48,001 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:48,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56796 synced till here 56794
2014-07-09 15:29:48,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944984060 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944988001
2014-07-09 15:29:50,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:50,864 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944988001 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944990847
2014-07-09 15:29:51,928 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8888, memsize=218.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/7ecd084bc67e4c2a8ef24e3f0cd62691
2014-07-09 15:29:51,942 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/7ecd084bc67e4c2a8ef24e3f0cd62691 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/7ecd084bc67e4c2a8ef24e3f0cd62691
2014-07-09 15:29:51,951 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/7ecd084bc67e4c2a8ef24e3f0cd62691, entries=796780, sequenceid=8888, filesize=56.7m
2014-07-09 15:29:51,956 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~218.8m/229451120, currentsize=9.1m/9589520 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 7490ms, sequenceid=8888, compaction requested=true
2014-07-09 15:29:51,957 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:29:51,957 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-09 15:29:51,957 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-09 15:29:51,957 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:29:51,957 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:29:51,958 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:29:53,677 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:53,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56952 synced till here 56951
2014-07-09 15:29:53,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944990847 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944993678
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944779529
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944781323
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944787072
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944788689
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944793484
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944795306
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944800275
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944802905
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944807373
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944810104
2014-07-09 15:29:53,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944812936
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944817908
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944820036
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944824860
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944827057
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944830669
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944834105
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944837071
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944841109
2014-07-09 15:29:53,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944843960
2014-07-09 15:29:53,803 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:29:56,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:29:57,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57036 synced till here 57035
2014-07-09 15:29:57,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944993678 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944996883
2014-07-09 15:29:57,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:00,211 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:30:00,212 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:30:00,212 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:30:00,212 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:30:00,212 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:30:00,212 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:30:00,212 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:30:00,213 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:30:01,822 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:01,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944996883 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945001822
2014-07-09 15:30:01,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:04,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:04,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57193 synced till here 57192
2014-07-09 15:30:04,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945001822 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945004868
2014-07-09 15:30:04,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:08,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:08,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945004868 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945008153
2014-07-09 15:30:08,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:11,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:11,462 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57352 synced till here 57351
2014-07-09 15:30:11,470 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945008153 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945011449
2014-07-09 15:30:11,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:14,591 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:14,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945011449 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945014591
2014-07-09 15:30:14,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:17,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:17,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945014591 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945017561
2014-07-09 15:30:17,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:20,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:20,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945017561 with entries=78, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945020474
2014-07-09 15:30:20,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 2 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39, e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:23,911 INFO  [RpcServer.handler=42,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:30:23,911 INFO  [RpcServer.handler=31,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:30:24,069 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90205ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:30:24,070 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 611.2m
2014-07-09 15:30:24,517 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:30:24,961 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:25,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945020474 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945024962
2014-07-09 15:30:25,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:26,554 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:30:26,554 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:30:26,555 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:30:26,555 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:30:26,555 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:30:26,555 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:30:26,555 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:30:26,555 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:30:28,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:28,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945024962 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945028039
2014-07-09 15:30:28,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:28,344 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:30:28,344 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:30:28,345 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:30:28,345 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:30:28,345 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:30:28,345 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:30:28,345 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:30:28,345 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:30:31,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:31,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945028039 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945031311
2014-07-09 15:30:31,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:30:33,286 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90441ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:30:33,286 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 640.2m
2014-07-09 15:30:33,807 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:30:34,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:34,631 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57904 synced till here 57903
2014-07-09 15:30:34,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945031311 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945034603
2014-07-09 15:30:38,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:38,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945034603 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945038368
2014-07-09 15:30:42,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:42,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945038368 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945042037
2014-07-09 15:30:42,561 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:42,821 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:42,976 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:43,367 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:44,162 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:44,322 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:44,553 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:44,716 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:45,356 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:45,449 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:45,968 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:46,063 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:30:46,334 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9012, memsize=611.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/e77e37a5cce34f31a511f0e9ce0e2d15
2014-07-09 15:30:46,345 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/e77e37a5cce34f31a511f0e9ce0e2d15 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/e77e37a5cce34f31a511f0e9ce0e2d15
2014-07-09 15:30:46,614 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/e77e37a5cce34f31a511f0e9ce0e2d15, entries=2225240, sequenceid=9012, filesize=158.4m
2014-07-09 15:30:46,632 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~611.2m/640852160, currentsize=72.9m/76429520 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 22561ms, sequenceid=9012, compaction requested=true
2014-07-09 15:30:46,633 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:30:46,633 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:30:46,633 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 570ms
2014-07-09 15:30:46,633 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,633 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:30:46,633 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 665ms
2014-07-09 15:30:46,633 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,633 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:30:46,634 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1185ms
2014-07-09 15:30:46,634 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,634 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:30:46,634 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1278ms
2014-07-09 15:30:46,634 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,634 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:30:46,634 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1918ms
2014-07-09 15:30:46,634 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,634 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2081ms
2014-07-09 15:30:46,635 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,635 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2313ms
2014-07-09 15:30:46,635 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,635 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2473ms
2014-07-09 15:30:46,635 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,635 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3268ms
2014-07-09 15:30:46,635 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,635 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3659ms
2014-07-09 15:30:46,635 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,636 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3815ms
2014-07-09 15:30:46,636 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:46,639 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4077ms
2014-07-09 15:30:46,639 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:30:48,042 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:48,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58138 synced till here 58132
2014-07-09 15:30:48,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945042037 with entries=80, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945048042
2014-07-09 15:30:50,044 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:50,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58220 synced till here 58219
2014-07-09 15:30:50,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945048042 with entries=82, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945050045
2014-07-09 15:30:52,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:53,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58297 synced till here 58296
2014-07-09 15:30:53,018 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945050045 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945052996
2014-07-09 15:30:55,637 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90556ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:30:55,638 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 616.9m
2014-07-09 15:30:56,133 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:30:57,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:30:57,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58377 synced till here 58376
2014-07-09 15:30:57,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945052996 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945057041
2014-07-09 15:30:57,343 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9035, memsize=641.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a58fcbde017f42f4a0871c3ea161b62e
2014-07-09 15:30:57,353 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a58fcbde017f42f4a0871c3ea161b62e as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a58fcbde017f42f4a0871c3ea161b62e
2014-07-09 15:30:57,365 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a58fcbde017f42f4a0871c3ea161b62e, entries=2336620, sequenceid=9035, filesize=166.3m
2014-07-09 15:30:57,365 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~641.8m/672928000, currentsize=86.7m/90913040 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 24079ms, sequenceid=9035, compaction requested=true
2014-07-09 15:30:57,366 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:30:57,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:30:57,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:30:57,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:30:57,366 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:30:57,366 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:31:00,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:00,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945057041 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945060242
2014-07-09 15:31:00,272 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944848199
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944850806
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944854233
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944857259
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944860481
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944872570
2014-07-09 15:31:00,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944873294
2014-07-09 15:31:03,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:03,341 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945060242 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945063323
2014-07-09 15:31:07,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:07,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945063323 with entries=76, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945067608
2014-07-09 15:31:10,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:10,111 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945067608 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945070087
2014-07-09 15:31:10,208 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90402ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:31:10,209 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 617.3m
2014-07-09 15:31:10,718 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:31:13,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:13,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945070087 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945073601
2014-07-09 15:31:16,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:16,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945073601 with entries=77, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945076691
2014-07-09 15:31:18,981 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9090, memsize=618.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/28325c5fbc0c4712b5bf47f175d83fc8
2014-07-09 15:31:18,990 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/28325c5fbc0c4712b5bf47f175d83fc8 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/28325c5fbc0c4712b5bf47f175d83fc8
2014-07-09 15:31:19,220 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/28325c5fbc0c4712b5bf47f175d83fc8, entries=2252030, sequenceid=9090, filesize=160.3m
2014-07-09 15:31:19,248 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~618.5m/648564400, currentsize=93.0m/97479840 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 23610ms, sequenceid=9090, compaction requested=true
2014-07-09 15:31:19,249 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:31:19,249 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:31:19,249 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 94054ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:31:19,249 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:31:19,249 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:19,249 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:19,249 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:31:19,249 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 629.1m
2014-07-09 15:31:20,051 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:31:20,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:20,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945076691 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945080823
2014-07-09 15:31:20,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944875126
2014-07-09 15:31:20,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944902117
2014-07-09 15:31:20,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944903355
2014-07-09 15:31:20,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944904916
2014-07-09 15:31:20,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944910152
2014-07-09 15:31:24,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:24,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945080823 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945084374
2014-07-09 15:31:27,171 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:27,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945084374 with entries=77, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945087171
2014-07-09 15:31:30,101 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:31:30,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:31,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59154 synced till here 59153
2014-07-09 15:31:31,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945087171 with entries=78, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945090982
2014-07-09 15:31:32,177 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9126, memsize=617.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/55f61023515e47beaa73a0e5801563d2
2014-07-09 15:31:32,190 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/55f61023515e47beaa73a0e5801563d2 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/55f61023515e47beaa73a0e5801563d2
2014-07-09 15:31:32,198 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/55f61023515e47beaa73a0e5801563d2, entries=2247450, sequenceid=9126, filesize=160.0m
2014-07-09 15:31:32,199 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~617.3m/647247680, currentsize=82.2m/86221680 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 21989ms, sequenceid=9126, compaction requested=true
2014-07-09 15:31:32,199 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:31:32,199 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:31:32,199 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 91988ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:31:32,199 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:31:32,199 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:32,199 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:32,199 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 615.5m
2014-07-09 15:31:32,199 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:31:32,715 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:31:33,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:33,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945090982 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945093789
2014-07-09 15:31:33,806 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944911925
2014-07-09 15:31:37,348 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:37,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945093789 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945097348
2014-07-09 15:31:39,931 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:31:40,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:40,528 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59389 synced till here 59388
2014-07-09 15:31:40,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945097348 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945100486
2014-07-09 15:31:41,877 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9151, memsize=629.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/82b92dfa731f41bfbbeef151c1d0f8c7
2014-07-09 15:31:41,891 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/82b92dfa731f41bfbbeef151c1d0f8c7 as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/82b92dfa731f41bfbbeef151c1d0f8c7
2014-07-09 15:31:41,903 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/82b92dfa731f41bfbbeef151c1d0f8c7, entries=2290420, sequenceid=9151, filesize=163.0m
2014-07-09 15:31:41,916 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~629.1m/659623600, currentsize=89.8m/94113120 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 22667ms, sequenceid=9151, compaction requested=true
2014-07-09 15:31:41,917 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:31:41,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 38 store files, 0 compacting, 38 eligible, 20 blocking
2014-07-09 15:31:41,917 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. has too many store files; delaying flush up to 90000ms
2014-07-09 15:31:41,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 38 files from compaction candidates
2014-07-09 15:31:41,917 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:31:41,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:41,917 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. has too many store files; delaying flush up to 90000ms
2014-07-09 15:31:41,917 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:41,917 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:31:41,917 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:41,918 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:31:44,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:44,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945100486 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945104711
2014-07-09 15:31:44,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944916651
2014-07-09 15:31:44,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944920574
2014-07-09 15:31:44,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944923143
2014-07-09 15:31:44,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944925185
2014-07-09 15:31:44,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944930599
2014-07-09 15:31:48,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:48,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945104711 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945108603
2014-07-09 15:31:52,169 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:52,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59624 synced till here 59623
2014-07-09 15:31:52,193 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945108603 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945112169
2014-07-09 15:31:54,029 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9180, memsize=615.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/431e83224a7b45e29fc34f9154f0e08c
2014-07-09 15:31:54,041 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/431e83224a7b45e29fc34f9154f0e08c as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/431e83224a7b45e29fc34f9154f0e08c
2014-07-09 15:31:54,048 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/431e83224a7b45e29fc34f9154f0e08c, entries=2240990, sequenceid=9180, filesize=159.6m
2014-07-09 15:31:54,049 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~615.5m/645389120, currentsize=88.3m/92542720 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 21850ms, sequenceid=9180, compaction requested=true
2014-07-09 15:31:54,049 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:31:54,049 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:31:54,049 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:31:54,049 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:31:54,049 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:31:54,049 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:31:54,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:54,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945112169 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945114873
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944933864
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944942874
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944944393
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944946965
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944949611
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944954451
2014-07-09 15:31:54,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944956583
2014-07-09 15:31:54,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:31:56,584 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90030ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:31:56,584 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 604.7m
2014-07-09 15:31:57,209 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:31:58,143 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:31:58,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945114873 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945118143
2014-07-09 15:31:58,436 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90092ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:31:58,436 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 604.0m
2014-07-09 15:31:59,242 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:32:00,875 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:32:00,918 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:00,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945118143 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945120918
2014-07-09 15:32:04,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:04,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945120918 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945124865
2014-07-09 15:32:07,309 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:07,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945124865 with entries=77, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945127309
2014-07-09 15:32:11,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:11,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945127309 with entries=77, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945131110
2014-07-09 15:32:14,120 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:14,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60169 synced till here 60168
2014-07-09 15:32:14,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945131110 with entries=79, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945134120
2014-07-09 15:32:14,210 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:32:17,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:17,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945134120 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945137781
2014-07-09 15:32:18,732 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9242, memsize=606.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d51592b207684475949a95cc530a1c1f
2014-07-09 15:32:18,747 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/d51592b207684475949a95cc530a1c1f as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d51592b207684475949a95cc530a1c1f
2014-07-09 15:32:18,763 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d51592b207684475949a95cc530a1c1f, entries=2207550, sequenceid=9242, filesize=157.2m
2014-07-09 15:32:18,763 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~606.3m/635756240, currentsize=90.1m/94465120 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 22179ms, sequenceid=9242, compaction requested=true
2014-07-09 15:32:18,764 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:18,764 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:32:18,764 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. has too many store files; delaying flush up to 90000ms
2014-07-09 15:32:18,764 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:32:18,764 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:32:18,764 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:18,764 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. has too many store files; delaying flush up to 90000ms
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:18,765 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:32:18,765 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-09 15:32:18,766 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-09 15:32:18,766 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:18,766 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:18,766 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:32:20,929 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9247, memsize=604.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/90bf4fc1eb074d99ac31f7cb264a0fc3
2014-07-09 15:32:20,939 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/90bf4fc1eb074d99ac31f7cb264a0fc3 as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/90bf4fc1eb074d99ac31f7cb264a0fc3
2014-07-09 15:32:20,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:21,284 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/90bf4fc1eb074d99ac31f7cb264a0fc3, entries=2199210, sequenceid=9247, filesize=156.6m
2014-07-09 15:32:21,315 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~604.0m/633355280, currentsize=93.4m/97957440 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 22879ms, sequenceid=9247, compaction requested=true
2014-07-09 15:32:21,316 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:32:21,316 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:32:21,316 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:21,316 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:21,316 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:32:21,316 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:21,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60334 synced till here 60333
2014-07-09 15:32:22,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945137781 with entries=87, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945140994
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944960416
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944964593
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944968205
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944971446
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944974892
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944977453
2014-07-09 15:32:22,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944981304
2014-07-09 15:32:22,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): ab8fe21463419a7329d4993471fedc73
2014-07-09 15:32:22,763 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 188.1m
2014-07-09 15:32:22,940 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:32:23,482 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:32:23,482 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. has too many store files; delaying flush up to 90000ms
2014-07-09 15:32:23,483 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:23,483 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 38 store files, 0 compacting, 38 eligible, 20 blocking
2014-07-09 15:32:23,483 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 38 files from compaction candidates
2014-07-09 15:32:23,483 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:23,484 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:23,484 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:32:24,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:24,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945140994 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945144830
2014-07-09 15:32:28,821 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9291, memsize=188.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/cccfdf625122409ea076c91ec5b2e474
2014-07-09 15:32:28,831 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/cccfdf625122409ea076c91ec5b2e474 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/cccfdf625122409ea076c91ec5b2e474
2014-07-09 15:32:28,844 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/cccfdf625122409ea076c91ec5b2e474, entries=685000, sequenceid=9291, filesize=48.8m
2014-07-09 15:32:28,864 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~188.1m/197262560, currentsize=7.4m/7772720 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 6101ms, sequenceid=9291, compaction requested=true
2014-07-09 15:32:28,865 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:28,865 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-09 15:32:28,865 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 18 files from compaction candidates
2014-07-09 15:32:28,865 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-09 15:32:28,865 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:28,865 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:32:29,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:29,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945144830 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945149127
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944984060
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944988001
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944990847
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944993678
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404944996883
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945001822
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945004868
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945008153
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945011449
2014-07-09 15:32:29,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945014591
2014-07-09 15:32:29,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945017561
2014-07-09 15:32:29,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:31,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:31,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60568 synced till here 60567
2014-07-09 15:32:31,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945149127 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945151943
2014-07-09 15:32:31,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:36,003 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:36,029 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945151943 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945156004
2014-07-09 15:32:36,029 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:36,329 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:32:36,330 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. has too many store files; delaying flush up to 90000ms
2014-07-09 15:32:36,330 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:36,330 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:32:36,330 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:32:36,330 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:36,330 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:36,330 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:32:39,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:39,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945156004 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945159555
2014-07-09 15:32:39,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:42,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:42,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945159555 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945162805
2014-07-09 15:32:42,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:45,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:45,326 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945162805 with entries=77, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945165306
2014-07-09 15:32:45,326 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:48,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:48,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945165306 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945168532
2014-07-09 15:32:48,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:51,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:51,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945168532 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945171849
2014-07-09 15:32:51,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:55,105 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:55,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945171849 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945175105
2014-07-09 15:32:55,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:58,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:32:58,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945175105 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945178460
2014-07-09 15:32:58,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:32:59,492 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:32:59,492 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. has too many store files; delaying flush up to 90000ms
2014-07-09 15:32:59,493 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:32:59,493 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:32:59,493 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:32:59,493 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:32:59,493 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:32:59,493 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:33:00,292 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90191ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:33:00,292 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 619.6m
2014-07-09 15:33:00,605 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:33:00,605 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. has too many store files; delaying flush up to 90000ms
2014-07-09 15:33:00,606 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:33:00,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:33:00,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:33:00,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:33:00,606 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:33:00,607 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:33:00,806 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:33:01,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:01,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945178460 with entries=78, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945181325
2014-07-09 15:33:04,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:04,579 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945181325 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945184562
2014-07-09 15:33:07,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:07,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945184562 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945187400
2014-07-09 15:33:10,646 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90715ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:33:10,647 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 621.5m
2014-07-09 15:33:11,237 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:33:11,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:11,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945187400 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945191817
2014-07-09 15:33:15,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:15,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945191817 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945195443
2014-07-09 15:33:19,780 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:19,789 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:19,942 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,162 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,489 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,632 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,725 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,914 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:20,995 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:21,364 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:21,842 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:51,499 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.87 GB, free=87.53 MB, max=3.96 GB, blocks=62145, accesses=92383563, hits=90780304, hitRatio=98.26%, , cachingAccesses=92376699, cachingHits=90780302, cachingHitsRatio=98.27%, evictions=597, evicted=1533168, evictedPerRun=2568.12060546875
2014-07-09 15:33:51,500 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 33394ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:33:51,500 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 33395ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:33:51,501 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 29659ms
2014-07-09 15:33:51,501 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30506ms
2014-07-09 15:33:51,501 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30869ms
2014-07-09 15:33:51,502 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30138ms
2014-07-09 15:33:51,503 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31013ms
2014-07-09 15:33:51,503 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30778ms
2014-07-09 15:33:51,503 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30589ms
2014-07-09 15:33:51,505 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29224ms
GC pool 'ParNew' had collection(s): count=1 time=1084ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=28308ms
2014-07-09 15:33:51,505 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31342ms
2014-07-09 15:33:51,505 WARN  [regionserver60020] util.Sleeper: We slept 32378ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-09 15:33:51,506 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31725ms
2014-07-09 15:33:51,506 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31717ms
2014-07-09 15:33:51,508 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31564ms
2014-07-09 15:33:51,541 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:51,610 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:51,830 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:51,977 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:52,139 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:52,276 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1404941325989: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-09 15:33:52,534 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9412, memsize=619.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/6bfe403e5f074c64b6599c233773d6ce
2014-07-09 15:33:52,544 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/6bfe403e5f074c64b6599c233773d6ce as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6bfe403e5f074c64b6599c233773d6ce
2014-07-09 15:33:52,552 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6bfe403e5f074c64b6599c233773d6ce, entries=2255980, sequenceid=9412, filesize=160.7m
2014-07-09 15:33:52,561 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~619.6m/649703760, currentsize=72.9m/76413360 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 52269ms, sequenceid=9412, compaction requested=true
2014-07-09 15:33:52,561 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:33:52,561 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 38 store files, 0 compacting, 38 eligible, 20 blocking
2014-07-09 15:33:52,562 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 285ms
2014-07-09 15:33:52,562 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 38 files from compaction candidates
2014-07-09 15:33:52,562 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 98352ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:33:52,562 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:33:52,562 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,562 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:33:52,562 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 423ms
2014-07-09 15:33:52,562 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,562 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 512.5m
2014-07-09 15:33:52,562 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 585ms
2014-07-09 15:33:52,562 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,562 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:33:52,563 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 733ms
2014-07-09 15:33:52,563 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,563 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 953ms
2014-07-09 15:33:52,563 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,563 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1022ms
2014-07-09 15:33:52,564 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,564 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32622ms
2014-07-09 15:33:52,564 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,564 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32775ms
2014-07-09 15:33:52,564 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,564 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32784ms
2014-07-09 15:33:52,564 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,564 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32402ms
2014-07-09 15:33:52,564 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,564 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31650ms
2014-07-09 15:33:52,565 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,565 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31840ms
2014-07-09 15:33:52,565 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,567 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32078ms
2014-07-09 15:33:52,568 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,568 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31204ms
2014-07-09 15:33:52,568 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,571 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31939ms
2014-07-09 15:33:52,572 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,578 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31583ms
2014-07-09 15:33:52,578 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,579 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30737ms
2014-07-09 15:33:52,579 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1404941325989
2014-07-09 15:33:52,641 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:52,696 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61678 synced till here 61663
2014-07-09 15:33:52,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945195443 with entries=94, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945232641
2014-07-09 15:33:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945020474
2014-07-09 15:33:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945024962
2014-07-09 15:33:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945028039
2014-07-09 15:33:53,031 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:33:53,824 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945199158,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:54,102 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945199314,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:54,257 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:54,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61764 synced till here 61757
2014-07-09 15:33:54,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945232641 with entries=86, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945234257
2014-07-09 15:33:54,972 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200487,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,036 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200160,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,037 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34043,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200993,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,037 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":33198,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945201839,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,051 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":33688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945201362,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,051 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200912,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,052 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34329,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200723,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,072 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":35132,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945199939,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:55,072 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34441,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:55483","starttimems":1404945200630,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-09 15:33:56,414 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:56,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61850 synced till here 61849
2014-07-09 15:33:56,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945234257 with entries=86, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945236415
2014-07-09 15:33:58,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:33:58,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945236415 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945238850
2014-07-09 15:34:02,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:02,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62008 synced till here 62006
2014-07-09 15:34:02,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945238850 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945242365
2014-07-09 15:34:03,081 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9436, memsize=621.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a59e6098efcb4ae98eb7ffea10b096cf
2014-07-09 15:34:03,090 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/a59e6098efcb4ae98eb7ffea10b096cf as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a59e6098efcb4ae98eb7ffea10b096cf
2014-07-09 15:34:03,098 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a59e6098efcb4ae98eb7ffea10b096cf, entries=2262850, sequenceid=9436, filesize=161.2m
2014-07-09 15:34:03,220 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~621.5m/651682240, currentsize=93.3m/97877040 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 52573ms, sequenceid=9436, compaction requested=true
2014-07-09 15:34:03,221 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:03,221 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:34:03,221 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 122346ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:03,221 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:34:03,221 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:34:03,221 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:34:03,221 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 632.4m
2014-07-09 15:34:03,221 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:34:03,786 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:05,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:05,114 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62088 synced till here 62087
2014-07-09 15:34:05,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945242365 with entries=80, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945245099
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945031311
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945034603
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945038368
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945042037
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945048042
2014-07-09 15:34:05,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945050045
2014-07-09 15:34:08,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:08,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62167 synced till here 62166
2014-07-09 15:34:08,165 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945245099 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945248139
2014-07-09 15:34:10,993 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9457, memsize=512.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/bd853451573e49238354b4150264ed83
2014-07-09 15:34:11,005 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/bd853451573e49238354b4150264ed83 as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/bd853451573e49238354b4150264ed83
2014-07-09 15:34:11,017 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/bd853451573e49238354b4150264ed83, entries=1866020, sequenceid=9457, filesize=133.0m
2014-07-09 15:34:11,017 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~512.5m/537398400, currentsize=96.4m/101085600 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 18455ms, sequenceid=9457, compaction requested=true
2014-07-09 15:34:11,017 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:11,017 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 36 store files, 0 compacting, 36 eligible, 20 blocking
2014-07-09 15:34:11,017 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 94688ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:11,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 36 files from compaction candidates
2014-07-09 15:34:11,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:34:11,018 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:34:11,018 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 525.2m
2014-07-09 15:34:11,018 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:34:11,486 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:11,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:11,868 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945248139 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945251841
2014-07-09 15:34:14,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:14,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945251841 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945254645
2014-07-09 15:34:19,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:19,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945254645 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945259760
2014-07-09 15:34:21,741 INFO  [regionserver60020] regionserver.HRegionServer: Closing user regions
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.: disabling compactions & flushes
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.: disabling compactions & flushes
2014-07-09 15:34:21,757 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Running close preflush of usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:34:21,757 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Running close preflush of usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 109.4m
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:21,757 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 209.7m
2014-07-09 15:34:21,758 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.: disabling compactions & flushes
2014-07-09 15:34:21,758 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: waiting for 0 compactions & cache flush to complete for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:21,848 DEBUG [RS_CLOSE_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:22,017 DEBUG [RS_CLOSE_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:22,030 INFO  [RS_CLOSE_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-09 15:34:22,030 INFO  [RS_CLOSE_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-09 15:34:22,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:22,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945259760 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945262604
2014-07-09 15:34:24,761 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: ab8fe21463419a7329d4993471fedc73 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,762 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region ab8fe21463419a7329d4993471fedc73 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,762 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: fa2ab9ffb0b5a85ad4c1c3400a6b6d39 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,762 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region fa2ab9ffb0b5a85ad4c1c3400a6b6d39 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,762 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 035ce5d09f7bc593b2c68d83d9f7e1cf ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,762 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 035ce5d09f7bc593b2c68d83d9f7e1cf was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,762 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 967e1d7e4e4a9cd6ca99d66bdf70a02a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,763 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 967e1d7e4e4a9cd6ca99d66bdf70a02a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,763 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,763 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,763 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e5ee55a21ff19d69490518939b0887e0 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,763 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e5ee55a21ff19d69490518939b0887e0 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,763 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0e294e1cc84fff4243a9d24c11e9bc8d ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,763 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0e294e1cc84fff4243a9d24c11e9bc8d was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,763 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e20ad9e2278dfb99d0d4ac9b665b26ed ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,763 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e20ad9e2278dfb99d0d4ac9b665b26ed was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,764 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,764 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,764 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,764 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,764 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:24,764 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:24,765 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on ab8fe21463419a7329d4993471fedc73, fa2ab9ffb0b5a85ad4c1c3400a6b6d39, 035ce5d09f7bc593b2c68d83d9f7e1cf, 967e1d7e4e4a9cd6ca99d66bdf70a02a, 369c8092e5553636aa4ff097e825820a, e5ee55a21ff19d69490518939b0887e0, 0e294e1cc84fff4243a9d24c11e9bc8d, e20ad9e2278dfb99d0d4ac9b665b26ed, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:25,191 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9498, memsize=632.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/450a0b1f371d435aba2711169317e4ec
2014-07-09 15:34:25,201 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/450a0b1f371d435aba2711169317e4ec as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/450a0b1f371d435aba2711169317e4ec
2014-07-09 15:34:25,208 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/450a0b1f371d435aba2711169317e4ec, entries=2302560, sequenceid=9498, filesize=164.1m
2014-07-09 15:34:25,223 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~632.4m/663118880, currentsize=89.1m/93436240 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 22002ms, sequenceid=9498, compaction requested=true
2014-07-09 15:34:25,224 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:25,224 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:34:25,225 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 121743ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:25,225 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:34:25,225 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:34:25,225 DEBUG [regionserver60020-smallCompactions-1404941363881] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:34:25,225 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 629.6m
2014-07-09 15:34:25,225 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:34:25,570 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9526, memsize=109.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/5a1ea8c39737400faaecf227579ccf7f
2014-07-09 15:34:25,579 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/5a1ea8c39737400faaecf227579ccf7f as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5a1ea8c39737400faaecf227579ccf7f
2014-07-09 15:34:25,587 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5a1ea8c39737400faaecf227579ccf7f, entries=398420, sequenceid=9526, filesize=28.4m
2014-07-09 15:34:25,587 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~109.4m/114735360, currentsize=5.4m/5650480 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 3830ms, sequenceid=9526, compaction requested=true
2014-07-09 15:34:25,587 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:34:25,587 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73., current region memstore size 5.4m
2014-07-09 15:34:25,590 DEBUG [RS_CLOSE_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:25,753 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9539, memsize=5.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/6c4dc7f3e6704cb3bdd5b8b999ae9992
2014-07-09 15:34:25,762 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/.tmp/6c4dc7f3e6704cb3bdd5b8b999ae9992 as hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6c4dc7f3e6704cb3bdd5b8b999ae9992
2014-07-09 15:34:25,769 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6c4dc7f3e6704cb3bdd5b8b999ae9992, entries=19620, sequenceid=9539, filesize=1.4m
2014-07-09 15:34:25,770 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~5.4m/5650480, currentsize=0.0/0 for region usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. in 183ms, sequenceid=9539, compaction requested=true
2014-07-09 15:34:25,780 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:26,166 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:34:26,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945262604 with entries=83, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945266166
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945052996
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945057041
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945060242
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945063323
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945067608
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945070087
2014-07-09 15:34:26,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989/slave1%2C60020%2C1404941325989.1404945073601
2014-07-09 15:34:26,215 INFO  [StoreCloserThread-usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.-1] regionserver.HStore: Closed family
2014-07-09 15:34:26,215 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:34:26,215 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:34:26,215 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:34:26,215 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.: disabling compactions & flushes
2014-07-09 15:34:26,216 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:34:26,216 INFO  [StoreCloserThread-usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.-1] regionserver.HStore: Closed family
2014-07-09 15:34:26,217 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:34:26,217 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:34:26,217 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:34:26,217 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.: disabling compactions & flushes
2014-07-09 15:34:26,217 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Running close preflush of usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:34:26,217 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a., current region memstore size 479.7m
2014-07-09 15:34:26,614 DEBUG [RS_CLOSE_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:27,768 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: fa2ab9ffb0b5a85ad4c1c3400a6b6d39 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,769 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region fa2ab9ffb0b5a85ad4c1c3400a6b6d39 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,769 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 035ce5d09f7bc593b2c68d83d9f7e1cf ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,769 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 035ce5d09f7bc593b2c68d83d9f7e1cf was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,769 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,769 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,769 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e5ee55a21ff19d69490518939b0887e0 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,769 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e5ee55a21ff19d69490518939b0887e0 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,770 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0e294e1cc84fff4243a9d24c11e9bc8d ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,770 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0e294e1cc84fff4243a9d24c11e9bc8d was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,770 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e20ad9e2278dfb99d0d4ac9b665b26ed ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,770 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e20ad9e2278dfb99d0d4ac9b665b26ed was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,770 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,770 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,770 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,770 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,770 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:27,770 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:27,771 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on fa2ab9ffb0b5a85ad4c1c3400a6b6d39, 035ce5d09f7bc593b2c68d83d9f7e1cf, 369c8092e5553636aa4ff097e825820a, e5ee55a21ff19d69490518939b0887e0, 0e294e1cc84fff4243a9d24c11e9bc8d, e20ad9e2278dfb99d0d4ac9b665b26ed, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:28,624 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9549, memsize=211.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/8b85ecec808e464aab94e528f519cbe7
2014-07-09 15:34:28,636 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/8b85ecec808e464aab94e528f519cbe7 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b85ecec808e464aab94e528f519cbe7
2014-07-09 15:34:28,648 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b85ecec808e464aab94e528f519cbe7, entries=769270, sequenceid=9549, filesize=54.8m
2014-07-09 15:34:28,648 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~211.3m/221544080, currentsize=16.3m/17101120 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 6891ms, sequenceid=9549, compaction requested=true
2014-07-09 15:34:28,648 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:34:28,648 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39., current region memstore size 16.3m
2014-07-09 15:34:28,657 DEBUG [RS_CLOSE_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:29,053 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9519, memsize=525.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/fb96da48d405489dbf68c655d5a04f11
2014-07-09 15:34:29,064 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/fb96da48d405489dbf68c655d5a04f11 as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/fb96da48d405489dbf68c655d5a04f11
2014-07-09 15:34:29,072 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/fb96da48d405489dbf68c655d5a04f11, entries=1912090, sequenceid=9519, filesize=136.2m
2014-07-09 15:34:29,072 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~525.2m/550664000, currentsize=61.1m/64018080 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 18054ms, sequenceid=9519, compaction requested=true
2014-07-09 15:34:29,072 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Running close preflush of usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:29,073 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:29,073 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf., current region memstore size 61.1m
2014-07-09 15:34:29,073 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:34:29,103 DEBUG [RS_CLOSE_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:29,117 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9561, memsize=16.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/1df9975ddd5d4b0fb26f59d6a1670b76
2014-07-09 15:34:29,135 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/.tmp/1df9975ddd5d4b0fb26f59d6a1670b76 as hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/1df9975ddd5d4b0fb26f59d6a1670b76
2014-07-09 15:34:29,145 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/1df9975ddd5d4b0fb26f59d6a1670b76, entries=59380, sequenceid=9561, filesize=4.2m
2014-07-09 15:34:29,145 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~16.3m/17101120, currentsize=0.0/0 for region usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. in 497ms, sequenceid=9561, compaction requested=true
2014-07-09 15:34:29,412 INFO  [StoreCloserThread-usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.-1] regionserver.HStore: Closed family
2014-07-09 15:34:29,412 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:34:29,413 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:34:29,413 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:34:29,413 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.: disabling compactions & flushes
2014-07-09 15:34:29,413 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:34:29,424 INFO  [StoreCloserThread-hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.-1] regionserver.HStore: Closed info
2014-07-09 15:34:29,425 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:34:29,425 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:34:29,425 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:29,425 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.: disabling compactions & flushes
2014-07-09 15:34:29,425 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Running close preflush of usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:29,425 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d., current region memstore size 93.5m
2014-07-09 15:34:29,471 DEBUG [RS_CLOSE_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:29,973 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90481ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:29,973 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516., current region memstore size 488.2m
2014-07-09 15:34:30,535 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:30,539 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-09 15:34:30,539 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-09 15:34:30,775 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 035ce5d09f7bc593b2c68d83d9f7e1cf ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,775 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 035ce5d09f7bc593b2c68d83d9f7e1cf was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,775 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,775 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,776 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0e294e1cc84fff4243a9d24c11e9bc8d ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,776 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0e294e1cc84fff4243a9d24c11e9bc8d was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,776 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e20ad9e2278dfb99d0d4ac9b665b26ed ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,776 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e20ad9e2278dfb99d0d4ac9b665b26ed was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,776 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,776 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,776 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,776 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,776 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:30,776 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:30,777 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 035ce5d09f7bc593b2c68d83d9f7e1cf, 369c8092e5553636aa4ff097e825820a, 0e294e1cc84fff4243a9d24c11e9bc8d, e20ad9e2278dfb99d0d4ac9b665b26ed, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:30,996 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9560, memsize=61.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4f65e84dd18d488db47ece11cfacb38b
2014-07-09 15:34:31,005 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/.tmp/4f65e84dd18d488db47ece11cfacb38b as hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4f65e84dd18d488db47ece11cfacb38b
2014-07-09 15:34:31,015 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4f65e84dd18d488db47ece11cfacb38b, entries=222290, sequenceid=9560, filesize=15.8m
2014-07-09 15:34:31,015 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~61.1m/64018080, currentsize=0.0/0 for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. in 1942ms, sequenceid=9560, compaction requested=true
2014-07-09 15:34:31,015 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:31,247 INFO  [StoreCloserThread-usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.-1] regionserver.HStore: Closed family
2014-07-09 15:34:31,248 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:31,248 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:34:31,248 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:34:31,248 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.: disabling compactions & flushes
2014-07-09 15:34:31,248 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Running close preflush of usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:34:31,248 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed., current region memstore size 187.2m
2014-07-09 15:34:31,414 DEBUG [RS_CLOSE_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:32,188 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9560, memsize=93.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/8a725dec42264a20b3d81b0a48017cd1
2014-07-09 15:34:32,198 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/.tmp/8a725dec42264a20b3d81b0a48017cd1 as hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8a725dec42264a20b3d81b0a48017cd1
2014-07-09 15:34:32,209 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8a725dec42264a20b3d81b0a48017cd1, entries=340500, sequenceid=9560, filesize=24.3m
2014-07-09 15:34:32,209 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~93.5m/98061440, currentsize=0.0/0 for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. in 2784ms, sequenceid=9560, compaction requested=true
2014-07-09 15:34:32,209 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:32,415 INFO  [StoreCloserThread-usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.-1] regionserver.HStore: Closed family
2014-07-09 15:34:32,416 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:32,416 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:34:32,416 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:32,416 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.: disabling compactions & flushes
2014-07-09 15:34:32,416 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: waiting for 0 compactions & cache flush to complete for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:33,780 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:33,781 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:33,781 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e20ad9e2278dfb99d0d4ac9b665b26ed ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:33,781 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e20ad9e2278dfb99d0d4ac9b665b26ed was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:33,781 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:33,781 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:33,782 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:33,782 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:33,782 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:33,782 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:33,783 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 369c8092e5553636aa4ff097e825820a, e20ad9e2278dfb99d0d4ac9b665b26ed, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:36,788 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:36,788 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:36,789 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: e20ad9e2278dfb99d0d4ac9b665b26ed ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:36,789 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region e20ad9e2278dfb99d0d4ac9b665b26ed was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:36,789 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:36,789 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:36,790 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:36,790 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:36,790 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:36,790 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:36,790 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 369c8092e5553636aa4ff097e825820a, e20ad9e2278dfb99d0d4ac9b665b26ed, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:36,998 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9558, memsize=187.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/df818ae84cab4512a1fa934b40e11f72
2014-07-09 15:34:37,010 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/.tmp/df818ae84cab4512a1fa934b40e11f72 as hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df818ae84cab4512a1fa934b40e11f72
2014-07-09 15:34:37,018 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df818ae84cab4512a1fa934b40e11f72, entries=681730, sequenceid=9558, filesize=48.6m
2014-07-09 15:34:37,019 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~187.2m/196333040, currentsize=0.0/0 for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. in 5770ms, sequenceid=9558, compaction requested=true
2014-07-09 15:34:37,019 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:34:37,182 INFO  [StoreCloserThread-usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.-1] regionserver.HStore: Closed family
2014-07-09 15:34:37,182 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:34:37,182 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:34:37,183 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:34:37,183 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.: disabling compactions & flushes
2014-07-09 15:34:37,183 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Running close preflush of usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:34:37,183 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18., current region memstore size 154.8m
2014-07-09 15:34:37,306 DEBUG [RS_CLOSE_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:39,793 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 369c8092e5553636aa4ff097e825820a ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:39,793 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 369c8092e5553636aa4ff097e825820a was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:39,794 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:39,794 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:39,794 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 01d5d06c09b8c415be3f4fdd32569a18 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:39,794 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 01d5d06c09b8c415be3f4fdd32569a18 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:39,794 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:39,794 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:39,794 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 369c8092e5553636aa4ff097e825820a, 0cec477330d16ea60f6b986e45ac1516, 01d5d06c09b8c415be3f4fdd32569a18, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:40,665 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9558, memsize=481.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9bcc0cc80e114e7f91cf310cc12e946c
2014-07-09 15:34:40,674 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/.tmp/9bcc0cc80e114e7f91cf310cc12e946c as hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9bcc0cc80e114e7f91cf310cc12e946c
2014-07-09 15:34:40,685 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9bcc0cc80e114e7f91cf310cc12e946c, entries=1752110, sequenceid=9558, filesize=124.9m
2014-07-09 15:34:40,686 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~481.2m/504593360, currentsize=0.0/0 for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. in 14468ms, sequenceid=9558, compaction requested=true
2014-07-09 15:34:40,686 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:34:40,883 INFO  [StoreCloserThread-usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.-1] regionserver.HStore: Closed family
2014-07-09 15:34:40,884 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:34:40,884 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:34:40,884 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:40,884 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.: disabling compactions & flushes
2014-07-09 15:34:40,884 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: waiting for 0 compactions & cache flush to complete for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:41,676 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9558, memsize=154.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/8a404a0050074dc89f3fecb7fefe486f
2014-07-09 15:34:41,689 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/.tmp/8a404a0050074dc89f3fecb7fefe486f as hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8a404a0050074dc89f3fecb7fefe486f
2014-07-09 15:34:41,698 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8a404a0050074dc89f3fecb7fefe486f, entries=563580, sequenceid=9558, filesize=40.2m
2014-07-09 15:34:41,698 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~154.8m/162307120, currentsize=0.0/0 for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. in 4515ms, sequenceid=9558, compaction requested=true
2014-07-09 15:34:41,699 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:34:41,795 INFO  [StoreCloserThread-usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.-1] regionserver.HStore: Closed family
2014-07-09 15:34:41,796 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:34:41,796 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:34:42,798 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: 0cec477330d16ea60f6b986e45ac1516 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:42,798 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region 0cec477330d16ea60f6b986e45ac1516 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:42,798 INFO  [regionserver60020] regionserver.HRegionServer: Received CLOSE for the region: aba5d255d2a2118b681bca61272578b4 ,which we are already trying to CLOSE, but not completed yet
2014-07-09 15:34:42,798 WARN  [regionserver60020] regionserver.HRegionServer: Failed to close usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. - ignoring and continuing
org.apache.hadoop.hbase.regionserver.RegionAlreadyInTransitionException: The region aba5d255d2a2118b681bca61272578b4 was already closing. New CLOSE request is ignored.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegion(HRegionServer.java:2586)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeRegionIgnoreErrors(HRegionServer.java:2508)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.closeUserRegions(HRegionServer.java:2098)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:701)
2014-07-09 15:34:42,798 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 0cec477330d16ea60f6b986e45ac1516, 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:44,872 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9558, memsize=629.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/8c3e575943d0401392f8a6a935b193ad
2014-07-09 15:34:44,889 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/8c3e575943d0401392f8a6a935b193ad as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8c3e575943d0401392f8a6a935b193ad
2014-07-09 15:34:45,117 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9558, memsize=488.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/54ebec4d84b34702af97565d663ab59e
2014-07-09 15:34:45,130 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/.tmp/54ebec4d84b34702af97565d663ab59e as hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/54ebec4d84b34702af97565d663ab59e
2014-07-09 15:34:45,267 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8c3e575943d0401392f8a6a935b193ad, entries=2292270, sequenceid=9558, filesize=163.3m
2014-07-09 15:34:45,268 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~629.6m/660155120, currentsize=3.1m/3300400 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 20043ms, sequenceid=9558, compaction requested=true
2014-07-09 15:34:45,268 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:45,268 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4., current region memstore size 3.1m
2014-07-09 15:34:45,268 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:45,269 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:34:45,269 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Skipping flush on usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because closing
2014-07-09 15:34:45,271 DEBUG [RS_CLOSE_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-09 15:34:45,527 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/54ebec4d84b34702af97565d663ab59e, entries=1777350, sequenceid=9558, filesize=126.7m
2014-07-09 15:34:45,527 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~488.2m/511862560, currentsize=0.0/0 for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. in 15554ms, sequenceid=9558, compaction requested=true
2014-07-09 15:34:45,527 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:34:45,527 DEBUG [regionserver60020-smallCompactions-1404941363881] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:34:45,527 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:45,601 INFO  [StoreCloserThread-usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.-1] regionserver.HStore: Closed family
2014-07-09 15:34:45,601 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:45,601 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:34:45,801 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 1588230740, aba5d255d2a2118b681bca61272578b4
2014-07-09 15:34:46,241 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9561, memsize=3.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/9208b2140d9948be8bd0fa21eafe29de
2014-07-09 15:34:46,251 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/.tmp/9208b2140d9948be8bd0fa21eafe29de as hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9208b2140d9948be8bd0fa21eafe29de
2014-07-09 15:34:46,265 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9208b2140d9948be8bd0fa21eafe29de, entries=11460, sequenceid=9561, filesize=832.0k
2014-07-09 15:34:46,265 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~3.1m/3300400, currentsize=0.0/0 for region usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. in 997ms, sequenceid=9561, compaction requested=true
2014-07-09 15:34:46,310 INFO  [StoreCloserThread-usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.-1] regionserver.HStore: Closed family
2014-07-09 15:34:46,310 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:46,310 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:34:48,805 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 1588230740
2014-07-09 15:34:51,810 INFO  [regionserver60020] regionserver.HRegionServer: STOPPED: Stopped; only catalog regions remaining online
2014-07-09 15:34:51,810 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2014-07-09 15:34:51,811 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2014-07-09 15:34:51,816 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2014-07-09 15:34:51,816 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2014-07-09 15:34:51,818 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2014-07-09 15:34:51,818 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2014-07-09 15:34:51,827 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2014-07-09 15:34:51,827 INFO  [SplitLogWorker-slave1,60020,1404941325989] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1404941325989 exiting
2014-07-09 15:34:51,828 INFO  [regionserver60020] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:60030
2014-07-09 15:34:52,009 INFO  [RS_OPEN_META-slave1:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2014-07-09 15:34:52,009 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2014-07-09 15:34:52,009 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2014-07-09 15:34:52,009 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2014-07-09 15:34:52,010 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2014-07-09 15:34:52,010 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2014-07-09 15:34:52,010 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2014-07-09 15:34:52,011 INFO  [regionserver60020] regionserver.HRegionServer: stopping server slave1,60020,1404941325989
2014-07-09 15:34:52,011 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4beaf267
2014-07-09 15:34:52,012 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x471d07562a0003
2014-07-09 15:34:52,016 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x471d07562a0003 closed
2014-07-09 15:34:52,016 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-09 15:34:52,016 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2014-07-09 15:34:52,016 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2014-07-09 15:34:52,017 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2014-07-09 15:34:52,017 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2014-07-09 15:34:52,030 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2014-07-09 15:34:52,031 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2014-07-09 15:34:52,031 DEBUG [RS_CLOSE_META-slave1:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2014-07-09 15:34:52,031 DEBUG [RS_CLOSE_META-slave1:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2014-07-09 15:34:52,031 DEBUG [RS_CLOSE_META-slave1:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2014-07-09 15:34:52,035 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2014-07-09 15:34:52,035 DEBUG [RS_CLOSE_META-slave1:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2014-07-09 15:34:52,036 INFO  [RS_CLOSE_META-slave1:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2014-07-09 15:34:52,036 DEBUG [RS_CLOSE_META-slave1:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2014-07-09 15:34:52,231 INFO  [regionserver60020] regionserver.HRegionServer: stopping server slave1,60020,1404941325989; all regions closed.
2014-07-09 15:34:52,232 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2014-07-09 15:34:52,232 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncNotifier exiting
2014-07-09 15:34:52,242 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,242 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer0 exiting
2014-07-09 15:34:52,243 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,243 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer1 exiting
2014-07-09 15:34:52,244 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,244 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer2 exiting
2014-07-09 15:34:52,248 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,248 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer3 exiting
2014-07-09 15:34:52,249 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,249 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncSyncer4 exiting
2014-07-09 15:34:52,250 DEBUG [RS_OPEN_META-slave1:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2014-07-09 15:34:52,250 INFO  [RS_OPEN_META-slave1:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-slave1:60020-0-WAL.AsyncWriter exiting
2014-07-09 15:34:52,250 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989
2014-07-09 15:34:52,265 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2014-07-09 15:34:52,265 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2014-07-09 15:34:52,265 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,265 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2014-07-09 15:34:52,266 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,266 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2014-07-09 15:34:52,267 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,267 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2014-07-09 15:34:52,267 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,267 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2014-07-09 15:34:52,268 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2014-07-09 15:34:52,268 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2014-07-09 15:34:52,269 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2014-07-09 15:34:52,269 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2014-07-09 15:34:52,269 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://master:54310/hbase/WALs/slave1,60020,1404941325989
2014-07-09 15:34:52,420 DEBUG [regionserver60020] wal.FSHLog: Moved 50 WAL file(s) to /hbase/oldWALs
2014-07-09 15:34:52,522 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2014-07-09 15:34:52,522 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2014-07-09 15:35:01,742 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2014-07-09 15:35:01,744 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2014-07-09 15:35:01,744 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2014-07-09 15:35:01,756 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x471d07562a0004
2014-07-09 15:35:01,758 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x471d07562a0004 closed
2014-07-09 15:35:01,758 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-09 15:35:01,769 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x471d07562a0000 closed
2014-07-09 15:35:01,769 INFO  [regionserver60020] regionserver.HRegionServer: stopping server slave1,60020,1404941325989; zookeeper connection closed.
2014-07-09 15:35:01,769 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2014-07-09 15:35:01,769 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-09 15:35:01,821 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=Thread[Thread-9,5,main]
2014-07-09 15:35:01,821 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2014-07-09 15:35:01,822 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Shutdown hook finished.
Wed Jul  9 15:35:16 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-09 15:35:16,765 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-09 15:35:16,765 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-09 15:35:16,765 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-09 15:35:17,003 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 57591 22
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-09 15:35:17,004 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-09 15:35:17,005 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 57591 9.1.143.59 22
2014-07-09 15:35:17,006 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-09 15:35:17,006 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-09 15:35:17,006 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-09 15:35:17,008 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=295
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-09 15:35:17,009 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-09 15:35:17,011 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-09 15:35:17,011 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-09 15:35:17,252 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-09 15:35:17,720 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-09 15:35:17,817 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-09 15:35:17,830 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-09 15:35:17,893 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-09 15:35:17,895 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-09 15:35:17,895 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-09 15:35:17,900 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-09 15:35:17,905 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-09 15:35:17,986 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-09 15:35:17,986 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-09 15:35:17,990 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-09 15:35:17,993 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-09 15:35:18,067 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-09 15:35:18,125 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-09 15:35:18,135 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-09 15:35:18,137 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-09 15:35:18,137 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-09 15:35:18,137 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-09 15:35:18,444 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-09 15:35:18,517 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-09 15:35:18,520 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-09 15:35:18,520 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 15:35:18,547 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 15:35:18,552 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:35:18,557 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-09 15:35:18,566 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x1471d443fb70001, negotiated timeout = 90000
2014-07-09 15:35:20,708 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x615eac87, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 15:35:20,710 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x615eac87 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 15:35:20,710 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:35:20,710 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-09 15:35:20,714 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x471d4442340002, negotiated timeout = 90000
2014-07-09 15:35:21,000 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@38483536
2014-07-09 15:35:21,004 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-09 15:35:21,010 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-09 15:35:21,027 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-09 15:35:21,065 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-09 15:35:21,072 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-09 15:35:21,087 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-09 15:35:21,112 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1404945316746 with port=60020, startcode=1404945317916
2014-07-09 15:35:21,480 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-09 15:35:21,480 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-09 15:35:21,480 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-09 15:35:21,509 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-09 15:35:21,518 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1404945317916
2014-07-09 15:35:21,553 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-09 15:35:21,564 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-09 15:35:21,635 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945321572
2014-07-09 15:35:21,650 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-09 15:35:21,654 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-09 15:35:21,658 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-09 15:35:21,662 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-09 15:35:21,665 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-09 15:35:21,665 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-09 15:35:21,665 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-09 15:35:21,665 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-09 15:35:21,666 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-09 15:35:21,673 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1404945317916, sceplus-vm48.almaden.ibm.com,60020,1404945318376] other RSs: [slave1,60020,1404945317916, sceplus-vm48.almaden.ibm.com,60020,1404945318376]
2014-07-09 15:35:21,695 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-09 15:35:21,698 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x78b62ea, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-09 15:35:21,699 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x78b62ea connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-09 15:35:21,699 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-09 15:35:21,699 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-09 15:35:21,703 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x471d4442340003, negotiated timeout = 90000
2014-07-09 15:35:21,711 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-09 15:35:21,711 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-09 15:35:21,764 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1404945317916, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x1471d443fb70001
2014-07-09 15:35:21,764 INFO  [SplitLogWorker-slave1,60020,1404945317916] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1404945317916 starting
2014-07-09 15:35:21,765 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-09 15:35:21,765 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1404945317916
2014-07-09 15:35:21,765 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1404945317916'
2014-07-09 15:35:21,765 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-09 15:35:21,766 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-09 15:35:21,767 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-09 15:35:25,462 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-09 15:35:25,561 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:25,582 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:25,583 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1404945317916
2014-07-09 15:35:25,584 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-09 15:35:25,604 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945325586.meta
2014-07-09 15:35:25,644 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-09 15:35:25,665 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-09 15:35:25,670 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-09 15:35:25,673 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-09 15:35:25,678 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-09 15:35:25,678 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-09 15:35:25,678 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-09 15:35:25,751 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-09 15:35:25,789 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-09 15:35:25,832 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for 42f24efe7ce44c6297fdb152220bfaad
2014-07-09 15:35:25,833 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/42f24efe7ce44c6297fdb152220bfaad, isReference=false, isBulkLoadResult=false, seqid=2760, majorCompaction=false
2014-07-09 15:35:25,854 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/9d11290e141b4f299e20357845d13956, isReference=false, isBulkLoadResult=false, seqid=2729, majorCompaction=true
2014-07-09 15:35:25,886 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-09 15:35:25,890 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=2761
2014-07-09 15:35:25,890 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-09 15:35:25,892 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-09 15:35:25,893 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1404945317916
2014-07-09 15:35:25,898 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-09 15:35:25,899 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:25,903 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:25,903 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:25,903 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1404945317916
2014-07-09 15:35:26,219 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:35:26,249 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:35:26,251 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,252 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 967e1d7e4e4a9cd6ca99d66bdf70a02a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,251 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:35:26,254 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0cec477330d16ea60f6b986e45ac1516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,254 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:35:26,255 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:35:26,259 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,260 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 967e1d7e4e4a9cd6ca99d66bdf70a02a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,260 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => fa2ab9ffb0b5a85ad4c1c3400a6b6d39, NAME => 'usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-09 15:35:26,261 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0cec477330d16ea60f6b986e45ac1516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,261 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 967e1d7e4e4a9cd6ca99d66bdf70a02a, NAME => 'usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-09 15:35:26,261 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 0cec477330d16ea60f6b986e45ac1516, NAME => 'usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-09 15:35:26,262 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:35:26,262 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:35:26,262 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:35:26,262 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:35:26,263 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:35:26,263 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:35:26,263 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:35:26,263 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:35:26,263 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:35:26,264 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:35:26,264 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:35:26,264 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:35:26,270 INFO  [RS_OPEN_REGION-slave1:60020-0] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-09 15:35:26,272 INFO  [RS_OPEN_REGION-slave1:60020-0] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-09 15:35:26,274 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-09 15:35:26,274 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-09 15:35:26,274 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-09 15:35:26,283 INFO  [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:26,284 INFO  [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:26,287 INFO  [StoreOpener-967e1d7e4e4a9cd6ca99d66bdf70a02a-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:26,296 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:35:26,299 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 967e1d7e4e4a9cd6ca99d66bdf70a02a; next sequenceid=1
2014-07-09 15:35:26,299 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 967e1d7e4e4a9cd6ca99d66bdf70a02a
2014-07-09 15:35:26,300 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:35:26,362 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:26,368 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:26,371 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0a25622458054959a24e179ec17bb2bb, isReference=false, isBulkLoadResult=false, seqid=4439, majorCompaction=false
2014-07-09 15:35:26,371 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/0ec098d23b4f4555842e70d3395bdfc1, isReference=false, isBulkLoadResult=false, seqid=4352, majorCompaction=false
2014-07-09 15:35:26,389 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0d8950a81c4245ee9ba5aaab15bc4b21, isReference=false, isBulkLoadResult=false, seqid=2397, majorCompaction=false
2014-07-09 15:35:26,395 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/10935ab4a53e42dc885881592b602f1f, isReference=false, isBulkLoadResult=false, seqid=832, majorCompaction=false
2014-07-09 15:35:26,413 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/123fc3e0dc304d828b4b4abc14bb296e, isReference=false, isBulkLoadResult=false, seqid=5568, majorCompaction=false
2014-07-09 15:35:26,414 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/0e3d19f2250c460aac5a0fba103d05f7, isReference=false, isBulkLoadResult=false, seqid=1733, majorCompaction=false
2014-07-09 15:35:26,428 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/268853e99d764e48bfedb502a6d41194, isReference=false, isBulkLoadResult=false, seqid=2564, majorCompaction=false
2014-07-09 15:35:26,432 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] catalog.MetaEditor: Updated row usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a. with server=slave1,60020,1404945317916
2014-07-09 15:35:26,432 INFO  [PostOpenDeployTasks:967e1d7e4e4a9cd6ca99d66bdf70a02a] regionserver.HRegionServer: Finished post open deploy task for usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a.
2014-07-09 15:35:26,432 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 967e1d7e4e4a9cd6ca99d66bdf70a02a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:26,438 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 967e1d7e4e4a9cd6ca99d66bdf70a02a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:26,438 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 967e1d7e4e4a9cd6ca99d66bdf70a02a to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:26,438 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,,1404941702023.967e1d7e4e4a9cd6ca99d66bdf70a02a. on slave1,60020,1404945317916
2014-07-09 15:35:26,439 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e294e1cc84fff4243a9d24c11e9bc8d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,441 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/12c02592515f4088887d1165fc858ee1, isReference=false, isBulkLoadResult=false, seqid=2830, majorCompaction=false
2014-07-09 15:35:26,442 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e294e1cc84fff4243a9d24c11e9bc8d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:26,442 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 0e294e1cc84fff4243a9d24c11e9bc8d, NAME => 'usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-09 15:35:26,443 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:35:26,443 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:35:26,445 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/297a60cb4e1a4045830c9ed086b915ce, isReference=false, isBulkLoadResult=false, seqid=3063, majorCompaction=false
2014-07-09 15:35:26,451 INFO  [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:26,458 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/18484b4efc324c8eaffbab14f560d908, isReference=false, isBulkLoadResult=false, seqid=2164, majorCompaction=false
2014-07-09 15:35:26,466 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/1df9975ddd5d4b0fb26f59d6a1670b76, isReference=false, isBulkLoadResult=false, seqid=9561, majorCompaction=false
2014-07-09 15:35:26,474 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/2dde80329a6f4e618a3bf2ff69f29022, isReference=false, isBulkLoadResult=false, seqid=5245, majorCompaction=false
2014-07-09 15:35:26,490 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/145320010f5b4bcd9618548529be4182, isReference=false, isBulkLoadResult=false, seqid=899, majorCompaction=false
2014-07-09 15:35:26,498 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3b64f5264df2402a8fa40e5757c87f67, isReference=false, isBulkLoadResult=false, seqid=8104, majorCompaction=false
2014-07-09 15:35:26,500 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/2444d8abe5cc4d54bea8a0284398b0a3, isReference=false, isBulkLoadResult=false, seqid=3939, majorCompaction=false
2014-07-09 15:35:26,505 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/1b892d24e3c74062a20887e8d31e39d6, isReference=false, isBulkLoadResult=false, seqid=3395, majorCompaction=false
2014-07-09 15:35:26,518 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/288de302ea5d4f25ab4c0deca74c10ab, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-09 15:35:26,523 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/3cc067d0b142437aa75e89dfb00e55b2, isReference=false, isBulkLoadResult=false, seqid=4833, majorCompaction=false
2014-07-09 15:35:26,533 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/3c2a84c716224d27bb6cdc27534c8162, isReference=false, isBulkLoadResult=false, seqid=2497, majorCompaction=false
2014-07-09 15:35:26,534 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2320846854e948b69bf4207e997a7b58, isReference=false, isBulkLoadResult=false, seqid=5654, majorCompaction=false
2014-07-09 15:35:26,547 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/4d198ec64f36457b9764754c4522a9ca, isReference=false, isBulkLoadResult=false, seqid=566, majorCompaction=false
2014-07-09 15:35:26,549 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/28325c5fbc0c4712b5bf47f175d83fc8, isReference=false, isBulkLoadResult=false, seqid=9090, majorCompaction=false
2014-07-09 15:35:26,556 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/54ebec4d84b34702af97565d663ab59e, isReference=false, isBulkLoadResult=false, seqid=9558, majorCompaction=false
2014-07-09 15:35:26,561 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/2c0e2931c5854a0ea95762b39392e87e, isReference=false, isBulkLoadResult=false, seqid=8354, majorCompaction=false
2014-07-09 15:35:26,578 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/454df660313444e9aeea5604d7202962, isReference=false, isBulkLoadResult=false, seqid=5807, majorCompaction=false
2014-07-09 15:35:26,583 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/55428f9c1fc3432885ec04830c0333fb, isReference=false, isBulkLoadResult=false, seqid=1067, majorCompaction=false
2014-07-09 15:35:26,590 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/37489b3288ec4f25b9dd65f05e12d580, isReference=false, isBulkLoadResult=false, seqid=4030, majorCompaction=false
2014-07-09 15:35:26,600 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/59bfdce46e444c9dad821b0ddab4230d, isReference=false, isBulkLoadResult=false, seqid=5162, majorCompaction=false
2014-07-09 15:35:26,601 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/5c61223c852f41688ed3fff756af1031, isReference=false, isBulkLoadResult=false, seqid=3229, majorCompaction=false
2014-07-09 15:35:26,606 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3deae42579344e45b925af14c4749f22, isReference=false, isBulkLoadResult=false, seqid=6500, majorCompaction=false
2014-07-09 15:35:26,618 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/657c2a33be164d9ebd181bcf678ba480, isReference=false, isBulkLoadResult=false, seqid=3328, majorCompaction=false
2014-07-09 15:35:26,622 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/65c75ae746c745268f84090007c18129, isReference=false, isBulkLoadResult=false, seqid=8851, majorCompaction=false
2014-07-09 15:35:26,639 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/3fc3f22db77a406794ea1f1e23032122, isReference=false, isBulkLoadResult=false, seqid=2564, majorCompaction=false
2014-07-09 15:35:26,643 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/694566863ec34c48b3f3bbd3abd8c6d3, isReference=false, isBulkLoadResult=false, seqid=6881, majorCompaction=false
2014-07-09 15:35:26,646 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/6b2180b7e3544748ae4605a98b81c53b, isReference=false, isBulkLoadResult=false, seqid=5651, majorCompaction=false
2014-07-09 15:35:26,652 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/450a0b1f371d435aba2711169317e4ec, isReference=false, isBulkLoadResult=false, seqid=9498, majorCompaction=false
2014-07-09 15:35:26,661 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6bfe403e5f074c64b6599c233773d6ce, isReference=false, isBulkLoadResult=false, seqid=9412, majorCompaction=false
2014-07-09 15:35:26,670 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/833a91bdc2174f04ae7b755e5e64a5dd, isReference=false, isBulkLoadResult=false, seqid=734, majorCompaction=false
2014-07-09 15:35:26,684 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4a9891ae591b41f6ac22141b3043a279, isReference=false, isBulkLoadResult=false, seqid=212, majorCompaction=false
2014-07-09 15:35:26,687 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/6f1a2a76241841ac88cd4b0e0256a0a3, isReference=false, isBulkLoadResult=false, seqid=665, majorCompaction=false
2014-07-09 15:35:26,708 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4b035fb94d1b4330892f0dc7dde7caad, isReference=false, isBulkLoadResult=false, seqid=566, majorCompaction=false
2014-07-09 15:35:26,711 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8ad0dc2af3af433f863684719cc06d25, isReference=false, isBulkLoadResult=false, seqid=4027, majorCompaction=false
2014-07-09 15:35:26,726 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/77cf201cfbea4af3a3095547a81dd73e, isReference=false, isBulkLoadResult=false, seqid=1330, majorCompaction=false
2014-07-09 15:35:26,735 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8e1209b9d3234aebb76c7915ac86db95, isReference=false, isBulkLoadResult=false, seqid=1899, majorCompaction=false
2014-07-09 15:35:26,739 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/4d1d4a6bcc384af68343b2ec10023c1f, isReference=false, isBulkLoadResult=false, seqid=6576, majorCompaction=false
2014-07-09 15:35:26,752 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8f583897e5e944d196d02fa8ee260d14, isReference=false, isBulkLoadResult=false, seqid=8007, majorCompaction=false
2014-07-09 15:35:26,755 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/7bde56a2a0ce46f882739ed119a3399f, isReference=false, isBulkLoadResult=false, seqid=499, majorCompaction=false
2014-07-09 15:35:26,775 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/54fdb51e719942e9a47bf6e6747ca012, isReference=false, isBulkLoadResult=false, seqid=2065, majorCompaction=false
2014-07-09 15:35:26,779 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/8fb1da8b7a984ff9b7c65b9c123ca682, isReference=false, isBulkLoadResult=false, seqid=7214, majorCompaction=false
2014-07-09 15:35:26,804 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/87884ad8125f429681cc865847b5a422, isReference=false, isBulkLoadResult=false, seqid=3494, majorCompaction=false
2014-07-09 15:35:26,809 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/555a8566d5a341bcb52667d0ec20096d, isReference=false, isBulkLoadResult=false, seqid=3561, majorCompaction=false
2014-07-09 15:35:26,813 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/94c061ab697e4f93b3e4ca04a5c84756, isReference=false, isBulkLoadResult=false, seqid=3395, majorCompaction=false
2014-07-09 15:35:26,833 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8ae555f5c532416089c4a0230a62351c, isReference=false, isBulkLoadResult=false, seqid=1497, majorCompaction=false
2014-07-09 15:35:26,833 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/56125172ed8e4654af81eea1c2f167a8, isReference=false, isBulkLoadResult=false, seqid=2397, majorCompaction=false
2014-07-09 15:35:26,856 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9739cc28317b431a87dec6a49b6d6362, isReference=false, isBulkLoadResult=false, seqid=7599, majorCompaction=false
2014-07-09 15:35:26,859 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b117166eee847d6a2597f23d985eb44, isReference=false, isBulkLoadResult=false, seqid=1829, majorCompaction=false
2014-07-09 15:35:26,861 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/5e24a4c19a434c8f99a97ccb0a822972, isReference=false, isBulkLoadResult=false, seqid=1731, majorCompaction=false
2014-07-09 15:35:26,882 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/9f49ae5942054f8485081121898a4bd0, isReference=false, isBulkLoadResult=false, seqid=1399, majorCompaction=false
2014-07-09 15:35:26,885 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/65122adbecee4e3da9fb501c11e54a62, isReference=false, isBulkLoadResult=false, seqid=3063, majorCompaction=false
2014-07-09 15:35:26,885 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8b85ecec808e464aab94e528f519cbe7, isReference=false, isBulkLoadResult=false, seqid=9549, majorCompaction=false
2014-07-09 15:35:26,898 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a0bdf14cb65746b4a5a0f6948ffdc2f7, isReference=false, isBulkLoadResult=false, seqid=2896, majorCompaction=false
2014-07-09 15:35:26,903 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/8f8061df76324276b04e0ab3c797e8b8, isReference=false, isBulkLoadResult=false, seqid=7850, majorCompaction=false
2014-07-09 15:35:26,913 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/a93fe9c5cd01477ea5e3ce5147e4ebe1, isReference=false, isBulkLoadResult=false, seqid=6438, majorCompaction=false
2014-07-09 15:35:26,915 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6a74f989ead6472ab8afbcc0c2773897, isReference=false, isBulkLoadResult=false, seqid=5805, majorCompaction=false
2014-07-09 15:35:26,919 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/902b3939e642492d912edc5de686439b, isReference=false, isBulkLoadResult=false, seqid=6096, majorCompaction=false
2014-07-09 15:35:26,927 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ba2d8b719658485ca38e1da3fe86609e, isReference=false, isBulkLoadResult=false, seqid=3561, majorCompaction=false
2014-07-09 15:35:26,928 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/6bb2975734be48c788829f5f3d80579b, isReference=false, isBulkLoadResult=false, seqid=3229, majorCompaction=false
2014-07-09 15:35:26,935 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/a436d8f631f24d8c960fe458ee5df15d, isReference=false, isBulkLoadResult=false, seqid=4750, majorCompaction=false
2014-07-09 15:35:26,941 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c0bfdf08816d46dd957d841cbeacd6fb, isReference=false, isBulkLoadResult=false, seqid=379, majorCompaction=false
2014-07-09 15:35:26,941 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/79fddfe53a954baa9bb5ca10b733f0ba, isReference=false, isBulkLoadResult=false, seqid=2730, majorCompaction=false
2014-07-09 15:35:26,951 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/aaeae62a56124ec1b485f5045e3eea75, isReference=false, isBulkLoadResult=false, seqid=7469, majorCompaction=false
2014-07-09 15:35:26,961 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d01cd96ad164f6c832e895adb799023, isReference=false, isBulkLoadResult=false, seqid=733, majorCompaction=false
2014-07-09 15:35:26,966 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/ae7b7e6df4134a15858a02046cf99c03, isReference=false, isBulkLoadResult=false, seqid=6616, majorCompaction=false
2014-07-09 15:35:26,975 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/7d7f1e3f355f49039c98eaa8058a2b8d, isReference=false, isBulkLoadResult=false, seqid=2896, majorCompaction=false
2014-07-09 15:35:26,976 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/c7f068cc31ce450a88e42978112c6686, isReference=false, isBulkLoadResult=false, seqid=5804, majorCompaction=false
2014-07-09 15:35:26,977 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/af16ecb87beb4253af11e41c5c744e85, isReference=false, isBulkLoadResult=false, seqid=8618, majorCompaction=false
2014-07-09 15:35:26,999 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d1065a17cb6146029c9892551b99aa36, isReference=false, isBulkLoadResult=false, seqid=900, majorCompaction=false
2014-07-09 15:35:27,003 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8902cd057abd48e694f3a996b18f7b9f, isReference=false, isBulkLoadResult=false, seqid=4442, majorCompaction=false
2014-07-09 15:35:27,017 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b011fea696be4bb396d715d650e5f74b, isReference=false, isBulkLoadResult=false, seqid=2331, majorCompaction=false
2014-07-09 15:35:27,018 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d13d5b12f70041769320253668fdb779, isReference=false, isBulkLoadResult=false, seqid=1233, majorCompaction=false
2014-07-09 15:35:27,019 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8925e9a02f9840918f538ba86e5596b3, isReference=false, isBulkLoadResult=false, seqid=1399, majorCompaction=false
2014-07-09 15:35:27,034 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d51592b207684475949a95cc530a1c1f, isReference=false, isBulkLoadResult=false, seqid=9242, majorCompaction=false
2014-07-09 15:35:27,041 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8a725dec42264a20b3d81b0a48017cd1, isReference=false, isBulkLoadResult=false, seqid=9560, majorCompaction=false
2014-07-09 15:35:27,046 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/b2982f11829642ac84c1a3ea9952d43c, isReference=false, isBulkLoadResult=false, seqid=1997, majorCompaction=false
2014-07-09 15:35:27,057 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7a9f200b5324c47a2163d4acb877962, isReference=false, isBulkLoadResult=false, seqid=6830, majorCompaction=false
2014-07-09 15:35:27,068 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/8fc5148433834b48b819d036f4a7eda3, isReference=false, isBulkLoadResult=false, seqid=1067, majorCompaction=false
2014-07-09 15:35:27,071 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/bda669f73afd43208c395c2d7e851db1, isReference=false, isBulkLoadResult=false, seqid=2996, majorCompaction=false
2014-07-09 15:35:27,085 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7b4b53f7a764473be2834e024a254c1, isReference=false, isBulkLoadResult=false, seqid=8487, majorCompaction=false
2014-07-09 15:35:27,087 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/9692cd2b28ac4d97bb900ab0ef083648, isReference=false, isBulkLoadResult=false, seqid=2231, majorCompaction=false
2014-07-09 15:35:27,089 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/cebfc0ca2ddf48ddb06f54bf4609e7ce, isReference=false, isBulkLoadResult=false, seqid=2663, majorCompaction=false
2014-07-09 15:35:27,116 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/d7dac0168b4345e2ae9fd5479ce29eeb, isReference=false, isBulkLoadResult=false, seqid=2730, majorCompaction=false
2014-07-09 15:35:27,118 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a044a2cd564048ff9f9a630a6eaed6fe, isReference=false, isBulkLoadResult=false, seqid=5248, majorCompaction=false
2014-07-09 15:35:27,132 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d3f9a07a816441af8b949b3acd48d6df, isReference=false, isBulkLoadResult=false, seqid=6214, majorCompaction=false
2014-07-09 15:35:27,137 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ddc365707e424dce958d47b0be4edf9f, isReference=false, isBulkLoadResult=false, seqid=2231, majorCompaction=false
2014-07-09 15:35:27,146 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a486fbf37db644c3a9a0aa035876a3a3, isReference=false, isBulkLoadResult=false, seqid=7719, majorCompaction=false
2014-07-09 15:35:27,159 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/d6dd5e52b85842bcb74373bc4a90dfaa, isReference=false, isBulkLoadResult=false, seqid=5805, majorCompaction=false
2014-07-09 15:35:27,162 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/edd46d224132482d83ac6e6d19349497, isReference=false, isBulkLoadResult=false, seqid=2065, majorCompaction=false
2014-07-09 15:35:27,183 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a83d9bb773f04f48b63b7a494ef0bd2e, isReference=false, isBulkLoadResult=false, seqid=378, majorCompaction=false
2014-07-09 15:35:27,188 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/da3421c8de464cf9b5225d4cabce8ee4, isReference=false, isBulkLoadResult=false, seqid=1164, majorCompaction=false
2014-07-09 15:35:27,200 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/fbf0a16fee7d44b4a6ed61d2e176b36b, isReference=false, isBulkLoadResult=false, seqid=213, majorCompaction=false
2014-07-09 15:35:27,205 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/a849b34e14334ba185c2ca77a03a1298, isReference=false, isBulkLoadResult=false, seqid=7297, majorCompaction=false
2014-07-09 15:35:27,205 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/db253cb0944c40b0b1425e1ab348e6f9, isReference=false, isBulkLoadResult=false, seqid=3162, majorCompaction=false
2014-07-09 15:35:27,223 DEBUG [StoreOpener-0cec477330d16ea60f6b986e45ac1516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516/family/ff7b3788d1904946957d76d07ce88df1, isReference=false, isBulkLoadResult=false, seqid=1567, majorCompaction=false
2014-07-09 15:35:27,230 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/e77e37a5cce34f31a511f0e9ce0e2d15, isReference=false, isBulkLoadResult=false, seqid=9012, majorCompaction=false
2014-07-09 15:35:27,231 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ad9cdc44209d499c9a02dc535887266c, isReference=false, isBulkLoadResult=false, seqid=6178, majorCompaction=false
2014-07-09 15:35:27,232 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:35:27,239 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 0cec477330d16ea60f6b986e45ac1516; next sequenceid=9559
2014-07-09 15:35:27,239 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0cec477330d16ea60f6b986e45ac1516
2014-07-09 15:35:27,243 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:35:27,249 DEBUG [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:27,250 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:27,250 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:27,253 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:27,253 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/efe6eab791f74c879347c461e577c962, isReference=false, isBulkLoadResult=false, seqid=998, majorCompaction=false
2014-07-09 15:35:27,255 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:27,259 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:35:27,262 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/bca7b238a3a1436aaeb4d80c71bc8660, isReference=false, isBulkLoadResult=false, seqid=1898, majorCompaction=false
2014-07-09 15:35:27,265 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] catalog.MetaEditor: Updated row usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. with server=slave1,60020,1404945317916
2014-07-09 15:35:27,266 INFO  [PostOpenDeployTasks:0cec477330d16ea60f6b986e45ac1516] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516.
2014-07-09 15:35:27,267 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0cec477330d16ea60f6b986e45ac1516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,272 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0cec477330d16ea60f6b986e45ac1516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,272 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 0cec477330d16ea60f6b986e45ac1516 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:27,272 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. on slave1,60020,1404945317916
2014-07-09 15:35:27,273 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,277 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,277 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-09 15:35:27,279 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-09 15:35:27,279 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:35:27,292 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c5e62a29a925476d8d2722e5ae93fbf1, isReference=false, isBulkLoadResult=false, seqid=8691, majorCompaction=false
2014-07-09 15:35:27,294 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-09 15:35:27,295 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/f0eaf6a98e8d4cb7a725fa3051acc44f, isReference=false, isBulkLoadResult=false, seqid=1663, majorCompaction=false
2014-07-09 15:35:27,318 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fdd2d29a2e204552bba925cd65283725, isReference=false, isBulkLoadResult=false, seqid=5733, majorCompaction=false
2014-07-09 15:35:27,320 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c605b0d2f3614b53bab4f11a857d576b, isReference=false, isBulkLoadResult=false, seqid=6939, majorCompaction=false
2014-07-09 15:35:27,320 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-09 15:35:27,324 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-09 15:35:27,334 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fe45bc84abd946ce841fceb4d2a3ca61, isReference=false, isBulkLoadResult=false, seqid=333, majorCompaction=false
2014-07-09 15:35:27,334 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-09 15:35:27,335 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-09 15:35:27,336 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:35:27,337 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/c9f581396fed4e62a6636bd9ad2e4247, isReference=false, isBulkLoadResult=false, seqid=1233, majorCompaction=false
2014-07-09 15:35:27,345 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1404945317916
2014-07-09 15:35:27,345 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-09 15:35:27,346 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,349 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,349 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:27,349 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1404945317916
2014-07-09 15:35:27,349 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 01d5d06c09b8c415be3f4fdd32569a18 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,353 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 01d5d06c09b8c415be3f4fdd32569a18 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,354 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 01d5d06c09b8c415be3f4fdd32569a18, NAME => 'usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-09 15:35:27,354 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:35:27,354 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:35:27,358 DEBUG [StoreOpener-fa2ab9ffb0b5a85ad4c1c3400a6b6d39-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39/family/fec684da12284bb78bc7eb985c6c400f, isReference=false, isBulkLoadResult=false, seqid=8232, majorCompaction=false
2014-07-09 15:35:27,361 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/d5cec43e8cf04b7e817011371193affd, isReference=false, isBulkLoadResult=false, seqid=1565, majorCompaction=false
2014-07-09 15:35:27,366 INFO  [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:27,368 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:35:27,379 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined fa2ab9ffb0b5a85ad4c1c3400a6b6d39; next sequenceid=9562
2014-07-09 15:35:27,379 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fa2ab9ffb0b5a85ad4c1c3400a6b6d39
2014-07-09 15:35:27,381 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:35:27,381 DEBUG [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:27,382 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-09 15:35:27,382 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-09 15:35:27,382 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:27,382 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:27,382 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:35:27,388 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] catalog.MetaEditor: Updated row usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. with server=slave1,60020,1404945317916
2014-07-09 15:35:27,388 INFO  [PostOpenDeployTasks:fa2ab9ffb0b5a85ad4c1c3400a6b6d39] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39.
2014-07-09 15:35:27,389 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,392 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fa2ab9ffb0b5a85ad4c1c3400a6b6d39 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,392 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned fa2ab9ffb0b5a85ad4c1c3400a6b6d39 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:27,392 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. on slave1,60020,1404945317916
2014-07-09 15:35:27,393 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 369c8092e5553636aa4ff097e825820a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,395 DEBUG [StoreOpener-0e294e1cc84fff4243a9d24c11e9bc8d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d/family/ddb165bca89f49618a3f293263cee171, isReference=false, isBulkLoadResult=false, seqid=4840, majorCompaction=false
2014-07-09 15:35:27,399 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 369c8092e5553636aa4ff097e825820a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,399 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 369c8092e5553636aa4ff097e825820a, NAME => 'usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-09 15:35:27,400 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 369c8092e5553636aa4ff097e825820a
2014-07-09 15:35:27,400 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:35:27,402 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03ac59eb0cea4cb182d0b5c104e679ec, isReference=false, isBulkLoadResult=false, seqid=6212, majorCompaction=false
2014-07-09 15:35:27,402 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:35:27,407 INFO  [StoreOpener-369c8092e5553636aa4ff097e825820a-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:27,410 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 0e294e1cc84fff4243a9d24c11e9bc8d; next sequenceid=9561
2014-07-09 15:35:27,410 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e294e1cc84fff4243a9d24c11e9bc8d
2014-07-09 15:35:27,412 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:35:27,412 DEBUG [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:27,413 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 38 store files, 0 compacting, 38 eligible, 20 blocking
2014-07-09 15:35:27,413 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 38 files from compaction candidates
2014-07-09 15:35:27,413 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:27,413 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:27,413 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:35:27,420 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] catalog.MetaEditor: Updated row usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. with server=slave1,60020,1404945317916
2014-07-09 15:35:27,420 INFO  [PostOpenDeployTasks:0e294e1cc84fff4243a9d24c11e9bc8d] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d.
2014-07-09 15:35:27,422 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e294e1cc84fff4243a9d24c11e9bc8d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,426 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e294e1cc84fff4243a9d24c11e9bc8d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,426 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 0e294e1cc84fff4243a9d24c11e9bc8d to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:27,426 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. on slave1,60020,1404945317916
2014-07-09 15:35:27,427 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ab8fe21463419a7329d4993471fedc73 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,428 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/03c4b9ae15824886bae3000d621d8ddf, isReference=false, isBulkLoadResult=false, seqid=6614, majorCompaction=false
2014-07-09 15:35:27,431 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ab8fe21463419a7329d4993471fedc73 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,432 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => ab8fe21463419a7329d4993471fedc73, NAME => 'usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-09 15:35:27,433 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable ab8fe21463419a7329d4993471fedc73
2014-07-09 15:35:27,433 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:35:27,437 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/053246811ea44861986507fa064763fc, isReference=false, isBulkLoadResult=false, seqid=3333, majorCompaction=false
2014-07-09 15:35:27,439 INFO  [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:27,450 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0046a0d576c249abad89b943ef6da41f, isReference=false, isBulkLoadResult=false, seqid=3423, majorCompaction=false
2014-07-09 15:35:27,451 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/12480f8bcfa044df94f29ec25df311dd, isReference=false, isBulkLoadResult=false, seqid=2833, majorCompaction=false
2014-07-09 15:35:27,469 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/220634410fef40f4a3e5e2b44a459940, isReference=false, isBulkLoadResult=false, seqid=2327, majorCompaction=false
2014-07-09 15:35:27,472 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/017c1aa77f0b480db78db62a2f10bcb8, isReference=false, isBulkLoadResult=false, seqid=892, majorCompaction=false
2014-07-09 15:35:27,474 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0a42f9d104344b4987ec1e659b38f6d6, isReference=false, isBulkLoadResult=false, seqid=4987, majorCompaction=false
2014-07-09 15:35:27,490 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0624a799b6e342eda4ed22202a24154b, isReference=false, isBulkLoadResult=false, seqid=8857, majorCompaction=false
2014-07-09 15:35:27,491 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/0f7e9767690046e3a32191a27235e860, isReference=false, isBulkLoadResult=false, seqid=7508, majorCompaction=false
2014-07-09 15:35:27,491 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/22cb56db51a349078c05e1e5905fcd88, isReference=false, isBulkLoadResult=false, seqid=5161, majorCompaction=false
2014-07-09 15:35:27,504 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/28853f4a806046a697c970d61fb6f496, isReference=false, isBulkLoadResult=false, seqid=8045, majorCompaction=false
2014-07-09 15:35:27,508 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/18125a1b6d904111ba4966b0682878e9, isReference=false, isBulkLoadResult=false, seqid=7898, majorCompaction=false
2014-07-09 15:35:27,510 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/0e2b09e890e148078d1ec7be92599674, isReference=false, isBulkLoadResult=false, seqid=5807, majorCompaction=false
2014-07-09 15:35:27,517 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3bd1ba2780ee48468c889ef6ad13a07b, isReference=false, isBulkLoadResult=false, seqid=500, majorCompaction=false
2014-07-09 15:35:27,527 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/146cab6d1e454ae8aaf01b7ee0de447c, isReference=false, isBulkLoadResult=false, seqid=8109, majorCompaction=false
2014-07-09 15:35:27,538 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/3cafadf44d2742f2903416c7612ef640, isReference=false, isBulkLoadResult=false, seqid=1497, majorCompaction=false
2014-07-09 15:35:27,542 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/19015d7a681d460caffb6177e4e8a220, isReference=false, isBulkLoadResult=false, seqid=4449, majorCompaction=false
2014-07-09 15:35:27,549 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/2a8706097f0e4bbcb4d2a9f142d51b53, isReference=false, isBulkLoadResult=false, seqid=6280, majorCompaction=false
2014-07-09 15:35:27,566 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/514c2d56a6ba4dd089bb1fa87886d574, isReference=false, isBulkLoadResult=false, seqid=4751, majorCompaction=false
2014-07-09 15:35:27,571 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/266843fa05534fe987eb70676491ca43, isReference=false, isBulkLoadResult=false, seqid=3896, majorCompaction=false
2014-07-09 15:35:27,589 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/3b74b18767784e8da54050e98f1a6662, isReference=false, isBulkLoadResult=false, seqid=1224, majorCompaction=false
2014-07-09 15:35:27,597 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5327801a7d504514b9952473796b17ee, isReference=false, isBulkLoadResult=false, seqid=4357, majorCompaction=false
2014-07-09 15:35:27,604 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3096f05166614353a6260e805185dfc4, isReference=false, isBulkLoadResult=false, seqid=607, majorCompaction=false
2014-07-09 15:35:27,619 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/405c9e22ef8c4e10a539d5f3be40d0a9, isReference=false, isBulkLoadResult=false, seqid=4027, majorCompaction=false
2014-07-09 15:35:27,623 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/55f61023515e47beaa73a0e5801563d2, isReference=false, isBulkLoadResult=false, seqid=9126, majorCompaction=false
2014-07-09 15:35:27,642 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/3cb7ab78738c43018c2dd00b11c58e52, isReference=false, isBulkLoadResult=false, seqid=5536, majorCompaction=false
2014-07-09 15:35:27,643 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/59902211b8d14c6c8c2eac24916bbce9, isReference=false, isBulkLoadResult=false, seqid=6917, majorCompaction=false
2014-07-09 15:35:27,645 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/473654eddbd948e7a4f768c32ed157cb, isReference=false, isBulkLoadResult=false, seqid=1391, majorCompaction=false
2014-07-09 15:35:27,658 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/5deb9b38aed84dd680a561897e1ce6c2, isReference=false, isBulkLoadResult=false, seqid=8728, majorCompaction=false
2014-07-09 15:35:27,663 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/594a2da148e34145aacada934c582d21, isReference=false, isBulkLoadResult=false, seqid=726, majorCompaction=false
2014-07-09 15:35:27,670 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/47d2bb06ea704f79bf21a6fe2de516bf, isReference=false, isBulkLoadResult=false, seqid=8419, majorCompaction=false
2014-07-09 15:35:27,678 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/698139aafee94466a26a8ec7ade2f81c, isReference=false, isBulkLoadResult=false, seqid=1663, majorCompaction=false
2014-07-09 15:35:27,688 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/55282ea871d44e6cbf855fd4ae4faf1e, isReference=false, isBulkLoadResult=false, seqid=3348, majorCompaction=false
2014-07-09 15:35:27,691 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/738b20154d284d51ab9ae032e459d12d, isReference=false, isBulkLoadResult=false, seqid=999, majorCompaction=false
2014-07-09 15:35:27,696 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5a1ea8c39737400faaecf227579ccf7f, isReference=false, isBulkLoadResult=false, seqid=9526, majorCompaction=false
2014-07-09 15:35:27,711 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5d2971b8f45e42dbbe64ba6c0a4647fb, isReference=false, isBulkLoadResult=false, seqid=1762, majorCompaction=false
2014-07-09 15:35:27,718 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/5c02c1237d2948e683bff21bdffcfba0, isReference=false, isBulkLoadResult=false, seqid=1705, majorCompaction=false
2014-07-09 15:35:27,719 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7c10f75d27dd4889acfd03f5405c9cb9, isReference=false, isBulkLoadResult=false, seqid=1995, majorCompaction=false
2014-07-09 15:35:27,727 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/5fc30253b5d14f63ab7bbc6810435bb4, isReference=false, isBulkLoadResult=false, seqid=7311, majorCompaction=false
2014-07-09 15:35:27,733 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6c4dc7f3e6704cb3bdd5b8b999ae9992, isReference=false, isBulkLoadResult=false, seqid=9539, majorCompaction=false
2014-07-09 15:35:27,734 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/7e354200982d45a2beda783790527257, isReference=false, isBulkLoadResult=false, seqid=2494, majorCompaction=false
2014-07-09 15:35:27,740 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/605151e95bb2412a932d3ad2950a5a79, isReference=false, isBulkLoadResult=false, seqid=3091, majorCompaction=false
2014-07-09 15:35:27,743 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8a404a0050074dc89f3fecb7fefe486f, isReference=false, isBulkLoadResult=false, seqid=9558, majorCompaction=false
2014-07-09 15:35:27,746 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/6f23e20e29264db7b2733271fe41deb5, isReference=false, isBulkLoadResult=false, seqid=2799, majorCompaction=false
2014-07-09 15:35:27,752 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/6d661e525ba64eab82eebb69ae69e147, isReference=false, isBulkLoadResult=false, seqid=8488, majorCompaction=false
2014-07-09 15:35:27,753 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/8dc1524666c84b2fbe4c180b6fa27eb2, isReference=false, isBulkLoadResult=false, seqid=2161, majorCompaction=false
2014-07-09 15:35:27,765 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/7ecd084bc67e4c2a8ef24e3f0cd62691, isReference=false, isBulkLoadResult=false, seqid=8888, majorCompaction=false
2014-07-09 15:35:27,770 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/73d606aec1064729bd79aa82371654c8, isReference=false, isBulkLoadResult=false, seqid=215, majorCompaction=false
2014-07-09 15:35:27,774 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/940f22d2004341eca60101f74ccca96f, isReference=false, isBulkLoadResult=false, seqid=667, majorCompaction=false
2014-07-09 15:35:27,786 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/88cf372043b447deb69a5c20225d35a2, isReference=false, isBulkLoadResult=false, seqid=1156, majorCompaction=false
2014-07-09 15:35:27,786 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/7438d9864c0244f8b3c25c6ad144aa30, isReference=false, isBulkLoadResult=false, seqid=2427, majorCompaction=false
2014-07-09 15:35:27,787 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/945d8a0c8bda4d1b9a12d134b7e0f0bb, isReference=false, isBulkLoadResult=false, seqid=833, majorCompaction=false
2014-07-09 15:35:27,824 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/9a04919087404502bfe6c4eba5bda02a, isReference=false, isBulkLoadResult=false, seqid=3499, majorCompaction=false
2014-07-09 15:35:27,828 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/745daeb873e64f6fbe5ddd254890d8f4, isReference=false, isBulkLoadResult=false, seqid=4440, majorCompaction=false
2014-07-09 15:35:27,830 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/b6cf60e71a52470a858f6581279a1ad2, isReference=false, isBulkLoadResult=false, seqid=6988, majorCompaction=false
2014-07-09 15:35:27,858 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78ef81052ff246eb824ae924968c9f72, isReference=false, isBulkLoadResult=false, seqid=5249, majorCompaction=false
2014-07-09 15:35:27,860 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a089001dfac24b6fbc30f15310be1d88, isReference=false, isBulkLoadResult=false, seqid=1165, majorCompaction=false
2014-07-09 15:35:27,866 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ba8b7bde18aa4ffebc555765bf66f030, isReference=false, isBulkLoadResult=false, seqid=5940, majorCompaction=false
2014-07-09 15:35:27,880 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/78f1642125214e94ad35e327ed169d09, isReference=false, isBulkLoadResult=false, seqid=1928, majorCompaction=false
2014-07-09 15:35:27,882 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a1ee3936ce224269b0ad70f1101de272, isReference=false, isBulkLoadResult=false, seqid=168, majorCompaction=false
2014-07-09 15:35:27,897 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/c34a25bc7b7948728840cef4b261bd8e, isReference=false, isBulkLoadResult=false, seqid=2254, majorCompaction=false
2014-07-09 15:35:27,904 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/866a7f45a026429fbcefb476ef0abbeb, isReference=false, isBulkLoadResult=false, seqid=381, majorCompaction=false
2014-07-09 15:35:27,908 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/a2776ed447e04b42b498d7ce6a1dec5d, isReference=false, isBulkLoadResult=false, seqid=1829, majorCompaction=false
2014-07-09 15:35:27,916 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/cccfdf625122409ea076c91ec5b2e474, isReference=false, isBulkLoadResult=false, seqid=9291, majorCompaction=false
2014-07-09 15:35:27,922 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/8a6ad8bbdc0a4fa4b7e1b2fe2890249b, isReference=false, isBulkLoadResult=false, seqid=2094, majorCompaction=false
2014-07-09 15:35:27,929 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b25d25c5c5814fcc84900f0ebdbd9eb0, isReference=false, isBulkLoadResult=false, seqid=2660, majorCompaction=false
2014-07-09 15:35:27,943 DEBUG [StoreOpener-ab8fe21463419a7329d4993471fedc73-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73/family/ffcf02b1c34a468fa4d9e97b554427d8, isReference=false, isBulkLoadResult=false, seqid=6463, majorCompaction=false
2014-07-09 15:35:27,946 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/90bf4fc1eb074d99ac31f7cb264a0fc3, isReference=false, isBulkLoadResult=false, seqid=9247, majorCompaction=false
2014-07-09 15:35:27,946 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/ab8fe21463419a7329d4993471fedc73
2014-07-09 15:35:27,947 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b31da402be464d17b919064e90e4ff88, isReference=false, isBulkLoadResult=false, seqid=3166, majorCompaction=false
2014-07-09 15:35:27,949 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined ab8fe21463419a7329d4993471fedc73; next sequenceid=9540
2014-07-09 15:35:27,949 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node ab8fe21463419a7329d4993471fedc73
2014-07-09 15:35:27,950 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:35:27,951 DEBUG [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:27,951 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 15:35:27,952 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 15:35:27,952 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:27,952 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:27,952 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:35:27,960 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] catalog.MetaEditor: Updated row usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. with server=slave1,60020,1404945317916
2014-07-09 15:35:27,961 INFO  [PostOpenDeployTasks:ab8fe21463419a7329d4993471fedc73] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73.
2014-07-09 15:35:27,961 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ab8fe21463419a7329d4993471fedc73 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,964 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ab8fe21463419a7329d4993471fedc73 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:27,964 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned ab8fe21463419a7329d4993471fedc73 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:27,964 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. on slave1,60020,1404945317916
2014-07-09 15:35:27,965 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 035ce5d09f7bc593b2c68d83d9f7e1cf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,969 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 035ce5d09f7bc593b2c68d83d9f7e1cf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:27,969 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 035ce5d09f7bc593b2c68d83d9f7e1cf, NAME => 'usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-09 15:35:27,970 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:35:27,970 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:35:27,973 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9b3ce23d7af3458d936d5c8f96d5b335, isReference=false, isBulkLoadResult=false, seqid=1058, majorCompaction=false
2014-07-09 15:35:27,978 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/b7fc7496c0ac4b9aa6908fb0d9325be3, isReference=false, isBulkLoadResult=false, seqid=7258, majorCompaction=false
2014-07-09 15:35:27,981 INFO  [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:27,983 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9bcc0cc80e114e7f91cf310cc12e946c, isReference=false, isBulkLoadResult=false, seqid=9558, majorCompaction=false
2014-07-09 15:35:28,008 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/bd853451573e49238354b4150264ed83, isReference=false, isBulkLoadResult=false, seqid=9457, majorCompaction=false
2014-07-09 15:35:28,010 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/9c0bc9d5660c41adafaf3fa89e8498fc, isReference=false, isBulkLoadResult=false, seqid=553, majorCompaction=false
2014-07-09 15:35:28,022 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/0d74dd1562e84da1941f0b5c30c3319b, isReference=false, isBulkLoadResult=false, seqid=7211, majorCompaction=false
2014-07-09 15:35:28,025 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/be72003e848d424dbffdfcfe14d38bd5, isReference=false, isBulkLoadResult=false, seqid=334, majorCompaction=false
2014-07-09 15:35:28,044 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a6d0dcb3442f424bae08ce3492b43b57, isReference=false, isBulkLoadResult=false, seqid=3589, majorCompaction=false
2014-07-09 15:35:28,049 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1095e9a09dac497d870a443bfd5722a1, isReference=false, isBulkLoadResult=false, seqid=1609, majorCompaction=false
2014-07-09 15:35:28,065 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/c1b3caead681423c82c89715066525fa, isReference=false, isBulkLoadResult=false, seqid=3943, majorCompaction=false
2014-07-09 15:35:28,069 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/a9746e2e85ad4d75a7e20f81b7507f29, isReference=false, isBulkLoadResult=false, seqid=2593, majorCompaction=false
2014-07-09 15:35:28,071 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/154d2021577d455f96054beecac8e33d, isReference=false, isBulkLoadResult=false, seqid=6810, majorCompaction=false
2014-07-09 15:35:28,084 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/abbf8e35ed474552a196b03dead3eb67, isReference=false, isBulkLoadResult=false, seqid=6957, majorCompaction=false
2014-07-09 15:35:28,088 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/ca222c477df44470bdacb98aa6abff3e, isReference=false, isBulkLoadResult=false, seqid=7648, majorCompaction=false
2014-07-09 15:35:28,103 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/197497afa0154e71a6c3aa991576476d, isReference=false, isBulkLoadResult=false, seqid=5668, majorCompaction=false
2014-07-09 15:35:28,106 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/b4c2b14e44b04ebe8ab2f4cd03f479b3, isReference=false, isBulkLoadResult=false, seqid=2261, majorCompaction=false
2014-07-09 15:35:28,125 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/cb5a3952d9394058be03f1bcc595b9a3, isReference=false, isBulkLoadResult=false, seqid=5566, majorCompaction=false
2014-07-09 15:35:28,127 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/bb5e9d93f30e4a7ea8ab592053ff3c9f, isReference=false, isBulkLoadResult=false, seqid=2759, majorCompaction=false
2014-07-09 15:35:28,131 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/1b6ad9f477044a2d85a2ecbd88052d5e, isReference=false, isBulkLoadResult=false, seqid=5296, majorCompaction=false
2014-07-09 15:35:28,154 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c2c3e6421ff04830b8a19fa80a587602, isReference=false, isBulkLoadResult=false, seqid=7712, majorCompaction=false
2014-07-09 15:35:28,158 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2208afad86744ef0babdfbc61054d31e, isReference=false, isBulkLoadResult=false, seqid=6063, majorCompaction=false
2014-07-09 15:35:28,158 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/d61d55a7a1d54cbfb01b97554ff9e522, isReference=false, isBulkLoadResult=false, seqid=5807, majorCompaction=false
2014-07-09 15:35:28,175 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/2dd575800bac45a8a6dd274584100dd4, isReference=false, isBulkLoadResult=false, seqid=6422, majorCompaction=false
2014-07-09 15:35:28,179 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/c586c4a03f1c482c8a565ce2dd4625a1, isReference=false, isBulkLoadResult=false, seqid=3257, majorCompaction=false
2014-07-09 15:35:28,198 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/deec67dadd40487f949a463878e35365, isReference=false, isBulkLoadResult=false, seqid=3000, majorCompaction=false
2014-07-09 15:35:28,201 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3149fc5a224343a2b005dab1ac94c314, isReference=false, isBulkLoadResult=false, seqid=2299, majorCompaction=false
2014-07-09 15:35:28,206 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/cf167e9308f94c8aae386d9fa415035d, isReference=false, isBulkLoadResult=false, seqid=5638, majorCompaction=false
2014-07-09 15:35:28,217 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/3a1338eb786a426da2979e82aa0f1e38, isReference=false, isBulkLoadResult=false, seqid=2466, majorCompaction=false
2014-07-09 15:35:28,218 DEBUG [StoreOpener-01d5d06c09b8c415be3f4fdd32569a18-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18/family/e4a331acdaa6440b84facf79fe1a142a, isReference=false, isBulkLoadResult=false, seqid=1331, majorCompaction=false
2014-07-09 15:35:28,222 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:35:28,231 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/e3f1a09502fa4ddda6bbdd199ff8507e, isReference=false, isBulkLoadResult=false, seqid=2925, majorCompaction=false
2014-07-09 15:35:28,231 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/42b687d5ca39443db5d219fe1de51773, isReference=false, isBulkLoadResult=false, seqid=8354, majorCompaction=false
2014-07-09 15:35:28,232 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 01d5d06c09b8c415be3f4fdd32569a18; next sequenceid=9559
2014-07-09 15:35:28,232 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 01d5d06c09b8c415be3f4fdd32569a18
2014-07-09 15:35:28,233 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:35:28,234 DEBUG [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:28,235 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:28,235 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:28,235 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:28,235 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:28,235 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:35:28,245 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] catalog.MetaEditor: Updated row usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. with server=slave1,60020,1404945317916
2014-07-09 15:35:28,245 INFO  [PostOpenDeployTasks:01d5d06c09b8c415be3f4fdd32569a18] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18.
2014-07-09 15:35:28,245 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 01d5d06c09b8c415be3f4fdd32569a18 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,249 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 01d5d06c09b8c415be3f4fdd32569a18 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,249 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 01d5d06c09b8c415be3f4fdd32569a18 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:28,249 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. on slave1,60020,1404945317916
2014-07-09 15:35:28,250 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning aba5d255d2a2118b681bca61272578b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:28,254 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node aba5d255d2a2118b681bca61272578b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:28,254 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => aba5d255d2a2118b681bca61272578b4, NAME => 'usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-09 15:35:28,255 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable aba5d255d2a2118b681bca61272578b4
2014-07-09 15:35:28,255 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:35:28,256 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/f03be7260d494ad6a2f185fa05498c9a, isReference=false, isBulkLoadResult=false, seqid=6645, majorCompaction=false
2014-07-09 15:35:28,258 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/431e83224a7b45e29fc34f9154f0e08c, isReference=false, isBulkLoadResult=false, seqid=9180, majorCompaction=false
2014-07-09 15:35:28,260 INFO  [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:28,271 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4a11210cc47441fba958eb36297051e6, isReference=false, isBulkLoadResult=false, seqid=1071, majorCompaction=false
2014-07-09 15:35:28,274 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdda3761a9d44fbe910da9429f808216, isReference=false, isBulkLoadResult=false, seqid=1557, majorCompaction=false
2014-07-09 15:35:28,281 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/03943dd7f0f6421a89c520c21a929949, isReference=false, isBulkLoadResult=false, seqid=2165, majorCompaction=false
2014-07-09 15:35:28,284 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4b44b3efd7514e68a1b1471898568b72, isReference=false, isBulkLoadResult=false, seqid=738, majorCompaction=false
2014-07-09 15:35:28,295 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/37762d54f1424a2895b1afa471272ff3, isReference=false, isBulkLoadResult=false, seqid=1000, majorCompaction=false
2014-07-09 15:35:28,297 DEBUG [StoreOpener-369c8092e5553636aa4ff097e825820a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a/family/fdf1ee6c516c41fbaef1b21579cebc48, isReference=false, isBulkLoadResult=false, seqid=4839, majorCompaction=false
2014-07-09 15:35:28,299 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/369c8092e5553636aa4ff097e825820a
2014-07-09 15:35:28,300 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4db80c5d4f1b4e90bcfdca2e931c2e92, isReference=false, isBulkLoadResult=false, seqid=381, majorCompaction=false
2014-07-09 15:35:28,302 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 369c8092e5553636aa4ff097e825820a; next sequenceid=9559
2014-07-09 15:35:28,302 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 369c8092e5553636aa4ff097e825820a
2014-07-09 15:35:28,304 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:35:28,304 DEBUG [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:28,304 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:28,305 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:28,305 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:28,305 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:28,305 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:35:28,306 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/3c8638ebd260448a9d141e3ae81f58ce, isReference=false, isBulkLoadResult=false, seqid=2497, majorCompaction=false
2014-07-09 15:35:28,310 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/4f65e84dd18d488db47ece11cfacb38b, isReference=false, isBulkLoadResult=false, seqid=9560, majorCompaction=false
2014-07-09 15:35:28,313 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] catalog.MetaEditor: Updated row usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. with server=slave1,60020,1404945317916
2014-07-09 15:35:28,313 INFO  [PostOpenDeployTasks:369c8092e5553636aa4ff097e825820a] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a.
2014-07-09 15:35:28,314 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 369c8092e5553636aa4ff097e825820a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,317 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 369c8092e5553636aa4ff097e825820a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,317 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 369c8092e5553636aa4ff097e825820a to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:28,317 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. on slave1,60020,1404945317916
2014-07-09 15:35:28,317 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e20ad9e2278dfb99d0d4ac9b665b26ed from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:28,321 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e20ad9e2278dfb99d0d4ac9b665b26ed from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-09 15:35:28,321 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e20ad9e2278dfb99d0d4ac9b665b26ed, NAME => 'usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-09 15:35:28,322 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:35:28,322 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:35:28,323 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/49c3ac6d115a4e39bb6eb20cc3f5eaa9, isReference=false, isBulkLoadResult=false, seqid=5165, majorCompaction=false
2014-07-09 15:35:28,326 INFO  [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-09 15:35:28,332 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/506cc662f38d4f21b29f0c0b4d446450, isReference=false, isBulkLoadResult=false, seqid=1276, majorCompaction=false
2014-07-09 15:35:28,342 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/5c8598ea061942b1928f8848199f9c39, isReference=false, isBulkLoadResult=false, seqid=2997, majorCompaction=false
2014-07-09 15:35:28,352 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/63c2cdad2bfd455ba712a760537b7ed2, isReference=false, isBulkLoadResult=false, seqid=7631, majorCompaction=false
2014-07-09 15:35:28,353 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/561c77e552b247458d819ee298aed3f9, isReference=false, isBulkLoadResult=false, seqid=3628, majorCompaction=false
2014-07-09 15:35:28,355 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/208e3e5e2d404804817262a25615b194, isReference=false, isBulkLoadResult=false, seqid=3982, majorCompaction=false
2014-07-09 15:35:28,363 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/66d4bbac260b41bea450fbff446c779c, isReference=false, isBulkLoadResult=false, seqid=6818, majorCompaction=false
2014-07-09 15:35:28,368 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/22c2050298454f028a2869fdd84f396d, isReference=false, isBulkLoadResult=false, seqid=6232, majorCompaction=false
2014-07-09 15:35:28,369 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/67a0ae57387641b5813b3d6052058311, isReference=false, isBulkLoadResult=false, seqid=904, majorCompaction=false
2014-07-09 15:35:28,375 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6aa0d3baa1c54f95b658abb84b0e2aa1, isReference=false, isBulkLoadResult=false, seqid=7198, majorCompaction=false
2014-07-09 15:35:28,381 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/23fc57266e274a1cba3489e47b3a985f, isReference=false, isBulkLoadResult=false, seqid=1882, majorCompaction=false
2014-07-09 15:35:28,383 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/70356b511997474182a98d7d4700abad, isReference=false, isBulkLoadResult=false, seqid=2964, majorCompaction=false
2014-07-09 15:35:28,386 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6b632d2e6a214852b3d0d153f830674d, isReference=false, isBulkLoadResult=false, seqid=2665, majorCompaction=false
2014-07-09 15:35:28,395 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/3475e54300e64c65b1c4504cc0b2f8a5, isReference=false, isBulkLoadResult=false, seqid=2381, majorCompaction=false
2014-07-09 15:35:28,403 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/746cbd3cb1ea4c46bfbcbbd537222525, isReference=false, isBulkLoadResult=false, seqid=8411, majorCompaction=false
2014-07-09 15:35:28,411 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/6f0c39bfd41d4d42a986d02c7298a22d, isReference=false, isBulkLoadResult=false, seqid=5806, majorCompaction=false
2014-07-09 15:35:28,424 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/49180e1a5f25478f9d72d9d3515f732d, isReference=false, isBulkLoadResult=false, seqid=5807, majorCompaction=false
2014-07-09 15:35:28,425 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/791444f716504dcba7cf3daf7a7fddbf, isReference=false, isBulkLoadResult=false, seqid=7196, majorCompaction=false
2014-07-09 15:35:28,446 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/710403c5744a49dba8a85b9a95115101, isReference=false, isBulkLoadResult=false, seqid=666, majorCompaction=false
2014-07-09 15:35:28,448 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/496540bc85934cf29db67c59937e7772, isReference=false, isBulkLoadResult=false, seqid=681, majorCompaction=false
2014-07-09 15:35:28,453 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/8714aa33d6524622be56b9e3f66d973a, isReference=false, isBulkLoadResult=false, seqid=564, majorCompaction=false
2014-07-09 15:35:28,511 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7548f4182b884ddea62d8abd638180e6, isReference=false, isBulkLoadResult=false, seqid=1498, majorCompaction=false
2014-07-09 15:35:28,520 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/550d6f2093a34b7eae2f956724a58ad5, isReference=false, isBulkLoadResult=false, seqid=2048, majorCompaction=false
2014-07-09 15:35:28,531 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5558a2883ab14492be041a968ad6f83f, isReference=false, isBulkLoadResult=false, seqid=168, majorCompaction=false
2014-07-09 15:35:28,532 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/93f5add43dbd4e44be70c6827e8ee8fa, isReference=false, isBulkLoadResult=false, seqid=215, majorCompaction=false
2014-07-09 15:35:28,532 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/77dd2d11972b4a3fa96682a1a208bda7, isReference=false, isBulkLoadResult=false, seqid=2831, majorCompaction=false
2014-07-09 15:35:28,546 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/5585f20c9f4747c28568ee5dc68c2eea, isReference=false, isBulkLoadResult=false, seqid=8236, majorCompaction=false
2014-07-09 15:35:28,549 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/962fa5757d8342cfacaf29b328caf2e2, isReference=false, isBulkLoadResult=false, seqid=2798, majorCompaction=false
2014-07-09 15:35:28,550 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7a896ae50a7149a8bc850b4040f067fa, isReference=false, isBulkLoadResult=false, seqid=8398, majorCompaction=false
2014-07-09 15:35:28,568 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/68e4007c0c33452baa619be755cddd23, isReference=false, isBulkLoadResult=false, seqid=7469, majorCompaction=false
2014-07-09 15:35:28,571 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7b68ba0ed05845c4861702ba44c0fdd3, isReference=false, isBulkLoadResult=false, seqid=1166, majorCompaction=false
2014-07-09 15:35:28,583 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/a50b9e861fb84b5191c4b29efaff27ea, isReference=false, isBulkLoadResult=false, seqid=4065, majorCompaction=false
2014-07-09 15:35:28,587 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/74c2830e285c48d29fb7420af60f9696, isReference=false, isBulkLoadResult=false, seqid=8621, majorCompaction=false
2014-07-09 15:35:28,588 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/7e85b0ece7f34954baf6230f4d52857e, isReference=false, isBulkLoadResult=false, seqid=333, majorCompaction=false
2014-07-09 15:35:28,605 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/af621bc752664213b0072000ac3deae0, isReference=false, isBulkLoadResult=false, seqid=1942, majorCompaction=false
2014-07-09 15:35:28,609 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/7cdd2d9fc3a6450c8492d381d0e5a74c, isReference=false, isBulkLoadResult=false, seqid=848, majorCompaction=false
2014-07-09 15:35:28,622 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8271ba93a5d241528cf75694a3c094eb, isReference=false, isBulkLoadResult=false, seqid=6194, majorCompaction=false
2014-07-09 15:35:28,626 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf2f24f17e0646fcaf6ed406108f9ba9, isReference=false, isBulkLoadResult=false, seqid=3462, majorCompaction=false
2014-07-09 15:35:28,637 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/84299acf06664702861c9f9e62bd688b, isReference=false, isBulkLoadResult=false, seqid=4790, majorCompaction=false
2014-07-09 15:35:28,639 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/82b92dfa731f41bfbbeef151c1d0f8c7, isReference=false, isBulkLoadResult=false, seqid=9151, majorCompaction=false
2014-07-09 15:35:28,642 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/bf6575b4a0b943149b664b2cfc44d1f7, isReference=false, isBulkLoadResult=false, seqid=8007, majorCompaction=false
2014-07-09 15:35:28,649 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/87ca59cb96c14d038a95ae4c090a74c1, isReference=false, isBulkLoadResult=false, seqid=1716, majorCompaction=false
2014-07-09 15:35:28,652 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/8c3e575943d0401392f8a6a935b193ad, isReference=false, isBulkLoadResult=false, seqid=9558, majorCompaction=false
2014-07-09 15:35:28,664 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1ec0c2b1a714bbd8355ab24bbb9a4b7, isReference=false, isBulkLoadResult=false, seqid=1442, majorCompaction=false
2014-07-09 15:35:28,665 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/92574d98e3b54570bdfe0c4d867de3c3, isReference=false, isBulkLoadResult=false, seqid=2547, majorCompaction=false
2014-07-09 15:35:28,668 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9208b2140d9948be8bd0fa21eafe29de, isReference=false, isBulkLoadResult=false, seqid=9561, majorCompaction=false
2014-07-09 15:35:28,679 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c1fc0788e43940778409efaf14423d33, isReference=false, isBulkLoadResult=false, seqid=3130, majorCompaction=false
2014-07-09 15:35:28,686 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9c9fc27b1e2743308b0d5b652418ed70, isReference=false, isBulkLoadResult=false, seqid=5202, majorCompaction=false
2014-07-09 15:35:28,692 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/950865660c4c446a832a492e0840177f, isReference=false, isBulkLoadResult=false, seqid=6178, majorCompaction=false
2014-07-09 15:35:28,703 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c6f6d0fc881f413e9154e19bbe0de7e1, isReference=false, isBulkLoadResult=false, seqid=8783, majorCompaction=false
2014-07-09 15:35:28,708 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/9dce6f0a454f4e35a64f215955110def, isReference=false, isBulkLoadResult=false, seqid=1384, majorCompaction=false
2014-07-09 15:35:28,718 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/9bd713b234394c0dbe374350e17d5eb3, isReference=false, isBulkLoadResult=false, seqid=1998, majorCompaction=false
2014-07-09 15:35:28,723 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/c7424b6594374a34909f224c11c018c0, isReference=false, isBulkLoadResult=false, seqid=1775, majorCompaction=false
2014-07-09 15:35:28,731 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a1bd9b1daefb4437ba965c402dd278d2, isReference=false, isBulkLoadResult=false, seqid=7851, majorCompaction=false
2014-07-09 15:35:28,739 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/a8cf6f7dfc6f4724b4e13fa1c7f0e1bb, isReference=false, isBulkLoadResult=false, seqid=1332, majorCompaction=false
2014-07-09 15:35:28,742 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/cc8e89fc604941b5879893af546fde53, isReference=false, isBulkLoadResult=false, seqid=3296, majorCompaction=false
2014-07-09 15:35:28,744 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a2c23fb613424727a1b1c14c5f0e4e06, isReference=false, isBulkLoadResult=false, seqid=502, majorCompaction=false
2014-07-09 15:35:28,764 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d267737501f74c688f236345f56875ad, isReference=false, isBulkLoadResult=false, seqid=4493, majorCompaction=false
2014-07-09 15:35:28,770 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ab6f1f93c904477183599a8b59aca50c, isReference=false, isBulkLoadResult=false, seqid=4752, majorCompaction=false
2014-07-09 15:35:28,776 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a58fcbde017f42f4a0871c3ea161b62e, isReference=false, isBulkLoadResult=false, seqid=9035, majorCompaction=false
2014-07-09 15:35:28,784 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/d8d6e73fcef84af596235bd9c5f27fa8, isReference=false, isBulkLoadResult=false, seqid=2108, majorCompaction=false
2014-07-09 15:35:28,798 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/a59e6098efcb4ae98eb7ffea10b096cf, isReference=false, isBulkLoadResult=false, seqid=9436, majorCompaction=false
2014-07-09 15:35:28,806 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ace63e71a2ec41e384ba55aed5bd9f97, isReference=false, isBulkLoadResult=false, seqid=5571, majorCompaction=false
2014-07-09 15:35:28,811 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/dd7b32bb51da4a2488864193a80789a7, isReference=false, isBulkLoadResult=false, seqid=2632, majorCompaction=false
2014-07-09 15:35:28,823 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/abbe5621b9c64fe192f2e46b42891f71, isReference=false, isBulkLoadResult=false, seqid=1014, majorCompaction=false
2014-07-09 15:35:28,826 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/be28ed9c7dec408fbfdc0fe9ae002cac, isReference=false, isBulkLoadResult=false, seqid=3329, majorCompaction=false
2014-07-09 15:35:28,856 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b1e9e459177a4ab9836fef1a9e1261d7, isReference=false, isBulkLoadResult=false, seqid=4398, majorCompaction=false
2014-07-09 15:35:28,860 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/f219e2768942423489ca3df22a6d2b1a, isReference=false, isBulkLoadResult=false, seqid=4894, majorCompaction=false
2014-07-09 15:35:28,872 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/b6fa10283cae4fe6a6c921de50c6556f, isReference=false, isBulkLoadResult=false, seqid=3211, majorCompaction=false
2014-07-09 15:35:28,874 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/beca9b70e6ee445ea25d73c755388298, isReference=false, isBulkLoadResult=false, seqid=3940, majorCompaction=false
2014-07-09 15:35:28,875 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/fb96da48d405489dbf68c655d5a04f11, isReference=false, isBulkLoadResult=false, seqid=9519, majorCompaction=false
2014-07-09 15:35:28,889 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/c9a0e09b4db24628a5e1c395cd782a76, isReference=false, isBulkLoadResult=false, seqid=834, majorCompaction=false
2014-07-09 15:35:28,893 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c0e17bb55aa24c1394f627769dc59788, isReference=false, isBulkLoadResult=false, seqid=3543, majorCompaction=false
2014-07-09 15:35:28,894 DEBUG [StoreOpener-035ce5d09f7bc593b2c68d83d9f7e1cf-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf/family/ff3c72fb64ed45059c9fd44d5696f9a9, isReference=false, isBulkLoadResult=false, seqid=7598, majorCompaction=false
2014-07-09 15:35:28,901 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:35:28,904 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/ccced78695f84d3690c3e35010e69639, isReference=false, isBulkLoadResult=false, seqid=3495, majorCompaction=false
2014-07-09 15:35:28,907 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 035ce5d09f7bc593b2c68d83d9f7e1cf; next sequenceid=9561
2014-07-09 15:35:28,907 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 035ce5d09f7bc593b2c68d83d9f7e1cf
2014-07-09 15:35:28,909 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:35:28,909 DEBUG [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:28,910 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 39 store files, 0 compacting, 39 eligible, 20 blocking
2014-07-09 15:35:28,910 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 39 files from compaction candidates
2014-07-09 15:35:28,910 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:28,910 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:28,911 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:35:28,918 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] catalog.MetaEditor: Updated row usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. with server=slave1,60020,1404945317916
2014-07-09 15:35:28,918 INFO  [PostOpenDeployTasks:035ce5d09f7bc593b2c68d83d9f7e1cf] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf.
2014-07-09 15:35:28,919 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 035ce5d09f7bc593b2c68d83d9f7e1cf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,922 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 035ce5d09f7bc593b2c68d83d9f7e1cf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:28,922 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 035ce5d09f7bc593b2c68d83d9f7e1cf to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:28,922 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. on slave1,60020,1404945317916
2014-07-09 15:35:28,930 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/c31ca82fa5174080bf5bdc9617a89223, isReference=false, isBulkLoadResult=false, seqid=2215, majorCompaction=false
2014-07-09 15:35:28,933 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/cd257740e02048a7b094e5b555a99da9, isReference=false, isBulkLoadResult=false, seqid=4356, majorCompaction=false
2014-07-09 15:35:28,954 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/dd34bdfd00ad4dab8bf4555a4c38fc11, isReference=false, isBulkLoadResult=false, seqid=335, majorCompaction=false
2014-07-09 15:35:28,958 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d34e3ad8633249edae470500cc66f3c2, isReference=false, isBulkLoadResult=false, seqid=1664, majorCompaction=false
2014-07-09 15:35:28,982 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/de5f50185780423680ea0cd4ac5ffe7b, isReference=false, isBulkLoadResult=false, seqid=6642, majorCompaction=false
2014-07-09 15:35:28,986 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d364bc312adb45fca0136b9dc28d9cc3, isReference=false, isBulkLoadResult=false, seqid=500, majorCompaction=false
2014-07-09 15:35:29,015 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df73698b7e134d3bb08f42c73ab6fde6, isReference=false, isBulkLoadResult=false, seqid=3377, majorCompaction=false
2014-07-09 15:35:29,019 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d4c193d361914d3f8af9778ec13bc4f0, isReference=false, isBulkLoadResult=false, seqid=8025, majorCompaction=false
2014-07-09 15:35:29,040 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/df818ae84cab4512a1fa934b40e11f72, isReference=false, isBulkLoadResult=false, seqid=9558, majorCompaction=false
2014-07-09 15:35:29,042 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d60be0a9b3fa469dac33073d252570cc, isReference=false, isBulkLoadResult=false, seqid=8745, majorCompaction=false
2014-07-09 15:35:29,070 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e097fa95a140410fb6bd1c2aa93f8b84, isReference=false, isBulkLoadResult=false, seqid=3045, majorCompaction=false
2014-07-09 15:35:29,074 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d679777569084c3cb81ea37d4c24f3a4, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-09 15:35:29,113 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e5f47425fdec4e1787653103eada5180, isReference=false, isBulkLoadResult=false, seqid=1217, majorCompaction=false
2014-07-09 15:35:29,117 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/d67ddca54aa64393a75a1607309e8f5e, isReference=false, isBulkLoadResult=false, seqid=2331, majorCompaction=false
2014-07-09 15:35:29,146 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/e9c84ec1f1dd4271a6b0d6644d50bed2, isReference=false, isBulkLoadResult=false, seqid=2713, majorCompaction=false
2014-07-09 15:35:29,150 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/da8f56c9f94444d69163b9c854f6e271, isReference=false, isBulkLoadResult=false, seqid=3163, majorCompaction=false
2014-07-09 15:35:29,175 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f5643379e02549b6bf7a58c1649fd7b0, isReference=false, isBulkLoadResult=false, seqid=6997, majorCompaction=false
2014-07-09 15:35:29,179 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/dcd2782001f34a1a9f19c458548bbbc5, isReference=false, isBulkLoadResult=false, seqid=7216, majorCompaction=false
2014-07-09 15:35:29,210 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/f83c5a8e17124d18b70638b6af726628, isReference=false, isBulkLoadResult=false, seqid=1550, majorCompaction=false
2014-07-09 15:35:29,221 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/e633845284bb453bb5014dc55a5ef078, isReference=false, isBulkLoadResult=false, seqid=5805, majorCompaction=false
2014-07-09 15:35:29,259 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fa13366e41ae45bc9d9719ff74e4804a, isReference=false, isBulkLoadResult=false, seqid=5607, majorCompaction=false
2014-07-09 15:35:29,262 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/eed6e63c8b564094a4a591ff671ad457, isReference=false, isBulkLoadResult=false, seqid=5736, majorCompaction=false
2014-07-09 15:35:29,295 DEBUG [StoreOpener-e20ad9e2278dfb99d0d4ac9b665b26ed-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed/family/fb586941fcd3470ea8421c95bad5ec4c, isReference=false, isBulkLoadResult=false, seqid=2879, majorCompaction=false
2014-07-09 15:35:29,300 DEBUG [StoreOpener-aba5d255d2a2118b681bca61272578b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4/family/f19f26ee11164aacae079c3d6a3eb703, isReference=false, isBulkLoadResult=false, seqid=1832, majorCompaction=false
2014-07-09 15:35:29,304 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:35:29,306 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/aba5d255d2a2118b681bca61272578b4
2014-07-09 15:35:29,308 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e20ad9e2278dfb99d0d4ac9b665b26ed; next sequenceid=9559
2014-07-09 15:35:29,308 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e20ad9e2278dfb99d0d4ac9b665b26ed
2014-07-09 15:35:29,309 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:35:29,310 DEBUG [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:29,310 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:29,311 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:29,311 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:29,311 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:29,311 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:35:29,317 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] catalog.MetaEditor: Updated row usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. with server=slave1,60020,1404945317916
2014-07-09 15:35:29,317 INFO  [PostOpenDeployTasks:e20ad9e2278dfb99d0d4ac9b665b26ed] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed.
2014-07-09 15:35:29,318 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e20ad9e2278dfb99d0d4ac9b665b26ed from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:29,321 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e20ad9e2278dfb99d0d4ac9b665b26ed from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:29,321 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e20ad9e2278dfb99d0d4ac9b665b26ed to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:29,321 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. on slave1,60020,1404945317916
2014-07-09 15:35:29,347 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined aba5d255d2a2118b681bca61272578b4; next sequenceid=9562
2014-07-09 15:35:29,347 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node aba5d255d2a2118b681bca61272578b4
2014-07-09 15:35:29,348 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:35:29,349 DEBUG [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:29,349 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-09 15:35:29,350 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-09 15:35:29,350 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:29,350 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:29,350 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:35:29,355 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] catalog.MetaEditor: Updated row usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. with server=slave1,60020,1404945317916
2014-07-09 15:35:29,356 INFO  [PostOpenDeployTasks:aba5d255d2a2118b681bca61272578b4] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4.
2014-07-09 15:35:29,357 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning aba5d255d2a2118b681bca61272578b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:29,362 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1471d443fb70001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node aba5d255d2a2118b681bca61272578b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-09 15:35:29,362 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned aba5d255d2a2118b681bca61272578b4 to OPENED in zk on slave1,60020,1404945317916
2014-07-09 15:35:29,363 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. on slave1,60020,1404945317916
2014-07-09 15:35:31,669 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-09 15:35:31,669 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-09 15:35:31,670 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 20 files from compaction candidates
2014-07-09 15:35:31,670 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-09 15:35:31,670 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,671 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,671 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:35:31,671 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user9,1404941702023.ab8fe21463419a7329d4993471fedc73. because compaction request was cancelled
2014-07-09 15:35:31,671 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-09 15:35:31,671 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-09 15:35:31,672 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-09 15:35:31,672 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,672 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-09 15:35:31,672 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,672 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-09 15:35:31,672 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user2,1404941702023.fa2ab9ffb0b5a85ad4c1c3400a6b6d39. because compaction request was cancelled
2014-07-09 15:35:31,672 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-09 15:35:31,673 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 39 store files, 0 compacting, 39 eligible, 20 blocking
2014-07-09 15:35:31,673 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-09 15:35:31,673 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 39 files from compaction candidates
2014-07-09 15:35:31,673 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,673 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,673 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-09 15:35:31,673 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user8,1404941702023.035ce5d09f7bc593b2c68d83d9f7e1cf. because compaction request was cancelled
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user4,1404941702023.aba5d255d2a2118b681bca61272578b4. because compaction request was cancelled
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 38 store files, 0 compacting, 38 eligible, 20 blocking
2014-07-09 15:35:31,674 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 38 files from compaction candidates
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user6,1404941702023.0e294e1cc84fff4243a9d24c11e9bc8d. because compaction request was cancelled
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user1,1404941702023.01d5d06c09b8c415be3f4fdd32569a18. because compaction request was cancelled
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user5,1404941702023.369c8092e5553636aa4ff097e825820a. because compaction request was cancelled
2014-07-09 15:35:31,675 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user3,1404941702023.e20ad9e2278dfb99d0d4ac9b665b26ed. because compaction request was cancelled
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Selecting compaction from 37 store files, 0 compacting, 37 eligible, 20 blocking
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 37 files from compaction candidates
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-09 15:35:31,676 DEBUG [regionserver60020-smallCompactions-1404945327248] regionserver.CompactSplitThread: Not compacting usertable,user7,1404941702023.0cec477330d16ea60f6b986e45ac1516. because compaction request was cancelled
2014-07-09 15:35:32,124 INFO  [RpcServer.handler=25,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:32,138 INFO  [RpcServer.handler=33,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:32,138 INFO  [RpcServer.handler=34,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:32,139 INFO  [RpcServer.handler=45,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:32,883 INFO  [RpcServer.handler=22,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:32,883 INFO  [RpcServer.handler=21,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:34,216 INFO  [RpcServer.handler=28,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:34,216 INFO  [RpcServer.handler=33,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:34,650 INFO  [RpcServer.handler=38,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:34,650 INFO  [RpcServer.handler=19,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:38,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:35:38,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945321572 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945338238
2014-07-09 15:35:38,781 INFO  [RpcServer.handler=27,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:38,781 INFO  [RpcServer.handler=31,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-09 15:35:43,056 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:35:43,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945338238 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945343057
2014-07-09 15:35:48,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:35:48,128 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945343057 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945348108
2014-07-09 15:35:52,171 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:35:52,193 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945348108 with entries=85, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945352171
2014-07-09 15:35:56,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:35:56,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 420 synced till here 419
2014-07-09 15:35:56,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945352171 with entries=86, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945356365
2014-07-09 15:36:01,471 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:36:01,491 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 522 synced till here 521
2014-07-09 15:36:01,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945356365 with entries=102, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945361472
2014-07-09 15:36:05,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:36:05,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945361472 with entries=96, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945365894
2014-07-09 15:36:11,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-09 15:36:12,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945365894 with entries=113, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404945317916/slave1%2C60020%2C1404945317916.1404945371848
