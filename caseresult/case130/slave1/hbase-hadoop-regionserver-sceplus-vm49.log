Mon Jul 14 01:51:08 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-14 01:51:09,514 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-14 01:51:09,515 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-14 01:51:09,515 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-14 01:51:09,745 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-14 01:51:09,745 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-14 01:51:09,745 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 56679 22
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-14 01:51:09,746 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 56679 9.1.143.59 22
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-14 01:51:09,747 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-14 01:51:09,749 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=956
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-14 01:51:09,750 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-14 01:51:09,751 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-14 01:51:09,751 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-14 01:51:09,751 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-14 01:51:09,753 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-14 01:51:09,754 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-14 01:51:09,983 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-14 01:51:10,410 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-14 01:51:10,508 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-14 01:51:10,522 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-14 01:51:10,586 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-14 01:51:10,587 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-14 01:51:10,587 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-14 01:51:10,593 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-14 01:51:10,597 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-14 01:51:10,684 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-14 01:51:10,684 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-14 01:51:10,688 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-14 01:51:10,691 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-14 01:51:10,766 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-14 01:51:10,823 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-14 01:51:10,833 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-14 01:51:10,834 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-14 01:51:10,834 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-14 01:51:10,835 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-14 01:51:11,143 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-14 01:51:11,192 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-14 01:51:11,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-14 01:51:11,196 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 01:51:11,226 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 01:51:11,229 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 01:51:11,232 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 01:51:11,242 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14734118bbb0001, negotiated timeout = 90000
2014-07-14 01:51:43,030 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x7aac7212, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 01:51:43,032 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x7aac7212 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 01:51:43,032 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 01:51:43,032 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 01:51:43,059 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14734118bbb0003, negotiated timeout = 90000
2014-07-14 01:51:43,338 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3c646cd6
2014-07-14 01:51:43,341 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-14 01:51:43,346 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-14 01:51:43,361 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-14 01:51:43,396 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-14 01:51:43,403 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-14 01:51:43,407 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-14 01:51:43,424 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405327868908 with port=60020, startcode=1405327870609
2014-07-14 01:51:43,783 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-14 01:51:43,783 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-14 01:51:43,783 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-14 01:51:43,813 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-14 01:51:43,822 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609
2014-07-14 01:51:43,863 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-14 01:51:43,876 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-14 01:51:43,980 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405327903885
2014-07-14 01:51:43,995 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-14 01:51:43,999 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-14 01:51:44,003 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-14 01:51:44,007 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-14 01:51:44,010 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-14 01:51:44,010 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-14 01:51:44,010 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-14 01:51:44,010 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-14 01:51:44,011 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-14 01:51:44,017 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1405327870787, slave1,60020,1405327870609] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1405327870787, slave1,60020,1405327870609]
2014-07-14 01:51:44,039 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-14 01:51:44,041 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x772a025f, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 01:51:44,042 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x772a025f connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 01:51:44,042 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 01:51:44,043 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 01:51:44,047 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14734118bbb0005, negotiated timeout = 90000
2014-07-14 01:51:44,054 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-14 01:51:44,054 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-14 01:51:44,098 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405327870609, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x14734118bbb0001
2014-07-14 01:51:44,098 INFO  [SplitLogWorker-slave1,60020,1405327870609] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405327870609 starting
2014-07-14 01:51:44,099 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-14 01:51:44,099 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405327870609
2014-07-14 01:51:44,099 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405327870609'
2014-07-14 01:51:44,099 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-14 01:51:44,100 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-14 01:51:44,101 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-14 01:51:48,768 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:51:48,925 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 81e87aad5a4de9db5f0ddb9df4d4ccdb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,925 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:51:48,925 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:51:48,927 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6e2bf74487f61672cd8bc06d8b34f003 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,928 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:51:48,928 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5d5cc6db1bf5bd9142b4d4e667bac72 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,928 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 01:51:48,939 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:51:48,952 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6e2bf74487f61672cd8bc06d8b34f003 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,953 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 81e87aad5a4de9db5f0ddb9df4d4ccdb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,953 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5d5cc6db1bf5bd9142b4d4e667bac72 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:48,969 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 81e87aad5a4de9db5f0ddb9df4d4ccdb, NAME => 'usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-14 01:51:48,969 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => d5d5cc6db1bf5bd9142b4d4e667bac72, NAME => 'usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-14 01:51:48,969 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 6e2bf74487f61672cd8bc06d8b34f003, NAME => 'usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-14 01:51:48,995 INFO  [RS_OPEN_REGION-slave1:60020-1] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-14 01:51:48,996 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 6e2bf74487f61672cd8bc06d8b34f003
2014-07-14 01:51:48,996 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 81e87aad5a4de9db5f0ddb9df4d4ccdb
2014-07-14 01:51:48,996 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d5d5cc6db1bf5bd9142b4d4e667bac72
2014-07-14 01:51:48,997 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:51:48,997 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:51:48,997 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:51:49,006 INFO  [RS_OPEN_REGION-slave1:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-14 01:51:49,008 INFO  [RS_OPEN_REGION-slave1:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-14 01:51:49,011 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-14 01:51:49,011 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-14 01:51:49,012 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-14 01:51:49,084 INFO  [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 01:51:49,084 INFO  [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 01:51:49,092 INFO  [StoreOpener-81e87aad5a4de9db5f0ddb9df4d4ccdb-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 01:51:49,124 INFO  [StoreOpener-81e87aad5a4de9db5f0ddb9df4d4ccdb-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-14 01:51:49,138 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/81e87aad5a4de9db5f0ddb9df4d4ccdb
2014-07-14 01:51:49,143 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 81e87aad5a4de9db5f0ddb9df4d4ccdb; next sequenceid=1
2014-07-14 01:51:49,143 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 81e87aad5a4de9db5f0ddb9df4d4ccdb
2014-07-14 01:51:49,146 INFO  [PostOpenDeployTasks:81e87aad5a4de9db5f0ddb9df4d4ccdb] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:51:49,242 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-14 01:51:49,242 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-14 01:51:49,263 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/0b9693f360454f25baf1d38133206e9c, isReference=false, isBulkLoadResult=false, seqid=3845, majorCompaction=false
2014-07-14 01:51:49,263 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/030191f9474449e987556ad6437d01f8, isReference=false, isBulkLoadResult=false, seqid=10215, majorCompaction=false
2014-07-14 01:51:49,290 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/0fc322baa6824c12b8ad63ef14d2ad05, isReference=false, isBulkLoadResult=false, seqid=5139, majorCompaction=false
2014-07-14 01:51:49,297 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/03af0c61fd3440e0b5acebda2a31d26a, isReference=false, isBulkLoadResult=false, seqid=4135, majorCompaction=false
2014-07-14 01:51:49,331 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/1338e268c9be4ef1ab9df3ab2ce38fcd, isReference=false, isBulkLoadResult=false, seqid=2553, majorCompaction=false
2014-07-14 01:51:49,359 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/0753de3abee2415ca8a05b8475d2451b, isReference=false, isBulkLoadResult=false, seqid=1187, majorCompaction=false
2014-07-14 01:51:49,365 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/1392d596d97d4b06a5708f39abd8772f, isReference=false, isBulkLoadResult=false, seqid=13036, majorCompaction=false
2014-07-14 01:51:49,396 INFO  [PostOpenDeployTasks:81e87aad5a4de9db5f0ddb9df4d4ccdb] catalog.MetaEditor: Updated row usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb. with server=slave1,60020,1405327870609
2014-07-14 01:51:49,397 INFO  [PostOpenDeployTasks:81e87aad5a4de9db5f0ddb9df4d4ccdb] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:51:49,397 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/0942fcfb90f34fb69d5c5d9eb6437603, isReference=false, isBulkLoadResult=false, seqid=8976, majorCompaction=false
2014-07-14 01:51:49,397 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 81e87aad5a4de9db5f0ddb9df4d4ccdb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:49,402 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 81e87aad5a4de9db5f0ddb9df4d4ccdb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:49,402 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 81e87aad5a4de9db5f0ddb9df4d4ccdb to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:49,402 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb. on slave1,60020,1405327870609
2014-07-14 01:51:49,403 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5c4e1ff5b6b7753b9fecbe9b697bf45 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:49,403 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/1880eec90d13436aa5eecb11b006f537, isReference=false, isBulkLoadResult=false, seqid=730, majorCompaction=false
2014-07-14 01:51:49,411 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5c4e1ff5b6b7753b9fecbe9b697bf45 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:49,411 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => b5c4e1ff5b6b7753b9fecbe9b697bf45, NAME => 'usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-14 01:51:49,413 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b5c4e1ff5b6b7753b9fecbe9b697bf45
2014-07-14 01:51:49,413 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:51:49,420 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/095ca09c2a8749e59c31449cb7839e67, isReference=false, isBulkLoadResult=false, seqid=11542, majorCompaction=false
2014-07-14 01:51:49,427 INFO  [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 01:51:49,444 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/18c5e06d94114d1aa5eadd9b135d46f3, isReference=false, isBulkLoadResult=false, seqid=2281, majorCompaction=false
2014-07-14 01:51:49,451 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/09997fea27ee4ca69ba813d8d9e16ab0, isReference=false, isBulkLoadResult=false, seqid=13367, majorCompaction=false
2014-07-14 01:51:49,468 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/24da4f3746d24033976b612a0f276673, isReference=false, isBulkLoadResult=false, seqid=2868, majorCompaction=false
2014-07-14 01:51:49,470 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/1942ed93a451437ba93c349e0de62c6b, isReference=false, isBulkLoadResult=false, seqid=4972, majorCompaction=false
2014-07-14 01:51:49,492 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/35b8da31a59d4896b55dbd568eb5f424, isReference=false, isBulkLoadResult=false, seqid=13913, majorCompaction=false
2014-07-14 01:51:49,501 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/0b7565883a7e49ad86423c26058ea11d, isReference=false, isBulkLoadResult=false, seqid=544, majorCompaction=false
2014-07-14 01:51:49,512 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/1f97128584064f68bead373a2675d8a3, isReference=false, isBulkLoadResult=false, seqid=1532, majorCompaction=false
2014-07-14 01:51:49,520 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/3dd13f6e2f3a47b08512d7bd11a73d9f, isReference=false, isBulkLoadResult=false, seqid=7375, majorCompaction=false
2014-07-14 01:51:49,538 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/465c3809e5f34467a3ba005345029d22, isReference=false, isBulkLoadResult=false, seqid=715, majorCompaction=false
2014-07-14 01:51:49,544 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/282a4b7152e1468ab69e997f4d9e20e9, isReference=false, isBulkLoadResult=false, seqid=2941, majorCompaction=false
2014-07-14 01:51:49,561 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/0e52cfa28e5e460ba2dbf1154af6448c, isReference=false, isBulkLoadResult=false, seqid=12610, majorCompaction=false
2014-07-14 01:51:49,569 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/4816b678320946628ed897d109804c4e, isReference=false, isBulkLoadResult=false, seqid=10378, majorCompaction=false
2014-07-14 01:51:49,572 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/2c59de86ab9943adada3742b5ab9854a, isReference=false, isBulkLoadResult=false, seqid=17299, majorCompaction=false
2014-07-14 01:51:49,589 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/1656345618e04fb393cd83fb5a40b619, isReference=false, isBulkLoadResult=false, seqid=11896, majorCompaction=false
2014-07-14 01:51:49,597 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/2ed20dd26f5a452cb0c67d45083d51b5, isReference=false, isBulkLoadResult=false, seqid=19070, majorCompaction=false
2014-07-14 01:51:49,600 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/486364407d2e45ea81c727ffb16ca7d6, isReference=false, isBulkLoadResult=false, seqid=3912, majorCompaction=false
2014-07-14 01:51:49,624 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/28216b81975f47fd8670a1a57a946d8e, isReference=false, isBulkLoadResult=false, seqid=2444, majorCompaction=false
2014-07-14 01:51:49,628 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/467fd1e4aa984a07a894d6c39ffb2413, isReference=false, isBulkLoadResult=false, seqid=11053, majorCompaction=false
2014-07-14 01:51:49,643 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/5898fcd43b7b44a8bcf3e5e5a000b6cc, isReference=false, isBulkLoadResult=false, seqid=1910, majorCompaction=false
2014-07-14 01:51:49,657 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/4769da1df81c47e399d465797e4019cd, isReference=false, isBulkLoadResult=false, seqid=7789, majorCompaction=false
2014-07-14 01:51:49,661 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/2bc5562d8cfb4e5799b21cae9148a9eb, isReference=false, isBulkLoadResult=false, seqid=3454, majorCompaction=false
2014-07-14 01:51:49,668 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/5f9df6c9e3314a749fc08c203b99320c, isReference=false, isBulkLoadResult=false, seqid=18219, majorCompaction=false
2014-07-14 01:51:49,684 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/4accda75959541bead6d6662aa7a82dc, isReference=false, isBulkLoadResult=false, seqid=1311, majorCompaction=false
2014-07-14 01:51:49,696 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/2ea5bf583b2847489e428a45371c655e, isReference=false, isBulkLoadResult=false, seqid=17858, majorCompaction=false
2014-07-14 01:51:49,696 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/65389252f1f349eba4073fbaf6799424, isReference=false, isBulkLoadResult=false, seqid=11743, majorCompaction=false
2014-07-14 01:51:49,726 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/74ec5eece70647a289d3ce01c5ee5949, isReference=false, isBulkLoadResult=false, seqid=4146, majorCompaction=false
2014-07-14 01:51:49,727 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/4afe7d47407c45b49f285910a9a5acf5, isReference=false, isBulkLoadResult=false, seqid=411, majorCompaction=false
2014-07-14 01:51:49,728 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/376ee48c07b249f7a54f712625ae2303, isReference=false, isBulkLoadResult=false, seqid=17180, majorCompaction=false
2014-07-14 01:51:49,754 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/76bf6857caea42e8a69aae8399f26b89, isReference=false, isBulkLoadResult=false, seqid=16008, majorCompaction=false
2014-07-14 01:51:49,760 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/5295e76249184e7baeb659dfb740d646, isReference=false, isBulkLoadResult=false, seqid=232, majorCompaction=false
2014-07-14 01:51:49,773 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/3e877f1b65474ec1a307a278bfaaadb6, isReference=false, isBulkLoadResult=false, seqid=15172, majorCompaction=false
2014-07-14 01:51:49,784 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/7703482e5c62432c80aefc91c39923fb, isReference=false, isBulkLoadResult=false, seqid=3565, majorCompaction=false
2014-07-14 01:51:49,788 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/6473e3d386d040a5b26e84ae8831cefd, isReference=false, isBulkLoadResult=false, seqid=19104, majorCompaction=false
2014-07-14 01:51:49,802 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/40e6228e39bb481ba44a3eba6eb70f8e, isReference=false, isBulkLoadResult=false, seqid=3882, majorCompaction=false
2014-07-14 01:51:49,821 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/7e0db44a74c044cf917e4fbbee3caaa0, isReference=false, isBulkLoadResult=false, seqid=3745, majorCompaction=false
2014-07-14 01:51:49,832 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/4843b47b64a241da818cc9c7061375d6, isReference=false, isBulkLoadResult=false, seqid=5711, majorCompaction=false
2014-07-14 01:51:49,833 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/888ae84297c04aa1914c9a050b7accd3, isReference=false, isBulkLoadResult=false, seqid=19080, majorCompaction=false
2014-07-14 01:51:49,844 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/6c6d74f14cbe4b7dbbd425c3ae572370, isReference=false, isBulkLoadResult=false, seqid=1699, majorCompaction=false
2014-07-14 01:51:49,853 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/4b23068044484f078143696961bcef75, isReference=false, isBulkLoadResult=false, seqid=8235, majorCompaction=false
2014-07-14 01:51:49,855 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/8b6c37943fd9408384e135c204ec1c18, isReference=false, isBulkLoadResult=false, seqid=412, majorCompaction=false
2014-07-14 01:51:49,876 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/9207af4c24b44c5d81256068cc3d44de, isReference=false, isBulkLoadResult=false, seqid=4513, majorCompaction=false
2014-07-14 01:51:49,880 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/52f40d66044b4aa98a51f5085be80452, isReference=false, isBulkLoadResult=false, seqid=7384, majorCompaction=false
2014-07-14 01:51:49,896 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/6f74fd98ca7e4603819c6e1fba0c91bc, isReference=false, isBulkLoadResult=false, seqid=2044, majorCompaction=false
2014-07-14 01:51:49,927 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/7aff4535d79849d2b33c0d755b2d54b2, isReference=false, isBulkLoadResult=false, seqid=4191, majorCompaction=false
2014-07-14 01:51:49,933 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/545364d9f6d0472eb6315a00f3d3603e, isReference=false, isBulkLoadResult=false, seqid=4301, majorCompaction=false
2014-07-14 01:51:49,938 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/9a3c9858db75467999f2801b41d5e982, isReference=false, isBulkLoadResult=false, seqid=1656, majorCompaction=false
2014-07-14 01:51:49,948 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/7b12132762084ca1ac86826beb4ff7b0, isReference=false, isBulkLoadResult=false, seqid=18199, majorCompaction=false
2014-07-14 01:51:49,963 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/6b3933bcddaf499da0704d99ede9d907, isReference=false, isBulkLoadResult=false, seqid=3715, majorCompaction=false
2014-07-14 01:51:49,966 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/a660850a0f564671a943787936f3853b, isReference=false, isBulkLoadResult=false, seqid=1038, majorCompaction=false
2014-07-14 01:51:49,978 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/82a6d1969b974606be366e0750fc4ec6, isReference=false, isBulkLoadResult=false, seqid=6074, majorCompaction=false
2014-07-14 01:51:49,985 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/ac5a0f70cb4a4f698e5c58a909d889a6, isReference=false, isBulkLoadResult=false, seqid=11060, majorCompaction=false
2014-07-14 01:51:49,986 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/7039b4e00e3a47bda3bd2df8cd9a3e23, isReference=false, isBulkLoadResult=false, seqid=2167, majorCompaction=false
2014-07-14 01:51:50,001 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/9b719e3e484d4898819594d77493a323, isReference=false, isBulkLoadResult=false, seqid=4406, majorCompaction=false
2014-07-14 01:51:50,008 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/716c5a0f1a0c42dba513a064b079734d, isReference=false, isBulkLoadResult=false, seqid=14315, majorCompaction=false
2014-07-14 01:51:50,014 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/add62d373b7b4a6fb391544c3b6a3335, isReference=false, isBulkLoadResult=false, seqid=4725, majorCompaction=false
2014-07-14 01:51:50,020 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/9d13f5f3aa114391a4def95436479350, isReference=false, isBulkLoadResult=false, seqid=3332, majorCompaction=false
2014-07-14 01:51:50,037 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/717da64014a34decb1d3784bcc2a4753, isReference=false, isBulkLoadResult=false, seqid=10709, majorCompaction=false
2014-07-14 01:51:50,071 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/a055dcc902264ecb8d15cf410c0cd145, isReference=false, isBulkLoadResult=false, seqid=15484, majorCompaction=false
2014-07-14 01:51:50,074 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/ae1faf4d65174a029da43f45351418b6, isReference=false, isBulkLoadResult=false, seqid=8975, majorCompaction=false
2014-07-14 01:51:50,077 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/7f8fc72b2896499a95112062ee5a7e91, isReference=false, isBulkLoadResult=false, seqid=177, majorCompaction=false
2014-07-14 01:51:50,102 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/aefd4ce804914b46ba83ef1316d5280d, isReference=false, isBulkLoadResult=false, seqid=2235, majorCompaction=false
2014-07-14 01:51:50,104 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/a50f4845cab647dd8cfeab3b097a0754, isReference=false, isBulkLoadResult=false, seqid=10065, majorCompaction=false
2014-07-14 01:51:50,105 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/8aaad0b169834cfd88f2d1bb5322cd2d, isReference=false, isBulkLoadResult=false, seqid=4511, majorCompaction=false
2014-07-14 01:51:50,124 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/afb97d0516ed4c70ad591bf6fd2c38f4, isReference=false, isBulkLoadResult=false, seqid=5086, majorCompaction=false
2014-07-14 01:51:50,134 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/a9f0b948fbb742dbb58697bf7f9532f0, isReference=false, isBulkLoadResult=false, seqid=12272, majorCompaction=false
2014-07-14 01:51:50,148 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/8ae16bd9b4024cbabc2a1b5e673fe775, isReference=false, isBulkLoadResult=false, seqid=15872, majorCompaction=false
2014-07-14 01:51:50,157 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/b627597e80ed48ce9d847767c25044ad, isReference=false, isBulkLoadResult=false, seqid=9533, majorCompaction=false
2014-07-14 01:51:50,159 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/ab64ab7a9ef44897a419a9b94274aa20, isReference=false, isBulkLoadResult=false, seqid=1069, majorCompaction=false
2014-07-14 01:51:50,190 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/94d7d40dd7ea424fb3f1b97c739f44aa, isReference=false, isBulkLoadResult=false, seqid=2780, majorCompaction=false
2014-07-14 01:51:50,203 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/bcc76302ccc843139b7758fb33b28946, isReference=false, isBulkLoadResult=false, seqid=5858, majorCompaction=false
2014-07-14 01:51:50,203 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/af012ea9f066452fb5c58f7f6a8c601f, isReference=false, isBulkLoadResult=false, seqid=4572, majorCompaction=false
2014-07-14 01:51:50,211 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/9e5e6f10fc724f3cb0f17e27c7b1b2f4, isReference=false, isBulkLoadResult=false, seqid=19549, majorCompaction=false
2014-07-14 01:51:50,239 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/c063feb32168422cb65320334b6c2ef5, isReference=false, isBulkLoadResult=false, seqid=17216, majorCompaction=false
2014-07-14 01:51:50,245 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/b82858cb8cae437abb0c3b2688c03f66, isReference=false, isBulkLoadResult=false, seqid=13903, majorCompaction=false
2014-07-14 01:51:50,274 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/b6d39a502007401fa8a99b7a92cfd3ac, isReference=false, isBulkLoadResult=false, seqid=11097, majorCompaction=false
2014-07-14 01:51:50,279 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/c1d891f85ed04f94b73970ae10f93905, isReference=false, isBulkLoadResult=false, seqid=3306, majorCompaction=false
2014-07-14 01:51:50,281 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/bb029fdaa9164a46b35045a2aec5cb03, isReference=false, isBulkLoadResult=false, seqid=9400, majorCompaction=false
2014-07-14 01:51:50,315 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/c2589f1b704641b4b944623263e4a7c2, isReference=false, isBulkLoadResult=false, seqid=6519, majorCompaction=false
2014-07-14 01:51:50,316 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/bd3d00eec5c24a53a107f99c2daaab67, isReference=false, isBulkLoadResult=false, seqid=16608, majorCompaction=false
2014-07-14 01:51:50,321 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/bfbfe22cdb434c6e9f66c48b0ddbdb41, isReference=false, isBulkLoadResult=false, seqid=4804, majorCompaction=false
2014-07-14 01:51:50,349 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/c3597bada58a44acb22110deb87f81e7, isReference=false, isBulkLoadResult=false, seqid=16936, majorCompaction=false
2014-07-14 01:51:50,362 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/be166cd65a4c45a196504c3b4ef33c30, isReference=false, isBulkLoadResult=false, seqid=12309, majorCompaction=false
2014-07-14 01:51:50,368 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/c8cd0c8f5bbf4fcda42f695b2a5ae8f8, isReference=false, isBulkLoadResult=false, seqid=15998, majorCompaction=false
2014-07-14 01:51:50,377 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/c75689ec8ad34fe4a7160a9593878a47, isReference=false, isBulkLoadResult=false, seqid=4904, majorCompaction=false
2014-07-14 01:51:50,382 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/be21b8cd79254aabb13b3718f4845f8d, isReference=false, isBulkLoadResult=false, seqid=4902, majorCompaction=false
2014-07-14 01:51:50,397 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/ca565b0107d24355a42a1b9d1c0dcb16, isReference=false, isBulkLoadResult=false, seqid=8644, majorCompaction=false
2014-07-14 01:51:50,404 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/ca03d9c570c745938be5095dd74cf4ce, isReference=false, isBulkLoadResult=false, seqid=1288, majorCompaction=false
2014-07-14 01:51:50,405 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/c2f06fc2cbbc46eeb44cef0473df2cd4, isReference=false, isBulkLoadResult=false, seqid=4716, majorCompaction=false
2014-07-14 01:51:50,450 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/d22704ec36824d23b68ef459fe739e3c, isReference=false, isBulkLoadResult=false, seqid=4011, majorCompaction=false
2014-07-14 01:51:50,458 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/c937fbda2f65498dbead541e9af2ec75, isReference=false, isBulkLoadResult=false, seqid=5886, majorCompaction=false
2014-07-14 01:51:50,459 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/d5c2dd12bf14412ca77ce71d886edc7c, isReference=false, isBulkLoadResult=false, seqid=4314, majorCompaction=false
2014-07-14 01:51:50,481 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/d71dbd3a466d4f9ca142167cb3a0faa7, isReference=false, isBulkLoadResult=false, seqid=6865, majorCompaction=false
2014-07-14 01:51:50,491 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/c9e658467c8b459aa5deac0d3a4ddedf, isReference=false, isBulkLoadResult=false, seqid=367, majorCompaction=false
2014-07-14 01:51:50,493 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/d862e7aad5ea4e3a921d6fa4891e2a45, isReference=false, isBulkLoadResult=false, seqid=2491, majorCompaction=false
2014-07-14 01:51:50,517 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/d865be57c4764d57a5e660dfb5dd6ba0, isReference=false, isBulkLoadResult=false, seqid=11545, majorCompaction=false
2014-07-14 01:51:50,522 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/cba1f0b59e4544e1bbdc6c6e946994b6, isReference=false, isBulkLoadResult=false, seqid=1618, majorCompaction=false
2014-07-14 01:51:50,529 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/de3c57c6bdf44cc5ba661915e1cb3d7f, isReference=false, isBulkLoadResult=false, seqid=15494, majorCompaction=false
2014-07-14 01:51:50,533 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/e00def28a906443f9fc6706f8eaa6e8a, isReference=false, isBulkLoadResult=false, seqid=19543, majorCompaction=false
2014-07-14 01:51:50,559 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/e2472e3a9f3c4ca7813a5ec0b467b10d, isReference=false, isBulkLoadResult=false, seqid=19544, majorCompaction=false
2014-07-14 01:51:50,564 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/cc526b84327445c3b48dd82baa1678ee, isReference=false, isBulkLoadResult=false, seqid=3213, majorCompaction=false
2014-07-14 01:51:50,568 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/e37a64a5d1dd48d0864cb6e1ab2983fb, isReference=false, isBulkLoadResult=false, seqid=14741, majorCompaction=false
2014-07-14 01:51:50,596 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/e70b70c27ade4011ba6538a8995bd037, isReference=false, isBulkLoadResult=false, seqid=13184, majorCompaction=false
2014-07-14 01:51:50,602 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/ce69d6af21cd4b55b5ae704c889f27c3, isReference=false, isBulkLoadResult=false, seqid=1418, majorCompaction=false
2014-07-14 01:51:50,604 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/f32a4da695434189ae7c1c66c9f495c9, isReference=false, isBulkLoadResult=false, seqid=3618, majorCompaction=false
2014-07-14 01:51:50,632 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/d31972339cf34a59987257622e1310c3, isReference=false, isBulkLoadResult=false, seqid=5083, majorCompaction=false
2014-07-14 01:51:50,646 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/eac3439bfad6445b96807f114b50f759, isReference=false, isBulkLoadResult=false, seqid=232, majorCompaction=false
2014-07-14 01:51:50,646 DEBUG [StoreOpener-d5d5cc6db1bf5bd9142b4d4e667bac72-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72/family/f580e3f46a264ae9a36a939decc7d01c, isReference=false, isBulkLoadResult=false, seqid=16923, majorCompaction=false
2014-07-14 01:51:50,654 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d5d5cc6db1bf5bd9142b4d4e667bac72
2014-07-14 01:51:50,682 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/df21b5a0ef214236b718029f49193eaa, isReference=false, isBulkLoadResult=false, seqid=6541, majorCompaction=false
2014-07-14 01:51:50,682 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/ed933617490d454da35c5b3452f2ea8f, isReference=false, isBulkLoadResult=false, seqid=8234, majorCompaction=false
2014-07-14 01:51:50,683 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined d5d5cc6db1bf5bd9142b4d4e667bac72; next sequenceid=19544
2014-07-14 01:51:50,683 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d5d5cc6db1bf5bd9142b4d4e667bac72
2014-07-14 01:51:50,688 INFO  [PostOpenDeployTasks:d5d5cc6db1bf5bd9142b4d4e667bac72] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:51:50,691 DEBUG [PostOpenDeployTasks:d5d5cc6db1bf5bd9142b4d4e667bac72] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:50,693 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-14 01:51:50,693 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-14 01:51:50,696 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:50,696 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:50,700 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72. because compaction request was cancelled
2014-07-14 01:51:50,709 INFO  [PostOpenDeployTasks:d5d5cc6db1bf5bd9142b4d4e667bac72] catalog.MetaEditor: Updated row usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72. with server=slave1,60020,1405327870609
2014-07-14 01:51:50,710 INFO  [PostOpenDeployTasks:d5d5cc6db1bf5bd9142b4d4e667bac72] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:51:50,711 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5d5cc6db1bf5bd9142b4d4e667bac72 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,717 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5d5cc6db1bf5bd9142b4d4e667bac72 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,717 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned d5d5cc6db1bf5bd9142b4d4e667bac72 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:50,718 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72. on slave1,60020,1405327870609
2014-07-14 01:51:50,718 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:50,724 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:50,724 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-14 01:51:50,725 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-14 01:51:50,726 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 01:51:50,733 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/e4c10dfedd7c494493a30f06c110f8e9, isReference=false, isBulkLoadResult=false, seqid=16571, majorCompaction=false
2014-07-14 01:51:50,740 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/ee1a0331d51743fbb200dea1ec602e46, isReference=false, isBulkLoadResult=false, seqid=1488, majorCompaction=false
2014-07-14 01:51:50,743 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:51:50,760 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/eb0248ea5a9745e4abd7eb8cc86be87e, isReference=false, isBulkLoadResult=false, seqid=18699, majorCompaction=false
2014-07-14 01:51:50,770 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/f30c5ee741ee493f97711546582ece27, isReference=false, isBulkLoadResult=false, seqid=14758, majorCompaction=false
2014-07-14 01:51:50,778 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-14 01:51:50,787 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-14 01:51:50,792 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/ece8934bdd424b6eac564802ebc9a687, isReference=false, isBulkLoadResult=false, seqid=9469, majorCompaction=false
2014-07-14 01:51:50,795 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-14 01:51:50,795 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-14 01:51:50,797 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 01:51:50,807 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405327870609
2014-07-14 01:51:50,808 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 01:51:50,809 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,810 DEBUG [StoreOpener-b5c4e1ff5b6b7753b9fecbe9b697bf45-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45/family/fc543d0f45a646c0865889c6db6334eb, isReference=false, isBulkLoadResult=false, seqid=12510, majorCompaction=false
2014-07-14 01:51:50,815 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,815 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:50,815 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405327870609
2014-07-14 01:51:50,815 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 92dfa1977cf31f19d29822ea57a55422 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:50,819 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/eeb57ee83ccb42fa95cd3475a943011f, isReference=false, isBulkLoadResult=false, seqid=19529, majorCompaction=false
2014-07-14 01:51:50,820 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b5c4e1ff5b6b7753b9fecbe9b697bf45
2014-07-14 01:51:50,821 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 92dfa1977cf31f19d29822ea57a55422 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:51:50,822 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 92dfa1977cf31f19d29822ea57a55422, NAME => 'usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-14 01:51:50,823 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 92dfa1977cf31f19d29822ea57a55422
2014-07-14 01:51:50,823 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:51:50,825 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined b5c4e1ff5b6b7753b9fecbe9b697bf45; next sequenceid=19545
2014-07-14 01:51:50,825 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b5c4e1ff5b6b7753b9fecbe9b697bf45
2014-07-14 01:51:50,828 INFO  [PostOpenDeployTasks:b5c4e1ff5b6b7753b9fecbe9b697bf45] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:51:50,829 DEBUG [PostOpenDeployTasks:b5c4e1ff5b6b7753b9fecbe9b697bf45] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:50,829 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-14 01:51:50,830 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-14 01:51:50,830 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:50,830 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:50,830 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45. because compaction request was cancelled
2014-07-14 01:51:50,840 INFO  [PostOpenDeployTasks:b5c4e1ff5b6b7753b9fecbe9b697bf45] catalog.MetaEditor: Updated row usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45. with server=slave1,60020,1405327870609
2014-07-14 01:51:50,841 INFO  [PostOpenDeployTasks:b5c4e1ff5b6b7753b9fecbe9b697bf45] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:51:50,842 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5c4e1ff5b6b7753b9fecbe9b697bf45 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,848 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5c4e1ff5b6b7753b9fecbe9b697bf45 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,848 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned b5c4e1ff5b6b7753b9fecbe9b697bf45 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:50,848 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45. on slave1,60020,1405327870609
2014-07-14 01:51:50,849 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/ef9cec03543c49118d3b83b71a10f254, isReference=false, isBulkLoadResult=false, seqid=938, majorCompaction=false
2014-07-14 01:51:50,857 INFO  [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 01:51:50,876 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/f192137aff3f4dff859f6a0d95122fd7, isReference=false, isBulkLoadResult=false, seqid=1831, majorCompaction=false
2014-07-14 01:51:50,897 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/031c2727f7a84951b5ee7f782cce343c, isReference=false, isBulkLoadResult=false, seqid=14374, majorCompaction=false
2014-07-14 01:51:50,901 DEBUG [StoreOpener-6e2bf74487f61672cd8bc06d8b34f003-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003/family/f9dfc8f422494e8a8e13a0bf1a48c963, isReference=false, isBulkLoadResult=false, seqid=17934, majorCompaction=false
2014-07-14 01:51:50,908 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/6e2bf74487f61672cd8bc06d8b34f003
2014-07-14 01:51:50,913 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 6e2bf74487f61672cd8bc06d8b34f003; next sequenceid=19550
2014-07-14 01:51:50,913 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 6e2bf74487f61672cd8bc06d8b34f003
2014-07-14 01:51:50,915 INFO  [PostOpenDeployTasks:6e2bf74487f61672cd8bc06d8b34f003] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:51:50,916 DEBUG [PostOpenDeployTasks:6e2bf74487f61672cd8bc06d8b34f003] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:50,917 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 47 store files, 0 compacting, 47 eligible, 20 blocking
2014-07-14 01:51:50,917 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 47 files from compaction candidates
2014-07-14 01:51:50,917 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:50,917 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:50,917 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003. because compaction request was cancelled
2014-07-14 01:51:50,928 INFO  [PostOpenDeployTasks:6e2bf74487f61672cd8bc06d8b34f003] catalog.MetaEditor: Updated row usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003. with server=slave1,60020,1405327870609
2014-07-14 01:51:50,928 INFO  [PostOpenDeployTasks:6e2bf74487f61672cd8bc06d8b34f003] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:51:50,929 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6e2bf74487f61672cd8bc06d8b34f003 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,931 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/05897ce13acb499f9b62d840f685158d, isReference=false, isBulkLoadResult=false, seqid=1741, majorCompaction=false
2014-07-14 01:51:50,935 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6e2bf74487f61672cd8bc06d8b34f003 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:50,935 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 6e2bf74487f61672cd8bc06d8b34f003 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:50,935 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003. on slave1,60020,1405327870609
2014-07-14 01:51:50,962 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/05fdc72dec054a868175ad94fc666043, isReference=false, isBulkLoadResult=false, seqid=15894, majorCompaction=false
2014-07-14 01:51:50,984 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/06cbfb867aa54399bca6eeab1870bec7, isReference=false, isBulkLoadResult=false, seqid=3420, majorCompaction=false
2014-07-14 01:51:50,995 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/0ba2ffb909d04037ac86b26466111ce4, isReference=false, isBulkLoadResult=false, seqid=19592, majorCompaction=false
2014-07-14 01:51:51,027 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/0d6dc3a6363744f2abd9305106565c40, isReference=false, isBulkLoadResult=false, seqid=12872, majorCompaction=false
2014-07-14 01:51:51,055 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/0fa34a5869eb48a5930f6eb8f0974bfe, isReference=false, isBulkLoadResult=false, seqid=1393, majorCompaction=false
2014-07-14 01:51:51,088 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/17b56b897f3541fb86f6b274fff6af56, isReference=false, isBulkLoadResult=false, seqid=9420, majorCompaction=false
2014-07-14 01:51:51,111 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/1e354535e5014af9927d369fb2d7b984, isReference=false, isBulkLoadResult=false, seqid=18727, majorCompaction=false
2014-07-14 01:51:51,143 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/3ba167876af849c3a5441b332be2aaff, isReference=false, isBulkLoadResult=false, seqid=2410, majorCompaction=false
2014-07-14 01:51:51,174 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/47f8e94e80f140c5874eb5a35f6c48b1, isReference=false, isBulkLoadResult=false, seqid=4403, majorCompaction=false
2014-07-14 01:51:51,231 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/480fb673d3c04d4aab6a1ee832449bae, isReference=false, isBulkLoadResult=false, seqid=2119, majorCompaction=false
2014-07-14 01:51:51,277 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/4b1524c87b1e4fd3b92a5ef88e534134, isReference=false, isBulkLoadResult=false, seqid=11432, majorCompaction=false
2014-07-14 01:51:51,308 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/4dd8d1cd486a4702a6499dc884bd8097, isReference=false, isBulkLoadResult=false, seqid=2693, majorCompaction=false
2014-07-14 01:51:51,337 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/5c33baabb76c44f48dc23399db2effa6, isReference=false, isBulkLoadResult=false, seqid=177, majorCompaction=false
2014-07-14 01:51:51,373 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/658d409ca47c4ccbb814342c43281818, isReference=false, isBulkLoadResult=false, seqid=371, majorCompaction=false
2014-07-14 01:51:51,416 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/6af29fcae578490e822cda928cedacbe, isReference=false, isBulkLoadResult=false, seqid=4197, majorCompaction=false
2014-07-14 01:51:51,448 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/729f83d2442f4f1d8895657c311d1073, isReference=false, isBulkLoadResult=false, seqid=10595, majorCompaction=false
2014-07-14 01:51:51,476 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/77d8e6b9b947457f9073a153bfc3ea95, isReference=false, isBulkLoadResult=false, seqid=3013, majorCompaction=false
2014-07-14 01:51:51,518 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/79379bc4419b43a29ffb858058c388ea, isReference=false, isBulkLoadResult=false, seqid=4976, majorCompaction=false
2014-07-14 01:51:51,534 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/79c69e39de0246259b2ab8a25689e3d9, isReference=false, isBulkLoadResult=false, seqid=4810, majorCompaction=false
2014-07-14 01:51:51,559 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/847b35688c35463b88b4103733f6c7fe, isReference=false, isBulkLoadResult=false, seqid=16597, majorCompaction=false
2014-07-14 01:51:51,579 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/866eee253fec46e8b0749898389b6bcc, isReference=false, isBulkLoadResult=false, seqid=9961, majorCompaction=false
2014-07-14 01:51:51,597 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/87fea6592a064161afa7ca28a47835c7, isReference=false, isBulkLoadResult=false, seqid=16664, majorCompaction=false
2014-07-14 01:51:51,620 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/8abecb5cdc9c4460be7aaaa9923f1031, isReference=false, isBulkLoadResult=false, seqid=17906, majorCompaction=false
2014-07-14 01:51:51,638 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/8bd85c4c282a4f618cd3853785f325c9, isReference=false, isBulkLoadResult=false, seqid=17202, majorCompaction=false
2014-07-14 01:51:51,663 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/8ef00030c0854b9fb6be5e5fe5c05bfb, isReference=false, isBulkLoadResult=false, seqid=1167, majorCompaction=false
2014-07-14 01:51:51,687 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9980169cddda44419058659f9ca6b986, isReference=false, isBulkLoadResult=false, seqid=942, majorCompaction=false
2014-07-14 01:51:51,715 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9c73c3ef6c14408abc59683fc4b72e6c, isReference=false, isBulkLoadResult=false, seqid=12285, majorCompaction=false
2014-07-14 01:51:51,742 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9c9bde828e914623bba01c01b62e2220, isReference=false, isBulkLoadResult=false, seqid=14355, majorCompaction=false
2014-07-14 01:51:51,759 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9f4f533e751c45e984569533553603db, isReference=false, isBulkLoadResult=false, seqid=4570, majorCompaction=false
2014-07-14 01:51:51,768 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9f8d2d69b020450ca93c9fa3e490d5f0, isReference=false, isBulkLoadResult=false, seqid=19562, majorCompaction=false
2014-07-14 01:51:51,807 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9fcc50cdc0d140fb96be0b7d95f11ea6, isReference=false, isBulkLoadResult=false, seqid=548, majorCompaction=false
2014-07-14 01:51:51,836 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/9fec4fc8f21a4909beb85161a4f8378e, isReference=false, isBulkLoadResult=false, seqid=3636, majorCompaction=false
2014-07-14 01:51:51,868 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/a3668c7fb8e043beac8a705730df36e8, isReference=false, isBulkLoadResult=false, seqid=6512, majorCompaction=false
2014-07-14 01:51:51,893 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/b575c602910240afb2d83c071483247a, isReference=false, isBulkLoadResult=false, seqid=7072, majorCompaction=false
2014-07-14 01:51:51,935 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/b7401a77b7ef48129866e44054d59a4b, isReference=false, isBulkLoadResult=false, seqid=8654, majorCompaction=false
2014-07-14 01:51:51,965 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/c180be88e7fa4f44958ab1eafa5452d8, isReference=false, isBulkLoadResult=false, seqid=13574, majorCompaction=false
2014-07-14 01:51:51,982 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/c9aad76f2bad4763b29eaff58391bd80, isReference=false, isBulkLoadResult=false, seqid=17121, majorCompaction=false
2014-07-14 01:51:52,010 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/cb227f9914fb47e0b5857d617330f0c9, isReference=false, isBulkLoadResult=false, seqid=4030, majorCompaction=false
2014-07-14 01:51:52,028 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/cf600bcbcb894296b399853fba8bb01a, isReference=false, isBulkLoadResult=false, seqid=7809, majorCompaction=false
2014-07-14 01:51:52,054 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/d179b2a221a54d36b38ec3ecd1e538e3, isReference=false, isBulkLoadResult=false, seqid=3864, majorCompaction=false
2014-07-14 01:51:52,077 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/d2367a83cbf24d9e998e998e9cbd6da9, isReference=false, isBulkLoadResult=false, seqid=1560, majorCompaction=false
2014-07-14 01:51:52,105 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/d886fcd4915447cbbf30386ca5a34a22, isReference=false, isBulkLoadResult=false, seqid=7886, majorCompaction=false
2014-07-14 01:51:52,130 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/e1c667a5c8fa48d1aee312b5e2427699, isReference=false, isBulkLoadResult=false, seqid=15214, majorCompaction=false
2014-07-14 01:51:52,144 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/e6b2ad0f4a7f4f0aa15e27e65071cc5c, isReference=false, isBulkLoadResult=false, seqid=5712, majorCompaction=false
2014-07-14 01:51:52,170 DEBUG [StoreOpener-92dfa1977cf31f19d29822ea57a55422-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422/family/ebd0553474b041ea8fcfd7b1fd2f1e19, isReference=false, isBulkLoadResult=false, seqid=17873, majorCompaction=false
2014-07-14 01:51:52,173 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/92dfa1977cf31f19d29822ea57a55422
2014-07-14 01:51:52,176 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 92dfa1977cf31f19d29822ea57a55422; next sequenceid=19593
2014-07-14 01:51:52,176 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 92dfa1977cf31f19d29822ea57a55422
2014-07-14 01:51:52,177 INFO  [PostOpenDeployTasks:92dfa1977cf31f19d29822ea57a55422] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:51:52,178 DEBUG [PostOpenDeployTasks:92dfa1977cf31f19d29822ea57a55422] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:52,178 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 47 store files, 0 compacting, 47 eligible, 20 blocking
2014-07-14 01:51:52,178 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 47 files from compaction candidates
2014-07-14 01:51:52,178 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:52,178 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:52,178 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422. because compaction request was cancelled
2014-07-14 01:51:52,186 INFO  [PostOpenDeployTasks:92dfa1977cf31f19d29822ea57a55422] catalog.MetaEditor: Updated row usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422. with server=slave1,60020,1405327870609
2014-07-14 01:51:52,186 INFO  [PostOpenDeployTasks:92dfa1977cf31f19d29822ea57a55422] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:51:52,186 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 92dfa1977cf31f19d29822ea57a55422 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:52,189 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 92dfa1977cf31f19d29822ea57a55422 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:51:52,189 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 92dfa1977cf31f19d29822ea57a55422 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:51:52,189 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422. on slave1,60020,1405327870609
2014-07-14 01:51:54,014 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 47 store files, 0 compacting, 47 eligible, 20 blocking
2014-07-14 01:51:54,014 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 47 files from compaction candidates
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003. because compaction request was cancelled
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:54,014 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72. because compaction request was cancelled
2014-07-14 01:51:54,015 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 47 store files, 0 compacting, 47 eligible, 20 blocking
2014-07-14 01:51:54,015 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 47 files from compaction candidates
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:54,015 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422. because compaction request was cancelled
2014-07-14 01:51:54,016 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 41 store files, 0 compacting, 41 eligible, 20 blocking
2014-07-14 01:51:54,016 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 41 files from compaction candidates
2014-07-14 01:51:54,016 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-14 01:51:54,016 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-14 01:51:54,016 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Not compacting usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45. because compaction request was cancelled
2014-07-14 01:52:17,695 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 6e2bf74487f61672cd8bc06d8b34f003, via zk=yes, znode version=0, on null
2014-07-14 01:52:17,695 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close b5c4e1ff5b6b7753b9fecbe9b697bf45, via zk=yes, znode version=0, on null
2014-07-14 01:52:17,695 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 81e87aad5a4de9db5f0ddb9df4d4ccdb, via zk=yes, znode version=0, on null
2014-07-14 01:52:17,695 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close 92dfa1977cf31f19d29822ea57a55422, via zk=yes, znode version=0, on null
2014-07-14 01:52:17,695 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close d5d5cc6db1bf5bd9142b4d4e667bac72, via zk=yes, znode version=0, on null
2014-07-14 01:52:17,697 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:52:17,697 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:52:17,698 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:52:17,700 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.: disabling compactions & flushes
2014-07-14 01:52:17,700 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:52:17,701 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.: disabling compactions & flushes
2014-07-14 01:52:17,701 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.: disabling compactions & flushes
2014-07-14 01:52:17,701 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:52:17,701 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:52:17,702 INFO  [StoreCloserThread-usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.-1] regionserver.HStore: Closed family
2014-07-14 01:52:17,706 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:52:17,706 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 81e87aad5a4de9db5f0ddb9df4d4ccdb from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,710 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 81e87aad5a4de9db5f0ddb9df4d4ccdb from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,710 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb. on slave1,60020,1405327870609
2014-07-14 01:52:17,710 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,,1405324961957.81e87aad5a4de9db5f0ddb9df4d4ccdb.
2014-07-14 01:52:17,711 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:52:17,712 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.: disabling compactions & flushes
2014-07-14 01:52:17,712 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:52:17,751 INFO  [StoreCloserThread-usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.-1] regionserver.HStore: Closed family
2014-07-14 01:52:17,752 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:52:17,752 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5c4e1ff5b6b7753b9fecbe9b697bf45 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,752 INFO  [StoreCloserThread-usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.-1] regionserver.HStore: Closed family
2014-07-14 01:52:17,753 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:52:17,753 INFO  [StoreCloserThread-usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.-1] regionserver.HStore: Closed family
2014-07-14 01:52:17,753 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 92dfa1977cf31f19d29822ea57a55422 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,754 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:52:17,754 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6e2bf74487f61672cd8bc06d8b34f003 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,765 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5c4e1ff5b6b7753b9fecbe9b697bf45 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,765 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45. on slave1,60020,1405327870609
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user3,1405324961957.b5c4e1ff5b6b7753b9fecbe9b697bf45.
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 92dfa1977cf31f19d29822ea57a55422 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422. on slave1,60020,1405327870609
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user1,1405324961957.92dfa1977cf31f19d29822ea57a55422.
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6e2bf74487f61672cd8bc06d8b34f003 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003. on slave1,60020,1405327870609
2014-07-14 01:52:17,766 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user2,1405324961957.6e2bf74487f61672cd8bc06d8b34f003.
2014-07-14 01:52:17,768 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.: disabling compactions & flushes
2014-07-14 01:52:17,768 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:52:17,780 INFO  [StoreCloserThread-usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.-1] regionserver.HStore: Closed family
2014-07-14 01:52:17,781 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:52:17,781 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5d5cc6db1bf5bd9142b4d4e667bac72 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,787 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5d5cc6db1bf5bd9142b4d4e667bac72 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 01:52:17,787 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72. on slave1,60020,1405327870609
2014-07-14 01:52:17,787 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user7,1405324961957.d5d5cc6db1bf5bd9142b4d4e667bac72.
2014-07-14 01:56:10,701 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=5, hits=3, hitRatio=60.00%, , cachingAccesses=5, cachingHits=3, cachingHitsRatio=60.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-14 01:57:29,396 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:57:29,407 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:57:29,408 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,408 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:57:29,409 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:57:29,410 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,411 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,410 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 01:57:29,415 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,415 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => f7644f9dbefce312f180da53011ffa5c, NAME => 'usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-14 01:57:29,416 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,416 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 3990157c1b6a259f95c53a0f0007d7bc, NAME => 'usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-14 01:57:29,416 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,416 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f7644f9dbefce312f180da53011ffa5c
2014-07-14 01:57:29,417 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:57:29,417 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => c8a1d10978c87bbc043a64b1893a75b1, NAME => 'usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-14 01:57:29,417 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 01:57:29,417 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:57:29,417 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 01:57:29,418 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:57:29,427 INFO  [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:57:29,427 INFO  [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:57:29,430 INFO  [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:57:29,431 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 01:57:29,432 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c
2014-07-14 01:57:29,433 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 01:57:29,434 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 3990157c1b6a259f95c53a0f0007d7bc; next sequenceid=1
2014-07-14 01:57:29,434 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 01:57:29,435 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined f7644f9dbefce312f180da53011ffa5c; next sequenceid=1
2014-07-14 01:57:29,435 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f7644f9dbefce312f180da53011ffa5c
2014-07-14 01:57:29,435 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:57:29,436 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:57:29,451 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] catalog.MetaEditor: Updated row usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. with server=slave1,60020,1405327870609
2014-07-14 01:57:29,452 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:57:29,453 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3990157c1b6a259f95c53a0f0007d7bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,454 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] catalog.MetaEditor: Updated row usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. with server=slave1,60020,1405327870609
2014-07-14 01:57:29,454 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:57:29,455 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f7644f9dbefce312f180da53011ffa5c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,459 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3990157c1b6a259f95c53a0f0007d7bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,459 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 3990157c1b6a259f95c53a0f0007d7bc to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:57:29,459 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. on slave1,60020,1405327870609
2014-07-14 01:57:29,460 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,460 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f7644f9dbefce312f180da53011ffa5c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,460 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned f7644f9dbefce312f180da53011ffa5c to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:57:29,460 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. on slave1,60020,1405327870609
2014-07-14 01:57:29,461 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,463 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,464 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 4d29ddafd3242e2ff279396a5cf1682c, NAME => 'usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-14 01:57:29,464 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 01:57:29,465 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:57:29,466 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined c8a1d10978c87bbc043a64b1893a75b1; next sequenceid=1
2014-07-14 01:57:29,466 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 01:57:29,466 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 01:57:29,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 018fa362abf2ec7a02c06683da5e76f5, NAME => 'usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-14 01:57:29,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 018fa362abf2ec7a02c06683da5e76f5
2014-07-14 01:57:29,467 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:57:29,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 01:57:29,473 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] catalog.MetaEditor: Updated row usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. with server=slave1,60020,1405327870609
2014-07-14 01:57:29,473 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:57:29,474 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8a1d10978c87bbc043a64b1893a75b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,475 INFO  [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:57:29,477 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8a1d10978c87bbc043a64b1893a75b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,477 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned c8a1d10978c87bbc043a64b1893a75b1 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:57:29,477 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. on slave1,60020,1405327870609
2014-07-14 01:57:29,477 INFO  [StoreOpener-018fa362abf2ec7a02c06683da5e76f5-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 01:57:29,481 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 01:57:29,482 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/018fa362abf2ec7a02c06683da5e76f5
2014-07-14 01:57:29,483 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 4d29ddafd3242e2ff279396a5cf1682c; next sequenceid=1
2014-07-14 01:57:29,483 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 01:57:29,485 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:57:29,494 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] catalog.MetaEditor: Updated row usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. with server=slave1,60020,1405327870609
2014-07-14 01:57:29,494 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:57:29,495 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4d29ddafd3242e2ff279396a5cf1682c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,504 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4d29ddafd3242e2ff279396a5cf1682c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,504 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 4d29ddafd3242e2ff279396a5cf1682c to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:57:29,504 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. on slave1,60020,1405327870609
2014-07-14 01:57:29,522 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 018fa362abf2ec7a02c06683da5e76f5; next sequenceid=1
2014-07-14 01:57:29,522 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 018fa362abf2ec7a02c06683da5e76f5
2014-07-14 01:57:29,524 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 01:57:29,534 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] catalog.MetaEditor: Updated row usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5. with server=slave1,60020,1405327870609
2014-07-14 01:57:29,534 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 01:57:29,535 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 018fa362abf2ec7a02c06683da5e76f5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,540 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x14734118bbb0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 018fa362abf2ec7a02c06683da5e76f5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 01:57:29,541 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 018fa362abf2ec7a02c06683da5e76f5 to OPENED in zk on slave1,60020,1405327870609
2014-07-14 01:57:29,541 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5. on slave1,60020,1405327870609
2014-07-14 01:57:48,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:57:48,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86 synced till here 72
2014-07-14 01:57:48,873 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405327903885 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328268567
2014-07-14 01:57:51,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:57:51,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 165 synced till here 159
2014-07-14 01:57:51,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328268567 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328271038
2014-07-14 01:57:52,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:57:52,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328271038 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328272682
2014-07-14 01:57:55,760 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:57:55,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 312 synced till here 308
2014-07-14 01:57:55,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328272682 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328275761
2014-07-14 01:57:59,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:57:59,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 409 synced till here 390
2014-07-14 01:58:00,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328275761 with entries=97, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328279693
2014-07-14 01:58:04,384 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:04,743 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 531 synced till here 507
2014-07-14 01:58:05,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328279693 with entries=122, filesize=104.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328284385
2014-07-14 01:58:07,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:07,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 635 synced till here 610
2014-07-14 01:58:08,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328284385 with entries=104, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328287502
2014-07-14 01:58:09,089 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:58:09,092 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 278.4m
2014-07-14 01:58:10,895 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:58:10,896 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 258.8m
2014-07-14 01:58:11,836 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:12,000 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:12,005 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 01:58:12,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:12,056 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:58:12,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 751 synced till here 734
2014-07-14 01:58:12,664 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328287502 with entries=116, filesize=99.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328292040
2014-07-14 01:58:13,517 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:58:14,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:15,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 866 synced till here 855
2014-07-14 01:58:15,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328292040 with entries=115, filesize=98.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328294824
2014-07-14 01:58:16,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:16,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 982 synced till here 945
2014-07-14 01:58:17,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328294824 with entries=116, filesize=99.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328296843
2014-07-14 01:58:19,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:19,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1084 synced till here 1058
2014-07-14 01:58:19,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328296843 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328299317
2014-07-14 01:58:21,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:21,860 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328299317 with entries=73, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328301589
2014-07-14 01:58:21,883 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=197, memsize=91.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4f3d48bd7ec74e0b83b5580cb9848c8b
2014-07-14 01:58:21,922 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4f3d48bd7ec74e0b83b5580cb9848c8b as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f3d48bd7ec74e0b83b5580cb9848c8b
2014-07-14 01:58:22,082 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f3d48bd7ec74e0b83b5580cb9848c8b, entries=333750, sequenceid=197, filesize=23.8m
2014-07-14 01:58:22,082 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~303.2m/317901840, currentsize=180.7m/189454000 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 12990ms, sequenceid=197, compaction requested=false
2014-07-14 01:58:22,086 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 429.5m
2014-07-14 01:58:22,281 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=182, memsize=91.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/cf93db3711fb459093a05ddbc915eeb3
2014-07-14 01:58:22,332 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/cf93db3711fb459093a05ddbc915eeb3 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/cf93db3711fb459093a05ddbc915eeb3
2014-07-14 01:58:22,377 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/cf93db3711fb459093a05ddbc915eeb3, entries=334060, sequenceid=182, filesize=23.8m
2014-07-14 01:58:22,377 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~280.6m/294199840, currentsize=178.3m/186985280 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 11481ms, sequenceid=182, compaction requested=false
2014-07-14 01:58:22,378 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 426.9m
2014-07-14 01:58:23,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:24,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1276 synced till here 1254
2014-07-14 01:58:24,054 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:24,080 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:25,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328301589 with entries=119, filesize=102.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328303833
2014-07-14 01:58:26,548 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:26,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328303833 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328306549
2014-07-14 01:58:26,919 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:58:29,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:29,227 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1431 synced till here 1429
2014-07-14 01:58:29,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328306549 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328309206
2014-07-14 01:58:29,598 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:58:29,984 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=296, memsize=91.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/aa1a74abb91a4377bbbcb8e1773611be
2014-07-14 01:58:30,003 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/aa1a74abb91a4377bbbcb8e1773611be as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa1a74abb91a4377bbbcb8e1773611be
2014-07-14 01:58:30,022 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa1a74abb91a4377bbbcb8e1773611be, entries=332940, sequenceid=296, filesize=23.7m
2014-07-14 01:58:30,022 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~456.1m/478223680, currentsize=106.9m/112116720 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 7936ms, sequenceid=296, compaction requested=false
2014-07-14 01:58:30,023 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 286.1m
2014-07-14 01:58:30,128 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=279, memsize=91.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/fc805439f16046168c0b5df3bd33c07c
2014-07-14 01:58:30,148 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/fc805439f16046168c0b5df3bd33c07c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fc805439f16046168c0b5df3bd33c07c
2014-07-14 01:58:30,165 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fc805439f16046168c0b5df3bd33c07c, entries=334560, sequenceid=279, filesize=23.9m
2014-07-14 01:58:30,165 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~431.6m/452554320, currentsize=132.2m/138611840 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 7787ms, sequenceid=279, compaction requested=false
2014-07-14 01:58:30,166 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 264.5m
2014-07-14 01:58:30,540 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:31,173 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:31,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:31,374 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1511 synced till here 1505
2014-07-14 01:58:31,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328309206 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328311359
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405327903885
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328268567
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328271038
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328272682
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328275761
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328279693
2014-07-14 01:58:31,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328284385
2014-07-14 01:58:33,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:33,472 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328311359 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328313448
2014-07-14 01:58:35,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:35,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1662 synced till here 1655
2014-07-14 01:58:35,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328313448 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328315146
2014-07-14 01:58:37,669 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:38,798 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:58:39,426 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=368, memsize=87.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/66ea8d6c2a804a7f9369188d58dcee10
2014-07-14 01:58:39,428 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=373, memsize=87.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/2e37f331bab94649987db6e1b1026e01
2014-07-14 01:58:39,452 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/66ea8d6c2a804a7f9369188d58dcee10 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/66ea8d6c2a804a7f9369188d58dcee10
2014-07-14 01:58:39,452 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/2e37f331bab94649987db6e1b1026e01 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e37f331bab94649987db6e1b1026e01
2014-07-14 01:58:39,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1822 synced till here 1815
2014-07-14 01:58:39,784 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/66ea8d6c2a804a7f9369188d58dcee10, entries=317930, sequenceid=368, filesize=22.6m
2014-07-14 01:58:39,785 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~289.1m/303162400, currentsize=143.8m/150791840 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 9762ms, sequenceid=368, compaction requested=false
2014-07-14 01:58:39,786 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 263.9m
2014-07-14 01:58:39,825 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e37f331bab94649987db6e1b1026e01, entries=316620, sequenceid=373, filesize=22.5m
2014-07-14 01:58:39,826 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~270.7m/283900000, currentsize=142.9m/149836000 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 9660ms, sequenceid=373, compaction requested=false
2014-07-14 01:58:39,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328315146 with entries=160, filesize=137.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328317669
2014-07-14 01:58:39,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328287502
2014-07-14 01:58:39,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328292040
2014-07-14 01:58:39,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328294824
2014-07-14 01:58:39,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328296843
2014-07-14 01:58:39,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328299317
2014-07-14 01:58:40,491 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:58:40,492 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 257.5m
2014-07-14 01:58:40,632 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:41,168 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:42,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:42,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1916 synced till here 1898
2014-07-14 01:58:43,121 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328317669 with entries=94, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328322673
2014-07-14 01:58:45,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:45,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2022 synced till here 2003
2014-07-14 01:58:46,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328322673 with entries=106, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328325709
2014-07-14 01:58:49,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:49,108 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:58:49,260 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2121 synced till here 2100
2014-07-14 01:58:49,513 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:58:49,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328325709 with entries=99, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328329100
2014-07-14 01:58:52,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:53,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2221 synced till here 2204
2014-07-14 01:58:53,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328329100 with entries=100, filesize=86.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328332775
2014-07-14 01:58:53,711 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=454, memsize=175.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/dfaa4952164447faa056a9944911e028
2014-07-14 01:58:53,729 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/dfaa4952164447faa056a9944911e028 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/dfaa4952164447faa056a9944911e028
2014-07-14 01:58:53,741 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/dfaa4952164447faa056a9944911e028, entries=638200, sequenceid=454, filesize=45.5m
2014-07-14 01:58:53,742 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~270.1m/283214240, currentsize=122.9m/128848160 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 13956ms, sequenceid=454, compaction requested=false
2014-07-14 01:58:53,742 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 311.5m
2014-07-14 01:58:54,437 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=465, memsize=186.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/7cb8f3a579024f2db118f90c8cd31a94
2014-07-14 01:58:54,454 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/7cb8f3a579024f2db118f90c8cd31a94 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/7cb8f3a579024f2db118f90c8cd31a94
2014-07-14 01:58:54,470 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/7cb8f3a579024f2db118f90c8cd31a94, entries=678040, sequenceid=465, filesize=48.3m
2014-07-14 01:58:54,470 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.7m/273399440, currentsize=141.3m/148112800 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 13978ms, sequenceid=465, compaction requested=false
2014-07-14 01:58:54,470 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 316.7m
2014-07-14 01:58:55,680 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:55,795 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:58:56,028 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:56,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2331 synced till here 2319
2014-07-14 01:58:56,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328332775 with entries=110, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328336029
2014-07-14 01:58:56,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328301589
2014-07-14 01:58:56,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328303833
2014-07-14 01:58:56,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328306549
2014-07-14 01:58:58,193 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:58:58,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2446 synced till here 2424
2014-07-14 01:58:58,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328336029 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328338193
2014-07-14 01:58:59,854 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:58:59,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:00,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2528 synced till here 2522
2014-07-14 01:59:00,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328338193 with entries=82, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328339965
2014-07-14 01:59:00,259 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:59:01,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:01,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2604 synced till here 2600
2014-07-14 01:59:01,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328339965 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328341821
2014-07-14 01:59:03,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:03,907 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2687 synced till here 2681
2014-07-14 01:59:03,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328341821 with entries=83, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328343646
2014-07-14 01:59:05,934 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:08,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2877 synced till here 2873
2014-07-14 01:59:08,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328343646 with entries=190, filesize=163.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328345935
2014-07-14 01:59:09,289 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=584, memsize=161.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/dcff643ef48349eebbd02f41ac25aba4
2014-07-14 01:59:09,305 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/dcff643ef48349eebbd02f41ac25aba4 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/dcff643ef48349eebbd02f41ac25aba4
2014-07-14 01:59:09,411 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/dcff643ef48349eebbd02f41ac25aba4, entries=588300, sequenceid=584, filesize=42.0m
2014-07-14 01:59:09,412 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~325.6m/341402720, currentsize=230.8m/242011280 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 15670ms, sequenceid=584, compaction requested=true
2014-07-14 01:59:09,414 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 01:59:09,414 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 92596402 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 01:59:09,414 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating major compaction
2014-07-14 01:59:09,415 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:59:09,415 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=88.3m
2014-07-14 01:59:09,418 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f3d48bd7ec74e0b83b5580cb9848c8b, keycount=33375, bloomtype=ROW, size=23.8m, encoding=NONE, seqNum=197, earliestPutTs=1405328266976
2014-07-14 01:59:09,418 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e37f331bab94649987db6e1b1026e01, keycount=31662, bloomtype=ROW, size=22.5m, encoding=NONE, seqNum=373, earliestPutTs=1405328299835
2014-07-14 01:59:09,418 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/dcff643ef48349eebbd02f41ac25aba4, keycount=58830, bloomtype=ROW, size=42.0m, encoding=NONE, seqNum=584, earliestPutTs=1405328310187
2014-07-14 01:59:09,419 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 01:59:09,420 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 416.6m
2014-07-14 01:59:09,446 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:10,093 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=575, memsize=170.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/ad429535aa344a8a9668c0539ecae934
2014-07-14 01:59:10,114 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/ad429535aa344a8a9668c0539ecae934 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ad429535aa344a8a9668c0539ecae934
2014-07-14 01:59:10,132 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ad429535aa344a8a9668c0539ecae934, entries=620600, sequenceid=575, filesize=44.2m
2014-07-14 01:59:10,132 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~323.0m/338714880, currentsize=255.0m/267383680 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 15662ms, sequenceid=575, compaction requested=true
2014-07-14 01:59:10,133 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 01:59:10,133 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 417.7m
2014-07-14 01:59:10,240 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:59:10,300 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:10,577 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:10,581 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 01:59:10,581 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 01:59:10,618 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:10,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328345935 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328350618
2014-07-14 01:59:10,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328309206
2014-07-14 01:59:10,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328311359
2014-07-14 01:59:10,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328313448
2014-07-14 01:59:10,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328315146
2014-07-14 01:59:11,412 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:59:12,523 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:12,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3023 synced till here 3022
2014-07-14 01:59:12,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328350618 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328352523
2014-07-14 01:59:14,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:14,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3100 synced till here 3094
2014-07-14 01:59:14,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328352523 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328354396
2014-07-14 01:59:16,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:16,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3178 synced till here 3173
2014-07-14 01:59:16,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328354396 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328356219
2014-07-14 01:59:18,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:18,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3260 synced till here 3252
2014-07-14 01:59:18,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328356219 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328358505
2014-07-14 01:59:21,157 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:21,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3395 synced till here 3361
2014-07-14 01:59:22,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328358505 with entries=135, filesize=115.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328361158
2014-07-14 01:59:24,667 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=728, memsize=124.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/554e89c7dde749bbab3421fb980d91e3
2014-07-14 01:59:24,766 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/554e89c7dde749bbab3421fb980d91e3 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/554e89c7dde749bbab3421fb980d91e3
2014-07-14 01:59:24,778 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/554e89c7dde749bbab3421fb980d91e3, entries=452570, sequenceid=728, filesize=32.3m
2014-07-14 01:59:24,779 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~421.3m/441780320, currentsize=188.7m/197908080 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 15359ms, sequenceid=728, compaction requested=true
2014-07-14 01:59:24,780 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 01:59:24,781 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 463.3m
2014-07-14 01:59:24,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:25,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3509 synced till here 3480
2014-07-14 01:59:25,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328361158 with entries=114, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328364813
2014-07-14 01:59:26,339 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=738, memsize=135.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/3e94338d27534172a3d3156ed3638b24
2014-07-14 01:59:26,359 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/3e94338d27534172a3d3156ed3638b24 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3e94338d27534172a3d3156ed3638b24
2014-07-14 01:59:26,382 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3e94338d27534172a3d3156ed3638b24, entries=491970, sequenceid=738, filesize=35.1m
2014-07-14 01:59:26,382 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~422.4m/442878000, currentsize=208.0m/218120960 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 16249ms, sequenceid=738, compaction requested=true
2014-07-14 01:59:26,383 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-14 01:59:26,383 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 504.9m
2014-07-14 01:59:26,709 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:27,582 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:27,644 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:27,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3626 synced till here 3600
2014-07-14 01:59:28,373 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 01:59:28,389 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 01:59:28,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328364813 with entries=117, filesize=100.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328367645
2014-07-14 01:59:28,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328317669
2014-07-14 01:59:28,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328322673
2014-07-14 01:59:28,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328325709
2014-07-14 01:59:28,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328329100
2014-07-14 01:59:30,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:30,214 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3722 synced till here 3697
2014-07-14 01:59:30,542 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328367645 with entries=96, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328370168
2014-07-14 01:59:33,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:33,150 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3827 synced till here 3805
2014-07-14 01:59:33,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328370168 with entries=105, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328373110
2014-07-14 01:59:35,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:35,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3927 synced till here 3905
2014-07-14 01:59:35,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328373110 with entries=100, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328375399
2014-07-14 01:59:37,317 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/a9a21c2ba4bf483f90e919ad54daa4dd as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a9a21c2ba4bf483f90e919ad54daa4dd
2014-07-14 01:59:37,344 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 01:59:37,361 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f3d48bd7ec74e0b83b5580cb9848c8b, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f3d48bd7ec74e0b83b5580cb9848c8b
2014-07-14 01:59:37,364 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e37f331bab94649987db6e1b1026e01, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e37f331bab94649987db6e1b1026e01
2014-07-14 01:59:37,367 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/dcff643ef48349eebbd02f41ac25aba4, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/dcff643ef48349eebbd02f41ac25aba4
2014-07-14 01:59:37,367 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into a9a21c2ba4bf483f90e919ad54daa4dd(size=63.8m), total size for store is 63.8m. This selection was in queue for 0sec, and took 27sec to execute.
2014-07-14 01:59:37,371 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=3, fileSize=88.3m, priority=17, time=282256841564193; duration=27sec
2014-07-14 01:59:37,371 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-14 01:59:37,371 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 01:59:37,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 95111552 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 01:59:37,372 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating major compaction
2014-07-14 01:59:37,372 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:59:37,372 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=90.7m
2014-07-14 01:59:37,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/cf93db3711fb459093a05ddbc915eeb3, keycount=33406, bloomtype=ROW, size=23.8m, encoding=NONE, seqNum=182, earliestPutTs=1405328267435
2014-07-14 01:59:37,373 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/66ea8d6c2a804a7f9369188d58dcee10, keycount=31793, bloomtype=ROW, size=22.6m, encoding=NONE, seqNum=368, earliestPutTs=1405328301399
2014-07-14 01:59:37,373 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ad429535aa344a8a9668c0539ecae934, keycount=62060, bloomtype=ROW, size=44.2m, encoding=NONE, seqNum=575, earliestPutTs=1405328310115
2014-07-14 01:59:37,393 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:37,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:37,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328375399 with entries=72, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328377542
2014-07-14 01:59:39,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:40,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4087 synced till here 4076
2014-07-14 01:59:40,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328377542 with entries=88, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328379950
2014-07-14 01:59:42,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:42,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4178 synced till here 4158
2014-07-14 01:59:43,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328379950 with entries=91, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328382570
2014-07-14 01:59:45,093 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:46,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4357 synced till here 4331
2014-07-14 01:59:47,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328382570 with entries=179, filesize=154.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328385094
2014-07-14 01:59:48,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:48,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4451 synced till here 4428
2014-07-14 01:59:49,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328385094 with entries=94, filesize=80.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328388905
2014-07-14 01:59:50,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:51,006 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4542 synced till here 4528
2014-07-14 01:59:51,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328388905 with entries=91, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328390992
2014-07-14 01:59:52,668 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=910, memsize=259.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/1689b97cca1346498741e738497330b4
2014-07-14 01:59:52,687 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/1689b97cca1346498741e738497330b4 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1689b97cca1346498741e738497330b4
2014-07-14 01:59:52,703 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1689b97cca1346498741e738497330b4, entries=944220, sequenceid=910, filesize=67.3m
2014-07-14 01:59:52,703 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~504.9m/529392000, currentsize=387.0m/405845360 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 26320ms, sequenceid=910, compaction requested=false
2014-07-14 01:59:52,704 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 657.5m
2014-07-14 01:59:52,902 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 01:59:52,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:53,003 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4619 synced till here 4614
2014-07-14 01:59:53,026 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=888, memsize=260.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/2d1bec50a48d465f93054c5c8344f93e
2014-07-14 01:59:53,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328390992 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328392903
2014-07-14 01:59:53,055 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/2d1bec50a48d465f93054c5c8344f93e as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/2d1bec50a48d465f93054c5c8344f93e
2014-07-14 01:59:53,071 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/2d1bec50a48d465f93054c5c8344f93e, entries=947820, sequenceid=888, filesize=67.6m
2014-07-14 01:59:53,072 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~486.4m/509996560, currentsize=422.4m/442952720 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 28291ms, sequenceid=888, compaction requested=false
2014-07-14 01:59:53,072 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 653.7m
2014-07-14 01:59:53,210 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 01:59:54,175 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:54,194 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 01:59:55,066 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:55,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4695 synced till here 4693
2014-07-14 01:59:55,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328392903 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328395067
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328332775
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328336029
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328338193
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328339965
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328341821
2014-07-14 01:59:55,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328343646
2014-07-14 01:59:56,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:56,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4773 synced till here 4768
2014-07-14 01:59:57,232 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328395067 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328396854
2014-07-14 01:59:59,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 01:59:59,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4854 synced till here 4846
2014-07-14 02:00:00,113 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328396854 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328399710
2014-07-14 02:00:02,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:04,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4998 synced till here 4983
2014-07-14 02:00:05,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328399710 with entries=144, filesize=123.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328402324
2014-07-14 02:00:05,648 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f71bc9bb037047ddb943daf4c22d4881 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f71bc9bb037047ddb943daf4c22d4881
2014-07-14 02:00:06,795 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:00:06,804 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/cf93db3711fb459093a05ddbc915eeb3, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/cf93db3711fb459093a05ddbc915eeb3
2014-07-14 02:00:06,807 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/66ea8d6c2a804a7f9369188d58dcee10, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/66ea8d6c2a804a7f9369188d58dcee10
2014-07-14 02:00:06,812 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ad429535aa344a8a9668c0539ecae934, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ad429535aa344a8a9668c0539ecae934
2014-07-14 02:00:06,812 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into f71bc9bb037047ddb943daf4c22d4881(size=63.9m), total size for store is 131.4m. This selection was in queue for 0sec, and took 29sec to execute.
2014-07-14 02:00:06,812 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=90.7m, priority=17, time=282284799012620; duration=29sec
2014-07-14 02:00:06,813 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:00:06,813 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 02:00:06,813 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 112319986 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 02:00:06,813 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating major compaction
2014-07-14 02:00:06,814 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:00:06,814 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=107.1m
2014-07-14 02:00:06,814 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa1a74abb91a4377bbbcb8e1773611be, keycount=33294, bloomtype=ROW, size=23.7m, encoding=NONE, seqNum=296, earliestPutTs=1405328267843
2014-07-14 02:00:06,814 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/7cb8f3a579024f2db118f90c8cd31a94, keycount=67804, bloomtype=ROW, size=48.3m, encoding=NONE, seqNum=465, earliestPutTs=1405328306066
2014-07-14 02:00:06,814 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3e94338d27534172a3d3156ed3638b24, keycount=49197, bloomtype=ROW, size=35.1m, encoding=NONE, seqNum=738, earliestPutTs=1405328320636
2014-07-14 02:00:07,001 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:07,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:24,722 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 20114ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:00:24,722 WARN  [regionserver60020] util.Sleeper: We slept 17023ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:00:24,722 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 20115ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:00:24,971 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16118ms
GC pool 'ParNew' had collection(s): count=1 time=246ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=16323ms
2014-07-14 02:00:25,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5134 synced till here 5105
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21793,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328403260,"queuetimems":1,"class":"HRegionServer","responsesize":15835,"method":"Multi"}
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22776,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402279,"queuetimems":0,"class":"HRegionServer","responsesize":16267,"method":"Multi"}
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402801,"queuetimems":1,"class":"HRegionServer","responsesize":15904,"method":"Multi"}
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402959,"queuetimems":1,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22746,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402307,"queuetimems":0,"class":"HRegionServer","responsesize":15245,"method":"Multi"}
2014-07-14 02:00:25,148 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22879,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402176,"queuetimems":1,"class":"HRegionServer","responsesize":15875,"method":"Multi"}
2014-07-14 02:00:25,150 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1962 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,154 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,154 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1937 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,154 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,155 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1935 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,155 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,155 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1925 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,155 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,156 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1926 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,161 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,161 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1936 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,161 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,303 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22868,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402434,"queuetimems":0,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 02:00:25,303 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22290,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328403012,"queuetimems":0,"class":"HRegionServer","responsesize":16009,"method":"Multi"}
2014-07-14 02:00:25,303 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402633,"queuetimems":0,"class":"HRegionServer","responsesize":15042,"method":"Multi"}
2014-07-14 02:00:25,304 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1934 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,304 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,304 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1922 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,304 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,304 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22562,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402742,"queuetimems":0,"class":"HRegionServer","responsesize":15940,"method":"Multi"}
2014-07-14 02:00:25,305 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1928 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,305 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,309 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22539,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402770,"queuetimems":0,"class":"HRegionServer","responsesize":15934,"method":"Multi"}
2014-07-14 02:00:25,310 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1927 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,310 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,313 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1929 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,313 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328402324 with entries=136, filesize=115.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328407981
2014-07-14 02:00:25,665 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328402979,"queuetimems":0,"class":"HRegionServer","responsesize":15590,"method":"Multi"}
2014-07-14 02:00:25,666 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1924 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,666 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,668 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328403765,"queuetimems":1,"class":"HRegionServer","responsesize":15770,"method":"Multi"}
2014-07-14 02:00:25,668 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1958 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,668 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404150,"queuetimems":322,"class":"HRegionServer","responsesize":15551,"method":"Multi"}
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21222,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404447,"queuetimems":2,"class":"HRegionServer","responsesize":15269,"method":"Multi"}
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1957 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1952 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,669 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,814 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21180,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404621,"queuetimems":1,"class":"HRegionServer","responsesize":15876,"method":"Multi"}
2014-07-14 02:00:25,814 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1951 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,814 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21649,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404153,"queuetimems":23,"class":"HRegionServer","responsesize":16075,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404647,"queuetimems":1,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20384,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405418,"queuetimems":741,"class":"HRegionServer","responsesize":15642,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405422,"queuetimems":361,"class":"HRegionServer","responsesize":15974,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328403649,"queuetimems":0,"class":"HRegionServer","responsesize":15819,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1954 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328404383,"queuetimems":1,"class":"HRegionServer","responsesize":15054,"method":"Multi"}
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1949 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,822 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1950 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1953 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1959 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1945 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:25,823 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,070 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20649,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405420,"queuetimems":546,"class":"HRegionServer","responsesize":15772,"method":"Multi"}
2014-07-14 02:00:26,070 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1946 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,070 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,195 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18204,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328407991,"queuetimems":1797,"class":"HRegionServer","responsesize":15877,"method":"Multi"}
2014-07-14 02:00:26,195 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20424,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405771,"queuetimems":682,"class":"HRegionServer","responsesize":15993,"method":"Multi"}
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1981 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1944 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20403,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405793,"queuetimems":503,"class":"HRegionServer","responsesize":15876,"method":"Multi"}
2014-07-14 02:00:26,195 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405802,"queuetimems":412,"class":"HRegionServer","responsesize":15269,"method":"Multi"}
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1992 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,197 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,195 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20776,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405419,"queuetimems":576,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:00:26,197 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20391,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405805,"queuetimems":360,"class":"HRegionServer","responsesize":15948,"method":"Multi"}
2014-07-14 02:00:26,198 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20406,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405791,"queuetimems":564,"class":"HRegionServer","responsesize":15054,"method":"Multi"}
2014-07-14 02:00:26,198 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328406815,"queuetimems":1173,"class":"HRegionServer","responsesize":16267,"method":"Multi"}
2014-07-14 02:00:26,198 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328407385,"queuetimems":1578,"class":"HRegionServer","responsesize":15426,"method":"Multi"}
2014-07-14 02:00:26,195 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20408,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405787,"queuetimems":665,"class":"HRegionServer","responsesize":16075,"method":"Multi"}
2014-07-14 02:00:26,200 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20781,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405419,"queuetimems":606,"class":"HRegionServer","responsesize":15917,"method":"Multi"}
2014-07-14 02:00:26,200 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405791,"queuetimems":532,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-14 02:00:26,197 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1989 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,208 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,196 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19385,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328406811,"queuetimems":1199,"class":"HRegionServer","responsesize":15245,"method":"Multi"}
2014-07-14 02:00:26,208 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1947 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,208 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,209 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1986 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,209 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,209 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1995 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,209 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1948 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1997 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1983 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1985 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,210 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,211 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1996 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,211 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,211 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1988 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,211 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,200 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18216,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328407984,"queuetimems":2126,"class":"HRegionServer","responsesize":15551,"method":"Multi"}
2014-07-14 02:00:26,200 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328407385,"queuetimems":1713,"class":"HRegionServer","responsesize":15875,"method":"Multi"}
2014-07-14 02:00:26,209 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20394,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328405806,"queuetimems":219,"class":"HRegionServer","responsesize":15819,"method":"Multi"}
2014-07-14 02:00:26,215 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1982 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,215 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,216 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1987 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,216 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,216 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1984 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,216 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,257 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:26,259 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18148,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408110,"queuetimems":1723,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 02:00:26,259 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18144,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408114,"queuetimems":1487,"class":"HRegionServer","responsesize":15904,"method":"Multi"}
2014-07-14 02:00:26,720 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1979 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,720 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,720 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1976 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,720 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5215 synced till here 5208
2014-07-14 02:00:26,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328407981 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328426257
2014-07-14 02:00:26,879 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18757,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408121,"queuetimems":1150,"class":"HRegionServer","responsesize":15042,"method":"Multi"}
2014-07-14 02:00:26,879 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18745,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408133,"queuetimems":946,"class":"HRegionServer","responsesize":16009,"method":"Multi"}
2014-07-14 02:00:26,879 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1972 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,880 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,880 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1969 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,880 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,915 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18773,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408141,"queuetimems":925,"class":"HRegionServer","responsesize":15438,"method":"Multi"}
2014-07-14 02:00:26,915 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1966 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,915 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,927 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408115,"queuetimems":1352,"class":"HRegionServer","responsesize":15940,"method":"Multi"}
2014-07-14 02:00:26,928 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1975 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,928 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,984 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18863,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408120,"queuetimems":1303,"class":"HRegionServer","responsesize":15775,"method":"Multi"}
2014-07-14 02:00:26,985 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1973 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,986 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,986 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408109,"queuetimems":1737,"class":"HRegionServer","responsesize":15770,"method":"Multi"}
2014-07-14 02:00:26,987 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1980 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,987 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:26,996 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18880,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408115,"queuetimems":1328,"class":"HRegionServer","responsesize":15590,"method":"Multi"}
2014-07-14 02:00:26,996 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1974 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:26,996 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:27,025 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18899,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408125,"queuetimems":1127,"class":"HRegionServer","responsesize":15934,"method":"Multi"}
2014-07-14 02:00:27,025 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18894,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47186","starttimems":1405328408130,"queuetimems":960,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:00:27,026 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1971 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:27,026 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:27,026 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1970 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47186: output error
2014-07-14 02:00:27,026 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:00:28,805 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1159, memsize=190.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1e6dd6e18df14f069991aa7bf0ff08de
2014-07-14 02:00:28,822 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1e6dd6e18df14f069991aa7bf0ff08de as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1e6dd6e18df14f069991aa7bf0ff08de
2014-07-14 02:00:28,832 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1e6dd6e18df14f069991aa7bf0ff08de, entries=694990, sequenceid=1159, filesize=49.6m
2014-07-14 02:00:28,832 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~653.7m/685432480, currentsize=236.4m/247926720 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 35760ms, sequenceid=1159, compaction requested=false
2014-07-14 02:00:28,832 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 622.1m
2014-07-14 02:00:29,343 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:30,068 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1157, memsize=206.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/50794cdf4fc94564a2aa46f277007483
2014-07-14 02:00:30,088 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/50794cdf4fc94564a2aa46f277007483 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/50794cdf4fc94564a2aa46f277007483
2014-07-14 02:00:30,112 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/50794cdf4fc94564a2aa46f277007483, entries=751350, sequenceid=1157, filesize=53.6m
2014-07-14 02:00:30,114 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~663.7m/695946640, currentsize=253.1m/265343040 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 37410ms, sequenceid=1157, compaction requested=true
2014-07-14 02:00:30,114 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:00:30,114 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 672.6m
2014-07-14 02:00:30,370 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:00:30,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:30,916 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:00:30,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5298 synced till here 5290
2014-07-14 02:00:31,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328426257 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328430917
2014-07-14 02:00:31,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328345935
2014-07-14 02:00:31,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328350618
2014-07-14 02:00:31,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328352523
2014-07-14 02:00:31,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328354396
2014-07-14 02:00:31,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328356219
2014-07-14 02:00:31,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328358505
2014-07-14 02:00:31,335 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:33,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:33,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5376 synced till here 5370
2014-07-14 02:00:33,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328430917 with entries=78, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328433386
2014-07-14 02:00:34,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:35,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328433386 with entries=92, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328434682
2014-07-14 02:00:37,059 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:37,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328434682 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328437060
2014-07-14 02:00:39,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:39,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328437060 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328439241
2014-07-14 02:00:41,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:41,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5685 synced till here 5684
2014-07-14 02:00:41,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328439241 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328441436
2014-07-14 02:00:42,078 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1313, memsize=192.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b9af1ee9a1a74bd48e8707dba5e578dd
2014-07-14 02:00:42,103 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b9af1ee9a1a74bd48e8707dba5e578dd as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b9af1ee9a1a74bd48e8707dba5e578dd
2014-07-14 02:00:42,120 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b9af1ee9a1a74bd48e8707dba5e578dd, entries=700190, sequenceid=1313, filesize=49.9m
2014-07-14 02:00:42,120 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~622.1m/652282640, currentsize=200.0m/209695520 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 13288ms, sequenceid=1313, compaction requested=true
2014-07-14 02:00:42,121 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-14 02:00:42,121 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 435.1m
2014-07-14 02:00:42,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:42,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5763 synced till here 5756
2014-07-14 02:00:43,150 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:43,638 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1326, memsize=192.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/6cc5adc87dde4e549e9d52f531253e39
2014-07-14 02:00:43,649 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328441436 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328442960
2014-07-14 02:00:43,704 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/6cc5adc87dde4e549e9d52f531253e39 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/6cc5adc87dde4e549e9d52f531253e39
2014-07-14 02:00:43,719 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/6cc5adc87dde4e549e9d52f531253e39, entries=699180, sequenceid=1326, filesize=49.9m
2014-07-14 02:00:43,719 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~677.1m/710030320, currentsize=189.8m/198978800 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 13605ms, sequenceid=1326, compaction requested=true
2014-07-14 02:00:43,719 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:00:43,720 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 444.1m
2014-07-14 02:00:43,806 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/dce557b91b094ad2bf307c8126e04680 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dce557b91b094ad2bf307c8126e04680
2014-07-14 02:00:43,847 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:00:43,857 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa1a74abb91a4377bbbcb8e1773611be, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa1a74abb91a4377bbbcb8e1773611be
2014-07-14 02:00:43,860 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/7cb8f3a579024f2db118f90c8cd31a94, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/7cb8f3a579024f2db118f90c8cd31a94
2014-07-14 02:00:43,863 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3e94338d27534172a3d3156ed3638b24, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3e94338d27534172a3d3156ed3638b24
2014-07-14 02:00:43,863 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into dce557b91b094ad2bf307c8126e04680(size=82.9m), total size for store is 132.5m. This selection was in queue for 0sec, and took 37sec to execute.
2014-07-14 02:00:43,863 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=107.1m, priority=17, time=282314240615109; duration=37sec
2014-07-14 02:00:43,863 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:00:43,863 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-14 02:00:43,864 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 162734321 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-14 02:00:43,864 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating major compaction
2014-07-14 02:00:43,864 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:00:43,864 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=155.2m
2014-07-14 02:00:43,864 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fc805439f16046168c0b5df3bd33c07c, keycount=33456, bloomtype=ROW, size=23.9m, encoding=NONE, seqNum=279, earliestPutTs=1405328268038
2014-07-14 02:00:43,865 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/dfaa4952164447faa056a9944911e028, keycount=63820, bloomtype=ROW, size=45.5m, encoding=NONE, seqNum=454, earliestPutTs=1405328306553
2014-07-14 02:00:43,865 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/554e89c7dde749bbab3421fb980d91e3, keycount=45257, bloomtype=ROW, size=32.3m, encoding=NONE, seqNum=728, earliestPutTs=1405328320496
2014-07-14 02:00:43,865 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/50794cdf4fc94564a2aa46f277007483, keycount=75135, bloomtype=ROW, size=53.6m, encoding=NONE, seqNum=1157, earliestPutTs=1405328349471
2014-07-14 02:00:43,894 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:44,179 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:44,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:45,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5861 synced till here 5858
2014-07-14 02:00:45,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328442960 with entries=98, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328444900
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328361158
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328364813
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328367645
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328370168
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328373110
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328375399
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328377542
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328379950
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328382570
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328385094
2014-07-14 02:00:45,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328388905
2014-07-14 02:00:45,396 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:00:46,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:47,056 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:00:47,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328444900 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328446941
2014-07-14 02:00:49,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:49,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6015 synced till here 6014
2014-07-14 02:00:49,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328446941 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328449668
2014-07-14 02:00:51,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:51,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328449668 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328451077
2014-07-14 02:00:53,196 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:53,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328451077 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328453196
2014-07-14 02:00:55,085 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1439, memsize=233.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/2398ada75db04a5092157d3abd97d953
2014-07-14 02:00:55,105 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/2398ada75db04a5092157d3abd97d953 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2398ada75db04a5092157d3abd97d953
2014-07-14 02:00:55,122 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2398ada75db04a5092157d3abd97d953, entries=851220, sequenceid=1439, filesize=60.6m
2014-07-14 02:00:55,123 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~438.2m/459505200, currentsize=194.4m/203854240 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 13002ms, sequenceid=1439, compaction requested=false
2014-07-14 02:00:55,123 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 393.9m
2014-07-14 02:00:55,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:55,283 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6251 synced till here 6249
2014-07-14 02:00:55,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328453196 with entries=76, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328455242
2014-07-14 02:00:55,324 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328390992
2014-07-14 02:00:55,440 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:55,557 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1447, memsize=234.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/19b243cc64c844f2a5a0289bd330bc3e
2014-07-14 02:00:55,583 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/19b243cc64c844f2a5a0289bd330bc3e as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/19b243cc64c844f2a5a0289bd330bc3e
2014-07-14 02:00:55,602 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/19b243cc64c844f2a5a0289bd330bc3e, entries=851930, sequenceid=1447, filesize=60.7m
2014-07-14 02:00:55,602 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~447.2m/468909760, currentsize=194.3m/203749920 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 11882ms, sequenceid=1447, compaction requested=true
2014-07-14 02:00:55,602 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:00:55,603 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 384.1m
2014-07-14 02:00:56,245 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:00:56,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:56,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6328 synced till here 6321
2014-07-14 02:00:56,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328455242 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328456563
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328392903
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328395067
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328396854
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328399710
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328402324
2014-07-14 02:00:56,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328407981
2014-07-14 02:00:58,131 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:00:58,214 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:00:58,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6409 synced till here 6407
2014-07-14 02:00:59,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328456563 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328458214
2014-07-14 02:00:59,598 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:01:00,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:00,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6487 synced till here 6483
2014-07-14 02:01:00,267 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328458214 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328460167
2014-07-14 02:01:02,024 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:02,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6587 synced till here 6585
2014-07-14 02:01:02,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328460167 with entries=100, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328462024
2014-07-14 02:01:04,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:05,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6704 synced till here 6703
2014-07-14 02:01:05,232 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328462024 with entries=117, filesize=100.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328464335
2014-07-14 02:01:08,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:08,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6778 synced till here 6777
2014-07-14 02:01:08,071 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328464335 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328468034
2014-07-14 02:01:08,288 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1569, memsize=328.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/fa557ae853534fbbad19f30f07cac00f
2014-07-14 02:01:08,299 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/fa557ae853534fbbad19f30f07cac00f as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa557ae853534fbbad19f30f07cac00f
2014-07-14 02:01:08,310 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa557ae853534fbbad19f30f07cac00f, entries=1197380, sequenceid=1569, filesize=85.2m
2014-07-14 02:01:08,310 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~395.6m/414784240, currentsize=213.6m/223998880 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 13187ms, sequenceid=1569, compaction requested=true
2014-07-14 02:01:08,310 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-14 02:01:08,311 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 410.4m
2014-07-14 02:01:08,908 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:09,009 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1575, memsize=321.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/04ee03ac24ac4b6c9add5b01e921e6b8
2014-07-14 02:01:09,023 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/04ee03ac24ac4b6c9add5b01e921e6b8 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04ee03ac24ac4b6c9add5b01e921e6b8
2014-07-14 02:01:09,034 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04ee03ac24ac4b6c9add5b01e921e6b8, entries=1171660, sequenceid=1575, filesize=83.4m
2014-07-14 02:01:09,035 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~385.6m/404381840, currentsize=211.2m/221420400 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 13432ms, sequenceid=1575, compaction requested=true
2014-07-14 02:01:09,035 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-14 02:01:09,035 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 405.3m
2014-07-14 02:01:09,285 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:09,781 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cc835141bfb64df69c4b24c67d8486c5 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cc835141bfb64df69c4b24c67d8486c5
2014-07-14 02:01:09,801 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:01:09,817 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fc805439f16046168c0b5df3bd33c07c, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fc805439f16046168c0b5df3bd33c07c
2014-07-14 02:01:09,821 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/dfaa4952164447faa056a9944911e028, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/dfaa4952164447faa056a9944911e028
2014-07-14 02:01:09,824 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/554e89c7dde749bbab3421fb980d91e3, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/554e89c7dde749bbab3421fb980d91e3
2014-07-14 02:01:09,830 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/50794cdf4fc94564a2aa46f277007483, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/50794cdf4fc94564a2aa46f277007483
2014-07-14 02:01:09,831 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into cc835141bfb64df69c4b24c67d8486c5(size=127.3m), total size for store is 187.9m. This selection was in queue for 0sec, and took 25sec to execute.
2014-07-14 02:01:09,831 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=4, fileSize=155.2m, priority=16, time=282351291109304; duration=25sec
2014-07-14 02:01:09,831 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-14 02:01:09,831 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-14 02:01:09,832 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 279161962 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-14 02:01:09,832 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating major compaction
2014-07-14 02:01:09,832 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:01:09,832 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=266.2m
2014-07-14 02:01:09,832 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a9a21c2ba4bf483f90e919ad54daa4dd, keycount=89577, bloomtype=ROW, size=63.8m, encoding=NONE, seqNum=584, earliestPutTs=1405328266976
2014-07-14 02:01:09,833 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1689b97cca1346498741e738497330b4, keycount=94422, bloomtype=ROW, size=67.3m, encoding=NONE, seqNum=910, earliestPutTs=1405328338748
2014-07-14 02:01:09,833 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b9af1ee9a1a74bd48e8707dba5e578dd, keycount=70019, bloomtype=ROW, size=49.9m, encoding=NONE, seqNum=1313, earliestPutTs=1405328374712
2014-07-14 02:01:09,833 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa557ae853534fbbad19f30f07cac00f, keycount=119738, bloomtype=ROW, size=85.2m, encoding=NONE, seqNum=1569, earliestPutTs=1405328428964
2014-07-14 02:01:09,874 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=14985, hits=56, hitRatio=0.37%, , cachingAccesses=59, cachingHits=56, cachingHitsRatio=94.91%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-14 02:01:11,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:11,613 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328468034 with entries=74, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328471574
2014-07-14 02:01:11,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328426257
2014-07-14 02:01:11,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328430917
2014-07-14 02:01:11,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328433386
2014-07-14 02:01:11,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328434682
2014-07-14 02:01:11,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328437060
2014-07-14 02:01:11,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328439241
2014-07-14 02:01:15,297 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:01:16,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:16,752 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:01:17,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6946 synced till here 6945
2014-07-14 02:01:17,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328471574 with entries=94, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328476690
2014-07-14 02:01:19,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:19,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7021 synced till here 7018
2014-07-14 02:01:19,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328476690 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328479050
2014-07-14 02:01:21,076 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1705, memsize=378.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c9379685625e47f3b3a86263dc576d5b
2014-07-14 02:01:21,088 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c9379685625e47f3b3a86263dc576d5b as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c9379685625e47f3b3a86263dc576d5b
2014-07-14 02:01:21,103 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c9379685625e47f3b3a86263dc576d5b, entries=1379050, sequenceid=1705, filesize=98.2m
2014-07-14 02:01:21,103 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~411.9m/431945360, currentsize=99.5m/104289280 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 12792ms, sequenceid=1705, compaction requested=true
2014-07-14 02:01:21,103 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-14 02:01:21,104 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 316.1m
2014-07-14 02:01:21,305 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:21,572 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1711, memsize=382.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1b02afd90fed4164b589c88f6f98da29
2014-07-14 02:01:21,586 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1b02afd90fed4164b589c88f6f98da29 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1b02afd90fed4164b589c88f6f98da29
2014-07-14 02:01:21,596 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1b02afd90fed4164b589c88f6f98da29, entries=1390910, sequenceid=1711, filesize=99.1m
2014-07-14 02:01:21,597 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~406.8m/426516400, currentsize=102.4m/107398160 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 12562ms, sequenceid=1711, compaction requested=true
2014-07-14 02:01:21,597 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:01:21,597 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 313.7m
2014-07-14 02:01:21,814 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:22,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:22,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7095 synced till here 7093
2014-07-14 02:01:22,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328479050 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328482239
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328441436
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328442960
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328444900
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328446941
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328449668
2014-07-14 02:01:22,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328451077
2014-07-14 02:01:25,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:25,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7168 synced till here 7167
2014-07-14 02:01:25,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328482239 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328485156
2014-07-14 02:01:26,479 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:26,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328485156 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328486480
2014-07-14 02:01:27,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:27,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7317 synced till here 7314
2014-07-14 02:01:27,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328486480 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328487914
2014-07-14 02:01:29,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:29,837 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328487914 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328489812
2014-07-14 02:01:31,016 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1774, memsize=300.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4c36bc21997049dfbe17e92402117052
2014-07-14 02:01:31,032 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4c36bc21997049dfbe17e92402117052 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4c36bc21997049dfbe17e92402117052
2014-07-14 02:01:31,043 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4c36bc21997049dfbe17e92402117052, entries=1094180, sequenceid=1774, filesize=77.9m
2014-07-14 02:01:31,044 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~317.7m/333112480, currentsize=131.5m/137933520 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 9940ms, sequenceid=1774, compaction requested=false
2014-07-14 02:01:31,256 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1779, memsize=298.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/035a97cbbca240f2b0d94becb3294a3f
2014-07-14 02:01:31,268 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/035a97cbbca240f2b0d94becb3294a3f as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/035a97cbbca240f2b0d94becb3294a3f
2014-07-14 02:01:31,278 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/035a97cbbca240f2b0d94becb3294a3f, entries=1085620, sequenceid=1779, filesize=77.3m
2014-07-14 02:01:31,278 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~315.2m/330495200, currentsize=128.4m/134586720 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 9681ms, sequenceid=1779, compaction requested=true
2014-07-14 02:01:31,278 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-14 02:01:31,986 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:01:31,986 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 257.2m
2014-07-14 02:01:32,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:32,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7463 synced till here 7462
2014-07-14 02:01:32,149 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328489812 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328492080
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328453196
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328455242
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328456563
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328458214
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328460167
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328462024
2014-07-14 02:01:32,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328464335
2014-07-14 02:01:32,177 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:32,754 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:01:32,754 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 256.4m
2014-07-14 02:01:32,930 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:34,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:34,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7536 synced till here 7535
2014-07-14 02:01:34,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328492080 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328494490
2014-07-14 02:01:37,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:37,547 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328494490 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328497515
2014-07-14 02:01:39,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:39,697 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7679 synced till here 7678
2014-07-14 02:01:39,713 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328497515 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328499671
2014-07-14 02:01:40,689 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1874, memsize=260.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/4110508cba2f4e3a8e3b4df43ca78dca
2014-07-14 02:01:40,702 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/4110508cba2f4e3a8e3b4df43ca78dca as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4110508cba2f4e3a8e3b4df43ca78dca
2014-07-14 02:01:40,715 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4110508cba2f4e3a8e3b4df43ca78dca, entries=947830, sequenceid=1874, filesize=67.5m
2014-07-14 02:01:40,715 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.3m/272966000, currentsize=86.6m/90850640 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 8729ms, sequenceid=1874, compaction requested=true
2014-07-14 02:01:40,716 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-14 02:01:41,511 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:01:41,511 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 256.2m
2014-07-14 02:01:41,577 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1877, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6d0de515505440739f1afc622f046384
2014-07-14 02:01:41,590 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6d0de515505440739f1afc622f046384 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6d0de515505440739f1afc622f046384
2014-07-14 02:01:41,630 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6d0de515505440739f1afc622f046384, entries=933400, sequenceid=1877, filesize=66.5m
2014-07-14 02:01:41,630 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268811280, currentsize=95.0m/99660160 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 8876ms, sequenceid=1877, compaction requested=true
2014-07-14 02:01:41,630 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-14 02:01:41,706 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:41,929 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:01:41,929 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 257.1m
2014-07-14 02:01:41,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:42,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7755 synced till here 7752
2014-07-14 02:01:42,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328499671 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328501992
2014-07-14 02:01:42,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328468034
2014-07-14 02:01:42,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328471574
2014-07-14 02:01:42,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328476690
2014-07-14 02:01:42,168 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:43,183 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:43,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7842 synced till here 7841
2014-07-14 02:01:43,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328501992 with entries=87, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328503184
2014-07-14 02:01:47,964 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/1987b4f4ec674a1fac4c8f0979a2b366 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1987b4f4ec674a1fac4c8f0979a2b366
2014-07-14 02:01:47,980 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:01:47,988 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a9a21c2ba4bf483f90e919ad54daa4dd, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a9a21c2ba4bf483f90e919ad54daa4dd
2014-07-14 02:01:47,993 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1689b97cca1346498741e738497330b4, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1689b97cca1346498741e738497330b4
2014-07-14 02:01:48,000 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b9af1ee9a1a74bd48e8707dba5e578dd, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b9af1ee9a1a74bd48e8707dba5e578dd
2014-07-14 02:01:48,007 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa557ae853534fbbad19f30f07cac00f, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa557ae853534fbbad19f30f07cac00f
2014-07-14 02:01:48,007 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 1987b4f4ec674a1fac4c8f0979a2b366(size=221.4m), total size for store is 299.4m. This selection was in queue for 0sec, and took 38sec to execute.
2014-07-14 02:01:48,007 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=4, fileSize=266.2m, priority=16, time=282377259050256; duration=38sec
2014-07-14 02:01:48,007 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-14 02:01:48,008 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-14 02:01:48,008 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 358573722 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-14 02:01:48,008 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating major compaction
2014-07-14 02:01:48,008 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:01:48,008 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=342.0m
2014-07-14 02:01:48,009 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f71bc9bb037047ddb943daf4c22d4881, keycount=89640, bloomtype=ROW, size=63.9m, encoding=NONE, seqNum=575, earliestPutTs=1405328267435
2014-07-14 02:01:48,009 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/2d1bec50a48d465f93054c5c8344f93e, keycount=94782, bloomtype=ROW, size=67.6m, encoding=NONE, seqNum=888, earliestPutTs=1405328339260
2014-07-14 02:01:48,009 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/6cc5adc87dde4e549e9d52f531253e39, keycount=69918, bloomtype=ROW, size=49.9m, encoding=NONE, seqNum=1326, earliestPutTs=1405328375402
2014-07-14 02:01:48,009 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04ee03ac24ac4b6c9add5b01e921e6b8, keycount=117166, bloomtype=ROW, size=83.4m, encoding=NONE, seqNum=1575, earliestPutTs=1405328433685
2014-07-14 02:01:48,009 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/035a97cbbca240f2b0d94becb3294a3f, keycount=108562, bloomtype=ROW, size=77.3m, encoding=NONE, seqNum=1779, earliestPutTs=1405328455634
2014-07-14 02:01:48,087 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:01:50,255 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1941, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/cad45dd49a30468585886c97d74a76f2
2014-07-14 02:01:50,273 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/cad45dd49a30468585886c97d74a76f2 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/cad45dd49a30468585886c97d74a76f2
2014-07-14 02:01:50,292 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/cad45dd49a30468585886c97d74a76f2, entries=938210, sequenceid=1941, filesize=66.9m
2014-07-14 02:01:50,292 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270196960, currentsize=65.2m/68354320 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 8781ms, sequenceid=1941, compaction requested=true
2014-07-14 02:01:50,293 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-14 02:01:50,651 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1947, memsize=258.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/97fa454f858a4a18817ab0466674b2d4
2014-07-14 02:01:50,670 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/97fa454f858a4a18817ab0466674b2d4 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/97fa454f858a4a18817ab0466674b2d4
2014-07-14 02:01:50,692 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/97fa454f858a4a18817ab0466674b2d4, entries=942220, sequenceid=1947, filesize=67.1m
2014-07-14 02:01:50,693 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.8m/271351520, currentsize=56.2m/58902640 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 8764ms, sequenceid=1947, compaction requested=false
2014-07-14 02:01:58,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:01:58,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328503184 with entries=72, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328518639
2014-07-14 02:01:58,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328479050
2014-07-14 02:01:58,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328482239
2014-07-14 02:01:58,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328485156
2014-07-14 02:01:58,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328486480
2014-07-14 02:01:58,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328487914
2014-07-14 02:01:58,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328489812
2014-07-14 02:02:04,807 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:05,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8014 synced till here 8008
2014-07-14 02:02:05,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328518639 with entries=100, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328524808
2014-07-14 02:02:07,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:07,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8087 synced till here 8085
2014-07-14 02:02:07,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328524808 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328527085
2014-07-14 02:02:07,622 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:02:07,624 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 256.1m
2014-07-14 02:02:08,216 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:08,242 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:02:08,243 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 256.3m
2014-07-14 02:02:08,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:08,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8169 synced till here 8166
2014-07-14 02:02:08,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328527085 with entries=82, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328528430
2014-07-14 02:02:08,509 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:09,713 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:09,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8251 synced till here 8243
2014-07-14 02:02:09,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328528430 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328529714
2014-07-14 02:02:11,431 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:11,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8331 synced till here 8330
2014-07-14 02:02:11,599 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328529714 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328531432
2014-07-14 02:02:12,804 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:02:13,362 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:13,643 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:02:13,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8426 synced till here 8423
2014-07-14 02:02:13,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328531432 with entries=95, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328533362
2014-07-14 02:02:15,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:16,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8543 synced till here 8530
2014-07-14 02:02:17,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328533362 with entries=117, filesize=100.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328535778
2014-07-14 02:02:18,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:18,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8654 synced till here 8630
2014-07-14 02:02:19,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328535778 with entries=111, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328538820
2014-07-14 02:02:21,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:21,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8769 synced till here 8728
2014-07-14 02:02:23,097 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2041, memsize=251.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/22212a362b4546cb8e165ae9136607d1
2014-07-14 02:02:23,121 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/22212a362b4546cb8e165ae9136607d1 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22212a362b4546cb8e165ae9136607d1
2014-07-14 02:02:23,134 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22212a362b4546cb8e165ae9136607d1, entries=915790, sequenceid=2041, filesize=65.2m
2014-07-14 02:02:23,162 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270176720, currentsize=222.0m/232737920 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 15539ms, sequenceid=2041, compaction requested=true
2014-07-14 02:02:23,163 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-14 02:02:23,163 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 430.7m
2014-07-14 02:02:23,194 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328538820 with entries=115, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328541490
2014-07-14 02:02:23,882 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2046, memsize=248.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/4990676d4979425a90f42bb1aa87f448
2014-07-14 02:02:23,904 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/4990676d4979425a90f42bb1aa87f448 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4990676d4979425a90f42bb1aa87f448
2014-07-14 02:02:23,918 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4990676d4979425a90f42bb1aa87f448, entries=904880, sequenceid=2046, filesize=64.4m
2014-07-14 02:02:23,919 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.0m/273657200, currentsize=232.8m/244068640 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15677ms, sequenceid=2046, compaction requested=true
2014-07-14 02:02:23,919 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-14 02:02:23,919 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 423.0m
2014-07-14 02:02:23,953 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:02:25,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:25,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8874 synced till here 8841
2014-07-14 02:02:25,453 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:25,473 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:25,650 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:02:25,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328541490 with entries=105, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328545274
2014-07-14 02:02:25,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328492080
2014-07-14 02:02:25,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328494490
2014-07-14 02:02:25,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328497515
2014-07-14 02:02:27,980 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:28,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8993 synced till here 8954
2014-07-14 02:02:28,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328545274 with entries=119, filesize=100.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328547981
2014-07-14 02:02:30,539 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:31,495 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9104 synced till here 9076
2014-07-14 02:02:31,749 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328547981 with entries=111, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328550540
2014-07-14 02:02:33,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:34,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9254 synced till here 9229
2014-07-14 02:02:34,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328550540 with entries=150, filesize=128.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328553778
2014-07-14 02:02:35,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:35,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9350 synced till here 9333
2014-07-14 02:02:36,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328553778 with entries=96, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328555963
2014-07-14 02:02:37,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:38,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9448 synced till here 9437
2014-07-14 02:02:38,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328555963 with entries=98, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328557600
2014-07-14 02:02:39,647 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:39,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328557600 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328559648
2014-07-14 02:02:40,364 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2220, memsize=239.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f270f0cdd3a24b449034b5016c775bcd
2014-07-14 02:02:40,383 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f270f0cdd3a24b449034b5016c775bcd as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f270f0cdd3a24b449034b5016c775bcd
2014-07-14 02:02:40,410 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f270f0cdd3a24b449034b5016c775bcd, entries=873550, sequenceid=2220, filesize=62.2m
2014-07-14 02:02:40,410 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~424.7m/445298240, currentsize=273.6m/286891360 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 16491ms, sequenceid=2220, compaction requested=false
2014-07-14 02:02:40,411 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 537.5m
2014-07-14 02:02:40,448 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:02:40,563 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2234, memsize=248.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/54733bc5ad7d422780c2a1cb536bebad
2014-07-14 02:02:40,578 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/54733bc5ad7d422780c2a1cb536bebad as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/54733bc5ad7d422780c2a1cb536bebad
2014-07-14 02:02:40,597 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/54733bc5ad7d422780c2a1cb536bebad, entries=906290, sequenceid=2234, filesize=64.5m
2014-07-14 02:02:40,598 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~452.3m/474252480, currentsize=264.3m/277184080 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 17435ms, sequenceid=2234, compaction requested=true
2014-07-14 02:02:40,598 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-14 02:02:40,598 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 548.7m
2014-07-14 02:02:40,630 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:02:40,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:40,938 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:41,131 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:41,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9637 synced till here 9635
2014-07-14 02:02:41,724 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328559648 with entries=109, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328560910
2014-07-14 02:02:41,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328499671
2014-07-14 02:02:41,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328501992
2014-07-14 02:02:41,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328503184
2014-07-14 02:02:41,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328518639
2014-07-14 02:02:41,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328524808
2014-07-14 02:02:42,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:42,919 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9719 synced till here 9710
2014-07-14 02:02:42,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328560910 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328562364
2014-07-14 02:02:43,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:43,896 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9795 synced till here 9792
2014-07-14 02:02:43,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328562364 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328563868
2014-07-14 02:02:45,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:45,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328563868 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328565748
2014-07-14 02:02:47,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:47,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9942 synced till here 9940
2014-07-14 02:02:47,316 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328565748 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328567253
2014-07-14 02:02:48,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:49,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10041 synced till here 10038
2014-07-14 02:02:49,352 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328567253 with entries=99, filesize=85.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328568619
2014-07-14 02:02:49,603 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2397, memsize=147.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/70f84bf7ef244fcfb7727c8e37ae091f
2014-07-14 02:02:49,626 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/70f84bf7ef244fcfb7727c8e37ae091f as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/70f84bf7ef244fcfb7727c8e37ae091f
2014-07-14 02:02:49,640 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/70f84bf7ef244fcfb7727c8e37ae091f, entries=537240, sequenceid=2397, filesize=38.3m
2014-07-14 02:02:49,641 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~540.6m/566885440, currentsize=197.5m/207124800 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 9230ms, sequenceid=2397, compaction requested=true
2014-07-14 02:02:49,641 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-14 02:02:49,641 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 480.3m
2014-07-14 02:02:49,887 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2402, memsize=153.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/1c05c292dcb84e7fb5c86832e01b6d1c
2014-07-14 02:02:49,902 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/1c05c292dcb84e7fb5c86832e01b6d1c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/1c05c292dcb84e7fb5c86832e01b6d1c
2014-07-14 02:02:49,996 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:50,028 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:50,902 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/1c05c292dcb84e7fb5c86832e01b6d1c, entries=558550, sequenceid=2402, filesize=39.9m
2014-07-14 02:02:50,903 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~553.4m/580290800, currentsize=217.8m/228420240 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 10304ms, sequenceid=2402, compaction requested=true
2014-07-14 02:02:50,903 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-14 02:02:50,903 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 485.5m
2014-07-14 02:02:50,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10131 synced till here 10128
2014-07-14 02:02:50,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328568619 with entries=90, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328570028
2014-07-14 02:02:50,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328527085
2014-07-14 02:02:50,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328528430
2014-07-14 02:02:50,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328529714
2014-07-14 02:02:50,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328531432
2014-07-14 02:02:50,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328533362
2014-07-14 02:02:50,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328535778
2014-07-14 02:02:50,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328538820
2014-07-14 02:02:51,356 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:51,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:52,324 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:02:52,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10229 synced till here 10226
2014-07-14 02:02:52,421 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:02:52,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328570028 with entries=98, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328571700
2014-07-14 02:02:54,526 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1146ms
GC pool 'ParNew' had collection(s): count=1 time=1364ms
2014-07-14 02:02:54,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:54,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10305 synced till here 10302
2014-07-14 02:02:54,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328571700 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328574557
2014-07-14 02:02:55,714 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/142697ca4b6c49bc9283095bcf4c55de as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/142697ca4b6c49bc9283095bcf4c55de
2014-07-14 02:02:55,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:56,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10388 synced till here 10385
2014-07-14 02:02:56,183 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328574557 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328575729
2014-07-14 02:02:56,184 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:02:56,191 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f71bc9bb037047ddb943daf4c22d4881, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f71bc9bb037047ddb943daf4c22d4881
2014-07-14 02:02:56,193 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/2d1bec50a48d465f93054c5c8344f93e, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/2d1bec50a48d465f93054c5c8344f93e
2014-07-14 02:02:56,202 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/6cc5adc87dde4e549e9d52f531253e39, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/6cc5adc87dde4e549e9d52f531253e39
2014-07-14 02:02:56,205 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04ee03ac24ac4b6c9add5b01e921e6b8, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04ee03ac24ac4b6c9add5b01e921e6b8
2014-07-14 02:02:56,208 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/035a97cbbca240f2b0d94becb3294a3f, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/035a97cbbca240f2b0d94becb3294a3f
2014-07-14 02:02:56,208 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into 142697ca4b6c49bc9283095bcf4c55de(size=300.1m), total size for store is 429.4m. This selection was in queue for 0sec, and took 1mins, 8sec to execute.
2014-07-14 02:02:56,209 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=5, fileSize=342.0m, priority=15, time=282415435336869; duration=1mins, 8sec
2014-07-14 02:02:56,209 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-14 02:02:56,209 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-14 02:02:56,209 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 7 files of size 483795501 starting at candidate #0 after considering 15 permutations with 15 in ratio
2014-07-14 02:02:56,210 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating major compaction
2014-07-14 02:02:56,210 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:02:56,210 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 7 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=461.4m
2014-07-14 02:02:56,210 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dce557b91b094ad2bf307c8126e04680, keycount=116361, bloomtype=ROW, size=82.9m, encoding=NONE, seqNum=738, earliestPutTs=1405328267843
2014-07-14 02:02:56,210 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1e6dd6e18df14f069991aa7bf0ff08de, keycount=69499, bloomtype=ROW, size=49.6m, encoding=NONE, seqNum=1159, earliestPutTs=1405328350243
2014-07-14 02:02:56,210 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/19b243cc64c844f2a5a0289bd330bc3e, keycount=85193, bloomtype=ROW, size=60.7m, encoding=NONE, seqNum=1447, earliestPutTs=1405328393215
2014-07-14 02:02:56,211 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1b02afd90fed4164b589c88f6f98da29, keycount=139091, bloomtype=ROW, size=99.1m, encoding=NONE, seqNum=1711, earliestPutTs=1405328443841
2014-07-14 02:02:56,211 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6d0de515505440739f1afc622f046384, keycount=93340, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=1877, earliestPutTs=1405328469080
2014-07-14 02:02:56,211 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4990676d4979425a90f42bb1aa87f448, keycount=90488, bloomtype=ROW, size=64.4m, encoding=NONE, seqNum=2046, earliestPutTs=1405328492818
2014-07-14 02:02:56,211 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/70f84bf7ef244fcfb7727c8e37ae091f, keycount=53724, bloomtype=ROW, size=38.3m, encoding=NONE, seqNum=2397, earliestPutTs=1405328528632
2014-07-14 02:02:56,423 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:02:57,233 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:57,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10468 synced till here 10467
2014-07-14 02:02:57,920 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328575729 with entries=80, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328577233
2014-07-14 02:02:58,689 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:02:59,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10548 synced till here 10541
2014-07-14 02:02:59,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328577233 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328578690
2014-07-14 02:03:00,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:00,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10621 synced till here 10619
2014-07-14 02:03:00,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328578690 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328580694
2014-07-14 02:03:02,094 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:02,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10704 synced till here 10702
2014-07-14 02:03:02,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328580694 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328582094
2014-07-14 02:03:02,817 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2533, memsize=249.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/4c8bfaabed5343e3bd1a4ac29dc91782
2014-07-14 02:03:02,832 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/4c8bfaabed5343e3bd1a4ac29dc91782 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4c8bfaabed5343e3bd1a4ac29dc91782
2014-07-14 02:03:02,843 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4c8bfaabed5343e3bd1a4ac29dc91782, entries=907370, sequenceid=2533, filesize=64.6m
2014-07-14 02:03:02,844 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~483.3m/506781040, currentsize=245.3m/257243040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 13203ms, sequenceid=2533, compaction requested=true
2014-07-14 02:03:02,844 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-14 02:03:02,844 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 450.4m
2014-07-14 02:03:03,122 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:03:03,181 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:03,740 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2548, memsize=268.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/fa50798b16cb49af94a32799565f3ff7
2014-07-14 02:03:03,757 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/fa50798b16cb49af94a32799565f3ff7 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa50798b16cb49af94a32799565f3ff7
2014-07-14 02:03:03,770 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa50798b16cb49af94a32799565f3ff7, entries=979060, sequenceid=2548, filesize=69.6m
2014-07-14 02:03:03,771 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~487.0m/510641440, currentsize=238.5m/250083680 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 12868ms, sequenceid=2548, compaction requested=true
2014-07-14 02:03:03,771 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-14 02:03:03,771 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 472.2m
2014-07-14 02:03:04,090 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:05,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:05,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328582094 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328585131
2014-07-14 02:03:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328541490
2014-07-14 02:03:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328545274
2014-07-14 02:03:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328547981
2014-07-14 02:03:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328550540
2014-07-14 02:03:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328553778
2014-07-14 02:03:05,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328555963
2014-07-14 02:03:05,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328557600
2014-07-14 02:03:06,517 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:03:07,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:07,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10849 synced till here 10847
2014-07-14 02:03:07,267 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328585131 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328587220
2014-07-14 02:03:08,531 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:08,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10927 synced till here 10920
2014-07-14 02:03:09,060 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328587220 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328588531
2014-07-14 02:03:10,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:10,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11022 synced till here 10999
2014-07-14 02:03:11,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328588531 with entries=95, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328590488
2014-07-14 02:03:12,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:12,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11109 synced till here 11100
2014-07-14 02:03:12,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328590488 with entries=87, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328592535
2014-07-14 02:03:14,012 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:14,100 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11200 synced till here 11192
2014-07-14 02:03:14,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328592535 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328594012
2014-07-14 02:03:15,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:15,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11278 synced till here 11272
2014-07-14 02:03:15,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328594012 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328595536
2014-07-14 02:03:16,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:16,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11358 synced till here 11349
2014-07-14 02:03:16,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328595536 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328596871
2014-07-14 02:03:18,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:18,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11454 synced till here 11441
2014-07-14 02:03:18,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328596871 with entries=96, filesize=82.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328598563
2014-07-14 02:03:20,551 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2691, memsize=387.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/e2e37f1b006e42d2ada44f9fdac56a64
2014-07-14 02:03:20,552 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:21,371 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/e2e37f1b006e42d2ada44f9fdac56a64 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e2e37f1b006e42d2ada44f9fdac56a64
2014-07-14 02:03:21,372 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11562 synced till here 11538
2014-07-14 02:03:21,393 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e2e37f1b006e42d2ada44f9fdac56a64, entries=1409210, sequenceid=2691, filesize=100.3m
2014-07-14 02:03:21,394 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~454.9m/477045120, currentsize=303.3m/317998720 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 18550ms, sequenceid=2691, compaction requested=false
2014-07-14 02:03:21,394 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 566.7m
2014-07-14 02:03:21,399 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:03:21,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328598563 with entries=108, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328600553
2014-07-14 02:03:22,163 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:23,376 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:23,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11720 synced till here 11682
2014-07-14 02:03:23,821 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2706, memsize=403.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/b92328ec67674d32a8ce3cc8c62fa6cb
2014-07-14 02:03:23,836 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/b92328ec67674d32a8ce3cc8c62fa6cb as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b92328ec67674d32a8ce3cc8c62fa6cb
2014-07-14 02:03:23,848 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b92328ec67674d32a8ce3cc8c62fa6cb, entries=1467970, sequenceid=2706, filesize=104.4m
2014-07-14 02:03:23,849 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~472.2m/495171920, currentsize=320.6m/336171360 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 20078ms, sequenceid=2706, compaction requested=true
2014-07-14 02:03:23,849 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-14 02:03:23,849 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 624.0m
2014-07-14 02:03:23,956 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:03:24,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328600553 with entries=158, filesize=135.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328603377
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328559648
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328560910
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328562364
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328563868
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328565748
2014-07-14 02:03:24,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328567253
2014-07-14 02:03:25,559 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:27,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:27,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11851 synced till here 11801
2014-07-14 02:03:27,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328603377 with entries=131, filesize=112.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328607179
2014-07-14 02:03:29,525 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:29,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11966 synced till here 11929
2014-07-14 02:03:30,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328607179 with entries=115, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328609526
2014-07-14 02:03:32,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:32,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12071 synced till here 12043
2014-07-14 02:03:33,014 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328609526 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328612710
2014-07-14 02:03:34,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:34,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12186 synced till here 12147
2014-07-14 02:03:35,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328612710 with entries=115, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328614882
2014-07-14 02:03:37,235 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:37,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12292 synced till here 12275
2014-07-14 02:03:37,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328614882 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328617235
2014-07-14 02:03:39,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:39,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12385 synced till here 12372
2014-07-14 02:03:39,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328617235 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328619014
2014-07-14 02:03:40,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:40,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12459 synced till here 12458
2014-07-14 02:03:40,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328619014 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328620529
2014-07-14 02:03:42,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:42,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12541 synced till here 12531
2014-07-14 02:03:42,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328620529 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328622125
2014-07-14 02:03:43,687 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:43,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12618 synced till here 12612
2014-07-14 02:03:43,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328622125 with entries=77, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328623688
2014-07-14 02:03:45,093 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:45,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328623688 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328625094
2014-07-14 02:03:46,231 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2910, memsize=392.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/7380d04a7836426ca2f4bb769e13433c
2014-07-14 02:03:46,255 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/7380d04a7836426ca2f4bb769e13433c as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/7380d04a7836426ca2f4bb769e13433c
2014-07-14 02:03:46,271 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/7380d04a7836426ca2f4bb769e13433c, entries=1429500, sequenceid=2910, filesize=101.8m
2014-07-14 02:03:46,272 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~580.8m/609013840, currentsize=430.1m/451043040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 24878ms, sequenceid=2910, compaction requested=true
2014-07-14 02:03:46,272 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-14 02:03:46,272 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 769.8m
2014-07-14 02:03:46,575 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:03:46,863 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:47,555 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:47,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12768 synced till here 12766
2014-07-14 02:03:47,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328625094 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328627555
2014-07-14 02:03:47,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328568619
2014-07-14 02:03:47,765 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2959, memsize=377.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/3d61866cb33f4c70acc7cddf34bae45c
2014-07-14 02:03:47,795 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/3d61866cb33f4c70acc7cddf34bae45c as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/3d61866cb33f4c70acc7cddf34bae45c
2014-07-14 02:03:47,811 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/3d61866cb33f4c70acc7cddf34bae45c, entries=1372860, sequenceid=2959, filesize=97.7m
2014-07-14 02:03:47,812 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~634.9m/665704160, currentsize=385.4m/404162240 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 23963ms, sequenceid=2959, compaction requested=true
2014-07-14 02:03:47,812 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-14 02:03:47,812 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 775.0m
2014-07-14 02:03:47,815 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:03:48,784 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:03:48,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:48,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12847 synced till here 12843
2014-07-14 02:03:48,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328627555 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328628790
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328570028
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328571700
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328574557
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328575729
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328577233
2014-07-14 02:03:48,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328578690
2014-07-14 02:03:48,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328580694
2014-07-14 02:03:50,012 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:50,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12925 synced till here 12918
2014-07-14 02:03:50,093 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328628790 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328630013
2014-07-14 02:03:51,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:51,565 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13009 synced till here 13007
2014-07-14 02:03:51,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328630013 with entries=84, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328631398
2014-07-14 02:03:53,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:53,123 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13086 synced till here 13083
2014-07-14 02:03:53,588 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328631398 with entries=77, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328633101
2014-07-14 02:03:54,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:55,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328633101 with entries=105, filesize=90.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328634896
2014-07-14 02:03:57,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:57,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328634896 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328637381
2014-07-14 02:03:59,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:03:59,117 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13344 synced till here 13340
2014-07-14 02:03:59,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328637381 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328639104
2014-07-14 02:04:00,005 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3186, memsize=279.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/dc979f94794147adbccedd047ed17d29
2014-07-14 02:04:00,018 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/dc979f94794147adbccedd047ed17d29 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dc979f94794147adbccedd047ed17d29
2014-07-14 02:04:00,029 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dc979f94794147adbccedd047ed17d29, entries=1018080, sequenceid=3186, filesize=72.5m
2014-07-14 02:04:00,030 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~769.8m/807191600, currentsize=267.2m/280186560 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 13758ms, sequenceid=3186, compaction requested=false
2014-07-14 02:04:00,030 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 700.3m
2014-07-14 02:04:00,041 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:04:00,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:00,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13417 synced till here 13415
2014-07-14 02:04:00,580 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328639104 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328640537
2014-07-14 02:04:00,601 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:01,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:01,808 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3209, memsize=288.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f34bdd2202ff4d3ea2c04097a7602ef6
2014-07-14 02:04:01,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13507 synced till here 13505
2014-07-14 02:04:01,857 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f34bdd2202ff4d3ea2c04097a7602ef6 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f34bdd2202ff4d3ea2c04097a7602ef6
2014-07-14 02:04:01,866 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f34bdd2202ff4d3ea2c04097a7602ef6, entries=1049840, sequenceid=3209, filesize=74.8m
2014-07-14 02:04:01,867 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~779.8m/817699280, currentsize=277.9m/291427440 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 14055ms, sequenceid=3209, compaction requested=true
2014-07-14 02:04:01,867 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-14 02:04:01,867 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 666.2m
2014-07-14 02:04:01,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328640537 with entries=90, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328641654
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328582094
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328585131
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328587220
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328588531
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328590488
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328592535
2014-07-14 02:04:01,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328594012
2014-07-14 02:04:01,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328595536
2014-07-14 02:04:01,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328596871
2014-07-14 02:04:01,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328598563
2014-07-14 02:04:01,891 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:04:02,361 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:03,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:03,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13614 synced till here 13612
2014-07-14 02:04:04,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328641654 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328643188
2014-07-14 02:04:05,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:05,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13688 synced till here 13685
2014-07-14 02:04:05,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328643188 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328645689
2014-07-14 02:04:06,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:07,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328645689 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328646916
2014-07-14 02:04:08,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:08,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13842 synced till here 13838
2014-07-14 02:04:08,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328646916 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328648729
2014-07-14 02:04:10,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:10,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13916 synced till here 13914
2014-07-14 02:04:10,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328648729 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328650026
2014-07-14 02:04:12,140 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:12,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14001 synced till here 14000
2014-07-14 02:04:13,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328650026 with entries=85, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328652140
2014-07-14 02:04:14,986 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:15,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14077 synced till here 14073
2014-07-14 02:04:15,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328652140 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328654986
2014-07-14 02:04:15,976 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:16,428 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14155 synced till here 14151
2014-07-14 02:04:16,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328654986 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328655976
2014-07-14 02:04:17,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:17,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14238 synced till here 14231
2014-07-14 02:04:17,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328655976 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328657319
2014-07-14 02:04:18,369 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3363, memsize=387.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f69dc177837347d9b73cfc47f63dfdbc
2014-07-14 02:04:18,401 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f69dc177837347d9b73cfc47f63dfdbc as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f69dc177837347d9b73cfc47f63dfdbc
2014-07-14 02:04:18,444 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f69dc177837347d9b73cfc47f63dfdbc, entries=1410740, sequenceid=3363, filesize=100.4m
2014-07-14 02:04:18,447 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~701.9m/736017520, currentsize=344.2m/360909280 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 18417ms, sequenceid=3363, compaction requested=true
2014-07-14 02:04:18,447 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-14 02:04:18,448 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 610.8m
2014-07-14 02:04:18,508 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:04:18,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:19,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14323 synced till here 14316
2014-07-14 02:04:19,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328657319 with entries=85, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328658746
2014-07-14 02:04:19,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328600553
2014-07-14 02:04:19,834 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:20,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:21,166 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14404 synced till here 14397
2014-07-14 02:04:21,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328658746 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328660488
2014-07-14 02:04:22,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:22,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14486 synced till here 14477
2014-07-14 02:04:23,006 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328660488 with entries=82, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328662063
2014-07-14 02:04:23,647 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3390, memsize=431.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f701e767fe2b4e23a9128ffeabb6cc41
2014-07-14 02:04:23,659 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f701e767fe2b4e23a9128ffeabb6cc41 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f701e767fe2b4e23a9128ffeabb6cc41
2014-07-14 02:04:23,671 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f701e767fe2b4e23a9128ffeabb6cc41, entries=1572030, sequenceid=3390, filesize=111.9m
2014-07-14 02:04:23,671 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~666.2m/698563040, currentsize=409.1m/428920640 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 21804ms, sequenceid=3390, compaction requested=true
2014-07-14 02:04:23,671 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:04:23,672 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 672.7m
2014-07-14 02:04:23,826 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:04:25,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:25,154 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14592 synced till here 14566
2014-07-14 02:04:25,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328662063 with entries=106, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328665051
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328603377
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328607179
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328609526
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328612710
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328614882
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328617235
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328619014
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328620529
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328622125
2014-07-14 02:04:25,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328623688
2014-07-14 02:04:25,613 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:27,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:27,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14714 synced till here 14693
2014-07-14 02:04:27,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328665051 with entries=122, filesize=104.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328667110
2014-07-14 02:04:29,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:29,276 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14813 synced till here 14794
2014-07-14 02:04:30,286 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328667110 with entries=99, filesize=83.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328669182
2014-07-14 02:04:31,885 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/2660f1a703ca4633ae04f1e6c0738edb as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/2660f1a703ca4633ae04f1e6c0738edb
2014-07-14 02:04:32,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:32,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14924 synced till here 14911
2014-07-14 02:04:32,349 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:04:32,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328669182 with entries=111, filesize=94.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328672125
2014-07-14 02:04:32,385 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dce557b91b094ad2bf307c8126e04680, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dce557b91b094ad2bf307c8126e04680
2014-07-14 02:04:32,395 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1e6dd6e18df14f069991aa7bf0ff08de, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1e6dd6e18df14f069991aa7bf0ff08de
2014-07-14 02:04:32,399 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/19b243cc64c844f2a5a0289bd330bc3e, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/19b243cc64c844f2a5a0289bd330bc3e
2014-07-14 02:04:32,410 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1b02afd90fed4164b589c88f6f98da29, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1b02afd90fed4164b589c88f6f98da29
2014-07-14 02:04:32,413 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6d0de515505440739f1afc622f046384, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6d0de515505440739f1afc622f046384
2014-07-14 02:04:32,415 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4990676d4979425a90f42bb1aa87f448, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4990676d4979425a90f42bb1aa87f448
2014-07-14 02:04:32,417 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/70f84bf7ef244fcfb7727c8e37ae091f, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/70f84bf7ef244fcfb7727c8e37ae091f
2014-07-14 02:04:32,418 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 7 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into 2660f1a703ca4633ae04f1e6c0738edb(size=438.9m), total size for store is 611.7m. This selection was in queue for 0sec, and took 1mins, 36sec to execute.
2014-07-14 02:04:32,418 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=7, fileSize=461.4m, priority=13, time=282483636959574; duration=1mins, 36sec
2014-07-14 02:04:32,418 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:04:32,418 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-14 02:04:32,419 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 8 files of size 668918041 starting at candidate #0 after considering 21 permutations with 21 in ratio
2014-07-14 02:04:32,419 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating major compaction
2014-07-14 02:04:32,419 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:04:32,419 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 8 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=637.9m
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cc835141bfb64df69c4b24c67d8486c5, keycount=178635, bloomtype=ROW, size=127.3m, encoding=NONE, seqNum=1157, earliestPutTs=1405328268038
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2398ada75db04a5092157d3abd97d953, keycount=85122, bloomtype=ROW, size=60.6m, encoding=NONE, seqNum=1439, earliestPutTs=1405328392881
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c9379685625e47f3b3a86263dc576d5b, keycount=137905, bloomtype=ROW, size=98.2m, encoding=NONE, seqNum=1705, earliestPutTs=1405328442764
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4110508cba2f4e3a8e3b4df43ca78dca, keycount=94783, bloomtype=ROW, size=67.5m, encoding=NONE, seqNum=1874, earliestPutTs=1405328468340
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22212a362b4546cb8e165ae9136607d1, keycount=91579, bloomtype=ROW, size=65.2m, encoding=NONE, seqNum=2041, earliestPutTs=1405328492132
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/1c05c292dcb84e7fb5c86832e01b6d1c, keycount=55855, bloomtype=ROW, size=39.9m, encoding=NONE, seqNum=2402, earliestPutTs=1405328527658
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b92328ec67674d32a8ce3cc8c62fa6cb, keycount=146797, bloomtype=ROW, size=104.4m, encoding=NONE, seqNum=2706, earliestPutTs=1405328560633
2014-07-14 02:04:32,420 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f34bdd2202ff4d3ea2c04097a7602ef6, keycount=104984, bloomtype=ROW, size=74.8m, encoding=NONE, seqNum=3209, earliestPutTs=1405328585113
2014-07-14 02:04:32,633 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:34,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:34,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15039 synced till here 15002
2014-07-14 02:04:34,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328672125 with entries=115, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328674102
2014-07-14 02:04:35,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:36,023 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15131 synced till here 15124
2014-07-14 02:04:36,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328674102 with entries=92, filesize=79.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328675862
2014-07-14 02:04:37,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:37,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15205 synced till here 15203
2014-07-14 02:04:37,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328675862 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328677450
2014-07-14 02:04:38,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:39,238 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15316 synced till here 15311
2014-07-14 02:04:39,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328677450 with entries=111, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328678833
2014-07-14 02:04:40,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:40,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15399 synced till here 15390
2014-07-14 02:04:40,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328678833 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328680351
2014-07-14 02:04:42,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:42,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15479 synced till here 15473
2014-07-14 02:04:42,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328680351 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328682209
2014-07-14 02:04:43,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:43,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15556 synced till here 15551
2014-07-14 02:04:43,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328682209 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328683673
2014-07-14 02:04:45,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:45,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328683673 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328685312
2014-07-14 02:04:46,632 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:46,773 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,781 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,783 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,801 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,809 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,843 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15717 synced till here 15714
2014-07-14 02:04:46,871 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,885 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328685312 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328686632
2014-07-14 02:04:46,914 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,924 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:46,982 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,174 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,210 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,261 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,299 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,337 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,375 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,416 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,462 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,514 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,568 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,634 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,692 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,758 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,817 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,884 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,942 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:47,981 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,797 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,811 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,820 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,847 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,877 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,906 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,935 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,966 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:48,997 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,045 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,077 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,104 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,134 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,164 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,194 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,225 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,253 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,283 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,312 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,341 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,371 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:49,404 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:04:50,715 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3583, memsize=587.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/59bde93aa3b24fa59ebcb5bf1cb57782
2014-07-14 02:04:50,734 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/59bde93aa3b24fa59ebcb5bf1cb57782 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/59bde93aa3b24fa59ebcb5bf1cb57782
2014-07-14 02:04:50,745 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/59bde93aa3b24fa59ebcb5bf1cb57782, entries=2139740, sequenceid=3583, filesize=152.2m
2014-07-14 02:04:50,745 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~615.6m/645481200, currentsize=553.3m/580210880 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 32297ms, sequenceid=3583, compaction requested=true
2014-07-14 02:04:50,745 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:04:50,746 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1342ms
2014-07-14 02:04:50,746 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 900.8m
2014-07-14 02:04:50,746 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,746 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1375ms
2014-07-14 02:04:50,746 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,746 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1405ms
2014-07-14 02:04:50,746 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,746 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1434ms
2014-07-14 02:04:50,747 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,749 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1466ms
2014-07-14 02:04:50,749 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,749 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1496ms
2014-07-14 02:04:50,749 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,749 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1524ms
2014-07-14 02:04:50,749 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,749 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1555ms
2014-07-14 02:04:50,749 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,749 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1585ms
2014-07-14 02:04:50,749 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,750 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1616ms
2014-07-14 02:04:50,750 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,750 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1646ms
2014-07-14 02:04:50,750 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,753 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1676ms
2014-07-14 02:04:50,753 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,755 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1710ms
2014-07-14 02:04:50,755 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,755 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1758ms
2014-07-14 02:04:50,755 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,761 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1795ms
2014-07-14 02:04:50,761 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,761 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1826ms
2014-07-14 02:04:50,761 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,761 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1855ms
2014-07-14 02:04:50,761 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,761 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1884ms
2014-07-14 02:04:50,761 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,762 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1915ms
2014-07-14 02:04:50,762 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,764 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1944ms
2014-07-14 02:04:50,764 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,764 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1953ms
2014-07-14 02:04:50,764 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,765 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1968ms
2014-07-14 02:04:50,765 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,769 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2788ms
2014-07-14 02:04:50,769 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,769 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2827ms
2014-07-14 02:04:50,769 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,769 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2885ms
2014-07-14 02:04:50,769 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,769 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2952ms
2014-07-14 02:04:50,769 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,772 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3014ms
2014-07-14 02:04:50,772 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,772 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3080ms
2014-07-14 02:04:50,772 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,772 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3139ms
2014-07-14 02:04:50,773 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,781 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3213ms
2014-07-14 02:04:50,781 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,781 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3267ms
2014-07-14 02:04:50,781 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,781 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3319ms
2014-07-14 02:04:50,781 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,781 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3365ms
2014-07-14 02:04:50,781 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3406ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3445ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3483ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3521ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3572ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,782 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3609ms
2014-07-14 02:04:50,782 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,784 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3802ms
2014-07-14 02:04:50,784 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,785 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3862ms
2014-07-14 02:04:50,785 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,789 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3875ms
2014-07-14 02:04:50,789 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,789 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3904ms
2014-07-14 02:04:50,789 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,801 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3930ms
2014-07-14 02:04:50,801 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,806 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3964ms
2014-07-14 02:04:50,806 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,813 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4004ms
2014-07-14 02:04:50,813 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,813 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4012ms
2014-07-14 02:04:50,813 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,813 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4030ms
2014-07-14 02:04:50,813 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,813 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4033ms
2014-07-14 02:04:50,814 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,816 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4043ms
2014-07-14 02:04:50,816 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:04:50,913 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:04:52,532 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:04:52,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:52,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15830 synced till here 15793
2014-07-14 02:04:53,995 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328686632 with entries=113, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328692673
2014-07-14 02:04:53,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328625094
2014-07-14 02:04:55,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:56,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15937 synced till here 15910
2014-07-14 02:04:56,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328692673 with entries=107, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328695953
2014-07-14 02:04:57,970 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3650, memsize=581.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/6a7a695dd27d4bb58cb61d84a34ce19e
2014-07-14 02:04:58,002 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/6a7a695dd27d4bb58cb61d84a34ce19e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6a7a695dd27d4bb58cb61d84a34ce19e
2014-07-14 02:04:58,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:04:58,142 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6a7a695dd27d4bb58cb61d84a34ce19e, entries=2116830, sequenceid=3650, filesize=150.6m
2014-07-14 02:04:58,142 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~683.7m/716903120, currentsize=545.5m/572028000 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 34470ms, sequenceid=3650, compaction requested=false
2014-07-14 02:04:58,143 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 990.8m
2014-07-14 02:04:58,147 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:04:58,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16038 synced till here 16036
2014-07-14 02:04:58,390 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328695953 with entries=101, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328698129
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328627555
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328628790
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328630013
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328631398
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328633101
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328634896
2014-07-14 02:04:58,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328637381
2014-07-14 02:05:00,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:00,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16146 synced till here 16117
2014-07-14 02:05:00,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328698129 with entries=108, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328700005
2014-07-14 02:05:00,616 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:01,930 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1070ms
GC pool 'ParNew' had collection(s): count=1 time=1125ms
2014-07-14 02:05:02,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:03,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16282 synced till here 16270
2014-07-14 02:05:04,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328700005 with entries=136, filesize=116.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328702867
2014-07-14 02:05:05,062 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:05,086 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16383 synced till here 16353
2014-07-14 02:05:06,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328702867 with entries=101, filesize=86.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328705062
2014-07-14 02:05:08,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:08,131 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16469 synced till here 16456
2014-07-14 02:05:08,259 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328705062 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328708086
2014-07-14 02:05:10,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:10,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16577 synced till here 16549
2014-07-14 02:05:10,433 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,434 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,434 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,436 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328708086 with entries=108, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328710178
2014-07-14 02:05:10,438 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,438 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,439 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,442 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,444 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,445 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,448 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,457 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,458 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,459 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,463 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,464 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,466 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,467 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,468 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,469 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,470 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,471 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,472 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,475 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,476 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,478 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,479 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,479 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,564 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,565 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,612 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,613 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,613 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,614 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,614 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,615 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,616 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,616 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,688 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,689 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,690 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,691 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,691 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,692 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,692 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,692 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,692 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,693 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,696 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,697 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:10,698 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:05:15,434 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,434 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,434 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,438 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,439 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,440 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,443 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,445 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,446 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,448 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,458 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,458 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,459 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,464 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,464 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,466 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,468 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,468 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,469 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,471 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,472 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,473 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,475 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,476 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,478 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,479 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,480 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,565 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,565 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,612 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,613 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,613 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,614 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,614 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,616 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,616 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,617 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,689 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,690 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,690 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,691 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,691 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,693 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,693 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 02:05:15,693 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 02:05:15,693 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,693 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,696 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:05:15,697 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:15,698 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:05:20,435 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,435 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,435 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,439 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,439 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,440 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,443 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,445 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,446 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,449 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,458 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,459 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,460 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,464 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,465 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,467 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,468 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,468 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,470 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,471 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,472 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,473 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,476 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,476 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,479 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,480 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:05:20,480 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,566 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:05:20,566 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,613 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,613 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,614 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,614 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,615 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,616 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,617 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,618 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,689 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,690 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,690 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,691 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,692 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,693 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,694 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-14 02:05:20,694 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-14 02:05:20,694 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,695 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:05:20,696 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:05:20,697 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,699 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:05:20,983 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3944, memsize=500.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bab7eb2fe6224cdb9f451f7155579d95
2014-07-14 02:05:21,004 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bab7eb2fe6224cdb9f451f7155579d95 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bab7eb2fe6224cdb9f451f7155579d95
2014-07-14 02:05:21,022 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bab7eb2fe6224cdb9f451f7155579d95, entries=1820640, sequenceid=3944, filesize=129.6m
2014-07-14 02:05:21,022 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~900.8m/944516640, currentsize=353.1m/370219760 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 30276ms, sequenceid=3944, compaction requested=true
2014-07-14 02:05:21,023 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-14 02:05:21,023 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10325ms
2014-07-14 02:05:21,023 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,023 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 905.3m
2014-07-14 02:05:21,025 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10328ms
2014-07-14 02:05:21,025 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,029 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10334ms
2014-07-14 02:05:21,029 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,029 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10337ms
2014-07-14 02:05:21,029 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,029 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10336ms
2014-07-14 02:05:21,029 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,029 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10340ms
2014-07-14 02:05:21,029 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,029 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10341ms
2014-07-14 02:05:21,030 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,030 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10338ms
2014-07-14 02:05:21,030 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,031 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10340ms
2014-07-14 02:05:21,031 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,037 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10347ms
2014-07-14 02:05:21,037 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,037 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10347ms
2014-07-14 02:05:21,037 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,037 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10348ms
2014-07-14 02:05:21,037 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,049 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10361ms
2014-07-14 02:05:21,049 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,049 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10433ms
2014-07-14 02:05:21,049 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,049 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10433ms
2014-07-14 02:05:21,049 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,054 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10439ms
2014-07-14 02:05:21,054 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,055 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10441ms
2014-07-14 02:05:21,055 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,055 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10442ms
2014-07-14 02:05:21,056 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,056 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10443ms
2014-07-14 02:05:21,056 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,056 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10443ms
2014-07-14 02:05:21,056 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,056 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10444ms
2014-07-14 02:05:21,056 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,065 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10500ms
2014-07-14 02:05:21,065 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,065 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10501ms
2014-07-14 02:05:21,065 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,065 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10586ms
2014-07-14 02:05:21,065 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,065 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10587ms
2014-07-14 02:05:21,065 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,065 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10587ms
2014-07-14 02:05:21,066 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,066 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10591ms
2014-07-14 02:05:21,066 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,073 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10599ms
2014-07-14 02:05:21,073 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,073 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10601ms
2014-07-14 02:05:21,073 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,073 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10602ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,074 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10604ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,074 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10605ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,074 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10607ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,074 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10607ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,074 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10608ms
2014-07-14 02:05:21,074 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,081 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10617ms
2014-07-14 02:05:21,081 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,081 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10618ms
2014-07-14 02:05:21,081 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,087 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10628ms
2014-07-14 02:05:21,087 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,087 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10629ms
2014-07-14 02:05:21,087 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,087 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10630ms
2014-07-14 02:05:21,087 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,137 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10689ms
2014-07-14 02:05:21,138 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,149 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10704ms
2014-07-14 02:05:21,149 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,149 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10705ms
2014-07-14 02:05:21,149 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,156 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10714ms
2014-07-14 02:05:21,156 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,156 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10717ms
2014-07-14 02:05:21,156 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,165 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10727ms
2014-07-14 02:05:21,165 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,165 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10727ms
2014-07-14 02:05:21,165 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,169 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10735ms
2014-07-14 02:05:21,169 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,169 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10735ms
2014-07-14 02:05:21,169 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,169 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10736ms
2014-07-14 02:05:21,169 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:05:21,268 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12561,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708706,"queuetimems":77,"class":"HRegionServer","responsesize":15839,"method":"Multi"}
2014-07-14 02:05:21,556 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:05:21,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:21,709 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14589,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707119,"queuetimems":463,"class":"HRegionServer","responsesize":15599,"method":"Multi"}
2014-07-14 02:05:21,709 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707117,"queuetimems":490,"class":"HRegionServer","responsesize":15711,"method":"Multi"}
2014-07-14 02:05:21,709 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13361,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708347,"queuetimems":0,"class":"HRegionServer","responsesize":15889,"method":"Multi"}
2014-07-14 02:05:21,709 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707126,"queuetimems":411,"class":"HRegionServer","responsesize":15842,"method":"Multi"}
2014-07-14 02:05:21,709 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706329,"queuetimems":2092,"class":"HRegionServer","responsesize":15823,"method":"Multi"}
2014-07-14 02:05:21,710 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14700,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707010,"queuetimems":663,"class":"HRegionServer","responsesize":16189,"method":"Multi"}
2014-07-14 02:05:21,710 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14718,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706992,"queuetimems":912,"class":"HRegionServer","responsesize":15864,"method":"Multi"}
2014-07-14 02:05:21,711 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14713,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706997,"queuetimems":860,"class":"HRegionServer","responsesize":15962,"method":"Multi"}
2014-07-14 02:05:21,717 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706997,"queuetimems":830,"class":"HRegionServer","responsesize":15970,"method":"Multi"}
2014-07-14 02:05:21,721 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14737,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706984,"queuetimems":917,"class":"HRegionServer","responsesize":15325,"method":"Multi"}
2014-07-14 02:05:21,723 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15369,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706354,"queuetimems":1750,"class":"HRegionServer","responsesize":15778,"method":"Multi"}
2014-07-14 02:05:21,724 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706285,"queuetimems":4260,"class":"HRegionServer","responsesize":15245,"method":"Multi"}
2014-07-14 02:05:21,729 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15368,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706361,"queuetimems":1642,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-14 02:05:21,730 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707022,"queuetimems":628,"class":"HRegionServer","responsesize":15808,"method":"Multi"}
2014-07-14 02:05:21,730 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15376,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706354,"queuetimems":1880,"class":"HRegionServer","responsesize":15531,"method":"Multi"}
2014-07-14 02:05:21,731 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708389,"queuetimems":0,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:05:21,731 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13203,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708528,"queuetimems":0,"class":"HRegionServer","responsesize":15958,"method":"Multi"}
2014-07-14 02:05:21,737 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15384,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706345,"queuetimems":2062,"class":"HRegionServer","responsesize":15855,"method":"Multi"}
2014-07-14 02:05:21,738 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14755,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706982,"queuetimems":1909,"class":"HRegionServer","responsesize":15973,"method":"Multi"}
2014-07-14 02:05:21,738 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706373,"queuetimems":1498,"class":"HRegionServer","responsesize":16049,"method":"Multi"}
2014-07-14 02:05:21,738 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706994,"queuetimems":886,"class":"HRegionServer","responsesize":15741,"method":"Multi"}
2014-07-14 02:05:21,740 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706981,"queuetimems":1993,"class":"HRegionServer","responsesize":15649,"method":"Multi"}
2014-07-14 02:05:21,710 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707003,"queuetimems":776,"class":"HRegionServer","responsesize":15819,"method":"Multi"}
2014-07-14 02:05:21,746 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706350,"queuetimems":1936,"class":"HRegionServer","responsesize":15468,"method":"Multi"}
2014-07-14 02:05:21,753 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706317,"queuetimems":2368,"class":"HRegionServer","responsesize":15958,"method":"Multi"}
2014-07-14 02:05:21,738 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15408,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706329,"queuetimems":2139,"class":"HRegionServer","responsesize":15883,"method":"Multi"}
2014-07-14 02:05:21,730 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708516,"queuetimems":71,"class":"HRegionServer","responsesize":15468,"method":"Multi"}
2014-07-14 02:05:21,761 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706289,"queuetimems":4196,"class":"HRegionServer","responsesize":15494,"method":"Multi"}
2014-07-14 02:05:21,765 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15444,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706321,"queuetimems":2331,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:05:21,730 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14618,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707112,"queuetimems":514,"class":"HRegionServer","responsesize":15494,"method":"Multi"}
2014-07-14 02:05:21,769 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328707022,"queuetimems":546,"class":"HRegionServer","responsesize":15878,"method":"Multi"}
2014-07-14 02:05:21,773 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15460,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706313,"queuetimems":4081,"class":"HRegionServer","responsesize":15644,"method":"Multi"}
2014-07-14 02:05:22,219 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16660 synced till here 16652
2014-07-14 02:05:22,273 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13570,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328708703,"queuetimems":135,"class":"HRegionServer","responsesize":15973,"method":"Multi"}
2014-07-14 02:05:22,273 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328709118,"queuetimems":438,"class":"HRegionServer","responsesize":15883,"method":"Multi"}
2014-07-14 02:05:22,318 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328710178 with entries=83, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328721708
2014-07-14 02:05:22,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328639104
2014-07-14 02:05:22,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328640537
2014-07-14 02:05:22,464 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:22,469 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16147,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328706321,"queuetimems":2281,"class":"HRegionServer","responsesize":15839,"method":"Multi"}
2014-07-14 02:05:22,622 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12434,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710187,"queuetimems":1395,"class":"HRegionServer","responsesize":15960,"method":"Multi"}
2014-07-14 02:05:22,637 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11943,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710694,"queuetimems":432,"class":"HRegionServer","responsesize":15711,"method":"Multi"}
2014-07-14 02:05:22,926 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:22,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16761 synced till here 16735
2014-07-14 02:05:23,154 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710686,"queuetimems":620,"class":"HRegionServer","responsesize":15864,"method":"Multi"}
2014-07-14 02:05:23,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328721708 with entries=101, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328722927
2014-07-14 02:05:24,004 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710613,"queuetimems":1373,"class":"HRegionServer","responsesize":15699,"method":"Multi"}
2014-07-14 02:05:24,004 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710613,"queuetimems":1464,"class":"HRegionServer","responsesize":15970,"method":"Multi"}
2014-07-14 02:05:24,004 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710693,"queuetimems":515,"class":"HRegionServer","responsesize":15823,"method":"Multi"}
2014-07-14 02:05:24,005 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710610,"queuetimems":1630,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-14 02:05:24,011 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13321,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710690,"queuetimems":571,"class":"HRegionServer","responsesize":15778,"method":"Multi"}
2014-07-14 02:05:24,011 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13398,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710613,"queuetimems":1572,"class":"HRegionServer","responsesize":16049,"method":"Multi"}
2014-07-14 02:05:24,011 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13325,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710686,"queuetimems":606,"class":"HRegionServer","responsesize":15245,"method":"Multi"}
2014-07-14 02:05:24,021 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13331,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710690,"queuetimems":542,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-14 02:05:24,235 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710687,"queuetimems":595,"class":"HRegionServer","responsesize":15649,"method":"Multi"}
2014-07-14 02:05:24,252 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13558,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710694,"queuetimems":463,"class":"HRegionServer","responsesize":15599,"method":"Multi"}
2014-07-14 02:05:24,235 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328710562,"queuetimems":1695,"class":"HRegionServer","responsesize":15855,"method":"Multi"}
2014-07-14 02:05:24,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:24,711 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16871 synced till here 16842
2014-07-14 02:05:25,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328722927 with entries=110, filesize=93.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328724685
2014-07-14 02:05:27,269 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4049, memsize=495.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/36d8157fda334ddb9a492a72cfc96607
2014-07-14 02:05:27,298 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/36d8157fda334ddb9a492a72cfc96607 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/36d8157fda334ddb9a492a72cfc96607
2014-07-14 02:05:27,306 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/36d8157fda334ddb9a492a72cfc96607, entries=1804030, sequenceid=4049, filesize=128.5m
2014-07-14 02:05:27,307 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1021.6m/1071218080, currentsize=292.9m/307115360 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 29165ms, sequenceid=4049, compaction requested=true
2014-07-14 02:05:27,307 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-14 02:05:27,307 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 917.5m
2014-07-14 02:05:27,434 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:05:27,986 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:28,890 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:29,111 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328724685 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328728891
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328641654
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328643188
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328645689
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328646916
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328648729
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328650026
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328652140
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328654986
2014-07-14 02:05:29,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328655976
2014-07-14 02:05:29,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:29,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17019 synced till here 17018
2014-07-14 02:05:29,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328728891 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328729878
2014-07-14 02:05:31,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:31,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17117 synced till here 17115
2014-07-14 02:05:31,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328729878 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328731014
2014-07-14 02:05:32,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:33,061 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17199 synced till here 17196
2014-07-14 02:05:33,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328731014 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328732634
2014-07-14 02:05:34,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:34,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17280 synced till here 17278
2014-07-14 02:05:34,436 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328732634 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328734037
2014-07-14 02:05:35,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:35,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328734037 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328735481
2014-07-14 02:05:36,774 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4174, memsize=271.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/b347ee2dde374f18b716f807d2e615f9
2014-07-14 02:05:36,786 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/b347ee2dde374f18b716f807d2e615f9 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b347ee2dde374f18b716f807d2e615f9
2014-07-14 02:05:36,798 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b347ee2dde374f18b716f807d2e615f9, entries=987570, sequenceid=4174, filesize=70.4m
2014-07-14 02:05:36,799 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~905.3m/949253840, currentsize=304.4m/319149520 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15776ms, sequenceid=4174, compaction requested=true
2014-07-14 02:05:36,799 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-14 02:05:36,800 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 657.2m
2014-07-14 02:05:36,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:36,802 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:05:36,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17427 synced till here 17425
2014-07-14 02:05:36,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328735481 with entries=74, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328736802
2014-07-14 02:05:36,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328657319
2014-07-14 02:05:36,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328658746
2014-07-14 02:05:36,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328660488
2014-07-14 02:05:37,625 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:37,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:38,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17514 synced till here 17507
2014-07-14 02:05:38,412 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328736802 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328737896
2014-07-14 02:05:39,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:39,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17589 synced till here 17587
2014-07-14 02:05:39,919 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328737896 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328739853
2014-07-14 02:05:41,205 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4245, memsize=251.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f7498d9850a14a649efc73be1b4fb2ec
2014-07-14 02:05:41,221 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f7498d9850a14a649efc73be1b4fb2ec as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f7498d9850a14a649efc73be1b4fb2ec
2014-07-14 02:05:41,279 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f7498d9850a14a649efc73be1b4fb2ec, entries=915500, sequenceid=4245, filesize=65.2m
2014-07-14 02:05:41,279 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~917.5m/962101680, currentsize=275.3m/288698800 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 13972ms, sequenceid=4245, compaction requested=false
2014-07-14 02:05:41,280 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 575.4m
2014-07-14 02:05:41,282 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:05:41,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:41,918 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:42,194 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17678 synced till here 17675
2014-07-14 02:05:42,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328739853 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328741707
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328662063
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328665051
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328667110
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328669182
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328672125
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328674102
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328675862
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328677450
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328678833
2014-07-14 02:05:42,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328680351
2014-07-14 02:05:42,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328682209
2014-07-14 02:05:42,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328683673
2014-07-14 02:05:42,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328685312
2014-07-14 02:05:43,442 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:43,462 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17756 synced till here 17750
2014-07-14 02:05:43,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328741707 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328743442
2014-07-14 02:05:44,595 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:44,627 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17832 synced till here 17830
2014-07-14 02:05:44,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328743442 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328744596
2014-07-14 02:05:45,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:45,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17906 synced till here 17904
2014-07-14 02:05:46,023 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328744596 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328745959
2014-07-14 02:05:47,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:47,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17982 synced till here 17978
2014-07-14 02:05:47,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328745959 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328747451
2014-07-14 02:05:47,555 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4371, memsize=204.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/82b9297fe900465ea20ab2d91a34abc6
2014-07-14 02:05:47,569 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/82b9297fe900465ea20ab2d91a34abc6 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/82b9297fe900465ea20ab2d91a34abc6
2014-07-14 02:05:47,580 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/82b9297fe900465ea20ab2d91a34abc6, entries=745450, sequenceid=4371, filesize=53.1m
2014-07-14 02:05:47,580 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~660.3m/692409600, currentsize=216.2m/226722480 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 10780ms, sequenceid=4371, compaction requested=true
2014-07-14 02:05:47,580 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-14 02:05:47,581 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 522.1m
2014-07-14 02:05:48,202 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:48,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:48,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18058 synced till here 18054
2014-07-14 02:05:48,983 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328747451 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328748831
2014-07-14 02:05:48,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328686632
2014-07-14 02:05:48,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328692673
2014-07-14 02:05:48,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328695953
2014-07-14 02:05:49,364 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:05:50,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:50,224 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18131 synced till here 18130
2014-07-14 02:05:50,243 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328748831 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328750183
2014-07-14 02:05:52,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:52,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18234 synced till here 18232
2014-07-14 02:05:52,547 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328750183 with entries=103, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328752006
2014-07-14 02:05:53,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:54,418 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4424, memsize=285.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/43668de8487f4ec6b05ec5a4c721daef
2014-07-14 02:05:54,461 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328752006 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328753969
2014-07-14 02:05:54,499 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/43668de8487f4ec6b05ec5a4c721daef as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/43668de8487f4ec6b05ec5a4c721daef
2014-07-14 02:05:54,687 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/43668de8487f4ec6b05ec5a4c721daef, entries=1040370, sequenceid=4424, filesize=74.1m
2014-07-14 02:05:54,688 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~577.0m/605060560, currentsize=264.0m/276804960 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 13408ms, sequenceid=4424, compaction requested=true
2014-07-14 02:05:54,688 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-14 02:05:54,689 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 545.7m
2014-07-14 02:05:54,701 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:05:55,114 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:05:56,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:56,108 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18394 synced till here 18392
2014-07-14 02:05:56,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328753969 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328756080
2014-07-14 02:05:56,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328698129
2014-07-14 02:05:56,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328700005
2014-07-14 02:05:56,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328702867
2014-07-14 02:05:56,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328705062
2014-07-14 02:05:56,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328708086
2014-07-14 02:05:57,370 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:58,030 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18498 synced till here 18494
2014-07-14 02:05:58,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328756080 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328757371
2014-07-14 02:05:59,785 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:05:59,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18572 synced till here 18571
2014-07-14 02:05:59,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328757371 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328759785
2014-07-14 02:06:01,346 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:01,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18655 synced till here 18654
2014-07-14 02:06:01,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328759785 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328761346
2014-07-14 02:06:02,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:02,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18729 synced till here 18728
2014-07-14 02:06:02,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328761346 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328762872
2014-07-14 02:06:03,637 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4514, memsize=413.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/5b05322354b347e69ef61b4e4a28721f
2014-07-14 02:06:03,658 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/5b05322354b347e69ef61b4e4a28721f as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5b05322354b347e69ef61b4e4a28721f
2014-07-14 02:06:03,682 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5b05322354b347e69ef61b4e4a28721f, entries=1506240, sequenceid=4514, filesize=107.3m
2014-07-14 02:06:03,682 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~526.6m/552205040, currentsize=289.0m/303034880 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 16101ms, sequenceid=4514, compaction requested=true
2014-07-14 02:06:03,682 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-14 02:06:03,682 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 505.1m
2014-07-14 02:06:04,016 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:06:04,126 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:06:05,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:05,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18802 synced till here 18801
2014-07-14 02:06:05,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328762872 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328765645
2014-07-14 02:06:05,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328710178
2014-07-14 02:06:05,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328721708
2014-07-14 02:06:05,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328722927
2014-07-14 02:06:07,103 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:07,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18891 synced till here 18890
2014-07-14 02:06:07,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328765645 with entries=89, filesize=76.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328767103
2014-07-14 02:06:08,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:08,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18966 synced till here 18964
2014-07-14 02:06:09,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328767103 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328768935
2014-07-14 02:06:10,295 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:10,494 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19051 synced till here 19049
2014-07-14 02:06:10,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328768935 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328770295
2014-07-14 02:06:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.73 MB, free=3.95 GB, max=3.96 GB, blocks=7, accesses=82298, hits=14787, hitRatio=17.96%, , cachingAccesses=14796, cachingHits=14781, cachingHitsRatio=99.89%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-07-14 02:06:11,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:11,666 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328770295 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328771625
2014-07-14 02:06:12,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:13,150 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19228 synced till here 19221
2014-07-14 02:06:13,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328771625 with entries=103, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328772689
2014-07-14 02:06:14,238 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4598, memsize=539.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cb32be1fb19349d699274c5ef12d377c
2014-07-14 02:06:14,293 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cb32be1fb19349d699274c5ef12d377c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cb32be1fb19349d699274c5ef12d377c
2014-07-14 02:06:14,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:15,011 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cb32be1fb19349d699274c5ef12d377c, entries=1964320, sequenceid=4598, filesize=139.9m
2014-07-14 02:06:15,012 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~547.2m/573748640, currentsize=378.8m/397177680 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 20323ms, sequenceid=4598, compaction requested=true
2014-07-14 02:06:15,012 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-14 02:06:15,013 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 659.6m
2014-07-14 02:06:15,020 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19321 synced till here 19318
2014-07-14 02:06:15,024 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:06:15,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328772689 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328774392
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328724685
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328728891
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328729878
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328731014
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328732634
2014-07-14 02:06:15,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328734037
2014-07-14 02:06:15,048 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328735481
2014-07-14 02:06:15,551 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:06:15,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:16,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19411 synced till here 19409
2014-07-14 02:06:16,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328774392 with entries=90, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328775721
2014-07-14 02:06:17,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:17,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328775721 with entries=85, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328777059
2014-07-14 02:06:18,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:18,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328777059 with entries=80, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328778453
2014-07-14 02:06:20,269 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:20,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19653 synced till here 19648
2014-07-14 02:06:21,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328778453 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328780269
2014-07-14 02:06:22,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:22,347 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19735 synced till here 19727
2014-07-14 02:06:22,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328780269 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328782284
2014-07-14 02:06:23,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:23,696 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19812 synced till here 19806
2014-07-14 02:06:23,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328782284 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328783192
2014-07-14 02:06:24,105 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4697, memsize=505.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/14c90f2fe5054c319ef80f944f122c1a
2014-07-14 02:06:24,138 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/14c90f2fe5054c319ef80f944f122c1a as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/14c90f2fe5054c319ef80f944f122c1a
2014-07-14 02:06:24,164 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/14c90f2fe5054c319ef80f944f122c1a, entries=1838970, sequenceid=4697, filesize=131.0m
2014-07-14 02:06:24,164 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~505.1m/529610880, currentsize=443.1m/464647040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 20482ms, sequenceid=4697, compaction requested=true
2014-07-14 02:06:24,165 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-14 02:06:24,165 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 717.0m
2014-07-14 02:06:24,205 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:06:25,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:25,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19901 synced till here 19891
2014-07-14 02:06:25,447 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328783192 with entries=89, filesize=76.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328785323
2014-07-14 02:06:25,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328736802
2014-07-14 02:06:25,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328737896
2014-07-14 02:06:25,683 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:06:27,246 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19998 synced till here 19976
2014-07-14 02:06:27,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328785323 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328787246
2014-07-14 02:06:29,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:29,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20109 synced till here 20097
2014-07-14 02:06:29,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328787246 with entries=111, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328789439
2014-07-14 02:06:31,404 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:32,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20233 synced till here 20188
2014-07-14 02:06:32,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328789439 with entries=124, filesize=106.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328791405
2014-07-14 02:06:34,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:34,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20345 synced till here 20342
2014-07-14 02:06:34,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328791405 with entries=112, filesize=96.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328794675
2014-07-14 02:06:37,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:38,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20463 synced till here 20462
2014-07-14 02:06:38,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328794675 with entries=118, filesize=101.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328797110
2014-07-14 02:06:40,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:40,013 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/03f01ec3ba9645e9973850c6131f836a as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/03f01ec3ba9645e9973850c6131f836a
2014-07-14 02:06:40,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20573 synced till here 20539
2014-07-14 02:06:40,309 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:06:40,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328797110 with entries=110, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328800013
2014-07-14 02:06:40,371 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cc835141bfb64df69c4b24c67d8486c5, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cc835141bfb64df69c4b24c67d8486c5
2014-07-14 02:06:40,375 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2398ada75db04a5092157d3abd97d953, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2398ada75db04a5092157d3abd97d953
2014-07-14 02:06:40,377 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c9379685625e47f3b3a86263dc576d5b, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c9379685625e47f3b3a86263dc576d5b
2014-07-14 02:06:40,382 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4110508cba2f4e3a8e3b4df43ca78dca, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4110508cba2f4e3a8e3b4df43ca78dca
2014-07-14 02:06:40,384 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22212a362b4546cb8e165ae9136607d1, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22212a362b4546cb8e165ae9136607d1
2014-07-14 02:06:40,389 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/1c05c292dcb84e7fb5c86832e01b6d1c, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/1c05c292dcb84e7fb5c86832e01b6d1c
2014-07-14 02:06:40,395 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b92328ec67674d32a8ce3cc8c62fa6cb, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b92328ec67674d32a8ce3cc8c62fa6cb
2014-07-14 02:06:40,397 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f34bdd2202ff4d3ea2c04097a7602ef6, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f34bdd2202ff4d3ea2c04097a7602ef6
2014-07-14 02:06:40,398 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 8 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into 03f01ec3ba9645e9973850c6131f836a(size=607.5m), total size for store is 963.2m. This selection was in queue for 0sec, and took 2mins, 7sec to execute.
2014-07-14 02:06:40,398 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=8, fileSize=637.9m, priority=12, time=282579846286596; duration=2mins, 7sec
2014-07-14 02:06:40,398 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-14 02:06:40,398 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-14 02:06:40,399 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 9 files of size 956881122 starting at candidate #0 after considering 28 permutations with 27 in ratio
2014-07-14 02:06:40,400 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating major compaction
2014-07-14 02:06:40,400 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:06:40,400 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 9 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=912.6m
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1987b4f4ec674a1fac4c8f0979a2b366, keycount=311031, bloomtype=ROW, size=221.4m, encoding=NONE, seqNum=1569, earliestPutTs=1405328266976
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4c36bc21997049dfbe17e92402117052, keycount=109418, bloomtype=ROW, size=77.9m, encoding=NONE, seqNum=1774, earliestPutTs=1405328455148
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/cad45dd49a30468585886c97d74a76f2, keycount=93821, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=1941, earliestPutTs=1405328481254
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/54733bc5ad7d422780c2a1cb536bebad, keycount=90629, bloomtype=ROW, size=64.5m, encoding=NONE, seqNum=2234, earliestPutTs=1405328501531
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa50798b16cb49af94a32799565f3ff7, keycount=97906, bloomtype=ROW, size=69.6m, encoding=NONE, seqNum=2548, earliestPutTs=1405328556143
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/3d61866cb33f4c70acc7cddf34bae45c, keycount=137286, bloomtype=ROW, size=97.7m, encoding=NONE, seqNum=2959, earliestPutTs=1405328570905
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f701e767fe2b4e23a9128ffeabb6cc41, keycount=157203, bloomtype=ROW, size=111.9m, encoding=NONE, seqNum=3390, earliestPutTs=1405328618754
2014-07-14 02:06:40,401 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/36d8157fda334ddb9a492a72cfc96607, keycount=180403, bloomtype=ROW, size=128.5m, encoding=NONE, seqNum=4049, earliestPutTs=1405328642116
2014-07-14 02:06:40,402 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/43668de8487f4ec6b05ec5a4c721daef, keycount=104037, bloomtype=ROW, size=74.1m, encoding=NONE, seqNum=4424, earliestPutTs=1405328726667
2014-07-14 02:06:40,950 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:06:41,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:41,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328800013 with entries=96, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328801242
2014-07-14 02:06:43,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:43,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20764 synced till here 20750
2014-07-14 02:06:43,742 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328801242 with entries=95, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328803547
2014-07-14 02:06:44,000 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,004 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,004 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,005 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,011 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,012 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,013 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,050 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,050 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,110 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,110 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,110 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,112 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,115 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,119 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,127 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,172 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,172 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,176 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,193 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,254 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,318 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:44,394 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,617 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,658 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,698 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,735 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,779 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,818 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,858 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:45,905 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:46,668 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:46,696 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:46,727 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:46,757 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:48,156 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:48,195 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:48,225 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:48,497 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4851, memsize=598.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f8d7ae7fcfe14c81803e5f0da6a071fa
2014-07-14 02:06:48,513 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f8d7ae7fcfe14c81803e5f0da6a071fa as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8d7ae7fcfe14c81803e5f0da6a071fa
2014-07-14 02:06:48,524 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8d7ae7fcfe14c81803e5f0da6a071fa, entries=2179020, sequenceid=4851, filesize=155.1m
2014-07-14 02:06:48,525 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~662.7m/694925200, currentsize=574.5m/602458080 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 33512ms, sequenceid=4851, compaction requested=false
2014-07-14 02:06:48,525 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 300ms
2014-07-14 02:06:48,525 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,525 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 949.9m
2014-07-14 02:06:48,525 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 330ms
2014-07-14 02:06:48,525 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,525 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 369ms
2014-07-14 02:06:48,526 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,529 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1772ms
2014-07-14 02:06:48,529 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,529 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1802ms
2014-07-14 02:06:48,529 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,530 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1834ms
2014-07-14 02:06:48,530 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,530 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1862ms
2014-07-14 02:06:48,530 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,533 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2628ms
2014-07-14 02:06:48,533 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,533 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2675ms
2014-07-14 02:06:48,533 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,535 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2717ms
2014-07-14 02:06:48,535 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,536 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2756ms
2014-07-14 02:06:48,536 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,544 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2810ms
2014-07-14 02:06:48,544 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,553 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2855ms
2014-07-14 02:06:48,553 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,554 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2895ms
2014-07-14 02:06:48,554 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,554 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2937ms
2014-07-14 02:06:48,554 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4160ms
2014-07-14 02:06:48,555 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,556 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4237ms
2014-07-14 02:06:48,556 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,556 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4302ms
2014-07-14 02:06:48,556 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,557 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4363ms
2014-07-14 02:06:48,557 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,557 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4381ms
2014-07-14 02:06:48,557 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,558 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4386ms
2014-07-14 02:06:48,558 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,558 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4386ms
2014-07-14 02:06:48,558 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,559 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4431ms
2014-07-14 02:06:48,559 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,574 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4454ms
2014-07-14 02:06:48,574 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,574 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4459ms
2014-07-14 02:06:48,574 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,574 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4462ms
2014-07-14 02:06:48,574 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,575 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4464ms
2014-07-14 02:06:48,575 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,575 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4465ms
2014-07-14 02:06:48,575 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,575 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4465ms
2014-07-14 02:06:48,575 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,585 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4535ms
2014-07-14 02:06:48,585 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,586 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4535ms
2014-07-14 02:06:48,586 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,590 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4577ms
2014-07-14 02:06:48,590 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,591 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4578ms
2014-07-14 02:06:48,591 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,594 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4583ms
2014-07-14 02:06:48,594 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,595 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4591ms
2014-07-14 02:06:48,595 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,595 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4591ms
2014-07-14 02:06:48,595 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,596 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4591ms
2014-07-14 02:06:48,596 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,599 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4596ms
2014-07-14 02:06:48,599 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:48,737 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:06:49,050 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:49,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20876 synced till here 20837
2014-07-14 02:06:49,924 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:06:49,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328803547 with entries=112, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328809050
2014-07-14 02:06:49,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328739853
2014-07-14 02:06:49,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328741707
2014-07-14 02:06:49,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328743442
2014-07-14 02:06:49,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328744596
2014-07-14 02:06:49,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328745959
2014-07-14 02:06:50,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:50,798 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20953 synced till here 20949
2014-07-14 02:06:50,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328809050 with entries=77, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328810755
2014-07-14 02:06:52,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:52,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21028 synced till here 21026
2014-07-14 02:06:52,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328810755 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328812251
2014-07-14 02:06:53,859 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:53,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21103 synced till here 21101
2014-07-14 02:06:53,911 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328812251 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328813859
2014-07-14 02:06:55,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:55,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328813859 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328815140
2014-07-14 02:06:56,069 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,077 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,102 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,103 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,111 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,133 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,138 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,148 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,205 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,241 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,270 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,300 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,333 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,368 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,420 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,466 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,516 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,562 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,611 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,640 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,670 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,701 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,729 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,757 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,793 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,822 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,874 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,928 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,958 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:56,990 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:57,142 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:57,198 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:06:57,307 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4986, memsize=595.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/16f58ada12c3461c93be81c4060b1af1
2014-07-14 02:06:57,319 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/16f58ada12c3461c93be81c4060b1af1 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/16f58ada12c3461c93be81c4060b1af1
2014-07-14 02:06:57,328 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/16f58ada12c3461c93be81c4060b1af1, entries=2167990, sequenceid=4986, filesize=154.3m
2014-07-14 02:06:57,329 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~732.5m/768112960, currentsize=519.6m/544875440 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 33164ms, sequenceid=4986, compaction requested=true
2014-07-14 02:06:57,329 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-14 02:06:57,329 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 131ms
2014-07-14 02:06:57,329 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,329 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 187ms
2014-07-14 02:06:57,329 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 964.9m
2014-07-14 02:06:57,329 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,330 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 340ms
2014-07-14 02:06:57,330 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,333 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 375ms
2014-07-14 02:06:57,333 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,333 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 405ms
2014-07-14 02:06:57,333 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,333 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 459ms
2014-07-14 02:06:57,333 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,333 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 511ms
2014-07-14 02:06:57,333 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,337 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 545ms
2014-07-14 02:06:57,337 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,337 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 580ms
2014-07-14 02:06:57,337 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,341 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 612ms
2014-07-14 02:06:57,341 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,341 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 640ms
2014-07-14 02:06:57,341 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,341 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 671ms
2014-07-14 02:06:57,341 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,341 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 701ms
2014-07-14 02:06:57,341 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,342 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 732ms
2014-07-14 02:06:57,342 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,342 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 780ms
2014-07-14 02:06:57,342 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,348 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 833ms
2014-07-14 02:06:57,348 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,348 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 882ms
2014-07-14 02:06:57,348 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,348 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 929ms
2014-07-14 02:06:57,348 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,348 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 981ms
2014-07-14 02:06:57,348 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,348 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1015ms
2014-07-14 02:06:57,349 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,349 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1049ms
2014-07-14 02:06:57,349 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,356 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1086ms
2014-07-14 02:06:57,356 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,356 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1115ms
2014-07-14 02:06:57,356 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,356 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1151ms
2014-07-14 02:06:57,356 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,356 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1208ms
2014-07-14 02:06:57,356 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,357 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1219ms
2014-07-14 02:06:57,357 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,357 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1224ms
2014-07-14 02:06:57,357 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,357 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1246ms
2014-07-14 02:06:57,357 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,358 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1255ms
2014-07-14 02:06:57,358 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,358 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1256ms
2014-07-14 02:06:57,358 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,397 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1320ms
2014-07-14 02:06:57,397 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,401 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1333ms
2014-07-14 02:06:57,401 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:06:57,483 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:06:58,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:06:58,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21271 synced till here 21253
2014-07-14 02:06:59,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328815140 with entries=95, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328818799
2014-07-14 02:06:59,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328747451
2014-07-14 02:06:59,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328748831
2014-07-14 02:06:59,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328750183
2014-07-14 02:06:59,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328752006
2014-07-14 02:06:59,278 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:01,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:01,209 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21378 synced till here 21375
2014-07-14 02:07:01,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328818799 with entries=107, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328821096
2014-07-14 02:07:02,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:03,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21478 synced till here 21454
2014-07-14 02:07:03,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328821096 with entries=100, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328822999
2014-07-14 02:07:04,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:05,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21585 synced till here 21571
2014-07-14 02:07:05,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328822999 with entries=107, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328824920
2014-07-14 02:07:07,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:07,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21687 synced till here 21664
2014-07-14 02:07:08,282 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,282 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,283 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,284 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328824920 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328827291
2014-07-14 02:07:08,405 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,465 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,466 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,466 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,467 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,467 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,468 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,468 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,469 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,469 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,471 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,473 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,473 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,475 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,475 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,476 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,477 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,477 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,478 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,656 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,696 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,844 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,897 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:08,935 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,028 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,081 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,119 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,161 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,198 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,236 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,273 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,311 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,407 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,444 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,481 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,523 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,553 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,583 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,613 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,644 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,673 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:09,703 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:10,988 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:11,024 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:11,065 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:11,156 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:07:13,282 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,282 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,284 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,284 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,405 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,465 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,466 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,466 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,467 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,467 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,468 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,468 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,469 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:07:13,470 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,471 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,473 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,474 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,475 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,475 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,476 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,477 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,477 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,478 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,657 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,697 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,844 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:13,897 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:13,936 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,028 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,081 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,120 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,162 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,199 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:14,237 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,273 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,311 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,407 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,444 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,481 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,524 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:14,553 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,584 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,613 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,644 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:14,674 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:14,704 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:15,989 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:16,024 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:16,065 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:07:16,159 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:07:17,387 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5211, memsize=500.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/a68e4f3654d845ecaafbbba0c6d5931e
2014-07-14 02:07:17,409 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/a68e4f3654d845ecaafbbba0c6d5931e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a68e4f3654d845ecaafbbba0c6d5931e
2014-07-14 02:07:17,419 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a68e4f3654d845ecaafbbba0c6d5931e, entries=1821870, sequenceid=5211, filesize=129.7m
2014-07-14 02:07:17,419 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~949.9m/996090480, currentsize=343.3m/359990160 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 28894ms, sequenceid=5211, compaction requested=true
2014-07-14 02:07:17,420 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-14 02:07:17,420 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6265ms
2014-07-14 02:07:17,420 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,420 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 927.8m
2014-07-14 02:07:17,420 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6355ms
2014-07-14 02:07:17,420 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,420 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6396ms
2014-07-14 02:07:17,420 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,420 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6432ms
2014-07-14 02:07:17,421 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,421 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7718ms
2014-07-14 02:07:17,421 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,424 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7751ms
2014-07-14 02:07:17,424 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,424 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7780ms
2014-07-14 02:07:17,424 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7812ms
2014-07-14 02:07:17,425 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,428 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7845ms
2014-07-14 02:07:17,428 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,428 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7875ms
2014-07-14 02:07:17,428 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,429 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7905ms
2014-07-14 02:07:17,429 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,429 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7948ms
2014-07-14 02:07:17,429 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,430 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7986ms
2014-07-14 02:07:17,430 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,430 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8023ms
2014-07-14 02:07:17,430 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,432 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8120ms
2014-07-14 02:07:17,432 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,432 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8159ms
2014-07-14 02:07:17,432 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,432 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8196ms
2014-07-14 02:07:17,433 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,437 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8239ms
2014-07-14 02:07:17,437 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,437 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8276ms
2014-07-14 02:07:17,437 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,437 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8318ms
2014-07-14 02:07:17,437 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,437 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8356ms
2014-07-14 02:07:17,437 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,441 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8413ms
2014-07-14 02:07:17,441 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,442 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8507ms
2014-07-14 02:07:17,442 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,445 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8548ms
2014-07-14 02:07:17,445 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,446 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8603ms
2014-07-14 02:07:17,446 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,446 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8750ms
2014-07-14 02:07:17,446 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,449 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8793ms
2014-07-14 02:07:17,449 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,449 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8971ms
2014-07-14 02:07:17,449 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,451 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8974ms
2014-07-14 02:07:17,451 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,451 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8974ms
2014-07-14 02:07:17,452 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,452 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8976ms
2014-07-14 02:07:17,452 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,452 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8977ms
2014-07-14 02:07:17,452 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,454 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8979ms
2014-07-14 02:07:17,454 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,456 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8983ms
2014-07-14 02:07:17,456 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,458 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8985ms
2014-07-14 02:07:17,458 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,458 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8987ms
2014-07-14 02:07:17,459 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,461 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8992ms
2014-07-14 02:07:17,461 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,462 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8994ms
2014-07-14 02:07:17,462 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,464 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8996ms
2014-07-14 02:07:17,465 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,466 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8998ms
2014-07-14 02:07:17,466 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,467 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8999ms
2014-07-14 02:07:17,467 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,470 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9002ms
2014-07-14 02:07:17,471 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,472 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9007ms
2014-07-14 02:07:17,472 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,477 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9012ms
2014-07-14 02:07:17,477 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,480 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9016ms
2014-07-14 02:07:17,480 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,481 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9076ms
2014-07-14 02:07:17,481 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,481 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9197ms
2014-07-14 02:07:17,481 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,484 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9201ms
2014-07-14 02:07:17,484 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,487 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9205ms
2014-07-14 02:07:17,487 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:17,487 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9206ms
2014-07-14 02:07:17,487 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:07:18,125 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:07:18,127 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826441,"queuetimems":0,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:07:18,127 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12773,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328825354,"queuetimems":0,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 02:07:18,138 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11879,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826258,"queuetimems":0,"class":"HRegionServer","responsesize":15909,"method":"Multi"}
2014-07-14 02:07:18,138 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826347,"queuetimems":0,"class":"HRegionServer","responsesize":15951,"method":"Multi"}
2014-07-14 02:07:18,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:18,357 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11879,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826471,"queuetimems":0,"class":"HRegionServer","responsesize":16042,"method":"Multi"}
2014-07-14 02:07:18,358 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826278,"queuetimems":1,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:07:18,359 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826313,"queuetimems":0,"class":"HRegionServer","responsesize":15773,"method":"Multi"}
2014-07-14 02:07:18,360 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12960,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328825399,"queuetimems":0,"class":"HRegionServer","responsesize":15714,"method":"Multi"}
2014-07-14 02:07:18,365 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11956,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826409,"queuetimems":0,"class":"HRegionServer","responsesize":15862,"method":"Multi"}
2014-07-14 02:07:18,359 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826379,"queuetimems":0,"class":"HRegionServer","responsesize":16110,"method":"Multi"}
2014-07-14 02:07:18,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21795 synced till here 21761
2014-07-14 02:07:19,020 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:19,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328827291 with entries=108, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328838350
2014-07-14 02:07:19,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328753969
2014-07-14 02:07:19,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328756080
2014-07-14 02:07:19,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328757371
2014-07-14 02:07:19,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328759785
2014-07-14 02:07:19,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328761346
2014-07-14 02:07:20,334 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328827030,"queuetimems":0,"class":"HRegionServer","responsesize":15925,"method":"Multi"}
2014-07-14 02:07:20,335 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826939,"queuetimems":0,"class":"HRegionServer","responsesize":15966,"method":"Multi"}
2014-07-14 02:07:20,335 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826688,"queuetimems":0,"class":"HRegionServer","responsesize":15742,"method":"Multi"}
2014-07-14 02:07:20,337 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13618,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826718,"queuetimems":0,"class":"HRegionServer","responsesize":16006,"method":"Multi"}
2014-07-14 02:07:20,334 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826876,"queuetimems":0,"class":"HRegionServer","responsesize":15972,"method":"Multi"}
2014-07-14 02:07:20,338 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13492,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826846,"queuetimems":0,"class":"HRegionServer","responsesize":15793,"method":"Multi"}
2014-07-14 02:07:20,340 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13681,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826658,"queuetimems":0,"class":"HRegionServer","responsesize":15521,"method":"Multi"}
2014-07-14 02:07:20,345 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13376,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826969,"queuetimems":1,"class":"HRegionServer","responsesize":15980,"method":"Multi"}
2014-07-14 02:07:20,348 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13351,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826997,"queuetimems":0,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 02:07:20,334 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13424,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328826909,"queuetimems":0,"class":"HRegionServer","responsesize":15735,"method":"Multi"}
2014-07-14 02:07:20,525 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328827068,"queuetimems":0,"class":"HRegionServer","responsesize":15946,"method":"Multi"}
2014-07-14 02:07:20,525 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328827190,"queuetimems":0,"class":"HRegionServer","responsesize":15648,"method":"Multi"}
2014-07-14 02:07:20,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:20,902 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11231,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829671,"queuetimems":0,"class":"HRegionServer","responsesize":15862,"method":"Multi"}
2014-07-14 02:07:20,909 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328827160,"queuetimems":0,"class":"HRegionServer","responsesize":15885,"method":"Multi"}
2014-07-14 02:07:21,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21892 synced till here 21867
2014-07-14 02:07:21,146 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829024,"queuetimems":1,"class":"HRegionServer","responsesize":15496,"method":"Multi"}
2014-07-14 02:07:21,146 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11704,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829441,"queuetimems":1,"class":"HRegionServer","responsesize":15908,"method":"Multi"}
2014-07-14 02:07:21,146 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11444,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829701,"queuetimems":1,"class":"HRegionServer","responsesize":15909,"method":"Multi"}
2014-07-14 02:07:21,150 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11879,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829270,"queuetimems":0,"class":"HRegionServer","responsesize":15857,"method":"Multi"}
2014-07-14 02:07:21,161 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829308,"queuetimems":1,"class":"HRegionServer","responsesize":15661,"method":"Multi"}
2014-07-14 02:07:21,161 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11580,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829581,"queuetimems":0,"class":"HRegionServer","responsesize":16110,"method":"Multi"}
2014-07-14 02:07:21,162 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10141,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328831020,"queuetimems":0,"class":"HRegionServer","responsesize":15742,"method":"Multi"}
2014-07-14 02:07:21,162 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829195,"queuetimems":1,"class":"HRegionServer","responsesize":16053,"method":"Multi"}
2014-07-14 02:07:21,162 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11759,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829402,"queuetimems":0,"class":"HRegionServer","responsesize":15849,"method":"Multi"}
2014-07-14 02:07:21,162 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12468,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328828693,"queuetimems":1,"class":"HRegionServer","responsesize":15519,"method":"Multi"}
2014-07-14 02:07:21,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328838350 with entries=97, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328840843
2014-07-14 02:07:21,573 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12919,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328828653,"queuetimems":0,"class":"HRegionServer","responsesize":15894,"method":"Multi"}
2014-07-14 02:07:21,574 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12501,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829072,"queuetimems":1,"class":"HRegionServer","responsesize":15531,"method":"Multi"}
2014-07-14 02:07:21,577 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11935,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829642,"queuetimems":0,"class":"HRegionServer","responsesize":16042,"method":"Multi"}
2014-07-14 02:07:21,573 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328828839,"queuetimems":0,"class":"HRegionServer","responsesize":15633,"method":"Multi"}
2014-07-14 02:07:22,058 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12942,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829116,"queuetimems":1,"class":"HRegionServer","responsesize":15495,"method":"Multi"}
2014-07-14 02:07:22,065 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13180,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328828885,"queuetimems":0,"class":"HRegionServer","responsesize":15714,"method":"Multi"}
2014-07-14 02:07:22,073 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12841,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829232,"queuetimems":0,"class":"HRegionServer","responsesize":15718,"method":"Multi"}
2014-07-14 02:07:22,082 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12604,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829477,"queuetimems":0,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:07:22,083 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12472,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829611,"queuetimems":0,"class":"HRegionServer","responsesize":15951,"method":"Multi"}
2014-07-14 02:07:22,073 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829551,"queuetimems":0,"class":"HRegionServer","responsesize":15773,"method":"Multi"}
2014-07-14 02:07:22,093 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13167,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328828926,"queuetimems":0,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 02:07:22,095 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12574,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829521,"queuetimems":0,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:07:22,096 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328829156,"queuetimems":0,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 02:07:22,331 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:22,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21985 synced till here 21966
2014-07-14 02:07:22,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328840843 with entries=93, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328842331
2014-07-14 02:07:24,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:24,236 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22089 synced till here 22067
2014-07-14 02:07:24,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328842331 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328844219
2014-07-14 02:07:25,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:25,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328844219 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328845671
2014-07-14 02:07:27,332 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5319, memsize=427.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/5dfb399115a242638c20e69cb08ff176
2014-07-14 02:07:27,352 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/5dfb399115a242638c20e69cb08ff176 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dfb399115a242638c20e69cb08ff176
2014-07-14 02:07:27,361 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dfb399115a242638c20e69cb08ff176, entries=1555760, sequenceid=5319, filesize=110.7m
2014-07-14 02:07:27,361 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~964.9m/1011734560, currentsize=388.9m/407823040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 30032ms, sequenceid=5319, compaction requested=true
2014-07-14 02:07:27,362 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-14 02:07:27,362 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 914.4m
2014-07-14 02:07:27,412 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:07:27,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:27,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328845671 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328847819
2014-07-14 02:07:27,850 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328762872
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328765645
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328767103
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328768935
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328770295
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328771625
2014-07-14 02:07:27,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328772689
2014-07-14 02:07:28,211 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:30,157 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:30,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328847819 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328850158
2014-07-14 02:07:32,761 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:32,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328850158 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328852761
2014-07-14 02:07:34,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:34,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22457 synced till here 22453
2014-07-14 02:07:34,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328852761 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328854700
2014-07-14 02:07:35,988 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:36,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22537 synced till here 22531
2014-07-14 02:07:36,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328854700 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328855988
2014-07-14 02:07:37,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:37,773 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5452, memsize=317.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/d0fb0b813814411985b96ae65d1fa577
2014-07-14 02:07:37,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22642 synced till here 22640
2014-07-14 02:07:37,825 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/d0fb0b813814411985b96ae65d1fa577 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/d0fb0b813814411985b96ae65d1fa577
2014-07-14 02:07:37,837 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328855988 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328857329
2014-07-14 02:07:37,841 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/d0fb0b813814411985b96ae65d1fa577, entries=1154390, sequenceid=5452, filesize=82.2m
2014-07-14 02:07:37,841 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~927.8m/972867600, currentsize=350.3m/367336240 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 20421ms, sequenceid=5452, compaction requested=false
2014-07-14 02:07:37,841 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 724.5m
2014-07-14 02:07:37,882 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:07:38,713 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:38,945 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5576, memsize=200.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/c62bcd219ae24744b6c4f6364c9191aa
2014-07-14 02:07:38,960 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/c62bcd219ae24744b6c4f6364c9191aa as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c62bcd219ae24744b6c4f6364c9191aa
2014-07-14 02:07:38,973 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c62bcd219ae24744b6c4f6364c9191aa, entries=730750, sequenceid=5576, filesize=52.1m
2014-07-14 02:07:38,974 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~915.9m/960405360, currentsize=183.2m/192071760 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 11612ms, sequenceid=5576, compaction requested=true
2014-07-14 02:07:38,974 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:33), split_queue=0, merge_queue=0
2014-07-14 02:07:38,974 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 572.3m
2014-07-14 02:07:39,331 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:39,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:40,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22750 synced till here 22746
2014-07-14 02:07:40,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328857329 with entries=108, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328859710
2014-07-14 02:07:40,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328774392
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328775721
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328777059
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328778453
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328780269
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328782284
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328783192
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328785323
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328787246
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328789439
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328791405
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328794675
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328797110
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328800013
2014-07-14 02:07:40,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328801242
2014-07-14 02:07:41,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:41,627 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328859710 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328861591
2014-07-14 02:07:42,619 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:07:42,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:42,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22905 synced till here 22902
2014-07-14 02:07:43,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328861591 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328862781
2014-07-14 02:07:43,980 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:44,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22992 synced till here 22990
2014-07-14 02:07:44,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328862781 with entries=87, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328863981
2014-07-14 02:07:45,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:45,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23065 synced till here 23063
2014-07-14 02:07:45,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328863981 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328865418
2014-07-14 02:07:46,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:47,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23157 synced till here 23153
2014-07-14 02:07:47,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328865418 with entries=92, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328866619
2014-07-14 02:07:47,922 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:47,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23233 synced till here 23231
2014-07-14 02:07:48,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328866619 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328867922
2014-07-14 02:07:49,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:49,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23308 synced till here 23306
2014-07-14 02:07:49,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328867922 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328869311
2014-07-14 02:07:50,160 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5688, memsize=225.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/8aac1059c5114d44b08d0dffd3bbb23a
2014-07-14 02:07:50,175 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/8aac1059c5114d44b08d0dffd3bbb23a as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/8aac1059c5114d44b08d0dffd3bbb23a
2014-07-14 02:07:50,195 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/8aac1059c5114d44b08d0dffd3bbb23a, entries=821490, sequenceid=5688, filesize=58.5m
2014-07-14 02:07:50,196 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~572.3m/600131680, currentsize=246.4m/258416880 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 11222ms, sequenceid=5688, compaction requested=true
2014-07-14 02:07:50,196 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-14 02:07:50,196 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 618.8m
2014-07-14 02:07:50,477 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:07:50,744 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:50,763 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:50,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328869311 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328870763
2014-07-14 02:07:52,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:52,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23453 synced till here 23452
2014-07-14 02:07:52,605 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328870763 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328872565
2014-07-14 02:07:54,105 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5679, memsize=315.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c37e016b64e34a69bbdda3d282d625ea
2014-07-14 02:07:54,115 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c37e016b64e34a69bbdda3d282d625ea as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c37e016b64e34a69bbdda3d282d625ea
2014-07-14 02:07:54,123 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c37e016b64e34a69bbdda3d282d625ea, entries=1147290, sequenceid=5679, filesize=81.7m
2014-07-14 02:07:54,124 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~725.9m/761183040, currentsize=333.9m/350089920 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 16283ms, sequenceid=5679, compaction requested=true
2014-07-14 02:07:54,124 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:35), split_queue=0, merge_queue=0
2014-07-14 02:07:54,124 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 501.9m
2014-07-14 02:07:54,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:54,237 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:07:54,284 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23546 synced till here 23538
2014-07-14 02:07:54,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328872565 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328874237
2014-07-14 02:07:54,354 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328803547
2014-07-14 02:07:54,354 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328809050
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328810755
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328812251
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328813859
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328815140
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328818799
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328821096
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328822999
2014-07-14 02:07:54,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328824920
2014-07-14 02:07:55,550 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:07:56,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:57,337 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1011ms
GC pool 'ParNew' had collection(s): count=1 time=1143ms
2014-07-14 02:07:57,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23648 synced till here 23620
2014-07-14 02:07:57,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328874237 with entries=102, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328876142
2014-07-14 02:07:59,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:07:59,798 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23766 synced till here 23740
2014-07-14 02:08:00,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328876142 with entries=118, filesize=101.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328879702
2014-07-14 02:08:01,394 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1183ms
GC pool 'ParNew' had collection(s): count=1 time=1223ms
2014-07-14 02:08:02,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:02,210 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23875 synced till here 23849
2014-07-14 02:08:03,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328879702 with entries=109, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328882181
2014-07-14 02:08:04,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:04,295 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23972 synced till here 23948
2014-07-14 02:08:05,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328882181 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328884199
2014-07-14 02:08:06,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:06,951 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24080 synced till here 24075
2014-07-14 02:08:06,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328884199 with entries=108, filesize=93.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328886222
2014-07-14 02:08:07,925 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:07,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24154 synced till here 24151
2014-07-14 02:08:07,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328886222 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328887925
2014-07-14 02:08:09,177 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:09,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24244 synced till here 24242
2014-07-14 02:08:09,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328887925 with entries=90, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328889177
2014-07-14 02:08:11,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:11,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24333 synced till here 24327
2014-07-14 02:08:11,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328889177 with entries=89, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328891460
2014-07-14 02:08:13,611 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:13,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24423 synced till here 24406
2014-07-14 02:08:13,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328891460 with entries=90, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328893612
2014-07-14 02:08:15,558 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:15,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24518 synced till here 24502
2014-07-14 02:08:15,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328893612 with entries=95, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328895558
2014-07-14 02:08:17,268 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5855, memsize=410.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f9e187064d7e48e4aa90454305902294
2014-07-14 02:08:17,279 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f9e187064d7e48e4aa90454305902294 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f9e187064d7e48e4aa90454305902294
2014-07-14 02:08:17,290 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f9e187064d7e48e4aa90454305902294, entries=1494910, sequenceid=5855, filesize=106.4m
2014-07-14 02:08:17,291 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~625.0m/655333840, currentsize=497.7m/521923680 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 27095ms, sequenceid=5855, compaction requested=true
2014-07-14 02:08:17,291 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:08:17,291 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:36), split_queue=0, merge_queue=0
2014-07-14 02:08:17,292 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 743.4m
2014-07-14 02:08:17,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:17,646 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24620 synced till here 24599
2014-07-14 02:08:17,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328895558 with entries=102, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328897536
2014-07-14 02:08:17,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328827291
2014-07-14 02:08:17,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328838350
2014-07-14 02:08:17,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328840843
2014-07-14 02:08:17,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328842331
2014-07-14 02:08:17,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328844219
2014-07-14 02:08:19,193 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:08:19,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:19,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24712 synced till here 24706
2014-07-14 02:08:19,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328897536 with entries=92, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328899650
2014-07-14 02:08:21,404 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:21,571 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5904, memsize=405.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6ad2a953d2794db0b2409755b4e0132d
2014-07-14 02:08:21,634 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6ad2a953d2794db0b2409755b4e0132d as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6ad2a953d2794db0b2409755b4e0132d
2014-07-14 02:08:21,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24812 synced till here 24800
2014-07-14 02:08:21,739 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6ad2a953d2794db0b2409755b4e0132d, entries=1477200, sequenceid=5904, filesize=105.2m
2014-07-14 02:08:21,739 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~508.4m/533075680, currentsize=492.9m/516821280 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 27615ms, sequenceid=5904, compaction requested=true
2014-07-14 02:08:21,740 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:37), split_queue=0, merge_queue=0
2014-07-14 02:08:21,740 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 822.4m
2014-07-14 02:08:21,756 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:08:21,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328899650 with entries=100, filesize=85.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328901405
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328845671
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328847819
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328850158
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328852761
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328854700
2014-07-14 02:08:21,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328855988
2014-07-14 02:08:23,305 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:23,478 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24900 synced till here 24885
2014-07-14 02:08:23,503 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:08:23,603 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328901405 with entries=88, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328903306
2014-07-14 02:08:24,845 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:24,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24976 synced till here 24974
2014-07-14 02:08:24,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328903306 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328904846
2014-07-14 02:08:26,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:26,109 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25051 synced till here 25050
2014-07-14 02:08:26,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328904846 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328906092
2014-07-14 02:08:27,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:27,530 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25127 synced till here 25125
2014-07-14 02:08:27,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328906092 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328907499
2014-07-14 02:08:28,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:28,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25201 synced till here 25199
2014-07-14 02:08:28,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328907499 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328908904
2014-07-14 02:08:30,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:30,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328908904 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328910729
2014-07-14 02:08:32,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:33,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25370 synced till here 25368
2014-07-14 02:08:33,563 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328910729 with entries=98, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328912880
2014-07-14 02:08:36,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:36,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25477 synced till here 25459
2014-07-14 02:08:36,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328912880 with entries=107, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328916489
2014-07-14 02:08:38,493 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:38,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25592 synced till here 25562
2014-07-14 02:08:38,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328916489 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328918493
2014-07-14 02:08:40,736 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:40,762 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,768 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,775 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,776 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,776 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,778 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,779 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,779 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,779 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,780 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,782 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,783 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,783 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,784 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,784 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,785 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,789 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,789 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,790 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,796 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,797 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,797 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,800 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,801 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,801 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,801 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25687 synced till here 25679
2014-07-14 02:08:40,809 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,812 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,848 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,851 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,851 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,855 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,857 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,862 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,862 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,863 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328918493 with entries=95, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328920736
2014-07-14 02:08:40,878 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,914 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,936 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,937 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,938 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,953 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,956 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,958 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,959 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,969 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6171, memsize=345.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/3f9ab447904f4c619ded73efe82dad05
2014-07-14 02:08:40,983 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:08:40,988 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/3f9ab447904f4c619ded73efe82dad05 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/3f9ab447904f4c619ded73efe82dad05
2014-07-14 02:08:41,000 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/3f9ab447904f4c619ded73efe82dad05, entries=1259090, sequenceid=6171, filesize=89.6m
2014-07-14 02:08:41,000 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~748.0m/784325680, currentsize=427.6m/448339120 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 23708ms, sequenceid=6171, compaction requested=true
2014-07-14 02:08:41,001 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:38), split_queue=0, merge_queue=0
2014-07-14 02:08:41,001 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18ms
2014-07-14 02:08:41,001 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,001 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 938.5m
2014-07-14 02:08:41,001 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 42ms
2014-07-14 02:08:41,001 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,001 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 43ms
2014-07-14 02:08:41,001 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,009 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 53ms
2014-07-14 02:08:41,009 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,013 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 60ms
2014-07-14 02:08:41,013 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,013 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 75ms
2014-07-14 02:08:41,013 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,013 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 76ms
2014-07-14 02:08:41,013 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,014 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 77ms
2014-07-14 02:08:41,014 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,014 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 100ms
2014-07-14 02:08:41,014 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,015 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 137ms
2014-07-14 02:08:41,016 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,016 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 154ms
2014-07-14 02:08:41,016 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,016 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 154ms
2014-07-14 02:08:41,016 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,016 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 154ms
2014-07-14 02:08:41,016 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,016 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 159ms
2014-07-14 02:08:41,017 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,017 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 162ms
2014-07-14 02:08:41,017 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,017 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 166ms
2014-07-14 02:08:41,018 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,018 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 167ms
2014-07-14 02:08:41,018 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,018 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 170ms
2014-07-14 02:08:41,018 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,018 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 206ms
2014-07-14 02:08:41,018 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,018 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 217ms
2014-07-14 02:08:41,018 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,018 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 217ms
2014-07-14 02:08:41,019 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,019 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 221ms
2014-07-14 02:08:41,019 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,020 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 219ms
2014-07-14 02:08:41,020 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,020 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 220ms
2014-07-14 02:08:41,020 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,061 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 264ms
2014-07-14 02:08:41,061 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,062 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 266ms
2014-07-14 02:08:41,062 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,063 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 267ms
2014-07-14 02:08:41,063 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,066 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 276ms
2014-07-14 02:08:41,066 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,066 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 288ms
2014-07-14 02:08:41,066 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,066 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 277ms
2014-07-14 02:08:41,066 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,066 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 281ms
2014-07-14 02:08:41,066 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,068 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 284ms
2014-07-14 02:08:41,068 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,068 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 284ms
2014-07-14 02:08:41,068 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,068 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 285ms
2014-07-14 02:08:41,069 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,077 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 294ms
2014-07-14 02:08:41,077 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,077 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 295ms
2014-07-14 02:08:41,077 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,077 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 297ms
2014-07-14 02:08:41,077 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,085 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 306ms
2014-07-14 02:08:41,085 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,085 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 306ms
2014-07-14 02:08:41,085 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,085 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 307ms
2014-07-14 02:08:41,085 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,085 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 308ms
2014-07-14 02:08:41,085 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,088 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 312ms
2014-07-14 02:08:41,088 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,088 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 312ms
2014-07-14 02:08:41,089 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,090 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 314ms
2014-07-14 02:08:41,090 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,090 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 322ms
2014-07-14 02:08:41,090 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,090 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 328ms
2014-07-14 02:08:41,091 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:08:41,317 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:08:42,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:42,805 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:08:42,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25796 synced till here 25761
2014-07-14 02:08:44,220 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1031ms
GC pool 'ParNew' had collection(s): count=1 time=1046ms
2014-07-14 02:08:44,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328920736 with entries=109, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328922797
2014-07-14 02:08:45,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:46,260 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25896 synced till here 25895
2014-07-14 02:08:46,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328922797 with entries=100, filesize=84.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328925232
2014-07-14 02:08:48,256 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:48,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26009 synced till here 25976
2014-07-14 02:08:48,586 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6220, memsize=360.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ff4a0bc4e30241fcb5a4260a81847c2e
2014-07-14 02:08:48,598 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ff4a0bc4e30241fcb5a4260a81847c2e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ff4a0bc4e30241fcb5a4260a81847c2e
2014-07-14 02:08:48,609 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ff4a0bc4e30241fcb5a4260a81847c2e, entries=1313260, sequenceid=6220, filesize=93.5m
2014-07-14 02:08:48,610 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~841.1m/881954160, currentsize=425.7m/446364480 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 26870ms, sequenceid=6220, compaction requested=true
2014-07-14 02:08:48,610 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-14 02:08:48,610 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 934.2m
2014-07-14 02:08:48,614 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:08:48,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328925232 with entries=113, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328928256
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328857329
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328859710
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328861591
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328862781
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328863981
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328865418
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328866619
2014-07-14 02:08:48,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328867922
2014-07-14 02:08:50,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:50,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26119 synced till here 26083
2014-07-14 02:08:50,816 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328928256 with entries=110, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328930437
2014-07-14 02:08:51,032 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:08:52,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:52,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26227 synced till here 26207
2014-07-14 02:08:52,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328930437 with entries=108, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328932356
2014-07-14 02:08:53,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:54,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26307 synced till here 26299
2014-07-14 02:08:54,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328932356 with entries=80, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328933994
2014-07-14 02:08:55,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:55,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26387 synced till here 26380
2014-07-14 02:08:55,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328933994 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328935496
2014-07-14 02:08:57,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:08:57,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26491 synced till here 26458
2014-07-14 02:08:59,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328935496 with entries=104, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328937562
2014-07-14 02:09:00,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:01,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328937562 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328940165
2014-07-14 02:09:02,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:02,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26705 synced till here 26683
2014-07-14 02:09:03,129 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,129 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,130 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,130 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,131 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,132 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,132 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,136 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,136 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,137 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,139 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,140 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,157 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,159 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,161 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,162 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,164 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,188 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,221 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,252 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,283 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328940165 with entries=110, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328942939
2014-07-14 02:09:03,285 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,312 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,325 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,341 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,371 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,393 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,393 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,394 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,394 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,394 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,394 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,395 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,397 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,398 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,405 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,432 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,462 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,491 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,520 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,548 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,643 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,644 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,644 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,666 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,694 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,726 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,755 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,786 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,815 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:03,846 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:09:08,129 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,130 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,130 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,131 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,132 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,132 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,132 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,136 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,137 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,137 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,140 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,140 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,157 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,159 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,161 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,162 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,164 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,188 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,222 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,252 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,285 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,313 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,326 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,342 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,371 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,394 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,394 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,394 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,395 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,395 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,395 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:09:08,396 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,397 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,398 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,405 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,432 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,462 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,491 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:09:08,521 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:09:08,541 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6460, memsize=350.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/bd8ca60cbd1e46ce96f049e7aed1572a
2014-07-14 02:09:08,559 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/bd8ca60cbd1e46ce96f049e7aed1572a as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/bd8ca60cbd1e46ce96f049e7aed1572a
2014-07-14 02:09:08,575 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/bd8ca60cbd1e46ce96f049e7aed1572a, entries=1277040, sequenceid=6460, filesize=90.9m
2014-07-14 02:09:08,575 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~938.5m/984070240, currentsize=392.0m/411064720 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 27574ms, sequenceid=6460, compaction requested=true
2014-07-14 02:09:08,575 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:40), split_queue=0, merge_queue=0
2014-07-14 02:09:08,576 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5055ms
2014-07-14 02:09:08,576 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,576 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 807.2m
2014-07-14 02:09:08,577 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-14 02:09:08,577 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,577 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5116ms
2014-07-14 02:09:08,577 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,577 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5145ms
2014-07-14 02:09:08,577 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,577 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5172ms
2014-07-14 02:09:08,577 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,578 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5181ms
2014-07-14 02:09:08,578 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,578 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5181ms
2014-07-14 02:09:08,579 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,579 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5184ms
2014-07-14 02:09:08,579 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,581 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5188ms
2014-07-14 02:09:08,581 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,583 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-14 02:09:08,583 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,583 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-14 02:09:08,583 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,583 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-14 02:09:08,583 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,585 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5191ms
2014-07-14 02:09:08,585 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,585 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5192ms
2014-07-14 02:09:08,585 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,587 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5216ms
2014-07-14 02:09:08,587 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,587 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5246ms
2014-07-14 02:09:08,587 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,587 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5262ms
2014-07-14 02:09:08,587 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,588 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5276ms
2014-07-14 02:09:08,588 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,588 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5303ms
2014-07-14 02:09:08,588 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,588 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5336ms
2014-07-14 02:09:08,588 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,589 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5368ms
2014-07-14 02:09:08,589 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,590 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5403ms
2014-07-14 02:09:08,590 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,590 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5426ms
2014-07-14 02:09:08,590 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,591 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5428ms
2014-07-14 02:09:08,591 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,592 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5431ms
2014-07-14 02:09:08,592 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,594 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5435ms
2014-07-14 02:09:08,594 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,595 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5438ms
2014-07-14 02:09:08,596 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,596 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5456ms
2014-07-14 02:09:08,596 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,596 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5457ms
2014-07-14 02:09:08,596 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,596 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5459ms
2014-07-14 02:09:08,596 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,601 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5465ms
2014-07-14 02:09:08,603 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,603 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5467ms
2014-07-14 02:09:08,603 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,603 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5471ms
2014-07-14 02:09:08,603 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,604 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5472ms
2014-07-14 02:09:08,604 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,604 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5473ms
2014-07-14 02:09:08,604 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,605 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5475ms
2014-07-14 02:09:08,605 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,605 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5475ms
2014-07-14 02:09:08,605 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,613 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5484ms
2014-07-14 02:09:08,613 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,613 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5484ms
2014-07-14 02:09:08,613 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,613 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4767ms
2014-07-14 02:09:08,613 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,615 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4800ms
2014-07-14 02:09:08,615 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,616 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4830ms
2014-07-14 02:09:08,616 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,616 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4861ms
2014-07-14 02:09:08,616 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,616 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4890ms
2014-07-14 02:09:08,616 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,616 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4922ms
2014-07-14 02:09:08,616 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,625 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4959ms
2014-07-14 02:09:08,625 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,626 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5047ms
2014-07-14 02:09:08,626 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,635 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5027ms
2014-07-14 02:09:08,635 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,635 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4998ms
2014-07-14 02:09:08,635 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:08,635 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-14 02:09:08,635 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:09:09,570 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:09:10,235 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:10,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26812 synced till here 26788
2014-07-14 02:09:10,364 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:09:11,303 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328942939 with entries=107, filesize=92.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328950235
2014-07-14 02:09:11,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328869311
2014-07-14 02:09:11,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328870763
2014-07-14 02:09:12,540 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941467,"queuetimems":0,"class":"HRegionServer","responsesize":15702,"method":"Multi"}
2014-07-14 02:09:12,544 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941971,"queuetimems":0,"class":"HRegionServer","responsesize":15794,"method":"Multi"}
2014-07-14 02:09:12,561 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941850,"queuetimems":0,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:09:12,561 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941403,"queuetimems":1,"class":"HRegionServer","responsesize":15543,"method":"Multi"}
2014-07-14 02:09:12,565 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941632,"queuetimems":0,"class":"HRegionServer","responsesize":15978,"method":"Multi"}
2014-07-14 02:09:12,577 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941522,"queuetimems":0,"class":"HRegionServer","responsesize":15884,"method":"Multi"}
2014-07-14 02:09:12,581 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941246,"queuetimems":0,"class":"HRegionServer","responsesize":15721,"method":"Multi"}
2014-07-14 02:09:12,582 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10672,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941909,"queuetimems":0,"class":"HRegionServer","responsesize":15935,"method":"Multi"}
2014-07-14 02:09:12,597 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11037,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328941560,"queuetimems":0,"class":"HRegionServer","responsesize":15454,"method":"Multi"}
2014-07-14 02:09:12,597 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10555,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328942042,"queuetimems":1,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:09:12,954 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:13,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26919 synced till here 26883
2014-07-14 02:09:13,270 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10051,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328943218,"queuetimems":0,"class":"HRegionServer","responsesize":16344,"method":"Multi"}
2014-07-14 02:09:13,281 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10127,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328943154,"queuetimems":1,"class":"HRegionServer","responsesize":15648,"method":"Multi"}
2014-07-14 02:09:14,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328950235 with entries=107, filesize=90.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328952954
2014-07-14 02:09:14,370 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328943576,"queuetimems":0,"class":"HRegionServer","responsesize":15806,"method":"Multi"}
2014-07-14 02:09:14,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:15,004 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6524, memsize=318.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6f044d0a0b8c4dd6851b21e2b6c9a365
2014-07-14 02:09:15,040 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6f044d0a0b8c4dd6851b21e2b6c9a365 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6f044d0a0b8c4dd6851b21e2b6c9a365
2014-07-14 02:09:15,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27039 synced till here 27002
2014-07-14 02:09:15,203 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6f044d0a0b8c4dd6851b21e2b6c9a365, entries=1159960, sequenceid=6524, filesize=82.6m
2014-07-14 02:09:15,203 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~962.3m/1009012160, currentsize=365.9m/383702960 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 26593ms, sequenceid=6524, compaction requested=true
2014-07-14 02:09:15,203 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-14 02:09:15,204 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 816.9m
2014-07-14 02:09:16,051 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:09:16,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328952954 with entries=120, filesize=102.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328954999
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328872565
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328874237
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328876142
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328879702
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328882181
2014-07-14 02:09:16,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328884199
2014-07-14 02:09:16,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328886222
2014-07-14 02:09:16,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328887925
2014-07-14 02:09:16,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328889177
2014-07-14 02:09:16,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328891460
2014-07-14 02:09:16,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328893612
2014-07-14 02:09:17,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:18,042 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:09:18,055 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27139 synced till here 27110
2014-07-14 02:09:18,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328954999 with entries=100, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328957997
2014-07-14 02:09:20,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:20,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27250 synced till here 27221
2014-07-14 02:09:20,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328957997 with entries=111, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328960006
2014-07-14 02:09:21,122 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:21,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27334 synced till here 27333
2014-07-14 02:09:21,210 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328960006 with entries=84, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328961122
2014-07-14 02:09:34,716 WARN  [regionserver60020] util.Sleeper: We slept 15707ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:09:34,716 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13373ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=13436ms
2014-07-14 02:09:34,727 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328959041,"queuetimems":898,"class":"HRegionServer","responsesize":15576,"method":"Multi"}
2014-07-14 02:09:34,764 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15722,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328959042,"queuetimems":872,"class":"HRegionServer","responsesize":15659,"method":"Multi"}
2014-07-14 02:09:34,765 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14490,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960274,"queuetimems":336,"class":"HRegionServer","responsesize":15601,"method":"Multi"}
2014-07-14 02:09:34,764 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15890,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328958874,"queuetimems":2058,"class":"HRegionServer","responsesize":15733,"method":"Multi"}
2014-07-14 02:09:34,765 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15865,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328958900,"queuetimems":959,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-14 02:09:34,765 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960252,"queuetimems":2053,"class":"HRegionServer","responsesize":15683,"method":"Multi"}
2014-07-14 02:09:34,785 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960255,"queuetimems":378,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:09:34,822 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11256 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,822 WARN  [RpcServer.reader=9,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: count of bytes read: 0
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:251)
	at sun.nio.ch.IOUtil.read(IOUtil.java:224)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:254)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelIO(RpcServer.java:2263)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2229)
	at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1488)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:790)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:581)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:556)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-14 02:09:34,827 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11259 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,827 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,828 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught: java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcher.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:182)
	at sun.nio.ch.SocketChannelImpl.write0(SocketChannelImpl.java:383)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:406)
	at org.apache.hadoop.hbase.ipc.BufferChain.write(BufferChain.java:106)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelWrite(RpcServer.java:2209)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.processResponse(RpcServer.java:1004)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doRespond(RpcServer.java:1081)
	at org.apache.hadoop.hbase.ipc.RpcServer$Call.sendResponseIfReady(RpcServer.java:496)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:121)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:168)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:39)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:111)
	at java.lang.Thread.run(Thread.java:701)

2014-07-14 02:09:34,828 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11255 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,828 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,828 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11237 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,829 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,829 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11241 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,829 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,829 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11260 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,829 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,856 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960253,"queuetimems":2024,"class":"HRegionServer","responsesize":15806,"method":"Multi"}
2014-07-14 02:09:34,856 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960253,"queuetimems":1985,"class":"HRegionServer","responsesize":15904,"method":"Multi"}
2014-07-14 02:09:34,856 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14601,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47190","starttimems":1405328960255,"queuetimems":349,"class":"HRegionServer","responsesize":15695,"method":"Multi"}
2014-07-14 02:09:34,856 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11254 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,857 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,857 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11253 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,857 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:34,857 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11261 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:34,857 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:35,111 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 11264 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47190: output error
2014-07-14 02:09:35,111 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:09:35,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:35,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27410 synced till here 27408
2014-07-14 02:09:35,564 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328961122 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328975485
2014-07-14 02:09:36,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:37,272 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27505 synced till here 27503
2014-07-14 02:09:37,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328975485 with entries=95, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328976682
2014-07-14 02:09:38,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:38,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328976682 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328978020
2014-07-14 02:09:39,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:39,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27678 synced till here 27677
2014-07-14 02:09:39,701 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328978020 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328979317
2014-07-14 02:09:41,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:41,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328979317 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328981171
2014-07-14 02:09:41,534 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6698, memsize=277.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9c7dddb0e19e4ef9826c7c68f4314e3a
2014-07-14 02:09:41,547 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9c7dddb0e19e4ef9826c7c68f4314e3a as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9c7dddb0e19e4ef9826c7c68f4314e3a
2014-07-14 02:09:41,556 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9c7dddb0e19e4ef9826c7c68f4314e3a, entries=1011210, sequenceid=6698, filesize=72.0m
2014-07-14 02:09:41,556 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~807.2m/846400880, currentsize=413.8m/433856960 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 32980ms, sequenceid=6698, compaction requested=true
2014-07-14 02:09:41,557 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:42), split_queue=0, merge_queue=0
2014-07-14 02:09:41,557 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 781.5m
2014-07-14 02:09:41,558 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:09:42,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:42,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27833 synced till here 27826
2014-07-14 02:09:42,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328981171 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328982044
2014-07-14 02:09:42,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328895558
2014-07-14 02:09:42,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328897536
2014-07-14 02:09:42,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328899650
2014-07-14 02:09:42,615 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:09:43,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:44,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27917 synced till here 27910
2014-07-14 02:09:44,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328982044 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328983481
2014-07-14 02:09:45,027 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6759, memsize=270.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/402f8fa042bf46bf8c91d19f3c00245e
2014-07-14 02:09:45,040 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/402f8fa042bf46bf8c91d19f3c00245e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/402f8fa042bf46bf8c91d19f3c00245e
2014-07-14 02:09:45,067 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/402f8fa042bf46bf8c91d19f3c00245e, entries=985510, sequenceid=6759, filesize=70.2m
2014-07-14 02:09:45,067 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~835.6m/876161280, currentsize=397.7m/417022000 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 29863ms, sequenceid=6759, compaction requested=true
2014-07-14 02:09:45,067 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-14 02:09:45,067 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 765.9m
2014-07-14 02:09:45,070 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:09:45,123 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:45,148 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27992 synced till here 27989
2014-07-14 02:09:45,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328983481 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328985123
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328901405
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328903306
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328904846
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328906092
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328907499
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328908904
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328910729
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328912880
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328916489
2014-07-14 02:09:45,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328918493
2014-07-14 02:09:46,042 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:09:46,447 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:47,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328985123 with entries=97, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328986447
2014-07-14 02:09:48,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:48,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28163 synced till here 28162
2014-07-14 02:09:48,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328986447 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328988230
2014-07-14 02:09:49,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:49,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28244 synced till here 28243
2014-07-14 02:09:49,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328988230 with entries=81, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328989290
2014-07-14 02:09:51,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:51,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328989290 with entries=109, filesize=93.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328991575
2014-07-14 02:09:53,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:53,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28456 synced till here 28452
2014-07-14 02:09:53,626 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6967, memsize=214.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/07d2ffb735304638a7c7a385f4aa0b5e
2014-07-14 02:09:53,641 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/07d2ffb735304638a7c7a385f4aa0b5e as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/07d2ffb735304638a7c7a385f4aa0b5e
2014-07-14 02:09:53,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328991575 with entries=103, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328993140
2014-07-14 02:09:53,676 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/07d2ffb735304638a7c7a385f4aa0b5e, entries=782620, sequenceid=6967, filesize=55.8m
2014-07-14 02:09:53,677 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~786.2m/824377680, currentsize=256.1m/268524640 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 12120ms, sequenceid=6967, compaction requested=true
2014-07-14 02:09:53,677 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:44), split_queue=0, merge_queue=0
2014-07-14 02:09:53,677 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 674.4m
2014-07-14 02:09:53,677 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:09:54,509 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:09:54,779 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:54,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328993140 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328994780
2014-07-14 02:09:54,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328920736
2014-07-14 02:09:54,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328922797
2014-07-14 02:09:54,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328925232
2014-07-14 02:09:56,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:56,057 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28604 synced till here 28600
2014-07-14 02:09:56,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328994780 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328996042
2014-07-14 02:09:57,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:57,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28682 synced till here 28677
2014-07-14 02:09:57,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328996042 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328997146
2014-07-14 02:09:58,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:09:58,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28766 synced till here 28758
2014-07-14 02:09:58,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328997146 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328998898
2014-07-14 02:10:00,108 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7020, memsize=286.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/631116a979a54383992799e7b4a9860c
2014-07-14 02:10:00,123 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/631116a979a54383992799e7b4a9860c as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/631116a979a54383992799e7b4a9860c
2014-07-14 02:10:00,133 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/631116a979a54383992799e7b4a9860c, entries=1042420, sequenceid=7020, filesize=74.2m
2014-07-14 02:10:00,133 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~769.0m/806313360, currentsize=322.5m/338154240 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15066ms, sequenceid=7020, compaction requested=true
2014-07-14 02:10:00,134 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-14 02:10:00,134 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 721.1m
2014-07-14 02:10:00,241 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:10:00,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:00,324 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28850 synced till here 28840
2014-07-14 02:10:00,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328998898 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329000301
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328928256
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328930437
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328932356
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328933994
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328935496
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328937562
2014-07-14 02:10:00,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328940165
2014-07-14 02:10:01,398 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:01,742 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:01,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28936 synced till here 28927
2014-07-14 02:10:01,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329000301 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329001743
2014-07-14 02:10:02,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:03,061 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29028 synced till here 29025
2014-07-14 02:10:03,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329001743 with entries=92, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329002898
2014-07-14 02:10:04,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:04,627 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29145 synced till here 29143
2014-07-14 02:10:04,649 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329002898 with entries=117, filesize=100.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329004127
2014-07-14 02:10:05,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:05,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29236 synced till here 29231
2014-07-14 02:10:05,869 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329004127 with entries=91, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329005636
2014-07-14 02:10:07,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:07,631 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329005636 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329007604
2014-07-14 02:10:08,939 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:09,366 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29391 synced till here 29383
2014-07-14 02:10:09,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329007604 with entries=82, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329008940
2014-07-14 02:10:10,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:10,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29481 synced till here 29479
2014-07-14 02:10:10,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329008940 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329010162
2014-07-14 02:10:11,422 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/6c7eb087f31441ebbda90db74f6dc942 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/6c7eb087f31441ebbda90db74f6dc942
2014-07-14 02:10:11,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:11,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29556 synced till here 29551
2014-07-14 02:10:11,474 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:10:11,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329010162 with entries=75, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329011443
2014-07-14 02:10:11,494 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1987b4f4ec674a1fac4c8f0979a2b366, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1987b4f4ec674a1fac4c8f0979a2b366
2014-07-14 02:10:11,501 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4c36bc21997049dfbe17e92402117052, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4c36bc21997049dfbe17e92402117052
2014-07-14 02:10:11,889 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/cad45dd49a30468585886c97d74a76f2, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/cad45dd49a30468585886c97d74a76f2
2014-07-14 02:10:12,238 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/54733bc5ad7d422780c2a1cb536bebad, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/54733bc5ad7d422780c2a1cb536bebad
2014-07-14 02:10:12,253 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa50798b16cb49af94a32799565f3ff7, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/fa50798b16cb49af94a32799565f3ff7
2014-07-14 02:10:12,260 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/3d61866cb33f4c70acc7cddf34bae45c, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/3d61866cb33f4c70acc7cddf34bae45c
2014-07-14 02:10:12,355 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f701e767fe2b4e23a9128ffeabb6cc41, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f701e767fe2b4e23a9128ffeabb6cc41
2014-07-14 02:10:12,362 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/36d8157fda334ddb9a492a72cfc96607, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/36d8157fda334ddb9a492a72cfc96607
2014-07-14 02:10:12,368 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/43668de8487f4ec6b05ec5a4c721daef, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/43668de8487f4ec6b05ec5a4c721daef
2014-07-14 02:10:12,368 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed major compaction of 9 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 6c7eb087f31441ebbda90db74f6dc942(size=863.7m), total size for store is 1.3g. This selection was in queue for 0sec, and took 3mins, 31sec to execute.
2014-07-14 02:10:12,368 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=9, fileSize=912.6m, priority=11, time=282707827046519; duration=3mins, 31sec
2014-07-14 02:10:12,369 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-14 02:10:12,369 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-14 02:10:12,371 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 921742647 starting at candidate #1 after considering 60 permutations with 58 in ratio
2014-07-14 02:10:12,371 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:10:12,371 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:10:12,371 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=879.0m
2014-07-14 02:10:12,371 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/97fa454f858a4a18817ab0466674b2d4, keycount=94222, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=1947
2014-07-14 02:10:12,371 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f270f0cdd3a24b449034b5016c775bcd, keycount=87355, bloomtype=ROW, size=62.2m, encoding=NONE, seqNum=2220
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4c8bfaabed5343e3bd1a4ac29dc91782, keycount=90737, bloomtype=ROW, size=64.6m, encoding=NONE, seqNum=2533
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/7380d04a7836426ca2f4bb769e13433c, keycount=142950, bloomtype=ROW, size=101.8m, encoding=NONE, seqNum=2910
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f69dc177837347d9b73cfc47f63dfdbc, keycount=141074, bloomtype=ROW, size=100.4m, encoding=NONE, seqNum=3363
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bab7eb2fe6224cdb9f451f7155579d95, keycount=182064, bloomtype=ROW, size=129.6m, encoding=NONE, seqNum=3944
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/82b9297fe900465ea20ab2d91a34abc6, keycount=74545, bloomtype=ROW, size=53.1m, encoding=NONE, seqNum=4371
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/14c90f2fe5054c319ef80f944f122c1a, keycount=183897, bloomtype=ROW, size=131.0m, encoding=NONE, seqNum=4697
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dfb399115a242638c20e69cb08ff176, keycount=155576, bloomtype=ROW, size=110.7m, encoding=NONE, seqNum=5319
2014-07-14 02:10:12,372 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/8aac1059c5114d44b08d0dffd3bbb23a, keycount=82149, bloomtype=ROW, size=58.5m, encoding=NONE, seqNum=5688
2014-07-14 02:10:12,626 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:12,632 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7134, memsize=397.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/36f41bb928ed496b95da9e5721dcbbca
2014-07-14 02:10:12,698 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/36f41bb928ed496b95da9e5721dcbbca as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/36f41bb928ed496b95da9e5721dcbbca
2014-07-14 02:10:12,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29646 synced till here 29640
2014-07-14 02:10:12,771 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/36f41bb928ed496b95da9e5721dcbbca, entries=1448350, sequenceid=7134, filesize=103.1m
2014-07-14 02:10:12,771 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~676.0m/708798800, currentsize=463.5m/486036560 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 19094ms, sequenceid=7134, compaction requested=true
2014-07-14 02:10:12,772 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-14 02:10:12,772 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 723.8m
2014-07-14 02:10:12,776 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:10:12,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329011443 with entries=90, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329012626
2014-07-14 02:10:12,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328942939
2014-07-14 02:10:12,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328950235
2014-07-14 02:10:12,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328952954
2014-07-14 02:10:13,367 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:14,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:14,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29726 synced till here 29719
2014-07-14 02:10:14,095 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:14,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329012626 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329014043
2014-07-14 02:10:15,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:15,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29799 synced till here 29797
2014-07-14 02:10:15,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329014043 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329015161
2014-07-14 02:10:16,201 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:16,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29909 synced till here 29906
2014-07-14 02:10:16,672 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329015161 with entries=110, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329016201
2014-07-14 02:10:17,761 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:17,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29990 synced till here 29982
2014-07-14 02:10:18,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329016201 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329017761
2014-07-14 02:10:19,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:19,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329017761 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329019264
2014-07-14 02:10:21,308 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:21,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30175 synced till here 30171
2014-07-14 02:10:21,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329019264 with entries=92, filesize=79.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329021309
2014-07-14 02:10:22,640 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7227, memsize=501.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/71be01c5a5df4fe89e0e4681c4630708
2014-07-14 02:10:22,653 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/71be01c5a5df4fe89e0e4681c4630708 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/71be01c5a5df4fe89e0e4681c4630708
2014-07-14 02:10:22,671 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/71be01c5a5df4fe89e0e4681c4630708, entries=1825690, sequenceid=7227, filesize=130.0m
2014-07-14 02:10:22,672 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~725.9m/761125200, currentsize=544.8m/571287680 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 22538ms, sequenceid=7227, compaction requested=true
2014-07-14 02:10:22,672 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-14 02:10:22,672 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 871.2m
2014-07-14 02:10:22,709 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:10:22,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:22,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30253 synced till here 30249
2014-07-14 02:10:22,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329021309 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329022783
2014-07-14 02:10:22,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328954999
2014-07-14 02:10:22,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328957997
2014-07-14 02:10:22,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328960006
2014-07-14 02:10:22,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328961122
2014-07-14 02:10:22,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328975485
2014-07-14 02:10:22,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328976682
2014-07-14 02:10:22,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328978020
2014-07-14 02:10:22,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328979317
2014-07-14 02:10:23,355 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:24,788 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:24,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30327 synced till here 30326
2014-07-14 02:10:24,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329022783 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329024788
2014-07-14 02:10:26,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:26,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30429 synced till here 30428
2014-07-14 02:10:26,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329024788 with entries=102, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329026148
2014-07-14 02:10:27,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:27,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30502 synced till here 30501
2014-07-14 02:10:27,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329026148 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329027674
2014-07-14 02:10:28,876 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:29,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30597 synced till here 30595
2014-07-14 02:10:29,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329027674 with entries=95, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329028877
2014-07-14 02:10:30,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:30,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30672 synced till here 30670
2014-07-14 02:10:30,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329028877 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329030489
2014-07-14 02:10:32,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:32,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329030489 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329032106
2014-07-14 02:10:33,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:33,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30818 synced till here 30817
2014-07-14 02:10:33,745 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329032106 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329033698
2014-07-14 02:10:34,862 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,863 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,893 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,904 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,904 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,915 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,915 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,924 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,961 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:34,989 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,018 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,053 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,083 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,112 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,141 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,174 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,205 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,240 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,268 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,300 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,333 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,365 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,400 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,446 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,476 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,505 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,552 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,586 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,743 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,796 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,845 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,896 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,946 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:35,997 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,047 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,075 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,106 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,134 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,167 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:36,265 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,356 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,385 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,415 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,444 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,477 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,510 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,550 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,584 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,624 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,669 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:37,792 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7439, memsize=601.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/126df90076864347baaf622d2e39ffc3
2014-07-14 02:10:37,809 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/126df90076864347baaf622d2e39ffc3 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/126df90076864347baaf622d2e39ffc3
2014-07-14 02:10:37,821 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/126df90076864347baaf622d2e39ffc3, entries=2189940, sequenceid=7439, filesize=155.9m
2014-07-14 02:10:37,822 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~730.1m/765606080, currentsize=469.6m/492381760 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 25050ms, sequenceid=7439, compaction requested=true
2014-07-14 02:10:37,822 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-14 02:10:37,822 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 153ms
2014-07-14 02:10:37,822 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 943.4m
2014-07-14 02:10:37,822 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,822 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 198ms
2014-07-14 02:10:37,822 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,823 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 239ms
2014-07-14 02:10:37,823 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,823 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 273ms
2014-07-14 02:10:37,823 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,825 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 315ms
2014-07-14 02:10:37,825 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,833 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 356ms
2014-07-14 02:10:37,833 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,833 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 389ms
2014-07-14 02:10:37,833 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,833 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 418ms
2014-07-14 02:10:37,833 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,834 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 448ms
2014-07-14 02:10:37,834 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,834 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 479ms
2014-07-14 02:10:37,834 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,840 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1575ms
2014-07-14 02:10:37,840 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,840 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1673ms
2014-07-14 02:10:37,840 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,841 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1707ms
2014-07-14 02:10:37,841 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,841 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1735ms
2014-07-14 02:10:37,841 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,844 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1769ms
2014-07-14 02:10:37,844 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,847 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1800ms
2014-07-14 02:10:37,847 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,847 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1850ms
2014-07-14 02:10:37,847 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,849 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1903ms
2014-07-14 02:10:37,849 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,849 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1953ms
2014-07-14 02:10:37,850 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,850 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2005ms
2014-07-14 02:10:37,850 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,850 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2054ms
2014-07-14 02:10:37,850 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,852 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2109ms
2014-07-14 02:10:37,852 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,852 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2266ms
2014-07-14 02:10:37,853 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,853 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2301ms
2014-07-14 02:10:37,853 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,853 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2348ms
2014-07-14 02:10:37,853 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,853 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2377ms
2014-07-14 02:10:37,853 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,853 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2407ms
2014-07-14 02:10:37,853 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,854 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2454ms
2014-07-14 02:10:37,854 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,856 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2491ms
2014-07-14 02:10:37,856 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,858 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2524ms
2014-07-14 02:10:37,858 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,858 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2558ms
2014-07-14 02:10:37,858 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,859 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2590ms
2014-07-14 02:10:37,859 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,859 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2620ms
2014-07-14 02:10:37,859 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,860 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2654ms
2014-07-14 02:10:37,860 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,861 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2687ms
2014-07-14 02:10:37,861 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,862 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2720ms
2014-07-14 02:10:37,862 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,862 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2750ms
2014-07-14 02:10:37,862 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,862 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2779ms
2014-07-14 02:10:37,862 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,870 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2816ms
2014-07-14 02:10:37,870 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,873 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2855ms
2014-07-14 02:10:37,873 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,873 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2884ms
2014-07-14 02:10:37,873 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,876 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2915ms
2014-07-14 02:10:37,876 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,876 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2952ms
2014-07-14 02:10:37,876 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,877 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2962ms
2014-07-14 02:10:37,877 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,878 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2963ms
2014-07-14 02:10:37,878 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,878 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2974ms
2014-07-14 02:10:37,878 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,890 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2985ms
2014-07-14 02:10:37,890 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,895 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3002ms
2014-07-14 02:10:37,895 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,898 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3036ms
2014-07-14 02:10:37,898 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:37,899 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3037ms
2014-07-14 02:10:37,899 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:38,094 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:38,206 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:10:38,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30929 synced till here 30897
2014-07-14 02:10:38,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329033698 with entries=111, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329038094
2014-07-14 02:10:38,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328981171
2014-07-14 02:10:38,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328982044
2014-07-14 02:10:39,831 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:40,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:40,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31030 synced till here 31001
2014-07-14 02:10:40,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329038094 with entries=101, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329040463
2014-07-14 02:10:42,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:43,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31159 synced till here 31126
2014-07-14 02:10:43,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329040463 with entries=129, filesize=104.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329042203
2014-07-14 02:10:45,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:45,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31274 synced till here 31241
2014-07-14 02:10:45,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329042203 with entries=115, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329045372
2014-07-14 02:10:47,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:47,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31376 synced till here 31349
2014-07-14 02:10:47,948 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,949 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,951 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,952 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,957 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,959 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,959 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,960 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,960 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,961 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,961 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,961 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,962 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,965 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,965 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329045372 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329047695
2014-07-14 02:10:47,966 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,968 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,969 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,976 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,976 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,976 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,977 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,979 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,980 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,981 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,982 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:47,982 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,018 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,022 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,051 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,495 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,507 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,508 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,508 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,509 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,510 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,511 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,511 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,512 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,513 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,514 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,520 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,522 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,557 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,605 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,636 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,666 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,721 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,770 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:48,819 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:10:53,498 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5516ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5526ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5531ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5539ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5540ms
2014-07-14 02:10:53,499 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5551ms
2014-07-14 02:10:53,500 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5531ms
2014-07-14 02:10:53,500 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5531ms
2014-07-14 02:10:53,500 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5527ms
2014-07-14 02:10:53,500 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5523ms
2014-07-14 02:10:53,500 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5519ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5521ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5522ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5519ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5484ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5479ms
2014-07-14 02:10:53,501 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5450ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5551ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5553ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5551ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5545ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5543ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5542ms
2014-07-14 02:10:53,502 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5542ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5543ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5542ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5541ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5538ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5539ms
2014-07-14 02:10:53,503 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5537ms
2014-07-14 02:10:53,507 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,508 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,509 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:10:53,509 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,511 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:10:53,511 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,511 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,512 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,513 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,514 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,520 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,522 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,558 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:10:53,605 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,636 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,667 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:10:53,721 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,770 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:53,819 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:10:55,775 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7583, memsize=703.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/aa82df1846b3494f8efb0642053aba22
2014-07-14 02:10:55,790 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/aa82df1846b3494f8efb0642053aba22 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa82df1846b3494f8efb0642053aba22
2014-07-14 02:10:55,800 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa82df1846b3494f8efb0642053aba22, entries=2560760, sequenceid=7583, filesize=182.3m
2014-07-14 02:10:55,800 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~872.8m/915177760, currentsize=428.3m/449073600 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 33128ms, sequenceid=7583, compaction requested=true
2014-07-14 02:10:55,801 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:48), split_queue=0, merge_queue=0
2014-07-14 02:10:55,801 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6982ms
2014-07-14 02:10:55,801 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,801 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7031ms
2014-07-14 02:10:55,801 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 978.8m
2014-07-14 02:10:55,801 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,801 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7080ms
2014-07-14 02:10:55,801 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,802 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7135ms
2014-07-14 02:10:55,802 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,802 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7166ms
2014-07-14 02:10:55,802 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,805 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7200ms
2014-07-14 02:10:55,805 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,805 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7248ms
2014-07-14 02:10:55,805 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,805 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7283ms
2014-07-14 02:10:55,805 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,813 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7293ms
2014-07-14 02:10:55,813 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,813 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7299ms
2014-07-14 02:10:55,813 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,813 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7300ms
2014-07-14 02:10:55,813 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,813 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7301ms
2014-07-14 02:10:55,813 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,813 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7302ms
2014-07-14 02:10:55,814 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,828 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7317ms
2014-07-14 02:10:55,828 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,831 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7321ms
2014-07-14 02:10:55,832 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,832 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7323ms
2014-07-14 02:10:55,832 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,833 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7326ms
2014-07-14 02:10:55,834 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,835 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7327ms
2014-07-14 02:10:55,835 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,835 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7328ms
2014-07-14 02:10:55,835 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,835 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7869ms
2014-07-14 02:10:55,835 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,836 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7872ms
2014-07-14 02:10:55,836 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,836 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7871ms
2014-07-14 02:10:55,836 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,836 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7874ms
2014-07-14 02:10:55,836 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,837 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7876ms
2014-07-14 02:10:55,837 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,837 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7877ms
2014-07-14 02:10:55,837 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,839 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7879ms
2014-07-14 02:10:55,839 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,841 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7881ms
2014-07-14 02:10:55,841 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,843 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7884ms
2014-07-14 02:10:55,843 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,844 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7887ms
2014-07-14 02:10:55,844 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,845 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7894ms
2014-07-14 02:10:55,845 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,849 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7900ms
2014-07-14 02:10:55,849 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,851 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7899ms
2014-07-14 02:10:55,851 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,851 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7800ms
2014-07-14 02:10:55,851 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,851 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7829ms
2014-07-14 02:10:55,851 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,851 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7834ms
2014-07-14 02:10:55,851 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,861 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7879ms
2014-07-14 02:10:55,861 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,861 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7882ms
2014-07-14 02:10:55,861 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,861 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7882ms
2014-07-14 02:10:55,861 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,862 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7881ms
2014-07-14 02:10:55,862 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,862 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7885ms
2014-07-14 02:10:55,862 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,862 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7889ms
2014-07-14 02:10:55,862 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,873 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7904ms
2014-07-14 02:10:55,873 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,873 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7904ms
2014-07-14 02:10:55,873 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,881 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7933ms
2014-07-14 02:10:55,881 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,889 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7930ms
2014-07-14 02:10:55,889 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,897 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7937ms
2014-07-14 02:10:55,897 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,901 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7933ms
2014-07-14 02:10:55,901 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,901 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7928ms
2014-07-14 02:10:55,901 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,901 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7919ms
2014-07-14 02:10:55,901 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,905 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7410ms
2014-07-14 02:10:55,905 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:10:55,924 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:10:56,526 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329046310,"queuetimems":1027,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 02:10:56,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:57,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31468 synced till here 31455
2014-07-14 02:10:57,295 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10989,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329046306,"queuetimems":1809,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-14 02:10:57,295 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10988,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329046307,"queuetimems":1073,"class":"HRegionServer","responsesize":16018,"method":"Multi"}
2014-07-14 02:10:57,376 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:10:57,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329047695 with entries=92, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329056526
2014-07-14 02:10:57,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328983481
2014-07-14 02:10:57,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328985123
2014-07-14 02:10:57,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328986447
2014-07-14 02:10:57,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328988230
2014-07-14 02:10:57,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328989290
2014-07-14 02:10:57,422 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328991575
2014-07-14 02:10:59,376 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:10:59,376 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12102,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047274,"queuetimems":1539,"class":"HRegionServer","responsesize":15781,"method":"Multi"}
2014-07-14 02:10:59,377 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12112,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047265,"queuetimems":1700,"class":"HRegionServer","responsesize":16044,"method":"Multi"}
2014-07-14 02:10:59,377 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11672,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047704,"queuetimems":0,"class":"HRegionServer","responsesize":15757,"method":"Multi"}
2014-07-14 02:10:59,386 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047269,"queuetimems":1591,"class":"HRegionServer","responsesize":15735,"method":"Multi"}
2014-07-14 02:10:59,387 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12125,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047261,"queuetimems":1726,"class":"HRegionServer","responsesize":15893,"method":"Multi"}
2014-07-14 02:10:59,387 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047743,"queuetimems":1,"class":"HRegionServer","responsesize":15940,"method":"Multi"}
2014-07-14 02:10:59,386 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12109,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047277,"queuetimems":1513,"class":"HRegionServer","responsesize":15908,"method":"Multi"}
2014-07-14 02:10:59,386 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047270,"queuetimems":1563,"class":"HRegionServer","responsesize":15868,"method":"Multi"}
2014-07-14 02:10:59,389 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047393,"queuetimems":7,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:10:59,393 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12144,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047249,"queuetimems":1937,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:10:59,394 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329046309,"queuetimems":1064,"class":"HRegionServer","responsesize":15757,"method":"Multi"}
2014-07-14 02:10:59,397 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048664,"queuetimems":0,"class":"HRegionServer","responsesize":15735,"method":"Multi"}
2014-07-14 02:10:59,401 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047257,"queuetimems":1752,"class":"HRegionServer","responsesize":15695,"method":"Multi"}
2014-07-14 02:10:59,405 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12148,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047256,"queuetimems":1843,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:10:59,406 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10773,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048633,"queuetimems":0,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 02:10:59,408 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12122,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047286,"queuetimems":1263,"class":"HRegionServer","responsesize":15270,"method":"Multi"}
2014-07-14 02:10:59,408 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10893,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048515,"queuetimems":0,"class":"HRegionServer","responsesize":16399,"method":"Multi"}
2014-07-14 02:10:59,409 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047255,"queuetimems":1884,"class":"HRegionServer","responsesize":16100,"method":"Multi"}
2014-07-14 02:10:59,387 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048766,"queuetimems":0,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:10:59,413 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10598,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048815,"queuetimems":0,"class":"HRegionServer","responsesize":15868,"method":"Multi"}
2014-07-14 02:10:59,416 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10814,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048602,"queuetimems":0,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 02:10:59,420 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11777,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047643,"queuetimems":0,"class":"HRegionServer","responsesize":16018,"method":"Multi"}
2014-07-14 02:10:59,408 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12122,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047286,"queuetimems":1307,"class":"HRegionServer","responsesize":15825,"method":"Multi"}
2014-07-14 02:10:59,425 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047267,"queuetimems":1617,"class":"HRegionServer","responsesize":15872,"method":"Multi"}
2014-07-14 02:10:59,426 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047256,"queuetimems":1802,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:10:59,389 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047282,"queuetimems":1342,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:10:59,425 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12096,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047329,"queuetimems":10,"class":"HRegionServer","responsesize":15825,"method":"Multi"}
2014-07-14 02:10:59,429 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047287,"queuetimems":27,"class":"HRegionServer","responsesize":15835,"method":"Multi"}
2014-07-14 02:10:59,425 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12160,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047265,"queuetimems":1644,"class":"HRegionServer","responsesize":15579,"method":"Multi"}
2014-07-14 02:10:59,420 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11828,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047592,"queuetimems":0,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:10:59,433 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11640,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047793,"queuetimems":0,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 02:10:59,438 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047265,"queuetimems":1672,"class":"HRegionServer","responsesize":15620,"method":"Multi"}
2014-07-14 02:10:59,441 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10887,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048554,"queuetimems":0,"class":"HRegionServer","responsesize":15695,"method":"Multi"}
2014-07-14 02:10:59,441 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12187,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047254,"queuetimems":1913,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 02:10:59,441 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12159,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047282,"queuetimems":1382,"class":"HRegionServer","responsesize":16282,"method":"Multi"}
2014-07-14 02:10:59,586 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12304,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047281,"queuetimems":1471,"class":"HRegionServer","responsesize":15425,"method":"Multi"}
2014-07-14 02:10:59,587 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11574,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048013,"queuetimems":0,"class":"HRegionServer","responsesize":15327,"method":"Multi"}
2014-07-14 02:10:59,589 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048048,"queuetimems":0,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-14 02:10:59,589 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047978,"queuetimems":1,"class":"HRegionServer","responsesize":16282,"method":"Multi"}
2014-07-14 02:10:59,597 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11512,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048085,"queuetimems":0,"class":"HRegionServer","responsesize":15342,"method":"Multi"}
2014-07-14 02:10:59,631 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31586 synced till here 31572
2014-07-14 02:10:59,705 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10988,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329048717,"queuetimems":0,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:10:59,705 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047287,"queuetimems":3,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:10:59,705 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329047905,"queuetimems":0,"class":"HRegionServer","responsesize":16100,"method":"Multi"}
2014-07-14 02:10:59,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329056526 with entries=118, filesize=98.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329059376
2014-07-14 02:11:01,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:01,317 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31687 synced till here 31659
2014-07-14 02:11:01,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329059376 with entries=101, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329061175
2014-07-14 02:11:02,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:02,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31794 synced till here 31768
2014-07-14 02:11:03,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329061175 with entries=107, filesize=84.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329062906
2014-07-14 02:11:04,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:04,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31896 synced till here 31875
2014-07-14 02:11:05,147 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329062906 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329064900
2014-07-14 02:11:05,615 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,616 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,616 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,616 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,619 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,622 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,623 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,624 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,674 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,674 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,674 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,675 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:05,675 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:07,841 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:09,389 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:10,074 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:10,616 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,616 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:10,616 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:10,616 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:10,620 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,623 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,623 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,624 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,674 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,674 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:10,675 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,675 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:10,675 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.53 MB, free=3.95 GB, max=3.96 GB, blocks=5, accesses=142178, hits=30326, hitRatio=21.32%, , cachingAccesses=30342, cachingHits=30313, cachingHitsRatio=99.90%, evictions=0, evicted=24, evictedPerRun=Infinity
2014-07-14 02:11:12,277 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,525 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,544 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,572 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,600 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,630 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,664 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:12,842 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:11:14,172 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:14,390 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:11:14,565 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7741, memsize=765.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/b9f5252e887f4eff879f138ac984a536
2014-07-14 02:11:14,581 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/b9f5252e887f4eff879f138ac984a536 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b9f5252e887f4eff879f138ac984a536
2014-07-14 02:11:14,594 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b9f5252e887f4eff879f138ac984a536, entries=2785280, sequenceid=7741, filesize=198.2m
2014-07-14 02:11:14,595 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~943.4m/989217840, currentsize=410.5m/430475120 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 36772ms, sequenceid=7741, compaction requested=true
2014-07-14 02:11:14,595 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-14 02:11:14,595 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5206ms
2014-07-14 02:11:14,595 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,595 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 424ms
2014-07-14 02:11:14,595 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 880.4m
2014-07-14 02:11:14,596 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,596 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6755ms
2014-07-14 02:11:14,596 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,596 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1932ms
2014-07-14 02:11:14,596 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,596 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1966ms
2014-07-14 02:11:14,597 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,600 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1999ms
2014-07-14 02:11:14,600 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,601 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2029ms
2014-07-14 02:11:14,603 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,603 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2059ms
2014-07-14 02:11:14,603 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,603 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2078ms
2014-07-14 02:11:14,603 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,604 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2328ms
2014-07-14 02:11:14,604 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,604 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8929ms
2014-07-14 02:11:14,604 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,611 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8937ms
2014-07-14 02:11:14,611 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,611 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8937ms
2014-07-14 02:11:14,611 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,612 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8937ms
2014-07-14 02:11:14,612 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,612 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8939ms
2014-07-14 02:11:14,612 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,613 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8990ms
2014-07-14 02:11:14,613 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,624 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9002ms
2014-07-14 02:11:14,625 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,625 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9003ms
2014-07-14 02:11:14,625 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,625 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9006ms
2014-07-14 02:11:14,625 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,631 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9015ms
2014-07-14 02:11:14,631 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,638 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9021ms
2014-07-14 02:11:14,638 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,644 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9027ms
2014-07-14 02:11:14,644 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,644 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9029ms
2014-07-14 02:11:14,644 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,644 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4571ms
2014-07-14 02:11:14,644 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:14,815 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:14,817 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10017,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064799,"queuetimems":1,"class":"HRegionServer","responsesize":15905,"method":"Multi"}
2014-07-14 02:11:14,817 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064768,"queuetimems":0,"class":"HRegionServer","responsesize":16282,"method":"Multi"}
2014-07-14 02:11:14,817 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:11:14,817 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329063865,"queuetimems":0,"class":"HRegionServer","responsesize":15695,"method":"Multi"}
2014-07-14 02:11:14,817 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10066,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064751,"queuetimems":0,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:11:14,818 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10842,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329063976,"queuetimems":0,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 02:11:14,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31979 synced till here 31971
2014-07-14 02:11:14,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329064900 with entries=83, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329074815
2014-07-14 02:11:14,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328993140
2014-07-14 02:11:14,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328994780
2014-07-14 02:11:14,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328996042
2014-07-14 02:11:14,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328997146
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329065027,"queuetimems":0,"class":"HRegionServer","responsesize":15758,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10141,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064940,"queuetimems":0,"class":"HRegionServer","responsesize":16043,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10115,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064966,"queuetimems":0,"class":"HRegionServer","responsesize":15825,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064879,"queuetimems":0,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10083,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064998,"queuetimems":0,"class":"HRegionServer","responsesize":15940,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064835,"queuetimems":0,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 02:11:15,081 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10175,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329064906,"queuetimems":1,"class":"HRegionServer","responsesize":15327,"method":"Multi"}
2014-07-14 02:11:15,325 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:11:16,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:16,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32056 synced till here 32054
2014-07-14 02:11:16,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329074815 with entries=77, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329076168
2014-07-14 02:11:17,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:17,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32151 synced till here 32146
2014-07-14 02:11:17,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329076168 with entries=95, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329077459
2014-07-14 02:11:18,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:18,970 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32226 synced till here 32225
2014-07-14 02:11:18,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329077459 with entries=75, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329078939
2014-07-14 02:11:20,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:20,363 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32301 synced till here 32300
2014-07-14 02:11:20,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329078939 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329080343
2014-07-14 02:11:21,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:21,603 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32375 synced till here 32374
2014-07-14 02:11:21,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329080343 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329081588
2014-07-14 02:11:22,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:22,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32449 synced till here 32447
2014-07-14 02:11:22,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329081588 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329082882
2014-07-14 02:11:24,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:24,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32525 synced till here 32523
2014-07-14 02:11:24,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329082882 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329084358
2014-07-14 02:11:24,589 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,593 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,613 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,649 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,650 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,650 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,707 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,750 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,792 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,839 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,887 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:24,927 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,030 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,073 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,121 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,159 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,204 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,243 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,286 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,326 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,367 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,411 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,452 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,495 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,539 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,579 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:25,622 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:26,934 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:26,948 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:26,964 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:26,985 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,014 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,068 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,106 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,139 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,172 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,205 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,248 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,284 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,623 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,659 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,696 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,735 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:27,767 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:28,248 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7861, memsize=716.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/971edc57457c47ac995582fd0c144eea
2014-07-14 02:11:28,267 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/971edc57457c47ac995582fd0c144eea as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/971edc57457c47ac995582fd0c144eea
2014-07-14 02:11:28,287 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/971edc57457c47ac995582fd0c144eea, entries=2607590, sequenceid=7861, filesize=185.5m
2014-07-14 02:11:28,288 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~978.8m/1026365360, currentsize=457.0m/479161360 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 32487ms, sequenceid=7861, compaction requested=true
2014-07-14 02:11:28,288 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:50), split_queue=0, merge_queue=0
2014-07-14 02:11:28,288 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 521ms
2014-07-14 02:11:28,288 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,289 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 554ms
2014-07-14 02:11:28,289 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 889.3m
2014-07-14 02:11:28,289 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,289 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 593ms
2014-07-14 02:11:28,289 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,289 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 630ms
2014-07-14 02:11:28,289 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,290 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 667ms
2014-07-14 02:11:28,290 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,297 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1014ms
2014-07-14 02:11:28,297 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,303 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1055ms
2014-07-14 02:11:28,303 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,303 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1098ms
2014-07-14 02:11:28,303 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,303 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1131ms
2014-07-14 02:11:28,303 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,305 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1166ms
2014-07-14 02:11:28,305 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,307 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1201ms
2014-07-14 02:11:28,307 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,307 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1239ms
2014-07-14 02:11:28,307 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,307 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1293ms
2014-07-14 02:11:28,307 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,308 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1322ms
2014-07-14 02:11:28,308 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,308 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1344ms
2014-07-14 02:11:28,308 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,308 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1361ms
2014-07-14 02:11:28,308 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,309 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1375ms
2014-07-14 02:11:28,309 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,314 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2692ms
2014-07-14 02:11:28,314 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,314 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2735ms
2014-07-14 02:11:28,314 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,315 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2777ms
2014-07-14 02:11:28,315 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,315 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2820ms
2014-07-14 02:11:28,315 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,315 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2863ms
2014-07-14 02:11:28,315 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,317 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2906ms
2014-07-14 02:11:28,317 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,317 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2951ms
2014-07-14 02:11:28,318 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,318 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2992ms
2014-07-14 02:11:28,318 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,318 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3032ms
2014-07-14 02:11:28,318 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,318 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3076ms
2014-07-14 02:11:28,318 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,319 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3115ms
2014-07-14 02:11:28,319 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,322 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3162ms
2014-07-14 02:11:28,322 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,322 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3201ms
2014-07-14 02:11:28,322 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,323 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3250ms
2014-07-14 02:11:28,323 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,324 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3294ms
2014-07-14 02:11:28,324 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,325 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3398ms
2014-07-14 02:11:28,325 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,326 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3440ms
2014-07-14 02:11:28,326 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,326 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3487ms
2014-07-14 02:11:28,326 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,327 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3534ms
2014-07-14 02:11:28,327 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,329 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3579ms
2014-07-14 02:11:28,329 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,329 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3622ms
2014-07-14 02:11:28,329 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,329 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3679ms
2014-07-14 02:11:28,329 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,331 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3680ms
2014-07-14 02:11:28,331 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,331 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3682ms
2014-07-14 02:11:28,331 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,331 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3718ms
2014-07-14 02:11:28,331 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,333 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3740ms
2014-07-14 02:11:28,333 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,333 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3744ms
2014-07-14 02:11:28,333 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:28,427 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:11:28,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:29,988 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:11:30,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32608 synced till here 32596
2014-07-14 02:11:30,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329084358 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329089885
2014-07-14 02:11:30,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405328998898
2014-07-14 02:11:30,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329000301
2014-07-14 02:11:30,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329001743
2014-07-14 02:11:30,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329002898
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329004127
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329005636
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329007604
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329008940
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329010162
2014-07-14 02:11:30,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329011443
2014-07-14 02:11:30,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:30,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32713 synced till here 32684
2014-07-14 02:11:31,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329089885 with entries=105, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329090809
2014-07-14 02:11:32,940 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:33,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32811 synced till here 32790
2014-07-14 02:11:34,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329090809 with entries=98, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329092941
2014-07-14 02:11:34,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:34,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32902 synced till here 32889
2014-07-14 02:11:35,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329092941 with entries=91, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329094787
2014-07-14 02:11:36,344 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:36,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32985 synced till here 32976
2014-07-14 02:11:37,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329094787 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329096345
2014-07-14 02:11:38,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:38,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33060 synced till here 33059
2014-07-14 02:11:38,407 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329096345 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329098339
2014-07-14 02:11:39,765 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:39,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33142 synced till here 33132
2014-07-14 02:11:39,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329098339 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329099766
2014-07-14 02:11:40,784 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,786 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,829 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,829 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,831 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,837 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,871 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,871 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,871 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,875 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,884 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,901 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,935 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8013, memsize=463.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/1063b48f64274ab698f7eb1eeef87e58
2014-07-14 02:11:40,936 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:40,948 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/1063b48f64274ab698f7eb1eeef87e58 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1063b48f64274ab698f7eb1eeef87e58
2014-07-14 02:11:40,958 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1063b48f64274ab698f7eb1eeef87e58, entries=1686670, sequenceid=8013, filesize=120.0m
2014-07-14 02:11:40,958 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~880.4m/923120080, currentsize=473.0m/495944560 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 26363ms, sequenceid=8013, compaction requested=true
2014-07-14 02:11:40,958 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:51), split_queue=0, merge_queue=0
2014-07-14 02:11:40,959 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23ms
2014-07-14 02:11:40,959 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 883.2m
2014-07-14 02:11:40,959 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,959 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 58ms
2014-07-14 02:11:40,959 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,959 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 75ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,960 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,960 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 89ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,960 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 89ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,960 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 89ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,960 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 124ms
2014-07-14 02:11:40,960 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,973 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 143ms
2014-07-14 02:11:40,973 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,973 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 144ms
2014-07-14 02:11:40,973 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,977 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 148ms
2014-07-14 02:11:40,977 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,983 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 197ms
2014-07-14 02:11:40,983 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:40,983 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 199ms
2014-07-14 02:11:40,983 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:41,088 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:11:41,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:41,480 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33230 synced till here 33226
2014-07-14 02:11:41,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329099766 with entries=88, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329101306
2014-07-14 02:11:41,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329012626
2014-07-14 02:11:41,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329014043
2014-07-14 02:11:41,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329015161
2014-07-14 02:11:41,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329016201
2014-07-14 02:11:41,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329017761
2014-07-14 02:11:41,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329019264
2014-07-14 02:11:42,565 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:11:43,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:43,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33315 synced till here 33314
2014-07-14 02:11:43,856 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329101306 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329103672
2014-07-14 02:11:45,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:45,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33395 synced till here 33388
2014-07-14 02:11:45,141 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329103672 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329105051
2014-07-14 02:11:46,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:47,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33486 synced till here 33482
2014-07-14 02:11:47,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329105051 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329106542
2014-07-14 02:11:48,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:48,264 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33568 synced till here 33559
2014-07-14 02:11:48,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329106542 with entries=82, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329108226
2014-07-14 02:11:49,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:50,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329108226 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329109808
2014-07-14 02:11:51,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:51,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33741 synced till here 33739
2014-07-14 02:11:51,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329109808 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329111293
2014-07-14 02:11:52,000 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,012 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,038 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,040 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,045 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,045 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,046 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,047 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,049 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,052 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,063 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,070 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,121 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,175 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,210 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,268 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,434 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,494 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,578 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,615 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,651 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,685 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,720 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,759 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,788 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,827 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,858 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,900 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,925 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:52,971 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,018 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,073 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,134 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,175 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,208 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,261 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,290 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,390 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,448 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,497 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,530 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:53,729 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:54,064 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:54,300 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:54,349 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:54,386 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:54,422 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:55,327 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:55,336 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:55,347 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:11:55,588 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8162, memsize=434.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/17a576ac7ffd4ac3acf5efb366d5516b
2014-07-14 02:11:55,605 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/17a576ac7ffd4ac3acf5efb366d5516b as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/17a576ac7ffd4ac3acf5efb366d5516b
2014-07-14 02:11:55,617 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/17a576ac7ffd4ac3acf5efb366d5516b, entries=1580160, sequenceid=8162, filesize=112.4m
2014-07-14 02:11:55,617 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~889.3m/932516080, currentsize=462.0m/484451760 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 27328ms, sequenceid=8162, compaction requested=true
2014-07-14 02:11:55,617 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:52), split_queue=0, merge_queue=0
2014-07-14 02:11:55,618 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 271ms
2014-07-14 02:11:55,618 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,618 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 282ms
2014-07-14 02:11:55,618 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 919.7m
2014-07-14 02:11:55,618 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,618 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 291ms
2014-07-14 02:11:55,618 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,618 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1196ms
2014-07-14 02:11:55,618 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,619 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1233ms
2014-07-14 02:11:55,619 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,619 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1270ms
2014-07-14 02:11:55,619 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,619 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1319ms
2014-07-14 02:11:55,619 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,627 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1563ms
2014-07-14 02:11:55,627 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,627 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1898ms
2014-07-14 02:11:55,627 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,628 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2097ms
2014-07-14 02:11:55,628 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,628 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2131ms
2014-07-14 02:11:55,628 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,629 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2180ms
2014-07-14 02:11:55,629 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,632 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2242ms
2014-07-14 02:11:55,632 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,632 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2342ms
2014-07-14 02:11:55,632 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,632 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2371ms
2014-07-14 02:11:55,632 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,637 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2429ms
2014-07-14 02:11:55,637 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,637 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2462ms
2014-07-14 02:11:55,637 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,638 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2504ms
2014-07-14 02:11:55,638 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,640 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2567ms
2014-07-14 02:11:55,640 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,641 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2623ms
2014-07-14 02:11:55,641 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,642 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2670ms
2014-07-14 02:11:55,642 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,642 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2717ms
2014-07-14 02:11:55,642 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,643 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2742ms
2014-07-14 02:11:55,644 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,644 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2786ms
2014-07-14 02:11:55,644 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,645 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2818ms
2014-07-14 02:11:55,645 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,645 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2857ms
2014-07-14 02:11:55,645 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,646 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2887ms
2014-07-14 02:11:55,646 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,653 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2933ms
2014-07-14 02:11:55,653 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,653 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2968ms
2014-07-14 02:11:55,653 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,654 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3003ms
2014-07-14 02:11:55,654 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,654 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3039ms
2014-07-14 02:11:55,654 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,654 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3076ms
2014-07-14 02:11:55,654 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,657 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3162ms
2014-07-14 02:11:55,657 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,658 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3223ms
2014-07-14 02:11:55,658 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,658 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3390ms
2014-07-14 02:11:55,658 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,658 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3448ms
2014-07-14 02:11:55,658 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,662 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3487ms
2014-07-14 02:11:55,663 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,663 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3542ms
2014-07-14 02:11:55,663 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,663 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3593ms
2014-07-14 02:11:55,663 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,663 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3601ms
2014-07-14 02:11:55,663 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,664 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3611ms
2014-07-14 02:11:55,664 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,673 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3624ms
2014-07-14 02:11:55,673 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,673 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3626ms
2014-07-14 02:11:55,673 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,674 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3627ms
2014-07-14 02:11:55,674 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,681 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3636ms
2014-07-14 02:11:55,681 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,681 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3643ms
2014-07-14 02:11:55,681 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,682 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3643ms
2014-07-14 02:11:55,682 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,684 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3646ms
2014-07-14 02:11:55,684 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,688 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3676ms
2014-07-14 02:11:55,688 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,688 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3688ms
2014-07-14 02:11:55,688 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:11:55,867 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:11:56,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:56,453 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:11:56,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33826 synced till here 33817
2014-07-14 02:11:57,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329111293 with entries=85, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329116403
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329021309
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329022783
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329024788
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329026148
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329027674
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329028877
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329030489
2014-07-14 02:11:57,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329032106
2014-07-14 02:11:58,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:11:59,678 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33931 synced till here 33898
2014-07-14 02:11:59,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329116403 with entries=105, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329118623
2014-07-14 02:12:01,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:01,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34010 synced till here 34004
2014-07-14 02:12:01,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329118623 with entries=79, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329121728
2014-07-14 02:12:02,557 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8316, memsize=285.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/e9f696eaf68c416ebe8809b2133e602b
2014-07-14 02:12:02,588 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/e9f696eaf68c416ebe8809b2133e602b as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/e9f696eaf68c416ebe8809b2133e602b
2014-07-14 02:12:02,612 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/e9f696eaf68c416ebe8809b2133e602b, entries=1038350, sequenceid=8316, filesize=73.9m
2014-07-14 02:12:02,613 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~883.2m/926092000, currentsize=329.4m/345406640 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 21654ms, sequenceid=8316, compaction requested=true
2014-07-14 02:12:02,613 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-14 02:12:02,614 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 857.4m
2014-07-14 02:12:03,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:03,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34120 synced till here 34083
2014-07-14 02:12:03,994 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:12:04,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329121728 with entries=110, filesize=93.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329123759
2014-07-14 02:12:04,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329033698
2014-07-14 02:12:04,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329038094
2014-07-14 02:12:04,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329040463
2014-07-14 02:12:04,191 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329042203
2014-07-14 02:12:04,191 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329045372
2014-07-14 02:12:04,470 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:12:05,710 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1019ms
GC pool 'ParNew' had collection(s): count=1 time=1025ms
2014-07-14 02:12:06,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:06,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34232 synced till here 34207
2014-07-14 02:12:06,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329123759 with entries=112, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329126318
2014-07-14 02:12:08,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:08,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34336 synced till here 34308
2014-07-14 02:12:09,721 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1027ms
GC pool 'ParNew' had collection(s): count=1 time=1101ms
2014-07-14 02:12:09,964 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329126318 with entries=104, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329128544
2014-07-14 02:12:11,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:11,985 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34440 synced till here 34427
2014-07-14 02:12:12,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329128544 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329131893
2014-07-14 02:12:14,044 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:14,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34554 synced till here 34522
2014-07-14 02:12:14,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329131893 with entries=114, filesize=97.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329134045
2014-07-14 02:12:37,765 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 31957ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:12:37,766 WARN  [regionserver60020] util.Sleeper: We slept 25026ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:12:37,766 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 31957ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:12:37,849 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27106,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130742,"queuetimems":4358,"class":"HRegionServer","responsesize":15847,"method":"Multi"}
2014-07-14 02:12:37,849 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131899,"queuetimems":5251,"class":"HRegionServer","responsesize":16299,"method":"Multi"}
2014-07-14 02:12:37,853 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131901,"queuetimems":4204,"class":"HRegionServer","responsesize":16114,"method":"Multi"}
2014-07-14 02:12:37,853 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130742,"queuetimems":4448,"class":"HRegionServer","responsesize":16094,"method":"Multi"}
2014-07-14 02:12:37,853 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130739,"queuetimems":4792,"class":"HRegionServer","responsesize":16246,"method":"Multi"}
2014-07-14 02:12:37,854 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14281 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,855 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131903,"queuetimems":4155,"class":"HRegionServer","responsesize":15733,"method":"Multi"}
2014-07-14 02:12:37,856 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131909,"queuetimems":4132,"class":"HRegionServer","responsesize":15717,"method":"Multi"}
2014-07-14 02:12:37,856 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130742,"queuetimems":4498,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-14 02:12:37,856 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130739,"queuetimems":4713,"class":"HRegionServer","responsesize":15676,"method":"Multi"}
2014-07-14 02:12:37,857 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25959,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131898,"queuetimems":5416,"class":"HRegionServer","responsesize":15471,"method":"Multi"}
2014-07-14 02:12:37,857 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25958,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131899,"queuetimems":5376,"class":"HRegionServer","responsesize":15668,"method":"Multi"}
2014-07-14 02:12:37,857 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130741,"queuetimems":4541,"class":"HRegionServer","responsesize":15784,"method":"Multi"}
2014-07-14 02:12:37,857 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130741,"queuetimems":4610,"class":"HRegionServer","responsesize":16006,"method":"Multi"}
2014-07-14 02:12:37,858 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25956,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131902,"queuetimems":4194,"class":"HRegionServer","responsesize":15691,"method":"Multi"}
2014-07-14 02:12:37,858 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329130740,"queuetimems":4668,"class":"HRegionServer","responsesize":16046,"method":"Multi"}
2014-07-14 02:12:37,971 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:182)
	at sun.nio.ch.SocketChannelImpl.write0(SocketChannelImpl.java:383)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:406)
	at org.apache.hadoop.hbase.ipc.BufferChain.write(BufferChain.java:106)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelWrite(RpcServer.java:2209)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.processResponse(RpcServer.java:1004)
	at org.apache.hadoop.hbase.ipc.RpcServer$Responder.doRespond(RpcServer.java:1081)
	at org.apache.hadoop.hbase.ipc.RpcServer$Call.sendResponseIfReady(RpcServer.java:496)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:121)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.consumerLoop(SimpleRpcScheduler.java:168)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.access$000(SimpleRpcScheduler.java:39)
	at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler$1.run(SimpleRpcScheduler.java:111)
	at java.lang.Thread.run(Thread.java:701)

2014-07-14 02:12:37,972 WARN  [RpcServer.reader=1,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: count of bytes read: 0
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureReadOpen(SocketChannelImpl.java:131)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:174)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelIO(RpcServer.java:2263)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2229)
	at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1488)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:790)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:581)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:556)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-14 02:12:37,989 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14299 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14280 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14298 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14297 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,991 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,992 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14286 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,992 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,992 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14289 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,992 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14300 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14296 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14277 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14278 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,993 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14301 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,994 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:37,995 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14295 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:37,995 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,065 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25938,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132127,"queuetimems":4293,"class":"HRegionServer","responsesize":15612,"method":"Multi"}
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25791,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132274,"queuetimems":4411,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 02:12:38,065 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131903,"queuetimems":4184,"class":"HRegionServer","responsesize":15391,"method":"Multi"}
2014-07-14 02:12:38,065 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131895,"queuetimems":5449,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:12:38,065 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132126,"queuetimems":4320,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14275 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14292 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14276 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14279 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,066 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,067 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14274 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,067 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:38,208 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329131899,"queuetimems":5151,"class":"HRegionServer","responsesize":16002,"method":"Multi"}
2014-07-14 02:12:38,209 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14284 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,209 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,225 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34640 synced till here 34633
2014-07-14 02:12:38,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329134045 with entries=86, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329158207
2014-07-14 02:12:38,566 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133822,"queuetimems":5327,"class":"HRegionServer","responsesize":15391,"method":"Multi"}
2014-07-14 02:12:38,566 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25851,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132715,"queuetimems":4531,"class":"HRegionServer","responsesize":16002,"method":"Multi"}
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14329 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14337 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25861,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132706,"queuetimems":4785,"class":"HRegionServer","responsesize":16094,"method":"Multi"}
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14346 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,567 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,668 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25931,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132737,"queuetimems":4457,"class":"HRegionServer","responsesize":16046,"method":"Multi"}
2014-07-14 02:12:38,668 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24621,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134047,"queuetimems":4297,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14334 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14322 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132722,"queuetimems":4507,"class":"HRegionServer","responsesize":15380,"method":"Multi"}
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14336 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24854,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133815,"queuetimems":5395,"class":"HRegionServer","responsesize":15784,"method":"Multi"}
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25954,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132715,"queuetimems":4561,"class":"HRegionServer","responsesize":15724,"method":"Multi"}
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14331 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14338 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132707,"queuetimems":4668,"class":"HRegionServer","responsesize":15561,"method":"Multi"}
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25964,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132706,"queuetimems":4754,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14342 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133815,"queuetimems":5360,"class":"HRegionServer","responsesize":15676,"method":"Multi"}
2014-07-14 02:12:38,671 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14330 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24847,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133825,"queuetimems":5208,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133814,"queuetimems":5431,"class":"HRegionServer","responsesize":16063,"method":"Multi"}
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24843,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133829,"queuetimems":4089,"class":"HRegionServer","responsesize":15805,"method":"Multi"}
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14324 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14345 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14323 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,669 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132706,"queuetimems":4725,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24848,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133825,"queuetimems":5260,"class":"HRegionServer","responsesize":15668,"method":"Multi"}
2014-07-14 02:12:38,674 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14344 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,674 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133814,"queuetimems":5485,"class":"HRegionServer","responsesize":15654,"method":"Multi"}
2014-07-14 02:12:38,674 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25945,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132729,"queuetimems":4478,"class":"HRegionServer","responsesize":15847,"method":"Multi"}
2014-07-14 02:12:38,673 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25966,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132707,"queuetimems":4697,"class":"HRegionServer","responsesize":16246,"method":"Multi"}
2014-07-14 02:12:38,672 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329133825,"queuetimems":5290,"class":"HRegionServer","responsesize":16114,"method":"Multi"}
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25956,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132714,"queuetimems":4618,"class":"HRegionServer","responsesize":16299,"method":"Multi"}
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25956,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132714,"queuetimems":4589,"class":"HRegionServer","responsesize":16006,"method":"Multi"}
2014-07-14 02:12:38,670 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25966,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132704,"queuetimems":4812,"class":"HRegionServer","responsesize":15691,"method":"Multi"}
2014-07-14 02:12:38,674 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25964,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329132710,"queuetimems":4643,"class":"HRegionServer","responsesize":15471,"method":"Multi"}
2014-07-14 02:12:38,674 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14327 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14341 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14332 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14347 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14339 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,675 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14340 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14328 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14343 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14335 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14333 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,676 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134061,"queuetimems":4250,"class":"HRegionServer","responsesize":15798,"method":"Multi"}
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134321,"queuetimems":4480,"class":"HRegionServer","responsesize":15955,"method":"Multi"}
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14318 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134336,"queuetimems":4465,"class":"HRegionServer","responsesize":15665,"method":"Multi"}
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23994,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134722,"queuetimems":4822,"class":"HRegionServer","responsesize":15956,"method":"Multi"}
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47192","starttimems":1405329134047,"queuetimems":4265,"class":"HRegionServer","responsesize":15896,"method":"Multi"}
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14317 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14315 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,717 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14321 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14316 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,718 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,754 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14314 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,754 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:38,796 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 14313 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47192: output error
2014-07-14 02:12:38,796 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:12:39,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:39,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329158207 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329159694
2014-07-14 02:12:41,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:41,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329159694 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329161693
2014-07-14 02:12:42,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:43,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34880 synced till here 34875
2014-07-14 02:12:43,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329161693 with entries=94, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329162947
2014-07-14 02:12:43,398 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,409 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,410 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,416 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,430 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,454 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,470 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,480 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,487 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,508 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,554 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,608 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,641 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,675 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,736 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,780 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,863 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,864 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,887 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,934 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:43,968 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,005 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,037 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,070 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,106 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,135 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,169 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:44,208 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,091 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,100 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,113 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,142 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,169 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,200 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,242 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,752 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,788 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,829 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,860 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,897 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,932 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:45,969 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,005 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,049 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,094 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,125 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,163 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,203 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,237 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:46,277 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:12:47,577 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8463, memsize=418.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/14195a276ddd45c09119b3fcf82b8b3e
2014-07-14 02:12:47,598 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/14195a276ddd45c09119b3fcf82b8b3e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/14195a276ddd45c09119b3fcf82b8b3e
2014-07-14 02:12:47,611 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/14195a276ddd45c09119b3fcf82b8b3e, entries=1522670, sequenceid=8463, filesize=108.4m
2014-07-14 02:12:47,611 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~919.7m/964322960, currentsize=441.4m/462811200 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 51993ms, sequenceid=8463, compaction requested=true
2014-07-14 02:12:47,612 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:54), split_queue=0, merge_queue=0
2014-07-14 02:12:47,612 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1335ms
2014-07-14 02:12:47,612 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,612 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 906.5m
2014-07-14 02:12:47,613 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1375ms
2014-07-14 02:12:47,614 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,614 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1411ms
2014-07-14 02:12:47,614 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,614 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1451ms
2014-07-14 02:12:47,614 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,615 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1489ms
2014-07-14 02:12:47,615 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,617 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1523ms
2014-07-14 02:12:47,617 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,620 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1571ms
2014-07-14 02:12:47,620 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,623 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1618ms
2014-07-14 02:12:47,623 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,623 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1654ms
2014-07-14 02:12:47,623 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,625 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1693ms
2014-07-14 02:12:47,625 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,629 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1732ms
2014-07-14 02:12:47,629 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,629 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1769ms
2014-07-14 02:12:47,629 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,629 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1800ms
2014-07-14 02:12:47,629 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,633 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1845ms
2014-07-14 02:12:47,633 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,636 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1884ms
2014-07-14 02:12:47,636 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,636 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2394ms
2014-07-14 02:12:47,637 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,637 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2437ms
2014-07-14 02:12:47,637 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,645 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2476ms
2014-07-14 02:12:47,646 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,646 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2504ms
2014-07-14 02:12:47,646 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,647 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2533ms
2014-07-14 02:12:47,647 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,647 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2547ms
2014-07-14 02:12:47,647 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,647 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2556ms
2014-07-14 02:12:47,647 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,648 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3440ms
2014-07-14 02:12:47,648 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,649 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3480ms
2014-07-14 02:12:47,649 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,654 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3520ms
2014-07-14 02:12:47,654 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,654 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3548ms
2014-07-14 02:12:47,654 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,656 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3585ms
2014-07-14 02:12:47,656 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,656 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3619ms
2014-07-14 02:12:47,656 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,657 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3651ms
2014-07-14 02:12:47,657 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,658 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3690ms
2014-07-14 02:12:47,658 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,658 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3724ms
2014-07-14 02:12:47,658 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,658 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3771ms
2014-07-14 02:12:47,658 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,659 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3843ms
2014-07-14 02:12:47,660 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,660 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3804ms
2014-07-14 02:12:47,660 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,661 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3880ms
2014-07-14 02:12:47,661 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,661 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3925ms
2014-07-14 02:12:47,661 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,662 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3986ms
2014-07-14 02:12:47,662 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,662 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4021ms
2014-07-14 02:12:47,662 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,664 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4056ms
2014-07-14 02:12:47,664 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,665 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4111ms
2014-07-14 02:12:47,665 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,665 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4158ms
2014-07-14 02:12:47,665 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,665 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4178ms
2014-07-14 02:12:47,666 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,666 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4186ms
2014-07-14 02:12:47,666 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,666 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4196ms
2014-07-14 02:12:47,667 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,668 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4213ms
2014-07-14 02:12:47,668 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,668 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4238ms
2014-07-14 02:12:47,668 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,672 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4256ms
2014-07-14 02:12:47,672 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,673 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4263ms
2014-07-14 02:12:47,673 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,674 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4264ms
2014-07-14 02:12:47,674 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:47,674 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4276ms
2014-07-14 02:12:47,675 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:12:48,859 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:12:49,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:49,345 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:12:49,646 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35013 synced till here 34977
2014-07-14 02:12:49,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329162947 with entries=133, filesize=108.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329169145
2014-07-14 02:12:49,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329047695
2014-07-14 02:12:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329056526
2014-07-14 02:12:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329059376
2014-07-14 02:12:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329061175
2014-07-14 02:12:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329062906
2014-07-14 02:12:51,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:51,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35098 synced till here 35088
2014-07-14 02:12:51,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329169145 with entries=85, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329171420
2014-07-14 02:12:53,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:54,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35229 synced till here 35205
2014-07-14 02:12:54,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329171420 with entries=131, filesize=112.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329173248
2014-07-14 02:12:56,467 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:56,543 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35323 synced till here 35302
2014-07-14 02:12:56,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329173248 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329176467
2014-07-14 02:12:57,247 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8569, memsize=479.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4f501be8f3654e7d9a7969ff53484294
2014-07-14 02:12:57,262 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/4f501be8f3654e7d9a7969ff53484294 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f501be8f3654e7d9a7969ff53484294
2014-07-14 02:12:57,281 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f501be8f3654e7d9a7969ff53484294, entries=1747200, sequenceid=8569, filesize=124.4m
2014-07-14 02:12:57,282 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~860.7m/902478960, currentsize=474.6m/497691680 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 54668ms, sequenceid=8569, compaction requested=true
2014-07-14 02:12:57,282 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:55), split_queue=0, merge_queue=0
2014-07-14 02:12:57,282 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 826.9m
2014-07-14 02:12:57,547 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:12:58,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:12:58,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35400 synced till here 35396
2014-07-14 02:12:58,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329176467 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329178526
2014-07-14 02:12:58,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329064900
2014-07-14 02:12:58,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329074815
2014-07-14 02:12:58,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329076168
2014-07-14 02:12:58,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329077459
2014-07-14 02:12:58,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329078939
2014-07-14 02:12:58,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329080343
2014-07-14 02:12:58,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329081588
2014-07-14 02:12:58,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329082882
2014-07-14 02:12:59,338 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:00,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:00,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35507 synced till here 35489
2014-07-14 02:13:00,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329178526 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329180601
2014-07-14 02:13:03,264 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:03,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35581 synced till here 35579
2014-07-14 02:13:03,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329180601 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329183265
2014-07-14 02:13:04,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:04,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35698 synced till here 35697
2014-07-14 02:13:04,964 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329183265 with entries=117, filesize=100.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329184505
2014-07-14 02:13:06,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:06,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35774 synced till here 35773
2014-07-14 02:13:06,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329184505 with entries=76, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329186283
2014-07-14 02:13:07,699 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:07,723 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35847 synced till here 35846
2014-07-14 02:13:07,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329186283 with entries=73, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329187699
2014-07-14 02:13:09,689 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:09,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35929 synced till here 35921
2014-07-14 02:13:09,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329187699 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329189690
2014-07-14 02:13:10,024 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8749, memsize=315.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/5ba4342c7a5640438ac3196dec5e3b2a
2014-07-14 02:13:10,036 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/5ba4342c7a5640438ac3196dec5e3b2a as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5ba4342c7a5640438ac3196dec5e3b2a
2014-07-14 02:13:10,083 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5ba4342c7a5640438ac3196dec5e3b2a, entries=1147540, sequenceid=8749, filesize=81.7m
2014-07-14 02:13:10,085 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~906.5m/950482720, currentsize=404.4m/424013200 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 22473ms, sequenceid=8749, compaction requested=true
2014-07-14 02:13:10,085 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:56), split_queue=0, merge_queue=0
2014-07-14 02:13:10,086 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 847.0m
2014-07-14 02:13:10,093 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:13:10,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:10,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36009 synced till here 36003
2014-07-14 02:13:11,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329189690 with entries=80, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329190919
2014-07-14 02:13:11,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329084358
2014-07-14 02:13:11,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329089885
2014-07-14 02:13:11,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329090809
2014-07-14 02:13:11,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329092941
2014-07-14 02:13:11,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329094787
2014-07-14 02:13:11,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329096345
2014-07-14 02:13:11,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329098339
2014-07-14 02:13:11,362 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:12,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:12,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36087 synced till here 36083
2014-07-14 02:13:12,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329190919 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329192150
2014-07-14 02:13:13,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:13,653 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36179 synced till here 36176
2014-07-14 02:13:13,678 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329192150 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329193410
2014-07-14 02:13:14,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:14,948 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8878, memsize=272.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9df395f96931448b9c44ec84eff560bc
2014-07-14 02:13:15,006 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36260 synced till here 36253
2014-07-14 02:13:15,048 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9df395f96931448b9c44ec84eff560bc as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9df395f96931448b9c44ec84eff560bc
2014-07-14 02:13:15,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329193410 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329194928
2014-07-14 02:13:15,103 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9df395f96931448b9c44ec84eff560bc, entries=991070, sequenceid=8878, filesize=70.5m
2014-07-14 02:13:15,103 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~869.2m/911380240, currentsize=323.9m/339616240 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 17821ms, sequenceid=8878, compaction requested=true
2014-07-14 02:13:15,104 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-14 02:13:15,104 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 803.1m
2014-07-14 02:13:15,142 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:13:16,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:16,127 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:16,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36346 synced till here 36344
2014-07-14 02:13:16,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329194928 with entries=86, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329196084
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329099766
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329101306
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329103672
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329105051
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329106542
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329108226
2014-07-14 02:13:16,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329109808
2014-07-14 02:13:17,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:17,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36418 synced till here 36417
2014-07-14 02:13:17,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329196084 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329197538
2014-07-14 02:13:19,157 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:19,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36504 synced till here 36491
2014-07-14 02:13:19,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329197538 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329199157
2014-07-14 02:13:20,743 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:20,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329199157 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329200743
2014-07-14 02:13:22,767 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:22,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36655 synced till here 36651
2014-07-14 02:13:22,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329200743 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329202768
2014-07-14 02:13:23,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:24,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36728 synced till here 36727
2014-07-14 02:13:24,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329202768 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329203866
2014-07-14 02:13:24,381 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9016, memsize=226.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/e61b82f2ae5140a4a5a63e3f893df5f5
2014-07-14 02:13:24,395 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/e61b82f2ae5140a4a5a63e3f893df5f5 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e61b82f2ae5140a4a5a63e3f893df5f5
2014-07-14 02:13:24,717 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e61b82f2ae5140a4a5a63e3f893df5f5, entries=825350, sequenceid=9016, filesize=58.8m
2014-07-14 02:13:24,717 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~850.2m/891473040, currentsize=311.6m/326714720 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 14631ms, sequenceid=9016, compaction requested=true
2014-07-14 02:13:24,718 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-14 02:13:24,718 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 719.9m
2014-07-14 02:13:24,743 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:13:25,171 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:25,751 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36812 synced till here 36802
2014-07-14 02:13:25,797 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:25,856 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329203866 with entries=84, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329205172
2014-07-14 02:13:25,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329111293
2014-07-14 02:13:25,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329116403
2014-07-14 02:13:25,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329118623
2014-07-14 02:13:26,744 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:26,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36886 synced till here 36885
2014-07-14 02:13:26,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329205172 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329206745
2014-07-14 02:13:28,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:28,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36983 synced till here 36980
2014-07-14 02:13:28,840 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329206745 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329208036
2014-07-14 02:13:29,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:30,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37070 synced till here 37069
2014-07-14 02:13:30,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329208036 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329209659
2014-07-14 02:13:31,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:31,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37143 synced till here 37142
2014-07-14 02:13:31,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329209659 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329211543
2014-07-14 02:13:32,330 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9094, memsize=341.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0ee42f82cc7c42cbb9f3a847f3c21321
2014-07-14 02:13:32,345 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0ee42f82cc7c42cbb9f3a847f3c21321 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0ee42f82cc7c42cbb9f3a847f3c21321
2014-07-14 02:13:32,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:32,357 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0ee42f82cc7c42cbb9f3a847f3c21321, entries=1243460, sequenceid=9094, filesize=88.5m
2014-07-14 02:13:32,357 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~806.2m/845326960, currentsize=365.9m/383676080 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 17253ms, sequenceid=9094, compaction requested=true
2014-07-14 02:13:32,357 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:13:32,358 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-14 02:13:32,358 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 692.9m
2014-07-14 02:13:32,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37223 synced till here 37215
2014-07-14 02:13:33,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329211543 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329212353
2014-07-14 02:13:33,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329121728
2014-07-14 02:13:33,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329123759
2014-07-14 02:13:33,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329126318
2014-07-14 02:13:33,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329128544
2014-07-14 02:13:33,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329131893
2014-07-14 02:13:33,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329134045
2014-07-14 02:13:33,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329158207
2014-07-14 02:13:33,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329159694
2014-07-14 02:13:33,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329161693
2014-07-14 02:13:33,662 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:34,313 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:34,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37299 synced till here 37297
2014-07-14 02:13:34,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329212353 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329214313
2014-07-14 02:13:36,267 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:36,863 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37394 synced till here 37391
2014-07-14 02:13:37,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329214313 with entries=95, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329216267
2014-07-14 02:13:38,552 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:38,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37476 synced till here 37468
2014-07-14 02:13:38,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329216267 with entries=82, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329218553
2014-07-14 02:13:40,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:40,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37570 synced till here 37548
2014-07-14 02:13:40,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329218553 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329220318
2014-07-14 02:13:40,728 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f2286dd7c71f420cb684b8468134e246 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2286dd7c71f420cb684b8468134e246
2014-07-14 02:13:41,965 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:13:41,978 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/97fa454f858a4a18817ab0466674b2d4, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/97fa454f858a4a18817ab0466674b2d4
2014-07-14 02:13:41,982 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f270f0cdd3a24b449034b5016c775bcd, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f270f0cdd3a24b449034b5016c775bcd
2014-07-14 02:13:41,990 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4c8bfaabed5343e3bd1a4ac29dc91782, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4c8bfaabed5343e3bd1a4ac29dc91782
2014-07-14 02:13:42,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:42,109 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/7380d04a7836426ca2f4bb769e13433c, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/7380d04a7836426ca2f4bb769e13433c
2014-07-14 02:13:42,113 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f69dc177837347d9b73cfc47f63dfdbc, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f69dc177837347d9b73cfc47f63dfdbc
2014-07-14 02:13:42,119 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bab7eb2fe6224cdb9f451f7155579d95, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bab7eb2fe6224cdb9f451f7155579d95
2014-07-14 02:13:42,122 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/82b9297fe900465ea20ab2d91a34abc6, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/82b9297fe900465ea20ab2d91a34abc6
2014-07-14 02:13:42,123 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37666 synced till here 37644
2014-07-14 02:13:42,126 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/14c90f2fe5054c319ef80f944f122c1a, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/14c90f2fe5054c319ef80f944f122c1a
2014-07-14 02:13:42,129 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dfb399115a242638c20e69cb08ff176, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dfb399115a242638c20e69cb08ff176
2014-07-14 02:13:42,133 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/8aac1059c5114d44b08d0dffd3bbb23a, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/8aac1059c5114d44b08d0dffd3bbb23a
2014-07-14 02:13:42,133 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into f2286dd7c71f420cb684b8468134e246(size=834.2m), total size for store is 1.7g. This selection was in queue for 0sec, and took 3mins, 29sec to execute.
2014-07-14 02:13:42,133 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=10, fileSize=879.0m, priority=7, time=282919798064429; duration=3mins, 29sec
2014-07-14 02:13:42,133 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-14 02:13:42,134 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-14 02:13:42,136 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1018175753 starting at candidate #1 after considering 68 permutations with 66 in ratio
2014-07-14 02:13:42,136 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:13:42,136 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:13:42,136 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=971.0m
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e2e37f1b006e42d2ada44f9fdac56a64, keycount=140921, bloomtype=ROW, size=100.3m, encoding=NONE, seqNum=2691
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dc979f94794147adbccedd047ed17d29, keycount=101808, bloomtype=ROW, size=72.5m, encoding=NONE, seqNum=3186
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/59bde93aa3b24fa59ebcb5bf1cb57782, keycount=213974, bloomtype=ROW, size=152.2m, encoding=NONE, seqNum=3583
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b347ee2dde374f18b716f807d2e615f9, keycount=98757, bloomtype=ROW, size=70.4m, encoding=NONE, seqNum=4174
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5b05322354b347e69ef61b4e4a28721f, keycount=150624, bloomtype=ROW, size=107.3m, encoding=NONE, seqNum=4514
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/16f58ada12c3461c93be81c4060b1af1, keycount=216799, bloomtype=ROW, size=154.3m, encoding=NONE, seqNum=4986
2014-07-14 02:13:42,137 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c62bcd219ae24744b6c4f6364c9191aa, keycount=73075, bloomtype=ROW, size=52.1m, encoding=NONE, seqNum=5576
2014-07-14 02:13:42,138 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6ad2a953d2794db0b2409755b4e0132d, keycount=147720, bloomtype=ROW, size=105.2m, encoding=NONE, seqNum=5904
2014-07-14 02:13:42,138 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6f044d0a0b8c4dd6851b21e2b6c9a365, keycount=115996, bloomtype=ROW, size=82.6m, encoding=NONE, seqNum=6524
2014-07-14 02:13:42,138 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/631116a979a54383992799e7b4a9860c, keycount=104242, bloomtype=ROW, size=74.2m, encoding=NONE, seqNum=7020
2014-07-14 02:13:42,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329220318 with entries=96, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329222015
2014-07-14 02:13:43,597 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:43,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:43,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37763 synced till here 37747
2014-07-14 02:13:44,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329222015 with entries=97, filesize=83.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329223957
2014-07-14 02:13:46,144 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:46,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37867 synced till here 37844
2014-07-14 02:13:46,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329223957 with entries=104, filesize=88.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329226144
2014-07-14 02:13:49,400 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1028ms
GC pool 'ParNew' had collection(s): count=1 time=1104ms
2014-07-14 02:13:49,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:49,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37977 synced till here 37949
2014-07-14 02:13:49,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329226144 with entries=110, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329229462
2014-07-14 02:13:51,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:51,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38087 synced till here 38057
2014-07-14 02:13:52,055 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9216, memsize=451.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/a8a4bc0d17ba428e886ff1909b2cab2d
2014-07-14 02:13:52,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329229462 with entries=110, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329231789
2014-07-14 02:13:52,091 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/a8a4bc0d17ba428e886ff1909b2cab2d as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/a8a4bc0d17ba428e886ff1909b2cab2d
2014-07-14 02:13:52,161 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/a8a4bc0d17ba428e886ff1909b2cab2d, entries=1642410, sequenceid=9216, filesize=117.0m
2014-07-14 02:13:52,165 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~724.7m/759875440, currentsize=506.9m/531489440 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 27447ms, sequenceid=9216, compaction requested=true
2014-07-14 02:13:52,165 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-14 02:13:52,165 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 800.8m
2014-07-14 02:13:53,712 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:13:54,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:54,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38187 synced till here 38158
2014-07-14 02:13:54,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329231789 with entries=100, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329234284
2014-07-14 02:13:54,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329162947
2014-07-14 02:13:54,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329169145
2014-07-14 02:13:54,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329171420
2014-07-14 02:13:54,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329173248
2014-07-14 02:13:54,773 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:13:56,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:13:57,933 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1039ms
GC pool 'ParNew' had collection(s): count=1 time=1161ms
2014-07-14 02:13:57,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38303 synced till here 38276
2014-07-14 02:13:58,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329234284 with entries=116, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329236697
2014-07-14 02:14:00,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:00,135 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38420 synced till here 38385
2014-07-14 02:14:00,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329236697 with entries=117, filesize=99.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329240112
2014-07-14 02:14:02,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:02,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38527 synced till here 38492
2014-07-14 02:14:04,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329240112 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329242682
2014-07-14 02:14:05,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:06,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38649 synced till here 38626
2014-07-14 02:14:06,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329242682 with entries=122, filesize=104.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329245595
2014-07-14 02:14:07,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:08,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38749 synced till here 38721
2014-07-14 02:14:08,284 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,290 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,290 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,290 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,291 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,291 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,291 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,292 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,293 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,294 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,295 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,296 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,298 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,298 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,300 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,303 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,303 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,303 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,304 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,304 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,304 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,311 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329245595 with entries=100, filesize=85.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329247333
2014-07-14 02:14:08,355 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,375 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,375 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,376 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,377 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,378 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,378 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,406 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,561 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,591 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,622 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,649 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,679 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,707 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,735 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:08,763 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:11,199 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9328, memsize=615.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/5dad233ef821430482a41291d899aca6
2014-07-14 02:14:11,215 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/5dad233ef821430482a41291d899aca6 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dad233ef821430482a41291d899aca6
2014-07-14 02:14:11,229 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dad233ef821430482a41291d899aca6, entries=2240460, sequenceid=9328, filesize=159.5m
2014-07-14 02:14:11,230 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~697.6m/731455120, currentsize=610.6m/640304240 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 38872ms, sequenceid=9328, compaction requested=true
2014-07-14 02:14:11,230 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-14 02:14:11,230 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2467ms
2014-07-14 02:14:11,230 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,230 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 975.2m
2014-07-14 02:14:11,230 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2495ms
2014-07-14 02:14:11,230 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,231 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2524ms
2014-07-14 02:14:11,231 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,231 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2552ms
2014-07-14 02:14:11,231 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,231 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2582ms
2014-07-14 02:14:11,232 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,232 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2610ms
2014-07-14 02:14:11,232 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,232 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2642ms
2014-07-14 02:14:11,232 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,232 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2671ms
2014-07-14 02:14:11,232 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,233 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2827ms
2014-07-14 02:14:11,233 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,233 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2855ms
2014-07-14 02:14:11,233 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,242 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2865ms
2014-07-14 02:14:11,242 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,242 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2867ms
2014-07-14 02:14:11,242 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,243 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2866ms
2014-07-14 02:14:11,243 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,244 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2869ms
2014-07-14 02:14:11,245 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,245 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2871ms
2014-07-14 02:14:11,245 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,257 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2903ms
2014-07-14 02:14:11,257 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,257 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2946ms
2014-07-14 02:14:11,257 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,257 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2961ms
2014-07-14 02:14:11,257 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,261 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2964ms
2014-07-14 02:14:11,261 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,269 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2975ms
2014-07-14 02:14:11,269 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,269 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2975ms
2014-07-14 02:14:11,269 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2983ms
2014-07-14 02:14:11,277 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,285 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2982ms
2014-07-14 02:14:11,285 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,289 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2989ms
2014-07-14 02:14:11,289 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,290 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2991ms
2014-07-14 02:14:11,290 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,290 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2993ms
2014-07-14 02:14:11,290 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,290 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2994ms
2014-07-14 02:14:11,291 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,296 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3003ms
2014-07-14 02:14:11,296 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,296 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3002ms
2014-07-14 02:14:11,296 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,297 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3010ms
2014-07-14 02:14:11,297 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,297 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3005ms
2014-07-14 02:14:11,297 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,305 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3017ms
2014-07-14 02:14:11,305 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,305 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3017ms
2014-07-14 02:14:11,305 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,305 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3017ms
2014-07-14 02:14:11,305 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,306 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3018ms
2014-07-14 02:14:11,306 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,313 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3024ms
2014-07-14 02:14:11,313 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,313 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3024ms
2014-07-14 02:14:11,313 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:11,313 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3029ms
2014-07-14 02:14:11,313 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:12,243 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:14:12,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:12,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38828 synced till here 38821
2014-07-14 02:14:12,505 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329247333 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329252435
2014-07-14 02:14:12,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329176467
2014-07-14 02:14:12,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329178526
2014-07-14 02:14:12,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329180601
2014-07-14 02:14:12,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329183265
2014-07-14 02:14:12,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329184505
2014-07-14 02:14:12,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329186283
2014-07-14 02:14:12,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329187699
2014-07-14 02:14:12,619 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:14:14,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:15,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329252435 with entries=96, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329254882
2014-07-14 02:14:16,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:16,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39013 synced till here 39011
2014-07-14 02:14:16,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329254882 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329256464
2014-07-14 02:14:17,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:18,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329256464 with entries=96, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329257808
2014-07-14 02:14:19,494 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,502 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,517 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,520 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,531 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,552 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,599 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,669 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,709 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,742 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,781 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,829 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,893 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:19,936 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,581 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,589 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,601 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,628 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,657 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,692 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,738 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,774 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,803 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,834 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,861 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:20,890 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,526 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,557 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,586 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,619 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,648 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,677 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,708 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,738 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,767 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,796 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,826 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,857 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,888 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,916 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,945 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:21,975 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,004 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,033 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,065 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,094 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,122 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:22,153 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:24,484 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:24,495 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,498 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:24,502 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,517 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,520 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,532 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,552 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,599 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,669 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,709 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,742 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:24,782 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,830 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,893 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:24,936 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:25,578 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9551, memsize=602.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cbb009e34d5442b68028b2231f907367
2014-07-14 02:14:25,582 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:25,589 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:25,593 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cbb009e34d5442b68028b2231f907367 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cbb009e34d5442b68028b2231f907367
2014-07-14 02:14:25,601 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:14:25,609 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cbb009e34d5442b68028b2231f907367, entries=2194210, sequenceid=9551, filesize=156.2m
2014-07-14 02:14:25,610 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~828.9m/869187440, currentsize=423.2m/443716320 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 33445ms, sequenceid=9551, compaction requested=true
2014-07-14 02:14:25,610 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-14 02:14:25,610 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5009ms
2014-07-14 02:14:25,610 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,610 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-14 02:14:25,610 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,610 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 931.4m
2014-07-14 02:14:25,610 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5029ms
2014-07-14 02:14:25,611 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,611 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5675ms
2014-07-14 02:14:25,611 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,611 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5719ms
2014-07-14 02:14:25,611 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,617 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5788ms
2014-07-14 02:14:25,617 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,617 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5836ms
2014-07-14 02:14:25,617 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,617 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5875ms
2014-07-14 02:14:25,617 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,617 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5908ms
2014-07-14 02:14:25,617 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,624 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5955ms
2014-07-14 02:14:25,624 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,624 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6026ms
2014-07-14 02:14:25,624 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,625 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6073ms
2014-07-14 02:14:25,625 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,625 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6094ms
2014-07-14 02:14:25,625 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,629 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:14:25,630 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,631 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6111ms
2014-07-14 02:14:25,631 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,637 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6121ms
2014-07-14 02:14:25,637 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,641 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6139ms
2014-07-14 02:14:25,641 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,644 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1146ms
2014-07-14 02:14:25,644 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,644 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6150ms
2014-07-14 02:14:25,644 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,644 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1160ms
2014-07-14 02:14:25,645 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,645 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3493ms
2014-07-14 02:14:25,645 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,645 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3523ms
2014-07-14 02:14:25,645 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,646 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3552ms
2014-07-14 02:14:25,657 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,657 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3592ms
2014-07-14 02:14:25,657 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,657 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3624ms
2014-07-14 02:14:25,658 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,658 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3654ms
2014-07-14 02:14:25,658 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,658 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3683ms
2014-07-14 02:14:25,658 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,658 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3713ms
2014-07-14 02:14:25,658 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,658 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3742ms
2014-07-14 02:14:25,658 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,660 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3773ms
2014-07-14 02:14:25,660 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,662 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3804ms
2014-07-14 02:14:25,662 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,662 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3836ms
2014-07-14 02:14:25,662 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,663 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3867ms
2014-07-14 02:14:25,663 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,664 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3896ms
2014-07-14 02:14:25,664 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,664 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3926ms
2014-07-14 02:14:25,664 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,664 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3956ms
2014-07-14 02:14:25,664 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,664 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3987ms
2014-07-14 02:14:25,664 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,666 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4017ms
2014-07-14 02:14:25,666 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,666 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4047ms
2014-07-14 02:14:25,666 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,669 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4083ms
2014-07-14 02:14:25,669 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,669 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4112ms
2014-07-14 02:14:25,669 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,676 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4149ms
2014-07-14 02:14:25,678 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,679 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4788ms
2014-07-14 02:14:25,679 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,680 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4818ms
2014-07-14 02:14:25,680 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,680 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4846ms
2014-07-14 02:14:25,680 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,682 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4878ms
2014-07-14 02:14:25,682 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,682 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4908ms
2014-07-14 02:14:25,682 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,683 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4945ms
2014-07-14 02:14:25,683 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,683 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4991ms
2014-07-14 02:14:25,683 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,684 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5026ms
2014-07-14 02:14:25,684 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:25,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:25,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39229 synced till here 39187
2014-07-14 02:14:26,192 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:14:26,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329257808 with entries=120, filesize=98.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329265740
2014-07-14 02:14:26,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329189690
2014-07-14 02:14:26,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329190919
2014-07-14 02:14:26,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329192150
2014-07-14 02:14:26,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329193410
2014-07-14 02:14:27,992 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:14:28,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:28,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39342 synced till here 39308
2014-07-14 02:14:29,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329265740 with entries=113, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329268558
2014-07-14 02:14:30,077 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10188,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259889,"queuetimems":1,"class":"HRegionServer","responsesize":15764,"method":"Multi"}
2014-07-14 02:14:30,078 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10482,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259595,"queuetimems":0,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:14:30,093 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259825,"queuetimems":1,"class":"HRegionServer","responsesize":15861,"method":"Multi"}
2014-07-14 02:14:30,094 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259706,"queuetimems":1,"class":"HRegionServer","responsesize":15340,"method":"Multi"}
2014-07-14 02:14:30,096 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259665,"queuetimems":0,"class":"HRegionServer","responsesize":16342,"method":"Multi"}
2014-07-14 02:14:30,096 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10357,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259739,"queuetimems":0,"class":"HRegionServer","responsesize":15428,"method":"Multi"}
2014-07-14 02:14:30,098 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10570,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259528,"queuetimems":1,"class":"HRegionServer","responsesize":15869,"method":"Multi"}
2014-07-14 02:14:30,118 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329259775,"queuetimems":1,"class":"HRegionServer","responsesize":15780,"method":"Multi"}
2014-07-14 02:14:30,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:30,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39451 synced till here 39439
2014-07-14 02:14:31,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329268558 with entries=109, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329270617
2014-07-14 02:14:33,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:33,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39577 synced till here 39552
2014-07-14 02:14:33,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329270617 with entries=126, filesize=102.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329273604
2014-07-14 02:14:35,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:35,462 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39674 synced till here 39658
2014-07-14 02:14:35,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329273604 with entries=97, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329275415
2014-07-14 02:14:37,406 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,407 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,407 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,407 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,408 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,408 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,410 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,410 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,413 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,414 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,415 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,418 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:37,529 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,529 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,530 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,530 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,532 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,533 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,533 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,533 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,533 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,533 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,534 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:14:37,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329275415 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329277517
2014-07-14 02:14:38,117 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9723, memsize=469.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/e7d09c7f7a754c2e8f9186b30e27708d
2014-07-14 02:14:38,130 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/e7d09c7f7a754c2e8f9186b30e27708d as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e7d09c7f7a754c2e8f9186b30e27708d
2014-07-14 02:14:38,142 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e7d09c7f7a754c2e8f9186b30e27708d, entries=1707910, sequenceid=9723, filesize=121.7m
2014-07-14 02:14:38,142 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~975.2m/1022616880, currentsize=383.1m/401741040 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 26912ms, sequenceid=9723, compaction requested=true
2014-07-14 02:14:38,142 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:62), split_queue=0, merge_queue=0
2014-07-14 02:14:38,142 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 609ms
2014-07-14 02:14:38,142 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,142 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 609ms
2014-07-14 02:14:38,142 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 982.2m
2014-07-14 02:14:38,142 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,143 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 610ms
2014-07-14 02:14:38,143 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,143 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 610ms
2014-07-14 02:14:38,143 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,145 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 612ms
2014-07-14 02:14:38,145 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,145 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 612ms
2014-07-14 02:14:38,145 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,145 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 613ms
2014-07-14 02:14:38,145 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,149 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 619ms
2014-07-14 02:14:38,149 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,149 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 620ms
2014-07-14 02:14:38,149 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,150 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 621ms
2014-07-14 02:14:38,150 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,152 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 623ms
2014-07-14 02:14:38,152 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,152 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 735ms
2014-07-14 02:14:38,152 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,152 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 737ms
2014-07-14 02:14:38,152 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,152 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 738ms
2014-07-14 02:14:38,152 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,173 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 760ms
2014-07-14 02:14:38,173 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,173 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 763ms
2014-07-14 02:14:38,173 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,177 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 767ms
2014-07-14 02:14:38,177 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,177 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 769ms
2014-07-14 02:14:38,177 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,177 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 770ms
2014-07-14 02:14:38,177 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,177 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 770ms
2014-07-14 02:14:38,177 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,177 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 770ms
2014-07-14 02:14:38,178 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,180 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 773ms
2014-07-14 02:14:38,180 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,180 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 774ms
2014-07-14 02:14:38,180 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:14:38,945 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:14:39,603 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:14:40,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:40,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39830 synced till here 39827
2014-07-14 02:14:40,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329277517 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329280253
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329194928
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329196084
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329197538
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329199157
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329200743
2014-07-14 02:14:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329202768
2014-07-14 02:14:41,624 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:41,676 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329280253 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329281625
2014-07-14 02:14:42,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:42,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39975 synced till here 39974
2014-07-14 02:14:42,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329281625 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329282360
2014-07-14 02:14:44,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:44,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329282360 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329284542
2014-07-14 02:14:47,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:47,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329284542 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329287093
2014-07-14 02:14:49,174 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9818, memsize=369.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/b6ea7c73b401438693fe546ee4433061
2014-07-14 02:14:49,193 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/b6ea7c73b401438693fe546ee4433061 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b6ea7c73b401438693fe546ee4433061
2014-07-14 02:14:49,204 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b6ea7c73b401438693fe546ee4433061, entries=1345840, sequenceid=9818, filesize=95.8m
2014-07-14 02:14:49,204 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~931.4m/976655680, currentsize=383.1m/401737200 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 23594ms, sequenceid=9818, compaction requested=true
2014-07-14 02:14:49,204 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:63), split_queue=0, merge_queue=0
2014-07-14 02:14:49,205 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 802.1m
2014-07-14 02:14:49,557 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:14:49,879 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:14:50,851 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:50,886 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329287093 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329290852
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329203866
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329205172
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329206745
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329208036
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329209659
2014-07-14 02:14:50,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329211543
2014-07-14 02:14:51,097 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9969, memsize=243.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/0b53a10e6828412f839d190363f92d9a
2014-07-14 02:14:51,113 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/0b53a10e6828412f839d190363f92d9a as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/0b53a10e6828412f839d190363f92d9a
2014-07-14 02:14:51,131 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/0b53a10e6828412f839d190363f92d9a, entries=886360, sequenceid=9969, filesize=63.1m
2014-07-14 02:14:51,132 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~982.2m/1029944720, currentsize=169.3m/177491120 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 12990ms, sequenceid=9969, compaction requested=true
2014-07-14 02:14:51,132 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:64), split_queue=0, merge_queue=0
2014-07-14 02:14:51,132 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 541.9m
2014-07-14 02:14:51,630 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:14:52,336 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:52,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40271 synced till here 40265
2014-07-14 02:14:52,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329290852 with entries=80, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329292337
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329212353
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329214313
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329216267
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329218553
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329220318
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329222015
2014-07-14 02:14:52,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329223957
2014-07-14 02:14:52,444 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329226144
2014-07-14 02:14:52,444 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329229462
2014-07-14 02:14:55,300 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:55,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40344 synced till here 40343
2014-07-14 02:14:55,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329292337 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329295300
2014-07-14 02:14:57,433 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:14:57,642 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:14:57,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329295300 with entries=111, filesize=95.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329297433
2014-07-14 02:15:02,153 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10074, memsize=273.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/fcc8b80a576b43c8a2386fccd7c6ec8e
2014-07-14 02:15:02,171 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/fcc8b80a576b43c8a2386fccd7c6ec8e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fcc8b80a576b43c8a2386fccd7c6ec8e
2014-07-14 02:15:02,183 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fcc8b80a576b43c8a2386fccd7c6ec8e, entries=996110, sequenceid=10074, filesize=70.9m
2014-07-14 02:15:02,183 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~808.4m/847648400, currentsize=132.4m/138879920 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 12978ms, sequenceid=10074, compaction requested=true
2014-07-14 02:15:02,183 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:65), split_queue=0, merge_queue=0
2014-07-14 02:15:02,183 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 515.0m
2014-07-14 02:15:02,529 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:02,593 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10080, memsize=290.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f8e36cd8a367406da52207db5f07f9ea
2014-07-14 02:15:02,616 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f8e36cd8a367406da52207db5f07f9ea as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8e36cd8a367406da52207db5f07f9ea
2014-07-14 02:15:02,638 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8e36cd8a367406da52207db5f07f9ea, entries=1058240, sequenceid=10080, filesize=75.3m
2014-07-14 02:15:02,638 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~543.5m/569882000, currentsize=114.6m/120130080 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 11506ms, sequenceid=10080, compaction requested=true
2014-07-14 02:15:02,638 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:66), split_queue=0, merge_queue=0
2014-07-14 02:15:02,639 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 286.4m
2014-07-14 02:15:02,790 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:03,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:03,400 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40531 synced till here 40529
2014-07-14 02:15:03,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329297433 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329303350
2014-07-14 02:15:03,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329231789
2014-07-14 02:15:03,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329234284
2014-07-14 02:15:03,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329236697
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329240112
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329242682
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329245595
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329247333
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329252435
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329254882
2014-07-14 02:15:03,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329256464
2014-07-14 02:15:10,991 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10155, memsize=272.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bd86a997b7074b059450823eb354c8b2
2014-07-14 02:15:11,003 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bd86a997b7074b059450823eb354c8b2 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bd86a997b7074b059450823eb354c8b2
2014-07-14 02:15:11,014 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bd86a997b7074b059450823eb354c8b2, entries=992190, sequenceid=10155, filesize=70.6m
2014-07-14 02:15:11,015 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~286.4m/300354480, currentsize=24.9m/26112640 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 8376ms, sequenceid=10155, compaction requested=true
2014-07-14 02:15:11,015 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-14 02:15:12,156 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10151, memsize=274.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/941c29429a8f4d5899a3f92610bd9827
2014-07-14 02:15:12,171 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/941c29429a8f4d5899a3f92610bd9827 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/941c29429a8f4d5899a3f92610bd9827
2014-07-14 02:15:12,194 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/941c29429a8f4d5899a3f92610bd9827, entries=1000500, sequenceid=10151, filesize=71.2m
2014-07-14 02:15:12,194 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~515.0m/540051120, currentsize=25.0m/26163440 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 10011ms, sequenceid=10151, compaction requested=true
2014-07-14 02:15:12,194 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:68), split_queue=0, merge_queue=0
2014-07-14 02:15:12,722 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:12,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40605 synced till here 40602
2014-07-14 02:15:12,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329303350 with entries=74, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329312722
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329257808
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329265740
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329268558
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329270617
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329273604
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329275415
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329277517
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329280253
2014-07-14 02:15:12,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329281625
2014-07-14 02:15:12,758 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329282360
2014-07-14 02:15:12,758 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329284542
2014-07-14 02:15:16,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:16,724 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329312722 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329316694
2014-07-14 02:15:25,457 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:25,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329316694 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329325457
2014-07-14 02:15:29,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:29,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329325457 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329329095
2014-07-14 02:15:37,866 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:15:37,867 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 257.1m
2014-07-14 02:15:38,015 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:38,600 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:15:38,600 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 257.3m
2014-07-14 02:15:38,762 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:38,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:38,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40895 synced till here 40894
2014-07-14 02:15:38,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329329095 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329338898
2014-07-14 02:15:42,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:42,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329338898 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329342186
2014-07-14 02:15:45,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:45,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41041 synced till here 41040
2014-07-14 02:15:45,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329342186 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329345055
2014-07-14 02:15:46,083 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10240, memsize=255.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/9318d558c77d4434820c0a5e300e100c
2014-07-14 02:15:46,096 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/9318d558c77d4434820c0a5e300e100c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9318d558c77d4434820c0a5e300e100c
2014-07-14 02:15:46,106 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9318d558c77d4434820c0a5e300e100c, entries=930400, sequenceid=10240, filesize=66.2m
2014-07-14 02:15:46,106 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.1m/269561600, currentsize=101.1m/106003280 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 8240ms, sequenceid=10240, compaction requested=true
2014-07-14 02:15:46,107 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:69), split_queue=0, merge_queue=0
2014-07-14 02:15:46,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:46,241 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329345055 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329346218
2014-07-14 02:15:46,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329287093
2014-07-14 02:15:46,809 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10247, memsize=255.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/7c27c463683641ffac247eab70f72b3d
2014-07-14 02:15:46,828 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/7c27c463683641ffac247eab70f72b3d as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/7c27c463683641ffac247eab70f72b3d
2014-07-14 02:15:46,837 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/7c27c463683641ffac247eab70f72b3d, entries=931040, sequenceid=10247, filesize=66.3m
2014-07-14 02:15:46,838 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269811680, currentsize=99.8m/104679200 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 8238ms, sequenceid=10247, compaction requested=true
2014-07-14 02:15:46,838 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:70), split_queue=0, merge_queue=0
2014-07-14 02:15:47,165 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:15:47,165 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 256.4m
2014-07-14 02:15:47,227 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:15:47,227 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 256.5m
2014-07-14 02:15:47,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:47,363 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:47,425 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:15:47,545 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41190 synced till here 41186
2014-07-14 02:15:47,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329346218 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329347317
2014-07-14 02:15:47,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329290852
2014-07-14 02:15:47,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329292337
2014-07-14 02:15:47,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329295300
2014-07-14 02:15:52,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:15:52,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41262 synced till here 41261
2014-07-14 02:15:52,219 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329347317 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329352193
2014-07-14 02:15:55,935 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10322, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/50eff9f83b3f4826877b625d942718c1
2014-07-14 02:15:55,937 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10318, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6e28b13211a545909f02f50365a01407
2014-07-14 02:15:55,957 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/50eff9f83b3f4826877b625d942718c1 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/50eff9f83b3f4826877b625d942718c1
2014-07-14 02:15:55,958 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/6e28b13211a545909f02f50365a01407 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6e28b13211a545909f02f50365a01407
2014-07-14 02:15:55,976 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/50eff9f83b3f4826877b625d942718c1, entries=939100, sequenceid=10322, filesize=66.9m
2014-07-14 02:15:55,976 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.9m/270453440, currentsize=52.9m/55485040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 8811ms, sequenceid=10322, compaction requested=true
2014-07-14 02:15:55,976 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-14 02:15:55,977 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6e28b13211a545909f02f50365a01407, entries=939380, sequenceid=10318, filesize=66.9m
2014-07-14 02:15:55,978 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270532480, currentsize=52.8m/55377680 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 8751ms, sequenceid=10318, compaction requested=true
2014-07-14 02:15:55,978 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:72), split_queue=0, merge_queue=0
2014-07-14 02:16:01,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:01,113 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41336 synced till here 41335
2014-07-14 02:16:01,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329352193 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329361092
2014-07-14 02:16:01,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329297433
2014-07-14 02:16:01,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329303350
2014-07-14 02:16:01,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329312722
2014-07-14 02:16:01,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329316694
2014-07-14 02:16:01,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329325457
2014-07-14 02:16:03,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:03,143 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329361092 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329363095
2014-07-14 02:16:07,855 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:07,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41485 synced till here 41482
2014-07-14 02:16:07,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329363095 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329367856
2014-07-14 02:16:08,442 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:16:08,443 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 257.4m
2014-07-14 02:16:08,579 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:09,383 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:16:09,383 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 257.3m
2014-07-14 02:16:09,521 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:10,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:10,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329367856 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329370142
2014-07-14 02:16:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.56 MB, free=3.95 GB, max=3.96 GB, blocks=16, accesses=216938, hits=56826, hitRatio=26.19%, , cachingAccesses=56849, cachingHits=56803, cachingHitsRatio=99.91%, evictions=0, evicted=30, evictedPerRun=Infinity
2014-07-14 02:16:11,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:11,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41630 synced till here 41628
2014-07-14 02:16:11,249 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329370142 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329371196
2014-07-14 02:16:16,222 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10407, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/9635333aa663415299f6728c068adadd
2014-07-14 02:16:16,237 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/9635333aa663415299f6728c068adadd as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9635333aa663415299f6728c068adadd
2014-07-14 02:16:16,250 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9635333aa663415299f6728c068adadd, entries=937140, sequenceid=10407, filesize=66.7m
2014-07-14 02:16:16,251 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269887680, currentsize=69.7m/73094560 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 7808ms, sequenceid=10407, compaction requested=true
2014-07-14 02:16:16,251 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:73), split_queue=0, merge_queue=0
2014-07-14 02:16:16,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:16,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41705 synced till here 41704
2014-07-14 02:16:16,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329371196 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329376494
2014-07-14 02:16:17,134 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10413, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f5a28ac2aa5f4d8c9939e05cd962410c
2014-07-14 02:16:17,147 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f5a28ac2aa5f4d8c9939e05cd962410c as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f5a28ac2aa5f4d8c9939e05cd962410c
2014-07-14 02:16:17,576 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f5a28ac2aa5f4d8c9939e05cd962410c, entries=936680, sequenceid=10413, filesize=66.7m
2014-07-14 02:16:17,577 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269756640, currentsize=85.4m/89502080 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 8194ms, sequenceid=10413, compaction requested=true
2014-07-14 02:16:17,577 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-14 02:16:17,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:17,798 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41779 synced till here 41778
2014-07-14 02:16:17,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329376494 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329377781
2014-07-14 02:16:17,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329329095
2014-07-14 02:16:17,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329338898
2014-07-14 02:16:17,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329342186
2014-07-14 02:16:17,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329345055
2014-07-14 02:16:18,812 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:16:18,813 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 259.6m
2014-07-14 02:16:18,907 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:16:18,907 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 257.6m
2014-07-14 02:16:19,439 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:19,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:19,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41857 synced till here 41853
2014-07-14 02:16:19,544 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:19,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329377781 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329379469
2014-07-14 02:16:21,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:21,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41938 synced till here 41936
2014-07-14 02:16:21,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329379469 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329381542
2014-07-14 02:16:23,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:23,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42021 synced till here 42020
2014-07-14 02:16:23,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329381542 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329383234
2014-07-14 02:16:25,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:25,583 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42096 synced till here 42093
2014-07-14 02:16:25,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329383234 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329385563
2014-07-14 02:16:27,070 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:27,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42175 synced till here 42168
2014-07-14 02:16:27,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329385563 with entries=79, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329387071
2014-07-14 02:16:27,398 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:16:27,809 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:16:28,296 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/98106d908d2b428a9a37b4c8763a023b as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/98106d908d2b428a9a37b4c8763a023b
2014-07-14 02:16:28,326 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:16:28,343 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e2e37f1b006e42d2ada44f9fdac56a64, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e2e37f1b006e42d2ada44f9fdac56a64
2014-07-14 02:16:28,346 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dc979f94794147adbccedd047ed17d29, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/dc979f94794147adbccedd047ed17d29
2014-07-14 02:16:28,349 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/59bde93aa3b24fa59ebcb5bf1cb57782, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/59bde93aa3b24fa59ebcb5bf1cb57782
2014-07-14 02:16:28,352 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b347ee2dde374f18b716f807d2e615f9, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b347ee2dde374f18b716f807d2e615f9
2014-07-14 02:16:28,355 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5b05322354b347e69ef61b4e4a28721f, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5b05322354b347e69ef61b4e4a28721f
2014-07-14 02:16:28,358 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/16f58ada12c3461c93be81c4060b1af1, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/16f58ada12c3461c93be81c4060b1af1
2014-07-14 02:16:28,464 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c62bcd219ae24744b6c4f6364c9191aa, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c62bcd219ae24744b6c4f6364c9191aa
2014-07-14 02:16:28,469 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6ad2a953d2794db0b2409755b4e0132d, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6ad2a953d2794db0b2409755b4e0132d
2014-07-14 02:16:28,475 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6f044d0a0b8c4dd6851b21e2b6c9a365, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6f044d0a0b8c4dd6851b21e2b6c9a365
2014-07-14 02:16:28,481 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/631116a979a54383992799e7b4a9860c, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/631116a979a54383992799e7b4a9860c
2014-07-14 02:16:28,482 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into 98106d908d2b428a9a37b4c8763a023b(size=897.8m), total size for store is 2.0g. This selection was in queue for 0sec, and took 2mins, 46sec to execute.
2014-07-14 02:16:28,482 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=10, fileSize=971.0m, priority=6, time=283129563249016; duration=2mins, 46sec
2014-07-14 02:16:28,482 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-14 02:16:28,483 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-14 02:16:28,487 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1055359538 starting at candidate #6 after considering 84 permutations with 80 in ratio
2014-07-14 02:16:28,488 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating minor compaction
2014-07-14 02:16:28,488 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:16:28,488 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=1006.5m
2014-07-14 02:16:28,489 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ff4a0bc4e30241fcb5a4260a81847c2e, keycount=131326, bloomtype=ROW, size=93.5m, encoding=NONE, seqNum=6220
2014-07-14 02:16:28,489 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/402f8fa042bf46bf8c91d19f3c00245e, keycount=98551, bloomtype=ROW, size=70.2m, encoding=NONE, seqNum=6759
2014-07-14 02:16:28,489 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/71be01c5a5df4fe89e0e4681c4630708, keycount=182569, bloomtype=ROW, size=130.0m, encoding=NONE, seqNum=7227
2014-07-14 02:16:28,489 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/971edc57457c47ac995582fd0c144eea, keycount=260759, bloomtype=ROW, size=185.5m, encoding=NONE, seqNum=7861
2014-07-14 02:16:28,490 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/14195a276ddd45c09119b3fcf82b8b3e, keycount=152267, bloomtype=ROW, size=108.4m, encoding=NONE, seqNum=8463
2014-07-14 02:16:28,490 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e61b82f2ae5140a4a5a63e3f893df5f5, keycount=82535, bloomtype=ROW, size=58.8m, encoding=NONE, seqNum=9016
2014-07-14 02:16:28,490 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cbb009e34d5442b68028b2231f907367, keycount=219421, bloomtype=ROW, size=156.2m, encoding=NONE, seqNum=9551
2014-07-14 02:16:28,490 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fcc8b80a576b43c8a2386fccd7c6ec8e, keycount=99611, bloomtype=ROW, size=70.9m, encoding=NONE, seqNum=10074
2014-07-14 02:16:28,490 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9318d558c77d4434820c0a5e300e100c, keycount=93040, bloomtype=ROW, size=66.2m, encoding=NONE, seqNum=10240
2014-07-14 02:16:28,491 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9635333aa663415299f6728c068adadd, keycount=93714, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=10407
2014-07-14 02:16:29,271 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:29,483 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10490, memsize=259.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/73069c8e5473410eb0ca13af3d8768dd
2014-07-14 02:16:29,497 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/73069c8e5473410eb0ca13af3d8768dd as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/73069c8e5473410eb0ca13af3d8768dd
2014-07-14 02:16:29,510 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10486, memsize=259.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/21e1271c0b7f40aaa48f73d446f1331b
2014-07-14 02:16:29,527 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/73069c8e5473410eb0ca13af3d8768dd, entries=945080, sequenceid=10490, filesize=67.3m
2014-07-14 02:16:29,528 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.6m/272175600, currentsize=153.1m/160526160 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 10715ms, sequenceid=10490, compaction requested=true
2014-07-14 02:16:29,528 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-14 02:16:29,528 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 280.1m
2014-07-14 02:16:29,567 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/21e1271c0b7f40aaa48f73d446f1331b as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/21e1271c0b7f40aaa48f73d446f1331b
2014-07-14 02:16:29,587 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/21e1271c0b7f40aaa48f73d446f1331b, entries=943700, sequenceid=10486, filesize=67.2m
2014-07-14 02:16:29,587 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.2m/271777760, currentsize=151.1m/158394640 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 10680ms, sequenceid=10486, compaction requested=true
2014-07-14 02:16:29,588 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-14 02:16:29,588 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 275.7m
2014-07-14 02:16:29,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:29,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42252 synced till here 42248
2014-07-14 02:16:29,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329387071 with entries=77, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329389658
2014-07-14 02:16:29,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329346218
2014-07-14 02:16:29,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329347317
2014-07-14 02:16:29,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329352193
2014-07-14 02:16:29,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329361092
2014-07-14 02:16:29,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329363095
2014-07-14 02:16:29,830 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:29,899 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:31,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:31,448 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42342 synced till here 42335
2014-07-14 02:16:31,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329389658 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329391176
2014-07-14 02:16:33,060 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:33,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42419 synced till here 42413
2014-07-14 02:16:33,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329391176 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329393061
2014-07-14 02:16:34,675 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:34,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42518 synced till here 42493
2014-07-14 02:16:34,912 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:16:35,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329393061 with entries=99, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329394676
2014-07-14 02:16:36,257 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1032ms
GC pool 'ParNew' had collection(s): count=1 time=1116ms
2014-07-14 02:16:36,928 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:16:38,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:38,854 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42624 synced till here 42619
2014-07-14 02:16:38,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329394676 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329398757
2014-07-14 02:16:40,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:41,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42747 synced till here 42708
2014-07-14 02:16:42,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329398757 with entries=123, filesize=104.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329400983
2014-07-14 02:16:44,457 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1003ms
GC pool 'ParNew' had collection(s): count=1 time=1054ms
2014-07-14 02:16:44,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:44,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42904 synced till here 42855
2014-07-14 02:16:45,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329400983 with entries=157, filesize=130.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329404458
2014-07-14 02:16:47,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:48,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43042 synced till here 42992
2014-07-14 02:16:48,619 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10593, memsize=274.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/94e195ea9a544197af63956f9ca0c14f
2014-07-14 02:16:48,657 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/94e195ea9a544197af63956f9ca0c14f as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/94e195ea9a544197af63956f9ca0c14f
2014-07-14 02:16:48,728 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/94e195ea9a544197af63956f9ca0c14f, entries=998370, sequenceid=10593, filesize=71.1m
2014-07-14 02:16:48,728 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~277.3m/290717920, currentsize=333.4m/349545120 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 19140ms, sequenceid=10593, compaction requested=true
2014-07-14 02:16:48,728 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-14 02:16:48,729 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 444.7m
2014-07-14 02:16:48,855 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10590, memsize=280.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cf536ed0eeb94a7887da2d7328fdf69f
2014-07-14 02:16:48,862 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:16:48,878 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/cf536ed0eeb94a7887da2d7328fdf69f as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cf536ed0eeb94a7887da2d7328fdf69f
2014-07-14 02:16:48,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329404458 with entries=138, filesize=117.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329407380
2014-07-14 02:16:48,913 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cf536ed0eeb94a7887da2d7328fdf69f, entries=1019410, sequenceid=10590, filesize=72.6m
2014-07-14 02:16:48,914 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~283.2m/296916000, currentsize=292.3m/306509040 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 19386ms, sequenceid=10590, compaction requested=true
2014-07-14 02:16:48,914 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:77), split_queue=0, merge_queue=0
2014-07-14 02:16:48,914 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 444.8m
2014-07-14 02:16:49,232 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:16:50,462 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1093ms
GC pool 'ParNew' had collection(s): count=1 time=1157ms
2014-07-14 02:16:50,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:51,016 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:51,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43143 synced till here 43117
2014-07-14 02:16:51,090 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:16:51,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329407380 with entries=101, filesize=86.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329410971
2014-07-14 02:16:51,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329367856
2014-07-14 02:16:51,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329370142
2014-07-14 02:16:51,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329371196
2014-07-14 02:16:51,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329376494
2014-07-14 02:16:53,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:53,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43254 synced till here 43228
2014-07-14 02:16:55,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329410971 with entries=111, filesize=94.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329413634
2014-07-14 02:16:56,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:56,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43357 synced till here 43328
2014-07-14 02:16:57,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329413634 with entries=103, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329416962
2014-07-14 02:16:59,551 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:16:59,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43472 synced till here 43439
2014-07-14 02:16:59,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329416962 with entries=115, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329419551
2014-07-14 02:17:01,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:01,777 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43582 synced till here 43552
2014-07-14 02:17:02,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329419551 with entries=110, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329421746
2014-07-14 02:17:03,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:03,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43680 synced till here 43656
2014-07-14 02:17:04,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329421746 with entries=98, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329423790
2014-07-14 02:17:06,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:06,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43779 synced till here 43758
2014-07-14 02:17:06,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329423790 with entries=99, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329426011
2014-07-14 02:17:07,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:07,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43862 synced till here 43860
2014-07-14 02:17:07,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329426011 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329427831
2014-07-14 02:17:08,247 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10812, memsize=243.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/84037b41780d408abdb3712a7c7181e4
2014-07-14 02:17:08,261 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/84037b41780d408abdb3712a7c7181e4 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/84037b41780d408abdb3712a7c7181e4
2014-07-14 02:17:08,271 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/84037b41780d408abdb3712a7c7181e4, entries=885310, sequenceid=10812, filesize=63.1m
2014-07-14 02:17:08,272 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~491.1m/514992080, currentsize=302.0m/316650640 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 19544ms, sequenceid=10812, compaction requested=true
2014-07-14 02:17:08,272 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:78), split_queue=0, merge_queue=0
2014-07-14 02:17:08,272 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 634.1m
2014-07-14 02:17:08,292 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10782, memsize=244.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/eadc46ac44924819b40391aa22a69614
2014-07-14 02:17:08,316 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/eadc46ac44924819b40391aa22a69614 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/eadc46ac44924819b40391aa22a69614
2014-07-14 02:17:08,347 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/eadc46ac44924819b40391aa22a69614, entries=889540, sequenceid=10782, filesize=63.4m
2014-07-14 02:17:08,347 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~457.3m/479531040, currentsize=338.7m/355167440 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 19433ms, sequenceid=10782, compaction requested=true
2014-07-14 02:17:08,347 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:79), split_queue=0, merge_queue=0
2014-07-14 02:17:08,347 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 631.5m
2014-07-14 02:17:08,513 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:17:08,567 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:17:08,706 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:09,194 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:09,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:09,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43937 synced till here 43934
2014-07-14 02:17:09,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329427831 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329429390
2014-07-14 02:17:09,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329377781
2014-07-14 02:17:09,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329379469
2014-07-14 02:17:09,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329381542
2014-07-14 02:17:09,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329383234
2014-07-14 02:17:09,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329385563
2014-07-14 02:17:10,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:10,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44015 synced till here 44010
2014-07-14 02:17:11,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329429390 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329430722
2014-07-14 02:17:12,699 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:12,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44094 synced till here 44087
2014-07-14 02:17:12,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329430722 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329432699
2014-07-14 02:17:13,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:14,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44196 synced till here 44191
2014-07-14 02:17:14,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329432699 with entries=102, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329433979
2014-07-14 02:17:15,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:15,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329433979 with entries=74, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329435628
2014-07-14 02:17:15,921 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11004, memsize=96.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/39292b5431a148e1b3e1df6967df1364
2014-07-14 02:17:15,938 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/39292b5431a148e1b3e1df6967df1364 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/39292b5431a148e1b3e1df6967df1364
2014-07-14 02:17:15,949 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/39292b5431a148e1b3e1df6967df1364, entries=350570, sequenceid=11004, filesize=25.0m
2014-07-14 02:17:15,949 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~634.1m/664907680, currentsize=155.2m/162772720 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 7677ms, sequenceid=11004, compaction requested=true
2014-07-14 02:17:15,950 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:80), split_queue=0, merge_queue=0
2014-07-14 02:17:15,950 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 452.9m
2014-07-14 02:17:16,319 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:16,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:16,786 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44348 synced till here 44341
2014-07-14 02:17:16,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329435628 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329436772
2014-07-14 02:17:16,932 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11009, memsize=104.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c394dc3cfb2240cc9b1980a8898fc798
2014-07-14 02:17:16,954 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c394dc3cfb2240cc9b1980a8898fc798 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c394dc3cfb2240cc9b1980a8898fc798
2014-07-14 02:17:17,117 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c394dc3cfb2240cc9b1980a8898fc798, entries=379340, sequenceid=11009, filesize=27.0m
2014-07-14 02:17:17,118 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~648.7m/680221600, currentsize=172.6m/180943200 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 8771ms, sequenceid=11009, compaction requested=true
2014-07-14 02:17:17,118 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:81), split_queue=0, merge_queue=0
2014-07-14 02:17:17,118 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 518.8m
2014-07-14 02:17:17,544 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:17,598 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:17,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44421 synced till here 44419
2014-07-14 02:17:17,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329436772 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329437598
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329387071
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329389658
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329391176
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329393061
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329394676
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329398757
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329400983
2014-07-14 02:17:17,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329404458
2014-07-14 02:17:19,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:19,311 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44500 synced till here 44495
2014-07-14 02:17:20,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329437598 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329439252
2014-07-14 02:17:20,781 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:17:21,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:21,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44581 synced till here 44576
2014-07-14 02:17:21,795 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:17:21,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329439252 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329441200
2014-07-14 02:17:23,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:23,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44678 synced till here 44665
2014-07-14 02:17:23,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329441200 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329443752
2014-07-14 02:17:25,740 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:25,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44776 synced till here 44764
2014-07-14 02:17:25,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329443752 with entries=98, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329445740
2014-07-14 02:17:27,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:27,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44878 synced till here 44858
2014-07-14 02:17:28,025 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329445740 with entries=102, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329447797
2014-07-14 02:17:28,134 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11110, memsize=178.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/04c45a5b9c064074a985cb92e7b24ad5
2014-07-14 02:17:28,146 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/04c45a5b9c064074a985cb92e7b24ad5 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04c45a5b9c064074a985cb92e7b24ad5
2014-07-14 02:17:28,161 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04c45a5b9c064074a985cb92e7b24ad5, entries=650720, sequenceid=11110, filesize=46.4m
2014-07-14 02:17:28,162 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~457.6m/479778720, currentsize=229.4m/240497760 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 12212ms, sequenceid=11110, compaction requested=true
2014-07-14 02:17:28,162 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:82), split_queue=0, merge_queue=0
2014-07-14 02:17:28,162 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 399.0m
2014-07-14 02:17:29,626 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:29,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:29,726 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:17:29,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44989 synced till here 44960
2014-07-14 02:17:31,162 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329447797 with entries=111, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329449724
2014-07-14 02:17:32,974 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11119, memsize=202.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1a426a310f08412d9ee85a81a3ab0ebe
2014-07-14 02:17:32,986 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1a426a310f08412d9ee85a81a3ab0ebe as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1a426a310f08412d9ee85a81a3ab0ebe
2014-07-14 02:17:32,997 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1a426a310f08412d9ee85a81a3ab0ebe, entries=735340, sequenceid=11119, filesize=52.4m
2014-07-14 02:17:32,998 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~522.0m/547342400, currentsize=242.6m/254356480 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15879ms, sequenceid=11119, compaction requested=true
2014-07-14 02:17:32,998 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:83), split_queue=0, merge_queue=0
2014-07-14 02:17:32,998 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 410.4m
2014-07-14 02:17:33,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:33,169 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:17:33,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45098 synced till here 45085
2014-07-14 02:17:33,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329449724 with entries=109, filesize=93.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329453131
2014-07-14 02:17:33,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329407380
2014-07-14 02:17:33,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329410971
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329413634
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329416962
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329419551
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329421746
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329423790
2014-07-14 02:17:33,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329426011
2014-07-14 02:17:33,529 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:35,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:35,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45212 synced till here 45200
2014-07-14 02:17:35,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329453131 with entries=114, filesize=97.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329455142
2014-07-14 02:17:37,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:37,366 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45315 synced till here 45284
2014-07-14 02:17:37,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329455142 with entries=103, filesize=89.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329457326
2014-07-14 02:17:39,333 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:39,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45406 synced till here 45394
2014-07-14 02:17:39,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329457326 with entries=91, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329459334
2014-07-14 02:17:40,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:40,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45480 synced till here 45477
2014-07-14 02:17:40,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329459334 with entries=74, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329460956
2014-07-14 02:17:42,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:42,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329460956 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329462490
2014-07-14 02:17:44,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:44,490 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45635 synced till here 45628
2014-07-14 02:17:44,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329462490 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329464429
2014-07-14 02:17:45,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:46,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45729 synced till here 45725
2014-07-14 02:17:46,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329464429 with entries=94, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329465916
2014-07-14 02:17:47,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:47,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45819 synced till here 45810
2014-07-14 02:17:47,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329465916 with entries=90, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329467397
2014-07-14 02:17:48,795 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11271, memsize=305.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/5d0f48ca004442eebe0b95c8e5d8aac3
2014-07-14 02:17:48,810 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/5d0f48ca004442eebe0b95c8e5d8aac3 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5d0f48ca004442eebe0b95c8e5d8aac3
2014-07-14 02:17:48,824 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5d0f48ca004442eebe0b95c8e5d8aac3, entries=1113710, sequenceid=11271, filesize=79.3m
2014-07-14 02:17:48,825 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~413.0m/433080160, currentsize=360.1m/377590240 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 20663ms, sequenceid=11271, compaction requested=true
2014-07-14 02:17:48,825 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:84), split_queue=0, merge_queue=0
2014-07-14 02:17:48,825 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 619.2m
2014-07-14 02:17:48,868 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:17:48,894 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:48,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45899 synced till here 45893
2014-07-14 02:17:49,267 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329467397 with entries=80, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329468895
2014-07-14 02:17:49,397 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:50,579 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:50,748 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11284, memsize=305.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/96cd7a2fe1714191b4f86ce9d03f81ca
2014-07-14 02:17:50,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45982 synced till here 45980
2014-07-14 02:17:50,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329468895 with entries=83, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329470580
2014-07-14 02:17:50,815 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/96cd7a2fe1714191b4f86ce9d03f81ca as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/96cd7a2fe1714191b4f86ce9d03f81ca
2014-07-14 02:17:50,826 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/96cd7a2fe1714191b4f86ce9d03f81ca, entries=1113620, sequenceid=11284, filesize=79.3m
2014-07-14 02:17:50,826 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~425.9m/446552160, currentsize=381.3m/399784560 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 17828ms, sequenceid=11284, compaction requested=true
2014-07-14 02:17:50,827 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-14 02:17:50,827 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 624.7m
2014-07-14 02:17:51,041 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:17:51,833 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:17:51,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:51,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329470580 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329471917
2014-07-14 02:17:51,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329427831
2014-07-14 02:17:51,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329429390
2014-07-14 02:17:51,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329430722
2014-07-14 02:17:51,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329432699
2014-07-14 02:17:51,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329433979
2014-07-14 02:17:53,922 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:53,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46129 synced till here 46127
2014-07-14 02:17:54,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329471917 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329473923
2014-07-14 02:17:55,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:55,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329473923 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329475259
2014-07-14 02:17:56,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:56,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46285 synced till here 46277
2014-07-14 02:17:56,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329475259 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329476626
2014-07-14 02:17:57,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:57,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46361 synced till here 46359
2014-07-14 02:17:57,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329476626 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329477896
2014-07-14 02:17:59,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:17:59,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46445 synced till here 46434
2014-07-14 02:17:59,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329477896 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329479585
2014-07-14 02:18:01,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:01,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46527 synced till here 46520
2014-07-14 02:18:01,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329479585 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329481271
2014-07-14 02:18:02,764 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:02,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46605 synced till here 46600
2014-07-14 02:18:02,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329481271 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329482765
2014-07-14 02:18:03,215 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11509, memsize=264.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/21598f7b008245dfbbb89bfb3a636272
2014-07-14 02:18:03,229 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/21598f7b008245dfbbb89bfb3a636272 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/21598f7b008245dfbbb89bfb3a636272
2014-07-14 02:18:03,251 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/21598f7b008245dfbbb89bfb3a636272, entries=964550, sequenceid=11509, filesize=68.7m
2014-07-14 02:18:03,252 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~622.4m/652624160, currentsize=291.6m/305767040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 14427ms, sequenceid=11509, compaction requested=true
2014-07-14 02:18:03,252 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:86), split_queue=0, merge_queue=0
2014-07-14 02:18:03,252 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 651.9m
2014-07-14 02:18:03,296 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:18:04,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:04,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46684 synced till here 46678
2014-07-14 02:18:04,235 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329482765 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329484165
2014-07-14 02:18:04,236 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329435628
2014-07-14 02:18:04,251 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:18:05,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:05,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46765 synced till here 46756
2014-07-14 02:18:05,721 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329484165 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329485581
2014-07-14 02:18:06,329 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11523, memsize=267.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/ceef6c706b5540de91fed47c3c2c0be5
2014-07-14 02:18:06,344 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/ceef6c706b5540de91fed47c3c2c0be5 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/ceef6c706b5540de91fed47c3c2c0be5
2014-07-14 02:18:06,384 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/ceef6c706b5540de91fed47c3c2c0be5, entries=973310, sequenceid=11523, filesize=69.3m
2014-07-14 02:18:06,386 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~627.9m/658360160, currentsize=313.4m/328612080 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15558ms, sequenceid=11523, compaction requested=true
2014-07-14 02:18:06,386 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-14 02:18:06,386 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 692.1m
2014-07-14 02:18:06,459 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:18:07,479 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:07,499 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46850 synced till here 46839
2014-07-14 02:18:07,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329485581 with entries=85, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329487479
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329436772
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329437598
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329439252
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329441200
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329443752
2014-07-14 02:18:07,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329445740
2014-07-14 02:18:07,913 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:18:09,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:09,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46952 synced till here 46946
2014-07-14 02:18:09,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329487479 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329489146
2014-07-14 02:18:10,937 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:11,002 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47037 synced till here 47024
2014-07-14 02:18:11,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329489146 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329490938
2014-07-14 02:18:12,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:12,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47115 synced till here 47112
2014-07-14 02:18:12,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329490938 with entries=78, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329492430
2014-07-14 02:18:13,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:13,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47189 synced till here 47188
2014-07-14 02:18:13,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329492430 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329493865
2014-07-14 02:18:15,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:15,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47265 synced till here 47264
2014-07-14 02:18:15,588 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329493865 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329495017
2014-07-14 02:18:17,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:17,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47347 synced till here 47339
2014-07-14 02:18:17,093 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329495017 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329497012
2014-07-14 02:18:18,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:18,706 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47438 synced till here 47425
2014-07-14 02:18:18,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329497012 with entries=91, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329498665
2014-07-14 02:18:20,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:20,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47519 synced till here 47510
2014-07-14 02:18:20,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329498665 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329500391
2014-07-14 02:18:21,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:21,817 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47597 synced till here 47592
2014-07-14 02:18:21,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329500391 with entries=78, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329501303
2014-07-14 02:18:22,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:22,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47681 synced till here 47669
2014-07-14 02:18:23,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329501303 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329502607
2014-07-14 02:18:24,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:24,448 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47756 synced till here 47753
2014-07-14 02:18:24,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329502607 with entries=75, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329504413
2014-07-14 02:18:25,989 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:26,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47837 synced till here 47830
2014-07-14 02:18:26,071 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329504413 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329505989
2014-07-14 02:18:27,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:27,479 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47918 synced till here 47909
2014-07-14 02:18:27,521 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11694, memsize=398.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0081b9e8aea4465182c2283a157d7e6c
2014-07-14 02:18:27,538 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0081b9e8aea4465182c2283a157d7e6c as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0081b9e8aea4465182c2283a157d7e6c
2014-07-14 02:18:27,557 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0081b9e8aea4465182c2283a157d7e6c, entries=1449810, sequenceid=11694, filesize=103.2m
2014-07-14 02:18:27,557 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~653.5m/685222720, currentsize=496.1m/520196240 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 24305ms, sequenceid=11694, compaction requested=true
2014-07-14 02:18:27,558 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:88), split_queue=0, merge_queue=0
2014-07-14 02:18:27,558 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 786.8m
2014-07-14 02:18:27,570 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:18:27,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329505989 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329507452
2014-07-14 02:18:27,587 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329447797
2014-07-14 02:18:29,129 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:18:29,370 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48014 synced till here 47993
2014-07-14 02:18:30,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329507452 with entries=96, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329509371
2014-07-14 02:18:33,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:33,114 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48128 synced till here 48101
2014-07-14 02:18:33,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329509371 with entries=114, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329513034
2014-07-14 02:18:35,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:35,283 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48224 synced till here 48201
2014-07-14 02:18:35,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329513034 with entries=96, filesize=82.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329515229
2014-07-14 02:18:37,377 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11733, memsize=446.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/530de20f1e5042e7bf62d3f0760f52ea
2014-07-14 02:18:37,395 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/530de20f1e5042e7bf62d3f0760f52ea as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/530de20f1e5042e7bf62d3f0760f52ea
2014-07-14 02:18:37,406 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/530de20f1e5042e7bf62d3f0760f52ea, entries=1623920, sequenceid=11733, filesize=115.6m
2014-07-14 02:18:37,406 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~696.6m/730482560, currentsize=530.8m/556597520 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 31020ms, sequenceid=11733, compaction requested=true
2014-07-14 02:18:37,406 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:89), split_queue=0, merge_queue=0
2014-07-14 02:18:37,406 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 854.2m
2014-07-14 02:18:37,429 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:18:38,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:38,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48324 synced till here 48301
2014-07-14 02:18:39,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329515229 with entries=100, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329518124
2014-07-14 02:18:39,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329449724
2014-07-14 02:18:39,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329453131
2014-07-14 02:18:39,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329455142
2014-07-14 02:18:39,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329457326
2014-07-14 02:18:39,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329459334
2014-07-14 02:18:39,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329460956
2014-07-14 02:18:39,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329462490
2014-07-14 02:18:39,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329464429
2014-07-14 02:18:39,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329465916
2014-07-14 02:18:39,939 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:18:40,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:41,822 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48430 synced till here 48396
2014-07-14 02:18:42,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329518124 with entries=106, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329520521
2014-07-14 02:18:44,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:44,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48536 synced till here 48511
2014-07-14 02:18:44,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329520521 with entries=106, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329524138
2014-07-14 02:18:46,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:46,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48647 synced till here 48630
2014-07-14 02:18:46,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329524138 with entries=111, filesize=95.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329526549
2014-07-14 02:18:48,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:48,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48737 synced till here 48727
2014-07-14 02:18:48,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329526549 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329528442
2014-07-14 02:18:50,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:51,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329528442 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329530964
2014-07-14 02:18:52,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:52,589 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48888 synced till here 48880
2014-07-14 02:18:53,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329530964 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329532495
2014-07-14 02:18:54,713 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,717 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,719 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,724 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,727 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,727 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,729 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,746 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,747 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,768 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,833 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,857 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,862 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,863 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,877 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,878 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,878 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,889 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,904 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,909 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,911 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,922 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:54,934 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:18:54,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48969 synced till here 48960
2014-07-14 02:18:54,966 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,014 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,015 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,015 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,015 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,015 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,040 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,041 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,043 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,045 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,045 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,046 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,046 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,046 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,047 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:55,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329532495 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329534934
2014-07-14 02:18:56,548 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:56,616 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:56,682 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,490 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,500 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,512 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,544 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,576 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,604 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,637 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,668 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,699 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:57,731 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:18:59,714 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,717 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,720 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,724 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,728 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,728 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,729 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,746 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,748 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,769 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,834 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,857 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,862 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,863 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,877 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,878 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,879 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,889 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,905 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,909 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 02:18:59,912 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:18:59,923 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:18:59,966 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,015 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:19:00,015 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,016 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:19:00,017 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:19:00,017 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:19:00,040 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,041 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,044 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,046 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,046 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:19:00,046 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,046 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,046 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:19:00,048 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:19:01,400 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12020, memsize=504.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/feb479aa1c8d464bbc17e66dffe61976
2014-07-14 02:19:01,418 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/feb479aa1c8d464bbc17e66dffe61976 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/feb479aa1c8d464bbc17e66dffe61976
2014-07-14 02:19:01,433 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/feb479aa1c8d464bbc17e66dffe61976, entries=1835440, sequenceid=12020, filesize=130.6m
2014-07-14 02:19:01,433 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~791.6m/830075760, currentsize=412.5m/432539040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 33875ms, sequenceid=12020, compaction requested=true
2014-07-14 02:19:01,434 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:90), split_queue=0, merge_queue=0
2014-07-14 02:19:01,434 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6387ms
2014-07-14 02:19:01,435 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,435 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 919.4m
2014-07-14 02:19:01,435 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6389ms
2014-07-14 02:19:01,435 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,435 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6389ms
2014-07-14 02:19:01,435 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,435 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6389ms
2014-07-14 02:19:01,435 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,436 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6391ms
2014-07-14 02:19:01,436 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,436 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6391ms
2014-07-14 02:19:01,436 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,436 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6393ms
2014-07-14 02:19:01,436 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:01,436 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6395ms
2014-07-14 02:19:01,437 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,047 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5364ms
2014-07-14 02:19:02,047 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,048 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7008ms
2014-07-14 02:19:02,048 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,049 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7033ms
2014-07-14 02:19:02,049 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,049 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7034ms
2014-07-14 02:19:02,049 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,052 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7038ms
2014-07-14 02:19:02,052 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,053 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7038ms
2014-07-14 02:19:02,053 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,056 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7042ms
2014-07-14 02:19:02,056 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,056 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7090ms
2014-07-14 02:19:02,056 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,056 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7134ms
2014-07-14 02:19:02,057 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,057 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7146ms
2014-07-14 02:19:02,057 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,057 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7153ms
2014-07-14 02:19:02,057 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,057 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7153ms
2014-07-14 02:19:02,057 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,057 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7168ms
2014-07-14 02:19:02,057 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,065 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7187ms
2014-07-14 02:19:02,065 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,073 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7195ms
2014-07-14 02:19:02,073 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,073 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7196ms
2014-07-14 02:19:02,073 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,073 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7210ms
2014-07-14 02:19:02,073 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,077 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7216ms
2014-07-14 02:19:02,077 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,077 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7220ms
2014-07-14 02:19:02,077 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,077 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7244ms
2014-07-14 02:19:02,077 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,077 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7309ms
2014-07-14 02:19:02,077 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,077 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7330ms
2014-07-14 02:19:02,078 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,078 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7332ms
2014-07-14 02:19:02,078 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,079 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7351ms
2014-07-14 02:19:02,079 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,080 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7353ms
2014-07-14 02:19:02,080 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,080 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7353ms
2014-07-14 02:19:02,081 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,085 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7361ms
2014-07-14 02:19:02,085 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,085 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7366ms
2014-07-14 02:19:02,085 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,092 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7375ms
2014-07-14 02:19:02,148 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,149 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7436ms
2014-07-14 02:19:02,149 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,149 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4418ms
2014-07-14 02:19:02,149 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,150 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4450ms
2014-07-14 02:19:02,150 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,153 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4485ms
2014-07-14 02:19:02,153 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,153 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4516ms
2014-07-14 02:19:02,153 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,154 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4549ms
2014-07-14 02:19:02,154 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,161 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4585ms
2014-07-14 02:19:02,161 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,161 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4617ms
2014-07-14 02:19:02,161 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,161 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4649ms
2014-07-14 02:19:02,161 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,161 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4661ms
2014-07-14 02:19:02,162 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,162 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4672ms
2014-07-14 02:19:02,163 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,163 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5547ms
2014-07-14 02:19:02,163 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,163 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5615ms
2014-07-14 02:19:02,163 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:02,357 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:19:02,690 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532573,"queuetimems":1,"class":"HRegionServer","responsesize":15676,"method":"Multi"}
2014-07-14 02:19:02,690 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10050,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532639,"queuetimems":0,"class":"HRegionServer","responsesize":15704,"method":"Multi"}
2014-07-14 02:19:02,697 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532543,"queuetimems":1,"class":"HRegionServer","responsesize":15585,"method":"Multi"}
2014-07-14 02:19:02,701 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532480,"queuetimems":1,"class":"HRegionServer","responsesize":15919,"method":"Multi"}
2014-07-14 02:19:02,702 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10025,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532677,"queuetimems":4,"class":"HRegionServer","responsesize":15886,"method":"Multi"}
2014-07-14 02:19:03,112 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:19:03,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:03,439 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329533239,"queuetimems":0,"class":"HRegionServer","responsesize":16004,"method":"Multi"}
2014-07-14 02:19:03,439 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532765,"queuetimems":0,"class":"HRegionServer","responsesize":15832,"method":"Multi"}
2014-07-14 02:19:03,439 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532608,"queuetimems":0,"class":"HRegionServer","responsesize":16061,"method":"Multi"}
2014-07-14 02:19:04,187 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532797,"queuetimems":0,"class":"HRegionServer","responsesize":15845,"method":"Multi"}
2014-07-14 02:19:04,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49081 synced till here 49068
2014-07-14 02:19:04,356 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532919,"queuetimems":0,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:19:04,357 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534184,"queuetimems":0,"class":"HRegionServer","responsesize":15782,"method":"Multi"}
2014-07-14 02:19:04,359 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532884,"queuetimems":1,"class":"HRegionServer","responsesize":16167,"method":"Multi"}
2014-07-14 02:19:04,370 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534160,"queuetimems":1,"class":"HRegionServer","responsesize":15933,"method":"Multi"}
2014-07-14 02:19:04,370 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329532511,"queuetimems":0,"class":"HRegionServer","responsesize":15863,"method":"Multi"}
2014-07-14 02:19:04,370 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10198,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534172,"queuetimems":0,"class":"HRegionServer","responsesize":15880,"method":"Multi"}
2014-07-14 02:19:04,371 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11293,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329533077,"queuetimems":0,"class":"HRegionServer","responsesize":15498,"method":"Multi"}
2014-07-14 02:19:04,371 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329533209,"queuetimems":0,"class":"HRegionServer","responsesize":15781,"method":"Multi"}
2014-07-14 02:19:04,372 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10146,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534225,"queuetimems":0,"class":"HRegionServer","responsesize":15604,"method":"Multi"}
2014-07-14 02:19:04,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329534934 with entries=112, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329543435
2014-07-14 02:19:04,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329467397
2014-07-14 02:19:04,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329468895
2014-07-14 02:19:04,825 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534765,"queuetimems":1,"class":"HRegionServer","responsesize":15832,"method":"Multi"}
2014-07-14 02:19:04,831 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534640,"queuetimems":0,"class":"HRegionServer","responsesize":15845,"method":"Multi"}
2014-07-14 02:19:04,831 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329534829,"queuetimems":1,"class":"HRegionServer","responsesize":15555,"method":"Multi"}
2014-07-14 02:19:06,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:06,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49186 synced till here 49177
2014-07-14 02:19:06,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329543435 with entries=105, filesize=89.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329546185
2014-07-14 02:19:08,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:08,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49303 synced till here 49278
2014-07-14 02:19:08,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329546185 with entries=117, filesize=99.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329548092
2014-07-14 02:19:09,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:09,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49393 synced till here 49377
2014-07-14 02:19:10,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329548092 with entries=90, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329549931
2014-07-14 02:19:10,937 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,939 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,939 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,941 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,948 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,948 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12090, memsize=488.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/d374c28962f84d7fb2697ecd767cec48
2014-07-14 02:19:10,956 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:10,963 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/d374c28962f84d7fb2697ecd767cec48 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d374c28962f84d7fb2697ecd767cec48
2014-07-14 02:19:10,975 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d374c28962f84d7fb2697ecd767cec48, entries=1778130, sequenceid=12090, filesize=126.5m
2014-07-14 02:19:10,975 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~879.3m/922015280, currentsize=465.8m/488420080 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 33569ms, sequenceid=12090, compaction requested=true
2014-07-14 02:19:10,976 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:91), split_queue=0, merge_queue=0
2014-07-14 02:19:10,976 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20ms
2014-07-14 02:19:10,976 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:10,976 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 28ms
2014-07-14 02:19:10,976 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.0g
2014-07-14 02:19:10,976 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:10,977 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36ms
2014-07-14 02:19:10,977 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:10,977 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38ms
2014-07-14 02:19:10,977 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:10,977 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-14 02:19:10,977 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:10,977 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-14 02:19:10,977 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:11,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:11,391 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:19:11,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49469 synced till here 49467
2014-07-14 02:19:11,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329549931 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329551386
2014-07-14 02:19:11,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329470580
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329471917
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329473923
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329475259
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329476626
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329477896
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329479585
2014-07-14 02:19:11,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329481271
2014-07-14 02:19:12,311 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:19:12,475 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:12,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49550 synced till here 49543
2014-07-14 02:19:13,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329551386 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329552475
2014-07-14 02:19:14,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:14,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49630 synced till here 49623
2014-07-14 02:19:14,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329552475 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329554036
2014-07-14 02:19:15,409 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:15,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49710 synced till here 49708
2014-07-14 02:19:15,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329554036 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329555410
2014-07-14 02:19:16,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:17,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49793 synced till here 49791
2014-07-14 02:19:17,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329555410 with entries=83, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329556971
2014-07-14 02:19:18,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:18,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49877 synced till here 49876
2014-07-14 02:19:18,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329556971 with entries=84, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329558327
2014-07-14 02:19:19,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:19,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49952 synced till here 49950
2014-07-14 02:19:19,739 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329558327 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329559673
2014-07-14 02:19:21,289 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,289 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,295 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,295 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,296 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,298 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:21,305 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,306 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,324 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50028 synced till here 50024
2014-07-14 02:19:21,352 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,353 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,357 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329559673 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329561298
2014-07-14 02:19:21,408 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,540 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,609 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,671 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,736 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,771 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:21,823 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,499 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,508 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,519 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,548 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,574 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,611 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,663 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,711 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,761 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,812 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,846 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,889 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,936 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:22,972 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,008 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,054 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,109 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,138 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,371 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,551 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,581 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,609 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,638 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,669 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,697 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,727 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,755 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,782 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,811 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:23,840 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:19:24,821 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12287, memsize=349.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b19dda52643646089257745fc5ef5279
2014-07-14 02:19:24,836 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b19dda52643646089257745fc5ef5279 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b19dda52643646089257745fc5ef5279
2014-07-14 02:19:24,846 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b19dda52643646089257745fc5ef5279, entries=1270530, sequenceid=12287, filesize=90.4m
2014-07-14 02:19:24,847 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~919.4m/964040000, currentsize=397.2m/416521120 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 23412ms, sequenceid=12287, compaction requested=true
2014-07-14 02:19:24,847 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-14 02:19:24,848 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1007ms
2014-07-14 02:19:24,848 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,848 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 808.0m
2014-07-14 02:19:24,848 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1037ms
2014-07-14 02:19:24,848 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,849 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1067ms
2014-07-14 02:19:24,849 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,849 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1094ms
2014-07-14 02:19:24,849 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,850 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1124ms
2014-07-14 02:19:24,850 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,850 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1153ms
2014-07-14 02:19:24,851 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,856 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1185ms
2014-07-14 02:19:24,856 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,857 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1218ms
2014-07-14 02:19:24,857 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,857 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1248ms
2014-07-14 02:19:24,857 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,857 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1276ms
2014-07-14 02:19:24,857 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,861 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1310ms
2014-07-14 02:19:24,861 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,861 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1490ms
2014-07-14 02:19:24,861 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,870 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1731ms
2014-07-14 02:19:24,870 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,870 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1761ms
2014-07-14 02:19:24,870 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,873 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1816ms
2014-07-14 02:19:24,873 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,875 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1866ms
2014-07-14 02:19:24,875 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,876 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1904ms
2014-07-14 02:19:24,876 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,883 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1947ms
2014-07-14 02:19:24,883 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,887 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1998ms
2014-07-14 02:19:24,887 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,889 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2041ms
2014-07-14 02:19:24,889 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,892 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2078ms
2014-07-14 02:19:24,893 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,893 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-14 02:19:24,893 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,895 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2183ms
2014-07-14 02:19:24,896 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,896 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2233ms
2014-07-14 02:19:24,896 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,896 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2286ms
2014-07-14 02:19:24,896 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,904 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2330ms
2014-07-14 02:19:24,904 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,904 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2356ms
2014-07-14 02:19:24,904 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,914 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2386ms
2014-07-14 02:19:24,915 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,915 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2407ms
2014-07-14 02:19:24,915 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,921 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2422ms
2014-07-14 02:19:24,921 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,922 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3098ms
2014-07-14 02:19:24,922 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,922 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3151ms
2014-07-14 02:19:24,922 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,925 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3189ms
2014-07-14 02:19:24,925 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,931 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3259ms
2014-07-14 02:19:24,931 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,931 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3322ms
2014-07-14 02:19:24,931 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,938 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3398ms
2014-07-14 02:19:24,938 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,938 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3530ms
2014-07-14 02:19:24,939 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,939 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3582ms
2014-07-14 02:19:24,939 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,939 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3586ms
2014-07-14 02:19:24,939 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,949 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3597ms
2014-07-14 02:19:24,949 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,951 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3644ms
2014-07-14 02:19:24,951 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,951 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3646ms
2014-07-14 02:19:24,951 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,953 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3657ms
2014-07-14 02:19:24,953 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,953 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3658ms
2014-07-14 02:19:24,953 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,954 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3659ms
2014-07-14 02:19:24,954 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,985 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3696ms
2014-07-14 02:19:24,985 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:24,986 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3698ms
2014-07-14 02:19:24,986 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:19:25,162 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:19:26,783 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:19:27,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:27,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50140 synced till here 50105
2014-07-14 02:19:28,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329561298 with entries=112, filesize=96.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329567128
2014-07-14 02:19:28,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329482765
2014-07-14 02:19:28,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329484165
2014-07-14 02:19:31,374 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1340ms
GC pool 'ParNew' had collection(s): count=1 time=1528ms
2014-07-14 02:19:31,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:31,470 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10064,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561404,"queuetimems":0,"class":"HRegionServer","responsesize":16268,"method":"Multi"}
2014-07-14 02:19:31,495 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50243 synced till here 50215
2014-07-14 02:19:31,834 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561603,"queuetimems":1,"class":"HRegionServer","responsesize":15599,"method":"Multi"}
2014-07-14 02:19:31,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329567128 with entries=103, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329571444
2014-07-14 02:19:31,868 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561819,"queuetimems":0,"class":"HRegionServer","responsesize":15852,"method":"Multi"}
2014-07-14 02:19:31,890 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10537,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561353,"queuetimems":1,"class":"HRegionServer","responsesize":16103,"method":"Multi"}
2014-07-14 02:19:32,476 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11175,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561301,"queuetimems":1,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-14 02:19:32,477 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10748,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329561729,"queuetimems":1,"class":"HRegionServer","responsesize":16067,"method":"Multi"}
2014-07-14 02:19:34,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:34,108 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50352 synced till here 50324
2014-07-14 02:19:34,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329571444 with entries=109, filesize=92.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329574044
2014-07-14 02:19:37,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:37,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50445 synced till here 50424
2014-07-14 02:19:37,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329574044 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329577178
2014-07-14 02:19:39,407 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12398, memsize=315.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/4e4b0d442bc44db5975e70e49c78649c
2014-07-14 02:19:39,431 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/4e4b0d442bc44db5975e70e49c78649c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4e4b0d442bc44db5975e70e49c78649c
2014-07-14 02:19:39,445 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4e4b0d442bc44db5975e70e49c78649c, entries=1149320, sequenceid=12398, filesize=81.8m
2014-07-14 02:19:39,446 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1086593760, currentsize=384.6m/403307120 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 28470ms, sequenceid=12398, compaction requested=true
2014-07-14 02:19:39,446 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-14 02:19:39,447 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 857.3m
2014-07-14 02:19:39,545 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:39,547 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:19:39,598 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50552 synced till here 50517
2014-07-14 02:19:41,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329577178 with entries=107, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329579545
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329485581
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329487479
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329489146
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329490938
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329492430
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329493865
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329495017
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329497012
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329498665
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329500391
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329501303
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329502607
2014-07-14 02:19:41,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329504413
2014-07-14 02:19:41,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329505989
2014-07-14 02:19:41,953 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:19:43,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:43,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50667 synced till here 50633
2014-07-14 02:19:43,615 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329579545 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329583286
2014-07-14 02:19:45,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:45,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50790 synced till here 50754
2014-07-14 02:19:46,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329583286 with entries=123, filesize=103.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329585836
2014-07-14 02:19:48,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:48,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50893 synced till here 50862
2014-07-14 02:19:48,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329585836 with entries=103, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329588203
2014-07-14 02:19:50,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:50,888 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50998 synced till here 50996
2014-07-14 02:19:50,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329588203 with entries=105, filesize=89.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329590693
2014-07-14 02:19:52,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:52,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51104 synced till here 51074
2014-07-14 02:19:53,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329590693 with entries=106, filesize=91.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329592870
2014-07-14 02:19:55,708 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12544, memsize=310.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/fb45c0592fdc452ab93b55308947c1a4
2014-07-14 02:19:55,731 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/fb45c0592fdc452ab93b55308947c1a4 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fb45c0592fdc452ab93b55308947c1a4
2014-07-14 02:19:55,745 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fb45c0592fdc452ab93b55308947c1a4, entries=1129990, sequenceid=12544, filesize=80.4m
2014-07-14 02:19:55,745 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~808.0m/847236000, currentsize=438.0m/459303200 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 30897ms, sequenceid=12544, compaction requested=true
2014-07-14 02:19:55,746 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:94), split_queue=0, merge_queue=0
2014-07-14 02:19:55,746 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 823.3m
2014-07-14 02:19:56,414 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:19:58,312 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:19:59,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:19:59,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51186 synced till here 51178
2014-07-14 02:19:59,143 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329592870 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329599058
2014-07-14 02:19:59,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329507452
2014-07-14 02:19:59,144 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329509371
2014-07-14 02:19:59,144 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329513034
2014-07-14 02:20:00,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:00,243 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51259 synced till here 51257
2014-07-14 02:20:00,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329599058 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329600225
2014-07-14 02:20:01,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:01,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51350 synced till here 51348
2014-07-14 02:20:02,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329600225 with entries=91, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329601366
2014-07-14 02:20:03,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:03,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51438 synced till here 51437
2014-07-14 02:20:03,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329601366 with entries=88, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329603070
2014-07-14 02:20:05,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:05,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51522 synced till here 51512
2014-07-14 02:20:05,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329603070 with entries=84, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329605503
2014-07-14 02:20:06,192 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12657, memsize=352.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/db43f7b0cf784c26baa94eb30c7d9e01
2014-07-14 02:20:06,225 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/db43f7b0cf784c26baa94eb30c7d9e01 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/db43f7b0cf784c26baa94eb30c7d9e01
2014-07-14 02:20:06,371 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/db43f7b0cf784c26baa94eb30c7d9e01, entries=1282890, sequenceid=12657, filesize=91.3m
2014-07-14 02:20:06,371 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~872.8m/915231120, currentsize=397.8m/417166880 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 26924ms, sequenceid=12657, compaction requested=true
2014-07-14 02:20:06,371 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:95), split_queue=0, merge_queue=0
2014-07-14 02:20:06,372 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:20:06,372 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:96), split_queue=0, merge_queue=0
2014-07-14 02:20:06,372 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 600.0m
2014-07-14 02:20:06,382 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:20:07,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:07,723 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51613 synced till here 51601
2014-07-14 02:20:07,823 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329605503 with entries=91, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329607660
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329515229
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329518124
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329520521
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329524138
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329526549
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329528442
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329530964
2014-07-14 02:20:07,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329532495
2014-07-14 02:20:08,189 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:09,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:09,656 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51711 synced till here 51695
2014-07-14 02:20:09,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329607660 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329609603
2014-07-14 02:20:11,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:11,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51786 synced till here 51783
2014-07-14 02:20:11,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329609603 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329611223
2014-07-14 02:20:12,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:12,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51874 synced till here 51862
2014-07-14 02:20:12,964 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329611223 with entries=88, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329612756
2014-07-14 02:20:14,304 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:14,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51948 synced till here 51945
2014-07-14 02:20:14,341 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329612756 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329614305
2014-07-14 02:20:15,057 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12820, memsize=290.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/148666336011420eb5836cdf3a6faed5
2014-07-14 02:20:15,070 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/148666336011420eb5836cdf3a6faed5 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/148666336011420eb5836cdf3a6faed5
2014-07-14 02:20:15,079 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/148666336011420eb5836cdf3a6faed5, entries=1058870, sequenceid=12820, filesize=75.3m
2014-07-14 02:20:15,079 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~823.3m/863273600, currentsize=334.3m/350541360 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 19333ms, sequenceid=12820, compaction requested=true
2014-07-14 02:20:15,080 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:97), split_queue=0, merge_queue=0
2014-07-14 02:20:15,080 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 584.5m
2014-07-14 02:20:15,114 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:20:15,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:15,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52025 synced till here 52022
2014-07-14 02:20:15,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329614305 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329615201
2014-07-14 02:20:15,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329534934
2014-07-14 02:20:15,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329543435
2014-07-14 02:20:15,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329546185
2014-07-14 02:20:15,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329548092
2014-07-14 02:20:16,343 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:16,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:16,863 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52104 synced till here 52099
2014-07-14 02:20:16,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329615201 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329616809
2014-07-14 02:20:18,298 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:18,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52183 synced till here 52181
2014-07-14 02:20:18,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329616809 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329618298
2014-07-14 02:20:19,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:20,366 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52285 synced till here 52279
2014-07-14 02:20:20,423 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12944, memsize=169.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/be630ea895634f67b12fb9ca4c340970
2014-07-14 02:20:20,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329618298 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329619602
2014-07-14 02:20:20,443 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/be630ea895634f67b12fb9ca4c340970 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/be630ea895634f67b12fb9ca4c340970
2014-07-14 02:20:20,455 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/be630ea895634f67b12fb9ca4c340970, entries=618300, sequenceid=12944, filesize=44.1m
2014-07-14 02:20:20,455 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.7m/654031600, currentsize=258.1m/270596720 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 14083ms, sequenceid=12944, compaction requested=true
2014-07-14 02:20:20,456 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:98), split_queue=0, merge_queue=0
2014-07-14 02:20:20,456 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 441.4m
2014-07-14 02:20:20,462 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:20:20,841 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:21,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:21,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52366 synced till here 52359
2014-07-14 02:20:21,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329619602 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329621212
2014-07-14 02:20:21,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:22,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:23,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52474 synced till here 52466
2014-07-14 02:20:23,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329621212 with entries=108, filesize=92.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329622610
2014-07-14 02:20:23,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:25,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:25,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52565 synced till here 52548
2014-07-14 02:20:25,506 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329622610 with entries=91, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329625240
2014-07-14 02:20:25,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:27,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:27,350 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52656 synced till here 52641
2014-07-14 02:20:27,467 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329625240 with entries=91, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329627302
2014-07-14 02:20:27,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:28,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:28,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52741 synced till here 52733
2014-07-14 02:20:28,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329627302 with entries=85, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329628835
2014-07-14 02:20:28,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:30,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:30,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52846 synced till here 52840
2014-07-14 02:20:30,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329628835 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329630178
2014-07-14 02:20:30,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:31,910 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13036, memsize=220.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/d68fbd3748804553b48e79cbfce2883f
2014-07-14 02:20:31,927 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/d68fbd3748804553b48e79cbfce2883f as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d68fbd3748804553b48e79cbfce2883f
2014-07-14 02:20:31,948 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d68fbd3748804553b48e79cbfce2883f, entries=802740, sequenceid=13036, filesize=57.2m
2014-07-14 02:20:31,948 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~587.6m/616183760, currentsize=343.5m/360192240 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 16868ms, sequenceid=13036, compaction requested=true
2014-07-14 02:20:31,949 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-14 02:20:31,949 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 498.5m
2014-07-14 02:20:32,258 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:32,299 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:20:32,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:32,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52919 synced till here 52917
2014-07-14 02:20:32,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329630178 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329632408
2014-07-14 02:20:32,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:33,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:33,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52995 synced till here 52993
2014-07-14 02:20:33,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329632408 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329633598
2014-07-14 02:20:33,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:34,801 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:34,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53070 synced till here 53068
2014-07-14 02:20:34,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329633598 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329634802
2014-07-14 02:20:34,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:36,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:36,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53147 synced till here 53142
2014-07-14 02:20:36,171 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/915bbbeb2cc248ff93804d8f54227832 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/915bbbeb2cc248ff93804d8f54227832
2014-07-14 02:20:36,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329634802 with entries=77, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329636129
2014-07-14 02:20:36,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:20:36,192 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:20:36,222 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ff4a0bc4e30241fcb5a4260a81847c2e, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ff4a0bc4e30241fcb5a4260a81847c2e
2014-07-14 02:20:36,225 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/402f8fa042bf46bf8c91d19f3c00245e, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/402f8fa042bf46bf8c91d19f3c00245e
2014-07-14 02:20:36,228 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/71be01c5a5df4fe89e0e4681c4630708, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/71be01c5a5df4fe89e0e4681c4630708
2014-07-14 02:20:36,230 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/971edc57457c47ac995582fd0c144eea, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/971edc57457c47ac995582fd0c144eea
2014-07-14 02:20:36,234 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/14195a276ddd45c09119b3fcf82b8b3e, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/14195a276ddd45c09119b3fcf82b8b3e
2014-07-14 02:20:36,236 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e61b82f2ae5140a4a5a63e3f893df5f5, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e61b82f2ae5140a4a5a63e3f893df5f5
2014-07-14 02:20:36,239 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cbb009e34d5442b68028b2231f907367, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cbb009e34d5442b68028b2231f907367
2014-07-14 02:20:36,242 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fcc8b80a576b43c8a2386fccd7c6ec8e, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/fcc8b80a576b43c8a2386fccd7c6ec8e
2014-07-14 02:20:36,245 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9318d558c77d4434820c0a5e300e100c, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9318d558c77d4434820c0a5e300e100c
2014-07-14 02:20:36,248 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9635333aa663415299f6728c068adadd, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/9635333aa663415299f6728c068adadd
2014-07-14 02:20:36,248 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into 915bbbeb2cc248ff93804d8f54227832(size=931.9m), total size for store is 2.4g. This selection was in queue for 0sec, and took 4mins, 7sec to execute.
2014-07-14 02:20:36,248 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=10, fileSize=1006.5m, priority=4, time=283295914815543; duration=4mins, 7sec
2014-07-14 02:20:36,248 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-14 02:20:36,248 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-14 02:20:36,252 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 170701704 starting at candidate #13 after considering 116 permutations with 111 in ratio
2014-07-14 02:20:36,252 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:20:36,252 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:20:36,252 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=162.8m
2014-07-14 02:20:36,252 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f5a28ac2aa5f4d8c9939e05cd962410c, keycount=93668, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=10413
2014-07-14 02:20:36,252 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/94e195ea9a544197af63956f9ca0c14f, keycount=99837, bloomtype=ROW, size=71.1m, encoding=NONE, seqNum=10593
2014-07-14 02:20:36,252 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/39292b5431a148e1b3e1df6967df1364, keycount=35057, bloomtype=ROW, size=25.0m, encoding=NONE, seqNum=11004
2014-07-14 02:20:36,480 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:36,995 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13111, memsize=312.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/16af1e7052094d8ca9624c18f274fcd3
2014-07-14 02:20:37,005 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/16af1e7052094d8ca9624c18f274fcd3 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/16af1e7052094d8ca9624c18f274fcd3
2014-07-14 02:20:37,313 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/16af1e7052094d8ca9624c18f274fcd3, entries=1136020, sequenceid=13111, filesize=80.8m
2014-07-14 02:20:37,314 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~447.5m/469205520, currentsize=350.3m/367264000 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 16857ms, sequenceid=13111, compaction requested=true
2014-07-14 02:20:37,314 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-14 02:20:37,314 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.4g
2014-07-14 02:20:37,367 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:20:37,433 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:37,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53226 synced till here 53221
2014-07-14 02:20:37,545 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329636129 with entries=79, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329637433
2014-07-14 02:20:38,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:38,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53300 synced till here 53299
2014-07-14 02:20:38,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329637433 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329638447
2014-07-14 02:20:39,108 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:39,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:39,871 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53384 synced till here 53383
2014-07-14 02:20:39,885 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329638447 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329639430
2014-07-14 02:20:40,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:41,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53463 synced till here 53458
2014-07-14 02:20:41,247 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329639430 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329640649
2014-07-14 02:20:42,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:42,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53540 synced till here 53536
2014-07-14 02:20:42,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329640649 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329642339
2014-07-14 02:20:44,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:45,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53616 synced till here 53613
2014-07-14 02:20:45,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329642339 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329644998
2014-07-14 02:20:45,825 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13264, memsize=298.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/340f4f35b2444adcbedd13182d6ea725
2014-07-14 02:20:45,841 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/340f4f35b2444adcbedd13182d6ea725 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/340f4f35b2444adcbedd13182d6ea725
2014-07-14 02:20:45,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:46,426 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/340f4f35b2444adcbedd13182d6ea725, entries=1087410, sequenceid=13264, filesize=77.3m
2014-07-14 02:20:46,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53700 synced till here 53695
2014-07-14 02:20:46,430 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~498.5m/522735600, currentsize=307.7m/322689200 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 14481ms, sequenceid=13264, compaction requested=true
2014-07-14 02:20:46,430 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 02:20:46,430 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 649.4m
2014-07-14 02:20:46,475 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:20:46,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329644998 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329645946
2014-07-14 02:20:46,993 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:20:47,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53774 synced till here 53773
2014-07-14 02:20:47,568 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329645946 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329647529
2014-07-14 02:20:48,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:48,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53850 synced till here 53848
2014-07-14 02:20:49,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329647529 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329648932
2014-07-14 02:20:50,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:50,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53927 synced till here 53924
2014-07-14 02:20:50,506 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329648932 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329650403
2014-07-14 02:20:51,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:51,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54006 synced till here 54003
2014-07-14 02:20:52,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329650403 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329651826
2014-07-14 02:20:53,280 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:53,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54082 synced till here 54081
2014-07-14 02:20:53,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329651826 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329653281
2014-07-14 02:20:55,492 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:55,511 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54155 synced till here 54154
2014-07-14 02:20:55,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329653281 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329655493
2014-07-14 02:20:56,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:20:56,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329655493 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329656717
2014-07-14 02:20:57,861 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,874 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,918 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,920 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,920 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,924 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,941 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:57,967 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,017 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,059 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,106 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,153 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,340 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,392 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,495 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,931 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:58,983 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,029 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,075 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,184 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,228 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,287 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:20:59,671 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,312 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,322 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,346 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,375 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,403 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,432 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,461 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,508 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,550 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,596 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,646 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,711 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,784 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,836 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,878 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,937 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:00,984 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,025 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,207 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,246 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,300 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,360 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,416 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,452 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,530 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,570 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:01,740 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:02,862 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:02,875 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:02,918 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:02,920 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:03,849 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:03,850 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5926ms
2014-07-14 02:21:03,850 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5909ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5886ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5836ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5794ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5747ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5700ms
2014-07-14 02:21:03,853 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5513ms
2014-07-14 02:21:03,854 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5462ms
2014-07-14 02:21:03,854 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5359ms
2014-07-14 02:21:03,931 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:03,983 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:04,030 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:04,075 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:04,184 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:04,228 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:04,288 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,307 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5637ms
2014-07-14 02:21:05,313 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,322 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,347 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,366 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/ec6850bff8f44c32bb8bdd7d3741719b as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/ec6850bff8f44c32bb8bdd7d3741719b
2014-07-14 02:21:05,376 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,383 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:21:05,393 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f5a28ac2aa5f4d8c9939e05cd962410c, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f5a28ac2aa5f4d8c9939e05cd962410c
2014-07-14 02:21:05,397 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/94e195ea9a544197af63956f9ca0c14f, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/94e195ea9a544197af63956f9ca0c14f
2014-07-14 02:21:05,401 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/39292b5431a148e1b3e1df6967df1364, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/39292b5431a148e1b3e1df6967df1364
2014-07-14 02:21:05,401 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into ec6850bff8f44c32bb8bdd7d3741719b(size=159.9m), total size for store is 2.6g. This selection was in queue for 0sec, and took 29sec to execute.
2014-07-14 02:21:05,401 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=3, fileSize=162.8m, priority=0, time=283543679096057; duration=29sec
2014-07-14 02:21:05,402 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 02:21:05,402 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-14 02:21:05,403 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,405 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 185331835 starting at candidate #12 after considering 116 permutations with 107 in ratio
2014-07-14 02:21:05,405 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:21:05,405 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:21:05,405 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=176.7m
2014-07-14 02:21:05,406 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/73069c8e5473410eb0ca13af3d8768dd, keycount=94508, bloomtype=ROW, size=67.3m, encoding=NONE, seqNum=10490
2014-07-14 02:21:05,406 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/84037b41780d408abdb3712a7c7181e4, keycount=88531, bloomtype=ROW, size=63.1m, encoding=NONE, seqNum=10812
2014-07-14 02:21:05,406 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04c45a5b9c064074a985cb92e7b24ad5, keycount=65072, bloomtype=ROW, size=46.4m, encoding=NONE, seqNum=11110
2014-07-14 02:21:05,432 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,461 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,509 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,551 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,572 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:05,596 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,646 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,712 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,784 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,836 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:05,879 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,937 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:05,985 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,026 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,207 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,246 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:06,300 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:06,361 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,416 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,453 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,531 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,571 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:06,741 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:07,907 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10033ms
2014-07-14 02:21:07,907 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10046ms
2014-07-14 02:21:07,919 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:21:07,921 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:21:07,991 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13456, memsize=494.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/218bf59287d940669932bcd5a8399fb6
2014-07-14 02:21:08,009 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/218bf59287d940669932bcd5a8399fb6 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/218bf59287d940669932bcd5a8399fb6
2014-07-14 02:21:08,021 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/218bf59287d940669932bcd5a8399fb6, entries=1798900, sequenceid=13456, filesize=128.0m
2014-07-14 02:21:08,022 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~650.8m/682444640, currentsize=230.1m/241294400 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 21592ms, sequenceid=13456, compaction requested=true
2014-07-14 02:21:08,022 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 02:21:08,022 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10102ms
2014-07-14 02:21:08,022 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,022 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 772.4m
2014-07-14 02:21:08,022 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10105ms
2014-07-14 02:21:08,022 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,022 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10161ms
2014-07-14 02:21:08,022 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,025 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10151ms
2014-07-14 02:21:08,025 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,025 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6286ms
2014-07-14 02:21:08,025 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,025 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6455ms
2014-07-14 02:21:08,025 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,025 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6495ms
2014-07-14 02:21:08,025 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,025 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6573ms
2014-07-14 02:21:08,026 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,028 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6613ms
2014-07-14 02:21:08,028 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,029 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6669ms
2014-07-14 02:21:08,029 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,029 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6729ms
2014-07-14 02:21:08,029 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,036 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6790ms
2014-07-14 02:21:08,036 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,036 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6830ms
2014-07-14 02:21:08,036 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,036 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7011ms
2014-07-14 02:21:08,037 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,037 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7053ms
2014-07-14 02:21:08,037 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,039 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7103ms
2014-07-14 02:21:08,039 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,040 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7162ms
2014-07-14 02:21:08,040 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,040 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7204ms
2014-07-14 02:21:08,040 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,043 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7259ms
2014-07-14 02:21:08,043 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,043 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7332ms
2014-07-14 02:21:08,043 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,045 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7399ms
2014-07-14 02:21:08,045 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,045 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7449ms
2014-07-14 02:21:08,045 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,049 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7499ms
2014-07-14 02:21:08,049 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,051 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7543ms
2014-07-14 02:21:08,051 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,051 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7590ms
2014-07-14 02:21:08,051 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,054 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7622ms
2014-07-14 02:21:08,054 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,054 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7651ms
2014-07-14 02:21:08,054 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,059 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7684ms
2014-07-14 02:21:08,059 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,060 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7713ms
2014-07-14 02:21:08,060 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,060 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7738ms
2014-07-14 02:21:08,060 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,061 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7749ms
2014-07-14 02:21:08,062 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,062 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8392ms
2014-07-14 02:21:08,062 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,062 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8775ms
2014-07-14 02:21:08,062 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,062 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8834ms
2014-07-14 02:21:08,062 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,063 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8878ms
2014-07-14 02:21:08,063 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,065 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8990ms
2014-07-14 02:21:08,065 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,066 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9036ms
2014-07-14 02:21:08,066 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,068 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9084ms
2014-07-14 02:21:08,068 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,069 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9138ms
2014-07-14 02:21:08,069 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,069 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9574ms
2014-07-14 02:21:08,069 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,069 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9677ms
2014-07-14 02:21:08,070 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,070 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9730ms
2014-07-14 02:21:08,070 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,071 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9917ms
2014-07-14 02:21:08,071 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,074 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9968ms
2014-07-14 02:21:08,074 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,076 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10017ms
2014-07-14 02:21:08,076 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,077 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10059ms
2014-07-14 02:21:08,077 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,078 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10110ms
2014-07-14 02:21:08,078 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,078 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10137ms
2014-07-14 02:21:08,078 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,079 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10155ms
2014-07-14 02:21:08,080 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,080 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10160ms
2014-07-14 02:21:08,080 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:08,187 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:08,189 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657505,"queuetimems":0,"class":"HRegionServer","responsesize":15670,"method":"Multi"}
2014-07-14 02:21:08,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54312 synced till here 54301
2014-07-14 02:21:08,272 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657554,"queuetimems":1,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:21:08,315 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10715,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657600,"queuetimems":0,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 02:21:08,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329656717 with entries=84, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329668188
2014-07-14 02:21:08,630 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10993,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657636,"queuetimems":0,"class":"HRegionServer","responsesize":15779,"method":"Multi"}
2014-07-14 02:21:08,750 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657747,"queuetimems":1,"class":"HRegionServer","responsesize":15828,"method":"Multi"}
2014-07-14 02:21:08,754 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657684,"queuetimems":1,"class":"HRegionServer","responsesize":15523,"method":"Multi"}
2014-07-14 02:21:08,945 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:10,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:10,090 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12296,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657794,"queuetimems":0,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 02:21:10,117 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54418 synced till here 54388
2014-07-14 02:21:10,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329668188 with entries=106, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329670079
2014-07-14 02:21:10,418 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:21:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=286722, hits=83110, hitRatio=28.98%, , cachingAccesses=83141, cachingHits=83076, cachingHitsRatio=99.92%, evictions=0, evicted=62, evictedPerRun=Infinity
2014-07-14 02:21:12,218 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660549,"queuetimems":1,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 02:21:12,218 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12992,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659226,"queuetimems":0,"class":"HRegionServer","responsesize":15472,"method":"Multi"}
2014-07-14 02:21:12,218 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11345,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660873,"queuetimems":1,"class":"HRegionServer","responsesize":15766,"method":"Multi"}
2014-07-14 02:21:12,234 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660402,"queuetimems":1,"class":"HRegionServer","responsesize":15779,"method":"Multi"}
2014-07-14 02:21:12,234 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660707,"queuetimems":0,"class":"HRegionServer","responsesize":15705,"method":"Multi"}
2014-07-14 02:21:12,247 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658103,"queuetimems":0,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:21:12,277 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660643,"queuetimems":0,"class":"HRegionServer","responsesize":15744,"method":"Multi"}
2014-07-14 02:21:12,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:12,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54534 synced till here 54499
2014-07-14 02:21:12,591 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660344,"queuetimems":0,"class":"HRegionServer","responsesize":15523,"method":"Multi"}
2014-07-14 02:21:12,740 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658492,"queuetimems":0,"class":"HRegionServer","responsesize":15868,"method":"Multi"}
2014-07-14 02:21:12,740 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658015,"queuetimems":1,"class":"HRegionServer","responsesize":15366,"method":"Multi"}
2014-07-14 02:21:12,740 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660430,"queuetimems":0,"class":"HRegionServer","responsesize":15670,"method":"Multi"}
2014-07-14 02:21:12,740 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658056,"queuetimems":0,"class":"HRegionServer","responsesize":15653,"method":"Multi"}
2014-07-14 02:21:12,741 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13667,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659073,"queuetimems":0,"class":"HRegionServer","responsesize":16042,"method":"Multi"}
2014-07-14 02:21:12,741 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13559,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659181,"queuetimems":1,"class":"HRegionServer","responsesize":15655,"method":"Multi"}
2014-07-14 02:21:12,745 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658982,"queuetimems":1,"class":"HRegionServer","responsesize":15564,"method":"Multi"}
2014-07-14 02:21:12,745 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12435,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660310,"queuetimems":0,"class":"HRegionServer","responsesize":15982,"method":"Multi"}
2014-07-14 02:21:12,746 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14594,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658151,"queuetimems":0,"class":"HRegionServer","responsesize":15898,"method":"Multi"}
2014-07-14 02:21:12,740 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658389,"queuetimems":0,"class":"HRegionServer","responsesize":15105,"method":"Multi"}
2014-07-14 02:21:12,757 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660374,"queuetimems":1,"class":"HRegionServer","responsesize":15828,"method":"Multi"}
2014-07-14 02:21:12,757 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11975,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660782,"queuetimems":1,"class":"HRegionServer","responsesize":15968,"method":"Multi"}
2014-07-14 02:21:12,757 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14420,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658337,"queuetimems":0,"class":"HRegionServer","responsesize":16388,"method":"Multi"}
2014-07-14 02:21:12,757 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11928,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660829,"queuetimems":0,"class":"HRegionServer","responsesize":16026,"method":"Multi"}
2014-07-14 02:21:12,758 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12299,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660459,"queuetimems":0,"class":"HRegionServer","responsesize":15366,"method":"Multi"}
2014-07-14 02:21:12,761 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13832,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329658929,"queuetimems":0,"class":"HRegionServer","responsesize":15972,"method":"Multi"}
2014-07-14 02:21:12,764 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659027,"queuetimems":0,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:21:12,764 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660506,"queuetimems":0,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 02:21:12,764 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660594,"queuetimems":0,"class":"HRegionServer","responsesize":15890,"method":"Multi"}
2014-07-14 02:21:12,765 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12443,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329660320,"queuetimems":0,"class":"HRegionServer","responsesize":15736,"method":"Multi"}
2014-07-14 02:21:12,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329670079 with entries=116, filesize=98.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329672417
2014-07-14 02:21:14,298 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659669,"queuetimems":1,"class":"HRegionServer","responsesize":15959,"method":"Multi"}
2014-07-14 02:21:14,306 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329657963,"queuetimems":0,"class":"HRegionServer","responsesize":15890,"method":"Multi"}
2014-07-14 02:21:14,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:14,873 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329659285,"queuetimems":0,"class":"HRegionServer","responsesize":15644,"method":"Multi"}
2014-07-14 02:21:14,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54635 synced till here 54610
2014-07-14 02:21:16,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329672417 with entries=101, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329674862
2014-07-14 02:21:18,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:18,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54743 synced till here 54729
2014-07-14 02:21:18,691 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,692 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,694 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,694 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,696 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,697 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,697 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,698 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,699 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,699 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,700 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,700 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,701 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,702 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,703 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,705 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,705 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,706 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,709 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,710 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,711 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,712 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,712 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,713 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,716 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,716 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,716 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,718 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,718 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329674862 with entries=108, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329678561
2014-07-14 02:21:18,720 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,721 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,721 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,721 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,723 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,723 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,724 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,725 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,725 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,729 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,729 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,729 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,729 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,731 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,731 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,732 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,750 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,764 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,780 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,785 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,794 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:18,800 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:19,456 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13337, memsize=729.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/739223e5c99d45f58cec822b2c37da2f
2014-07-14 02:21:19,473 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/739223e5c99d45f58cec822b2c37da2f as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/739223e5c99d45f58cec822b2c37da2f
2014-07-14 02:21:19,486 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/739223e5c99d45f58cec822b2c37da2f, entries=2654180, sequenceid=13337, filesize=188.8m
2014-07-14 02:21:19,486 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.4g/1523060000, currentsize=588.6m/617192000 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 42172ms, sequenceid=13337, compaction requested=true
2014-07-14 02:21:19,486 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:101), split_queue=0, merge_queue=0
2014-07-14 02:21:19,487 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 687ms
2014-07-14 02:21:19,487 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,487 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 709.5m
2014-07-14 02:21:19,487 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 693ms
2014-07-14 02:21:19,487 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,487 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 702ms
2014-07-14 02:21:19,487 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,489 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 709ms
2014-07-14 02:21:19,489 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,489 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 725ms
2014-07-14 02:21:19,489 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,489 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 739ms
2014-07-14 02:21:19,489 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,490 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 758ms
2014-07-14 02:21:19,490 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,490 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 759ms
2014-07-14 02:21:19,490 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,499 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 768ms
2014-07-14 02:21:19,499 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,499 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 770ms
2014-07-14 02:21:19,499 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,499 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 774ms
2014-07-14 02:21:19,499 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,501 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 777ms
2014-07-14 02:21:19,501 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,501 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 777ms
2014-07-14 02:21:19,501 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,501 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 776ms
2014-07-14 02:21:19,501 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,501 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 776ms
2014-07-14 02:21:19,501 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,502 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 778ms
2014-07-14 02:21:19,502 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,502 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 779ms
2014-07-14 02:21:19,502 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,503 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 779ms
2014-07-14 02:21:19,503 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,505 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 784ms
2014-07-14 02:21:19,505 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,505 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 784ms
2014-07-14 02:21:19,505 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,515 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 794ms
2014-07-14 02:21:19,515 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,521 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 801ms
2014-07-14 02:21:19,521 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,521 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 803ms
2014-07-14 02:21:19,521 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,521 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 816ms
2014-07-14 02:21:19,521 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,524 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 818ms
2014-07-14 02:21:19,524 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,528 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 812ms
2014-07-14 02:21:19,528 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,530 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 817ms
2014-07-14 02:21:19,531 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,531 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 819ms
2014-07-14 02:21:19,531 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,534 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 822ms
2014-07-14 02:21:19,534 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,534 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 823ms
2014-07-14 02:21:19,535 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,535 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 825ms
2014-07-14 02:21:19,535 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,535 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 826ms
2014-07-14 02:21:19,535 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,535 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 829ms
2014-07-14 02:21:19,535 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,535 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 830ms
2014-07-14 02:21:19,536 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,536 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 831ms
2014-07-14 02:21:19,536 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,541 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 838ms
2014-07-14 02:21:19,541 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,541 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 839ms
2014-07-14 02:21:19,541 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,541 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 840ms
2014-07-14 02:21:19,541 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,541 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 841ms
2014-07-14 02:21:19,541 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,542 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 841ms
2014-07-14 02:21:19,542 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,543 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 843ms
2014-07-14 02:21:19,543 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,543 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 844ms
2014-07-14 02:21:19,543 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,547 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 848ms
2014-07-14 02:21:19,547 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,548 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 850ms
2014-07-14 02:21:19,548 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,552 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 855ms
2014-07-14 02:21:19,552 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,552 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 856ms
2014-07-14 02:21:19,553 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,553 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 859ms
2014-07-14 02:21:19,553 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,557 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 863ms
2014-07-14 02:21:19,558 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,565 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 873ms
2014-07-14 02:21:19,565 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,566 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 874ms
2014-07-14 02:21:19,566 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:19,761 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:21:21,183 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1121ms
GC pool 'ParNew' had collection(s): count=1 time=1353ms
2014-07-14 02:21:21,467 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:21,699 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:21,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54851 synced till here 54819
2014-07-14 02:21:22,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329678561 with entries=108, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329681699
2014-07-14 02:21:22,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329549931
2014-07-14 02:21:22,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329551386
2014-07-14 02:21:22,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329552475
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329554036
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329555410
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329556971
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329558327
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329559673
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329561298
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329567128
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329571444
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329574044
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329577178
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329579545
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329583286
2014-07-14 02:21:22,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329585836
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329588203
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329590693
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329592870
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329599058
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329600225
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329601366
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329603070
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329605503
2014-07-14 02:21:22,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329607660
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329609603
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329611223
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329612756
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329614305
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329615201
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329616809
2014-07-14 02:21:22,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329618298
2014-07-14 02:21:24,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:24,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54960 synced till here 54926
2014-07-14 02:21:25,273 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1023ms
GC pool 'ParNew' had collection(s): count=1 time=1061ms
2014-07-14 02:21:25,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329681699 with entries=109, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329684098
2014-07-14 02:21:27,236 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:27,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55074 synced till here 55046
2014-07-14 02:21:27,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329684098 with entries=114, filesize=97.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329687238
2014-07-14 02:21:29,482 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:29,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55187 synced till here 55154
2014-07-14 02:21:29,792 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329687238 with entries=113, filesize=95.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329689483
2014-07-14 02:21:31,758 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1021ms
GC pool 'ParNew' had collection(s): count=1 time=1456ms
2014-07-14 02:21:32,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:32,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55309 synced till here 55272
2014-07-14 02:21:32,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329689483 with entries=122, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329692223
2014-07-14 02:21:34,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:34,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55410 synced till here 55384
2014-07-14 02:21:34,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329692223 with entries=101, filesize=84.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329694693
2014-07-14 02:21:36,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:36,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55516 synced till here 55493
2014-07-14 02:21:36,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329694693 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329696371
2014-07-14 02:21:38,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:38,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55627 synced till here 55604
2014-07-14 02:21:38,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329696371 with entries=111, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329698044
2014-07-14 02:21:38,988 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,988 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,989 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,989 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,990 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,993 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,994 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,994 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:38,996 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,090 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,090 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,091 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,091 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,091 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,091 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,097 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,811 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,841 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,871 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,900 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,927 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,957 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:39,984 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,013 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,041 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,069 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,097 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,123 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,152 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,180 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,210 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,236 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,264 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,293 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,321 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,349 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,378 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,410 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,437 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,465 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:40,494 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,108 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,149 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,191 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,297 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,331 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,374 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,421 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,457 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:42,495 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:21:43,988 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:43,989 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:43,989 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:43,990 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:43,991 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:43,994 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:43,994 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:43,994 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:43,996 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,090 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,090 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,091 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,091 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,091 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,092 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,097 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,811 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,841 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,871 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,900 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,928 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:44,957 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:44,985 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:45,013 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,041 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,069 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,097 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,124 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:45,152 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,180 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,210 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,237 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:45,264 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,293 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,322 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,349 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,379 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,410 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:45,437 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,465 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:45,495 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,109 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,150 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,192 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,297 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,332 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:47,374 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,421 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,458 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:21:47,495 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:21:47,819 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13611, memsize=641.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/22682bcc6b6145f0b1eaf84294cfbb78
2014-07-14 02:21:47,942 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/22682bcc6b6145f0b1eaf84294cfbb78 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/22682bcc6b6145f0b1eaf84294cfbb78
2014-07-14 02:21:47,962 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/22682bcc6b6145f0b1eaf84294cfbb78, entries=2335950, sequenceid=13611, filesize=166.3m
2014-07-14 02:21:47,963 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~772.4m/809916480, currentsize=549.1m/575780720 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 39941ms, sequenceid=13611, compaction requested=true
2014-07-14 02:21:47,963 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-14 02:21:47,963 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5468ms
2014-07-14 02:21:47,963 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,963 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 765.2m
2014-07-14 02:21:47,963 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5506ms
2014-07-14 02:21:47,964 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,964 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5543ms
2014-07-14 02:21:47,964 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,964 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5590ms
2014-07-14 02:21:47,964 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,969 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5638ms
2014-07-14 02:21:47,969 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,969 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5672ms
2014-07-14 02:21:47,969 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,969 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5778ms
2014-07-14 02:21:47,969 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,977 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5828ms
2014-07-14 02:21:47,977 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,977 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5869ms
2014-07-14 02:21:47,977 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,977 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7483ms
2014-07-14 02:21:47,977 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,977 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7512ms
2014-07-14 02:21:47,978 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,981 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7544ms
2014-07-14 02:21:47,982 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,989 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7580ms
2014-07-14 02:21:47,990 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,990 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7612ms
2014-07-14 02:21:47,990 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,991 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7641ms
2014-07-14 02:21:47,991 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,991 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7670ms
2014-07-14 02:21:47,991 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,997 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7704ms
2014-07-14 02:21:47,997 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:47,998 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7733ms
2014-07-14 02:21:47,998 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,007 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7771ms
2014-07-14 02:21:48,007 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,008 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7798ms
2014-07-14 02:21:48,008 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,009 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7829ms
2014-07-14 02:21:48,010 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,010 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7858ms
2014-07-14 02:21:48,010 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,011 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7888ms
2014-07-14 02:21:48,011 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,012 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7915ms
2014-07-14 02:21:48,013 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,013 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7944ms
2014-07-14 02:21:48,013 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,015 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7974ms
2014-07-14 02:21:48,015 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,018 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8004ms
2014-07-14 02:21:48,018 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,019 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8034ms
2014-07-14 02:21:48,020 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,020 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8063ms
2014-07-14 02:21:48,021 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,021 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8094ms
2014-07-14 02:21:48,021 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,023 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8123ms
2014-07-14 02:21:48,023 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,023 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8152ms
2014-07-14 02:21:48,024 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,024 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8183ms
2014-07-14 02:21:48,024 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,031 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8213ms
2014-07-14 02:21:48,031 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,032 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8935ms
2014-07-14 02:21:48,032 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,033 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8942ms
2014-07-14 02:21:48,033 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,035 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8944ms
2014-07-14 02:21:48,035 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,045 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8955ms
2014-07-14 02:21:48,045 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,051 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8961ms
2014-07-14 02:21:48,051 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,052 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8961ms
2014-07-14 02:21:48,052 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,054 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8965ms
2014-07-14 02:21:48,054 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,055 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9058ms
2014-07-14 02:21:48,055 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,056 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9061ms
2014-07-14 02:21:48,056 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,061 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9067ms
2014-07-14 02:21:48,061 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,065 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9072ms
2014-07-14 02:21:48,065 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,068 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/4914e6e85054428f8de6e9f176aef83f as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4914e6e85054428f8de6e9f176aef83f
2014-07-14 02:21:48,073 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9083ms
2014-07-14 02:21:48,073 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,073 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9084ms
2014-07-14 02:21:48,073 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,073 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9085ms
2014-07-14 02:21:48,073 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,074 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9085ms
2014-07-14 02:21:48,074 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,075 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9087ms
2014-07-14 02:21:48,075 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:21:48,247 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:48,277 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:21:48,310 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/73069c8e5473410eb0ca13af3d8768dd, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/73069c8e5473410eb0ca13af3d8768dd
2014-07-14 02:21:48,314 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/84037b41780d408abdb3712a7c7181e4, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/84037b41780d408abdb3712a7c7181e4
2014-07-14 02:21:48,319 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04c45a5b9c064074a985cb92e7b24ad5, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/04c45a5b9c064074a985cb92e7b24ad5
2014-07-14 02:21:48,319 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into 4914e6e85054428f8de6e9f176aef83f(size=156.5m), total size for store is 2.6g. This selection was in queue for 0sec, and took 42sec to execute.
2014-07-14 02:21:48,319 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=176.7m, priority=0, time=283572832333249; duration=42sec
2014-07-14 02:21:48,320 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-14 02:21:48,320 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-14 02:21:48,323 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 351622122 starting at candidate #2 after considering 116 permutations with 111 in ratio
2014-07-14 02:21:48,323 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:21:48,324 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:21:48,324 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=335.3m
2014-07-14 02:21:48,324 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/d0fb0b813814411985b96ae65d1fa577, keycount=115439, bloomtype=ROW, size=82.2m, encoding=NONE, seqNum=5452
2014-07-14 02:21:48,325 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f9e187064d7e48e4aa90454305902294, keycount=149491, bloomtype=ROW, size=106.4m, encoding=NONE, seqNum=5855
2014-07-14 02:21:48,325 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/bd8ca60cbd1e46ce96f049e7aed1572a, keycount=127704, bloomtype=ROW, size=90.9m, encoding=NONE, seqNum=6460
2014-07-14 02:21:48,325 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/07d2ffb735304638a7c7a385f4aa0b5e, keycount=78262, bloomtype=ROW, size=55.8m, encoding=NONE, seqNum=6967
2014-07-14 02:21:48,665 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55710 synced till here 55701
2014-07-14 02:21:48,760 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:48,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329698044 with entries=83, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329708248
2014-07-14 02:21:48,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329619602
2014-07-14 02:21:48,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329621212
2014-07-14 02:21:48,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329622610
2014-07-14 02:21:48,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329625240
2014-07-14 02:21:48,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329627302
2014-07-14 02:21:48,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329628835
2014-07-14 02:21:48,901 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:21:49,116 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11477,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329697638,"queuetimems":5859,"class":"HRegionServer","responsesize":15619,"method":"Multi"}
2014-07-14 02:21:49,138 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11091,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698046,"queuetimems":6181,"class":"HRegionServer","responsesize":15968,"method":"Multi"}
2014-07-14 02:21:49,138 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329697002,"queuetimems":6726,"class":"HRegionServer","responsesize":15739,"method":"Multi"}
2014-07-14 02:21:49,138 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329696994,"queuetimems":6749,"class":"HRegionServer","responsesize":15834,"method":"Multi"}
2014-07-14 02:21:49,138 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12144,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329696993,"queuetimems":6805,"class":"HRegionServer","responsesize":15887,"method":"Multi"}
2014-07-14 02:21:49,138 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11492,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329697645,"queuetimems":5846,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-14 02:21:49,142 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10866,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698275,"queuetimems":6192,"class":"HRegionServer","responsesize":15886,"method":"Multi"}
2014-07-14 02:21:49,177 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:49,319 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698046,"queuetimems":6132,"class":"HRegionServer","responsesize":16026,"method":"Multi"}
2014-07-14 02:21:49,329 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698046,"queuetimems":6088,"class":"HRegionServer","responsesize":15625,"method":"Multi"}
2014-07-14 02:21:49,329 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329697892,"queuetimems":6065,"class":"HRegionServer","responsesize":15755,"method":"Multi"}
2014-07-14 02:21:50,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:50,088 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698286,"queuetimems":6168,"class":"HRegionServer","responsesize":15651,"method":"Multi"}
2014-07-14 02:21:50,090 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11817,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698273,"queuetimems":6244,"class":"HRegionServer","responsesize":15777,"method":"Multi"}
2014-07-14 02:21:50,091 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11801,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698290,"queuetimems":6101,"class":"HRegionServer","responsesize":15744,"method":"Multi"}
2014-07-14 02:21:50,092 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698290,"queuetimems":6136,"class":"HRegionServer","responsesize":15707,"method":"Multi"}
2014-07-14 02:21:50,094 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698270,"queuetimems":6280,"class":"HRegionServer","responsesize":15766,"method":"Multi"}
2014-07-14 02:21:50,095 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329698294,"queuetimems":6069,"class":"HRegionServer","responsesize":15727,"method":"Multi"}
2014-07-14 02:21:50,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55835 synced till here 55821
2014-07-14 02:21:50,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329708248 with entries=125, filesize=106.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329710049
2014-07-14 02:21:50,961 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700376,"queuetimems":0,"class":"HRegionServer","responsesize":15890,"method":"Multi"}
2014-07-14 02:21:50,963 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700435,"queuetimems":1,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:21:50,964 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10615,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700348,"queuetimems":1,"class":"HRegionServer","responsesize":15898,"method":"Multi"}
2014-07-14 02:21:50,965 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10560,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700404,"queuetimems":0,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:21:50,966 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700262,"queuetimems":0,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 02:21:50,966 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700178,"queuetimems":0,"class":"HRegionServer","responsesize":15653,"method":"Multi"}
2014-07-14 02:21:51,021 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699839,"queuetimems":0,"class":"HRegionServer","responsesize":15736,"method":"Multi"}
2014-07-14 02:21:51,248 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11097,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700150,"queuetimems":0,"class":"HRegionServer","responsesize":15868,"method":"Multi"}
2014-07-14 02:21:51,248 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11378,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699869,"queuetimems":0,"class":"HRegionServer","responsesize":15959,"method":"Multi"}
2014-07-14 02:21:51,381 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700319,"queuetimems":0,"class":"HRegionServer","responsesize":15644,"method":"Multi"}
2014-07-14 02:21:51,382 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11572,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699809,"queuetimems":0,"class":"HRegionServer","responsesize":15828,"method":"Multi"}
2014-07-14 02:21:51,382 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10888,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700492,"queuetimems":0,"class":"HRegionServer","responsesize":15982,"method":"Multi"}
2014-07-14 02:21:51,382 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11091,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700291,"queuetimems":0,"class":"HRegionServer","responsesize":16388,"method":"Multi"}
2014-07-14 02:21:51,382 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11484,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699898,"queuetimems":1,"class":"HRegionServer","responsesize":16042,"method":"Multi"}
2014-07-14 02:21:51,382 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700067,"queuetimems":0,"class":"HRegionServer","responsesize":15779,"method":"Multi"}
2014-07-14 02:21:51,383 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11287,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700095,"queuetimems":0,"class":"HRegionServer","responsesize":15366,"method":"Multi"}
2014-07-14 02:21:51,383 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11343,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700039,"queuetimems":0,"class":"HRegionServer","responsesize":15523,"method":"Multi"}
2014-07-14 02:21:51,383 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11400,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699982,"queuetimems":0,"class":"HRegionServer","responsesize":15564,"method":"Multi"}
2014-07-14 02:21:51,515 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700122,"queuetimems":1,"class":"HRegionServer","responsesize":15105,"method":"Multi"}
2014-07-14 02:21:51,515 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700206,"queuetimems":0,"class":"HRegionServer","responsesize":15670,"method":"Multi"}
2014-07-14 02:21:51,515 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700011,"queuetimems":0,"class":"HRegionServer","responsesize":15655,"method":"Multi"}
2014-07-14 02:21:51,516 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11589,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699926,"queuetimems":0,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:21:51,515 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11559,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329699955,"queuetimems":1,"class":"HRegionServer","responsesize":15972,"method":"Multi"}
2014-07-14 02:21:51,516 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11052,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700463,"queuetimems":1,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 02:21:51,516 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11280,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329700235,"queuetimems":1,"class":"HRegionServer","responsesize":15472,"method":"Multi"}
2014-07-14 02:21:51,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:51,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329710049 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329711536
2014-07-14 02:21:53,337 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13724, memsize=591.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/fedd2aeb548f4f3f97d72500df542bb2
2014-07-14 02:21:53,351 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/fedd2aeb548f4f3f97d72500df542bb2 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fedd2aeb548f4f3f97d72500df542bb2
2014-07-14 02:21:53,493 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:53,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55984 synced till here 55980
2014-07-14 02:21:53,592 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fedd2aeb548f4f3f97d72500df542bb2, entries=2154830, sequenceid=13724, filesize=153.4m
2014-07-14 02:21:53,593 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~709.5m/743972240, currentsize=483.3m/506734400 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 34105ms, sequenceid=13724, compaction requested=true
2014-07-14 02:21:53,593 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-14 02:21:53,593 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.0g
2014-07-14 02:21:53,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329711536 with entries=77, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329713494
2014-07-14 02:21:53,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329630178
2014-07-14 02:21:53,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329632408
2014-07-14 02:21:53,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329633598
2014-07-14 02:21:53,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329634802
2014-07-14 02:21:53,746 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:21:54,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:54,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56057 synced till here 56056
2014-07-14 02:21:54,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329713494 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329714885
2014-07-14 02:21:55,320 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:21:56,123 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:56,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56140 synced till here 56139
2014-07-14 02:21:56,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329714885 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329716124
2014-07-14 02:21:57,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:57,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56218 synced till here 56214
2014-07-14 02:21:57,904 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329716124 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329717823
2014-07-14 02:21:59,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:21:59,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56294 synced till here 56291
2014-07-14 02:21:59,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329717823 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329719674
2014-07-14 02:22:00,909 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:00,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56371 synced till here 56365
2014-07-14 02:22:01,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329719674 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329720910
2014-07-14 02:22:02,261 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:02,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56450 synced till here 56444
2014-07-14 02:22:02,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329720910 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329722262
2014-07-14 02:22:03,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:03,664 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56525 synced till here 56523
2014-07-14 02:22:03,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329722262 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329723650
2014-07-14 02:22:04,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:04,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56598 synced till here 56597
2014-07-14 02:22:04,864 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13952, memsize=295.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/3ed99555c5854aec8a0656312deed2cf
2014-07-14 02:22:04,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329723650 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329724843
2014-07-14 02:22:04,874 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/3ed99555c5854aec8a0656312deed2cf as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3ed99555c5854aec8a0656312deed2cf
2014-07-14 02:22:04,888 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3ed99555c5854aec8a0656312deed2cf, entries=1074720, sequenceid=13952, filesize=76.5m
2014-07-14 02:22:04,888 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~765.2m/802420880, currentsize=354.3m/371471040 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 16925ms, sequenceid=13952, compaction requested=true
2014-07-14 02:22:04,888 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:103), split_queue=0, merge_queue=0
2014-07-14 02:22:04,889 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 892.5m
2014-07-14 02:22:04,890 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:22:05,676 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:22:05,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:05,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56672 synced till here 56669
2014-07-14 02:22:05,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329724843 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329725715
2014-07-14 02:22:07,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:07,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56766 synced till here 56764
2014-07-14 02:22:07,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329725715 with entries=94, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329727114
2014-07-14 02:22:09,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:09,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56850 synced till here 56841
2014-07-14 02:22:09,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329727114 with entries=84, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329729302
2014-07-14 02:22:11,341 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:11,387 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56935 synced till here 56924
2014-07-14 02:22:11,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329729302 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329731341
2014-07-14 02:22:13,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:13,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57017 synced till here 57006
2014-07-14 02:22:13,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329731341 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329733087
2014-07-14 02:22:15,227 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:15,240 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,240 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,243 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,243 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,247 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,247 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,248 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,248 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,257 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,258 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,258 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,259 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,259 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,259 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,260 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,260 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,260 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,260 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,261 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,265 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,279 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,303 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,334 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,339 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,355 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,381 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,426 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,459 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,498 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,531 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,570 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,606 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,650 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,684 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,737 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,756 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329733087 with entries=104, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329735228
2014-07-14 02:22:15,775 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,819 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,856 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,899 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,934 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,966 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:15,998 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:16,031 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:16,066 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,174 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,189 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,213 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,241 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,270 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:18,301 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:22:20,203 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14191, memsize=215.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f2ff5c6f0e724786b85486f26e2e7dc6
2014-07-14 02:22:20,221 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/f2ff5c6f0e724786b85486f26e2e7dc6 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f2ff5c6f0e724786b85486f26e2e7dc6
2014-07-14 02:22:20,238 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f2ff5c6f0e724786b85486f26e2e7dc6, entries=785280, sequenceid=14191, filesize=55.9m
2014-07-14 02:22:20,238 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~897.2m/940799680, currentsize=215.7m/226148880 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 15349ms, sequenceid=14191, compaction requested=true
2014-07-14 02:22:20,239 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:104), split_queue=0, merge_queue=0
2014-07-14 02:22:20,239 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1938ms
2014-07-14 02:22:20,239 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,239 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 927.5m
2014-07-14 02:22:20,239 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1969ms
2014-07-14 02:22:20,239 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,240 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1999ms
2014-07-14 02:22:20,240 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,241 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:22:20,241 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,241 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2028ms
2014-07-14 02:22:20,241 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,243 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2054ms
2014-07-14 02:22:20,244 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,244 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:22:20,244 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,245 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2071ms
2014-07-14 02:22:20,245 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,246 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4179ms
2014-07-14 02:22:20,246 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,246 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4215ms
2014-07-14 02:22:20,246 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,247 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4248ms
2014-07-14 02:22:20,247 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,248 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4281ms
2014-07-14 02:22:20,248 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,256 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5009ms
2014-07-14 02:22:20,256 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,258 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4323ms
2014-07-14 02:22:20,258 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,259 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4359ms
2014-07-14 02:22:20,259 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,259 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4403ms
2014-07-14 02:22:20,259 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,259 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4440ms
2014-07-14 02:22:20,259 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,259 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4484ms
2014-07-14 02:22:20,260 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,260 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 02:22:20,260 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,261 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4523ms
2014-07-14 02:22:20,261 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,262 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4577ms
2014-07-14 02:22:20,262 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,263 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4612ms
2014-07-14 02:22:20,263 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,265 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4658ms
2014-07-14 02:22:20,265 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,266 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:22:20,267 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,272 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4702ms
2014-07-14 02:22:20,272 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,272 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4741ms
2014-07-14 02:22:20,272 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,274 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4775ms
2014-07-14 02:22:20,274 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,275 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4815ms
2014-07-14 02:22:20,275 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,276 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4849ms
2014-07-14 02:22:20,276 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,277 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4895ms
2014-07-14 02:22:20,277 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,280 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4925ms
2014-07-14 02:22:20,280 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,289 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4950ms
2014-07-14 02:22:20,289 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,289 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4955ms
2014-07-14 02:22:20,289 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,290 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4987ms
2014-07-14 02:22:20,290 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,309 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5030ms
2014-07-14 02:22:20,310 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5050ms
2014-07-14 02:22:20,312 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,313 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-14 02:22:20,313 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,314 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5059ms
2014-07-14 02:22:20,314 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,314 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5060ms
2014-07-14 02:22:20,314 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,317 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-14 02:22:20,317 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,325 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-14 02:22:20,325 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,326 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-14 02:22:20,326 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,326 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5068ms
2014-07-14 02:22:20,326 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,326 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-14 02:22:20,326 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,333 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5085ms
2014-07-14 02:22:20,333 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,333 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5093ms
2014-07-14 02:22:20,333 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,333 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5086ms
2014-07-14 02:22:20,333 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,337 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5090ms
2014-07-14 02:22:20,337 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,337 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5094ms
2014-07-14 02:22:20,337 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:20,337 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5097ms
2014-07-14 02:22:20,337 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:22:22,001 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:22:22,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:22,594 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:22:23,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57249 synced till here 57243
2014-07-14 02:22:23,792 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329735228 with entries=128, filesize=106.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329742589
2014-07-14 02:22:23,882 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14032, memsize=487.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/b4bf44c0d1914e4faffdce0b5dab6532
2014-07-14 02:22:23,915 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/b4bf44c0d1914e4faffdce0b5dab6532 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b4bf44c0d1914e4faffdce0b5dab6532
2014-07-14 02:22:23,943 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b4bf44c0d1914e4faffdce0b5dab6532, entries=1776590, sequenceid=14032, filesize=126.5m
2014-07-14 02:22:23,970 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1124461760, currentsize=466.0m/488597520 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 30377ms, sequenceid=14032, compaction requested=true
2014-07-14 02:22:23,971 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:105), split_queue=0, merge_queue=0
2014-07-14 02:22:23,971 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 596.6m
2014-07-14 02:22:24,349 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:22:24,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:24,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57354 synced till here 57322
2014-07-14 02:22:25,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329742589 with entries=105, filesize=90.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329744708
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329636129
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329637433
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329638447
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329639430
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329640649
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329642339
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329644998
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329645946
2014-07-14 02:22:25,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329647529
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329648932
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329650403
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329651826
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329653281
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329655493
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329656717
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329668188
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329670079
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329672417
2014-07-14 02:22:25,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329674862
2014-07-14 02:22:25,751 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:22:27,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:27,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57470 synced till here 57433
2014-07-14 02:22:28,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329744708 with entries=116, filesize=99.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329747521
2014-07-14 02:22:29,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:29,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57564 synced till here 57548
2014-07-14 02:22:29,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329747521 with entries=94, filesize=80.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329749285
2014-07-14 02:22:31,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57669 synced till here 57661
2014-07-14 02:22:31,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329749285 with entries=105, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329751248
2014-07-14 02:22:33,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:33,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329751248 with entries=91, filesize=78.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329753729
2014-07-14 02:22:35,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:35,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57833 synced till here 57832
2014-07-14 02:22:35,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329753729 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329755652
2014-07-14 02:22:37,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:37,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57944 synced till here 57942
2014-07-14 02:22:37,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329755652 with entries=111, filesize=95.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329757097
2014-07-14 02:22:38,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:38,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329757097 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329758729
2014-07-14 02:22:40,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:40,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58092 synced till here 58084
2014-07-14 02:22:40,648 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329758729 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329760533
2014-07-14 02:22:41,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:41,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58168 synced till here 58163
2014-07-14 02:22:42,165 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329760533 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329761887
2014-07-14 02:22:43,695 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:43,712 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58242 synced till here 58240
2014-07-14 02:22:43,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329761887 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329763695
2014-07-14 02:22:43,859 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14324, memsize=359.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/26121a0962fc4fcb9e89d6d50b98184f
2014-07-14 02:22:43,874 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/26121a0962fc4fcb9e89d6d50b98184f as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/26121a0962fc4fcb9e89d6d50b98184f
2014-07-14 02:22:43,887 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/26121a0962fc4fcb9e89d6d50b98184f, entries=1307020, sequenceid=14324, filesize=93.1m
2014-07-14 02:22:43,888 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~927.5m/972503360, currentsize=434.0m/455053840 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 23649ms, sequenceid=14324, compaction requested=true
2014-07-14 02:22:43,888 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-14 02:22:43,888 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:22:43,888 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-14 02:22:43,889 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 876.9m
2014-07-14 02:22:43,889 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:22:44,175 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14354, memsize=358.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/df495c966e794018b158f457d8c61e35
2014-07-14 02:22:44,192 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/df495c966e794018b158f457d8c61e35 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/df495c966e794018b158f457d8c61e35
2014-07-14 02:22:44,380 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/df495c966e794018b158f457d8c61e35, entries=1305700, sequenceid=14354, filesize=93.0m
2014-07-14 02:22:44,381 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.2m/653452960, currentsize=387.6m/406463520 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 20410ms, sequenceid=14354, compaction requested=true
2014-07-14 02:22:44,381 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-14 02:22:44,381 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 447.7m
2014-07-14 02:22:44,850 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:22:45,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:45,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58322 synced till here 58316
2014-07-14 02:22:45,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329763695 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329765014
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329678561
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329681699
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329684098
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329687238
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329689483
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329692223
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329694693
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329696371
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329698044
2014-07-14 02:22:45,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329708248
2014-07-14 02:22:45,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329710049
2014-07-14 02:22:45,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329711536
2014-07-14 02:22:45,251 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:22:45,252 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:22:46,384 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:46,400 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58397 synced till here 58393
2014-07-14 02:22:46,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329765014 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329766385
2014-07-14 02:22:47,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:47,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58475 synced till here 58472
2014-07-14 02:22:47,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329766385 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329767781
2014-07-14 02:22:49,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:49,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58557 synced till here 58545
2014-07-14 02:22:49,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329767781 with entries=82, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329769435
2014-07-14 02:22:51,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:51,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58641 synced till here 58630
2014-07-14 02:22:51,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329769435 with entries=84, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329771125
2014-07-14 02:22:52,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:52,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58724 synced till here 58715
2014-07-14 02:22:52,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329771125 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329772684
2014-07-14 02:22:54,577 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:54,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58811 synced till here 58800
2014-07-14 02:22:54,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329772684 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329774578
2014-07-14 02:22:56,639 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:56,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58909 synced till here 58908
2014-07-14 02:22:56,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329774578 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329776640
2014-07-14 02:22:58,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:22:58,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58994 synced till here 58982
2014-07-14 02:22:58,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329776640 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329778791
2014-07-14 02:23:00,535 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/80d9a77cf1c44168afc42f814df616db as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/80d9a77cf1c44168afc42f814df616db
2014-07-14 02:23:00,719 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:23:00,738 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/d0fb0b813814411985b96ae65d1fa577, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/d0fb0b813814411985b96ae65d1fa577
2014-07-14 02:23:00,744 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f9e187064d7e48e4aa90454305902294, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f9e187064d7e48e4aa90454305902294
2014-07-14 02:23:00,747 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/bd8ca60cbd1e46ce96f049e7aed1572a, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/bd8ca60cbd1e46ce96f049e7aed1572a
2014-07-14 02:23:00,749 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/07d2ffb735304638a7c7a385f4aa0b5e, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/07d2ffb735304638a7c7a385f4aa0b5e
2014-07-14 02:23:00,749 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 80d9a77cf1c44168afc42f814df616db(size=299.3m), total size for store is 2.8g. This selection was in queue for 0sec, and took 1mins, 12sec to execute.
2014-07-14 02:23:00,750 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=4, fileSize=335.3m, priority=0, time=283615750789620; duration=1mins, 12sec
2014-07-14 02:23:00,750 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-14 02:23:00,750 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-14 02:23:00,753 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 210388388 starting at candidate #9 after considering 116 permutations with 106 in ratio
2014-07-14 02:23:00,753 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:23:00,753 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:23:00,753 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=200.6m
2014-07-14 02:23:00,754 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/0b53a10e6828412f839d190363f92d9a, keycount=88636, bloomtype=ROW, size=63.1m, encoding=NONE, seqNum=9969
2014-07-14 02:23:00,754 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bd86a997b7074b059450823eb354c8b2, keycount=99219, bloomtype=ROW, size=70.6m, encoding=NONE, seqNum=10155
2014-07-14 02:23:00,754 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/50eff9f83b3f4826877b625d942718c1, keycount=93910, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=10322
2014-07-14 02:23:00,877 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:01,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:01,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59098 synced till here 59078
2014-07-14 02:23:01,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329778791 with entries=104, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329781078
2014-07-14 02:23:02,488 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14614, memsize=243.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/90b07a2c4f1c4c64a62fc70554fa2489
2014-07-14 02:23:02,507 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/90b07a2c4f1c4c64a62fc70554fa2489 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/90b07a2c4f1c4c64a62fc70554fa2489
2014-07-14 02:23:02,541 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/90b07a2c4f1c4c64a62fc70554fa2489, entries=887680, sequenceid=14614, filesize=63.2m
2014-07-14 02:23:02,541 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~449.3m/471112240, currentsize=322.5m/338138240 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 18160ms, sequenceid=14614, compaction requested=true
2014-07-14 02:23:02,542 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-14 02:23:02,542 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 992.1m
2014-07-14 02:23:02,753 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:23:03,196 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:03,269 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59193 synced till here 59171
2014-07-14 02:23:03,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329781078 with entries=95, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329783197
2014-07-14 02:23:05,037 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:05,401 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:05,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59294 synced till here 59267
2014-07-14 02:23:05,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329783197 with entries=101, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329785401
2014-07-14 02:23:07,299 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:07,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329785401 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329787300
2014-07-14 02:23:08,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:08,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59446 synced till here 59437
2014-07-14 02:23:09,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329787300 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329788953
2014-07-14 02:23:10,943 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:10,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329788953 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329790943
2014-07-14 02:23:12,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:13,847 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59637 synced till here 59623
2014-07-14 02:23:13,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329790943 with entries=119, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329792556
2014-07-14 02:23:14,188 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,189 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,190 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,193 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,199 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,230 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,241 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,244 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,244 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,247 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,247 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,247 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,260 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,274 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,276 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,277 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,292 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,322 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,322 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,323 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,323 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,324 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,350 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,353 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,353 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,353 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,380 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,411 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,444 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,476 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,506 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,536 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,566 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,596 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,626 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,661 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,692 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,722 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,752 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,783 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,820 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,852 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,884 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,930 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:14,968 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:15,006 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:15,048 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:16,228 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:16,237 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:16,251 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:18,273 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14601, memsize=507.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/a06716b3bcc048e48f5029761ff7da5b
2014-07-14 02:23:18,289 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/a06716b3bcc048e48f5029761ff7da5b as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a06716b3bcc048e48f5029761ff7da5b
2014-07-14 02:23:18,306 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a06716b3bcc048e48f5029761ff7da5b, entries=1849350, sequenceid=14601, filesize=131.7m
2014-07-14 02:23:18,306 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~883.1m/925962720, currentsize=537.4m/563538240 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 34417ms, sequenceid=14601, compaction requested=true
2014-07-14 02:23:18,306 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:109), split_queue=0, merge_queue=0
2014-07-14 02:23:18,306 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2055ms
2014-07-14 02:23:18,306 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,306 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 926.5m
2014-07-14 02:23:18,307 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2069ms
2014-07-14 02:23:18,307 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,309 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2081ms
2014-07-14 02:23:18,309 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,309 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3261ms
2014-07-14 02:23:18,309 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,309 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3303ms
2014-07-14 02:23:18,309 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,309 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3341ms
2014-07-14 02:23:18,309 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,313 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3383ms
2014-07-14 02:23:18,313 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,325 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3442ms
2014-07-14 02:23:18,325 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,325 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3473ms
2014-07-14 02:23:18,325 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,325 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3505ms
2014-07-14 02:23:18,325 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,325 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3542ms
2014-07-14 02:23:18,325 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,329 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3577ms
2014-07-14 02:23:18,329 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,329 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3607ms
2014-07-14 02:23:18,329 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,329 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3637ms
2014-07-14 02:23:18,330 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,333 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3672ms
2014-07-14 02:23:18,333 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,333 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3707ms
2014-07-14 02:23:18,333 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,333 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3738ms
2014-07-14 02:23:18,333 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,340 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3774ms
2014-07-14 02:23:18,340 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,344 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3808ms
2014-07-14 02:23:18,344 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,344 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3839ms
2014-07-14 02:23:18,344 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,344 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3868ms
2014-07-14 02:23:18,345 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,345 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3901ms
2014-07-14 02:23:18,345 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,349 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3938ms
2014-07-14 02:23:18,349 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,349 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3969ms
2014-07-14 02:23:18,350 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,350 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3997ms
2014-07-14 02:23:18,350 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,351 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3998ms
2014-07-14 02:23:18,351 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,353 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4000ms
2014-07-14 02:23:18,353 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,353 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4003ms
2014-07-14 02:23:18,353 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,353 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4029ms
2014-07-14 02:23:18,353 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,354 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4032ms
2014-07-14 02:23:18,354 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,355 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4033ms
2014-07-14 02:23:18,356 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,356 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4034ms
2014-07-14 02:23:18,356 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,356 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4034ms
2014-07-14 02:23:18,356 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,356 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4064ms
2014-07-14 02:23:18,356 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,380 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4102ms
2014-07-14 02:23:18,380 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,385 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4109ms
2014-07-14 02:23:18,385 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,385 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4111ms
2014-07-14 02:23:18,385 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,385 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4125ms
2014-07-14 02:23:18,385 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,385 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4138ms
2014-07-14 02:23:18,386 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,397 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4150ms
2014-07-14 02:23:18,397 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,397 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4150ms
2014-07-14 02:23:18,397 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4161ms
2014-07-14 02:23:18,405 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,405 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4161ms
2014-07-14 02:23:18,405 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,409 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4168ms
2014-07-14 02:23:18,409 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,417 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4187ms
2014-07-14 02:23:18,417 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,417 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4219ms
2014-07-14 02:23:18,417 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,419 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4226ms
2014-07-14 02:23:18,419 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,423 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4233ms
2014-07-14 02:23:18,423 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,429 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4240ms
2014-07-14 02:23:18,429 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:18,434 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4245ms
2014-07-14 02:23:18,434 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:20,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:20,065 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:23:20,479 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:20,627 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59794 synced till here 59766
2014-07-14 02:23:20,890 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329792556 with entries=157, filesize=134.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329800058
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329713494
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329714885
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329716124
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329717823
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329719674
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329720910
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329722262
2014-07-14 02:23:20,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329723650
2014-07-14 02:23:22,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:22,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59901 synced till here 59878
2014-07-14 02:23:22,971 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329792955,"queuetimems":1,"class":"HRegionServer","responsesize":15920,"method":"Multi"}
2014-07-14 02:23:23,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329800058 with entries=107, filesize=90.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329802747
2014-07-14 02:23:26,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:26,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60028 synced till here 59999
2014-07-14 02:23:26,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329802747 with entries=127, filesize=108.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329806085
2014-07-14 02:23:28,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:28,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60141 synced till here 60123
2014-07-14 02:23:28,541 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329806085 with entries=113, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329808287
2014-07-14 02:23:30,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:30,661 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,666 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,666 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,666 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,667 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,670 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,672 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,673 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,675 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,676 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,676 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,677 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,681 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60258 synced till here 60241
2014-07-14 02:23:30,810 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,811 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,814 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,814 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,815 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,815 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,816 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,816 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,816 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,817 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,819 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,819 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,830 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329808287 with entries=117, filesize=100.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329810631
2014-07-14 02:23:30,867 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,887 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,888 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,939 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,940 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,941 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,941 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,943 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,943 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,944 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,946 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,947 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,949 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:30,973 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:31,009 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:31,885 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:31,914 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:31,943 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:31,973 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:32,002 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:32,032 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:32,063 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:32,092 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:32,123 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:23:35,661 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,666 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,666 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,667 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,668 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,670 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,672 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,673 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,675 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,676 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,676 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,678 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,681 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,811 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,812 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,814 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,814 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,815 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,816 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:23:35,816 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,816 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:23:35,816 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:35,817 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,819 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,819 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,830 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,867 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,887 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:35,888 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:36,433 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5424ms
2014-07-14 02:23:36,433 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5493ms
2014-07-14 02:23:36,434 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5492ms
2014-07-14 02:23:36,434 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5493ms
2014-07-14 02:23:36,434 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5491ms
2014-07-14 02:23:36,435 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5491ms
2014-07-14 02:23:36,435 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5492ms
2014-07-14 02:23:36,435 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5489ms
2014-07-14 02:23:36,435 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5488ms
2014-07-14 02:23:36,436 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5462ms
2014-07-14 02:23:36,436 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5487ms
2014-07-14 02:23:36,436 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5497ms
2014-07-14 02:23:36,818 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14841, memsize=492.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/5e50ff5de7864737a4831a171510dd2a
2014-07-14 02:23:36,836 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/5e50ff5de7864737a4831a171510dd2a as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5e50ff5de7864737a4831a171510dd2a
2014-07-14 02:23:36,886 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:36,915 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:36,943 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:23:36,949 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5e50ff5de7864737a4831a171510dd2a, entries=1792600, sequenceid=14841, filesize=127.7m
2014-07-14 02:23:36,949 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1001.2m/1049793840, currentsize=432.0m/453003040 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 34407ms, sequenceid=14841, compaction requested=true
2014-07-14 02:23:36,949 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:110), split_queue=0, merge_queue=0
2014-07-14 02:23:36,950 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-14 02:23:36,950 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:23:36,950 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,950 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-14 02:23:36,950 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5036ms
2014-07-14 02:23:36,950 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,950 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5065ms
2014-07-14 02:23:36,950 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,950 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 752.4m
2014-07-14 02:23:36,950 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6011ms
2014-07-14 02:23:36,950 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,951 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6002ms
2014-07-14 02:23:36,951 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,951 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5978ms
2014-07-14 02:23:36,951 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,951 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6004ms
2014-07-14 02:23:36,951 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,953 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6007ms
2014-07-14 02:23:36,953 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,953 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6010ms
2014-07-14 02:23:36,953 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,953 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6010ms
2014-07-14 02:23:36,953 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,953 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6010ms
2014-07-14 02:23:36,953 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,969 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6028ms
2014-07-14 02:23:36,969 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,969 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6028ms
2014-07-14 02:23:36,970 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,971 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6031ms
2014-07-14 02:23:36,971 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,974 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:36,974 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,980 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5971ms
2014-07-14 02:23:36,980 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,980 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6093ms
2014-07-14 02:23:36,981 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,981 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6094ms
2014-07-14 02:23:36,981 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,981 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6114ms
2014-07-14 02:23:36,981 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,984 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6154ms
2014-07-14 02:23:36,984 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,984 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6165ms
2014-07-14 02:23:36,984 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,985 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6166ms
2014-07-14 02:23:36,985 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,985 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6168ms
2014-07-14 02:23:36,985 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,985 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6170ms
2014-07-14 02:23:36,985 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,985 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6171ms
2014-07-14 02:23:36,985 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,988 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6171ms
2014-07-14 02:23:36,988 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,988 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6174ms
2014-07-14 02:23:36,988 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,988 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6173ms
2014-07-14 02:23:36,988 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,993 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6179ms
2014-07-14 02:23:36,993 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,993 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6179ms
2014-07-14 02:23:36,993 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,993 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6182ms
2014-07-14 02:23:36,993 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,994 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6184ms
2014-07-14 02:23:36,994 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:36,995 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6314ms
2014-07-14 02:23:36,995 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,001 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6324ms
2014-07-14 02:23:37,001 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,001 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6325ms
2014-07-14 02:23:37,001 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,001 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6325ms
2014-07-14 02:23:37,001 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,003 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:37,003 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,005 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6330ms
2014-07-14 02:23:37,005 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,005 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6333ms
2014-07-14 02:23:37,005 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,005 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6333ms
2014-07-14 02:23:37,005 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,007 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6338ms
2014-07-14 02:23:37,007 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,010 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6343ms
2014-07-14 02:23:37,011 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,011 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6345ms
2014-07-14 02:23:37,011 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,011 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6345ms
2014-07-14 02:23:37,011 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,021 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6355ms
2014-07-14 02:23:37,021 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,021 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6361ms
2014-07-14 02:23:37,021 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,021 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4898ms
2014-07-14 02:23:37,021 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,033 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:23:37,033 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,041 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4949ms
2014-07-14 02:23:37,041 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,046 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4983ms
2014-07-14 02:23:37,046 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:23:37,119 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:23:37,733 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:37,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:38,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60360 synced till here 60329
2014-07-14 02:23:38,365 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10042,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808322,"queuetimems":60,"class":"HRegionServer","responsesize":15953,"method":"Multi"}
2014-07-14 02:23:38,365 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808293,"queuetimems":382,"class":"HRegionServer","responsesize":15717,"method":"Multi"}
2014-07-14 02:23:38,367 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10037,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808329,"queuetimems":1,"class":"HRegionServer","responsesize":15723,"method":"Multi"}
2014-07-14 02:23:38,367 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808290,"queuetimems":1294,"class":"HRegionServer","responsesize":16063,"method":"Multi"}
2014-07-14 02:23:38,386 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10079,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808306,"queuetimems":279,"class":"HRegionServer","responsesize":15555,"method":"Multi"}
2014-07-14 02:23:38,386 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808322,"queuetimems":97,"class":"HRegionServer","responsesize":15437,"method":"Multi"}
2014-07-14 02:23:38,387 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10078,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329808309,"queuetimems":129,"class":"HRegionServer","responsesize":15762,"method":"Multi"}
2014-07-14 02:23:38,548 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329810631 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329817965
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329724843
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329725715
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329727114
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329729302
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329731341
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329733087
2014-07-14 02:23:38,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329735228
2014-07-14 02:23:39,988 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:40,131 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329817965 with entries=98, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329819988
2014-07-14 02:23:41,394 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810801,"queuetimems":881,"class":"HRegionServer","responsesize":16090,"method":"Multi"}
2014-07-14 02:23:41,395 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329811005,"queuetimems":0,"class":"HRegionServer","responsesize":15766,"method":"Multi"}
2014-07-14 02:23:41,398 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10429,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810969,"queuetimems":0,"class":"HRegionServer","responsesize":15744,"method":"Multi"}
2014-07-14 02:23:41,399 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810658,"queuetimems":776,"class":"HRegionServer","responsesize":15823,"method":"Multi"}
2014-07-14 02:23:41,401 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10599,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810802,"queuetimems":843,"class":"HRegionServer","responsesize":15755,"method":"Multi"}
2014-07-14 02:23:41,404 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810640,"queuetimems":826,"class":"HRegionServer","responsesize":15723,"method":"Multi"}
2014-07-14 02:23:41,405 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810802,"queuetimems":798,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 02:23:41,405 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329810802,"queuetimems":750,"class":"HRegionServer","responsesize":15773,"method":"Multi"}
2014-07-14 02:23:41,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:41,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60543 synced till here 60535
2014-07-14 02:23:41,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329819988 with entries=85, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329821549
2014-07-14 02:23:43,238 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:43,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60631 synced till here 60629
2014-07-14 02:23:43,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329821549 with entries=88, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329823239
2014-07-14 02:23:44,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:44,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329823239 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329824951
2014-07-14 02:23:45,301 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f2098f5ba4484c06bdb126498fcdb59a as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2098f5ba4484c06bdb126498fcdb59a
2014-07-14 02:23:45,340 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:23:45,349 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/0b53a10e6828412f839d190363f92d9a, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/0b53a10e6828412f839d190363f92d9a
2014-07-14 02:23:45,351 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bd86a997b7074b059450823eb354c8b2, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bd86a997b7074b059450823eb354c8b2
2014-07-14 02:23:45,353 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/50eff9f83b3f4826877b625d942718c1, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/50eff9f83b3f4826877b625d942718c1
2014-07-14 02:23:45,353 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into f2098f5ba4484c06bdb126498fcdb59a(size=187.2m), total size for store is 2.9g. This selection was in queue for 0sec, and took 44sec to execute.
2014-07-14 02:23:45,353 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=200.6m, priority=0, time=283688180305767; duration=44sec
2014-07-14 02:23:45,354 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-14 02:23:45,354 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-14 02:23:45,356 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1099720866 starting at candidate #6 after considering 108 permutations with 98 in ratio
2014-07-14 02:23:45,357 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:23:45,357 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:23:45,357 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=1.0g
2014-07-14 02:23:45,357 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/e9f696eaf68c416ebe8809b2133e602b, keycount=103835, bloomtype=ROW, size=73.9m, encoding=NONE, seqNum=8316
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9df395f96931448b9c44ec84eff560bc, keycount=99107, bloomtype=ROW, size=70.5m, encoding=NONE, seqNum=8878
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dad233ef821430482a41291d899aca6, keycount=224046, bloomtype=ROW, size=159.5m, encoding=NONE, seqNum=9328
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2098f5ba4484c06bdb126498fcdb59a, keycount=263101, bloomtype=ROW, size=187.2m, encoding=NONE, seqNum=10322
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4914e6e85054428f8de6e9f176aef83f, keycount=219884, bloomtype=ROW, size=156.5m, encoding=NONE, seqNum=11110
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/21598f7b008245dfbbb89bfb3a636272, keycount=96455, bloomtype=ROW, size=68.7m, encoding=NONE, seqNum=11509
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/feb479aa1c8d464bbc17e66dffe61976, keycount=183544, bloomtype=ROW, size=130.6m, encoding=NONE, seqNum=12020
2014-07-14 02:23:45,358 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fb45c0592fdc452ab93b55308947c1a4, keycount=112999, bloomtype=ROW, size=80.4m, encoding=NONE, seqNum=12544
2014-07-14 02:23:45,359 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/be630ea895634f67b12fb9ca4c340970, keycount=61830, bloomtype=ROW, size=44.1m, encoding=NONE, seqNum=12944
2014-07-14 02:23:45,359 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/340f4f35b2444adcbedd13182d6ea725, keycount=108741, bloomtype=ROW, size=77.3m, encoding=NONE, seqNum=13264
2014-07-14 02:23:46,017 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14949, memsize=446.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/75d35efcd71642ab91fbbe74d212e59c
2014-07-14 02:23:46,032 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/75d35efcd71642ab91fbbe74d212e59c as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/75d35efcd71642ab91fbbe74d212e59c
2014-07-14 02:23:46,041 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/75d35efcd71642ab91fbbe74d212e59c, entries=1625310, sequenceid=14949, filesize=115.7m
2014-07-14 02:23:46,041 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:46,041 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~926.5m/971515520, currentsize=416.0m/436158240 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 27735ms, sequenceid=14949, compaction requested=true
2014-07-14 02:23:46,042 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-14 02:23:46,042 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 600.9m
2014-07-14 02:23:46,061 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:23:46,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:46,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60777 synced till here 60776
2014-07-14 02:23:46,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329824951 with entries=74, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329826461
2014-07-14 02:23:46,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329742589
2014-07-14 02:23:46,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329744708
2014-07-14 02:23:46,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329747521
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329749285
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329751248
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329753729
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329755652
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329757097
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329758729
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329760533
2014-07-14 02:23:46,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329761887
2014-07-14 02:23:46,538 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:47,803 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:47,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60854 synced till here 60848
2014-07-14 02:23:47,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329826461 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329827803
2014-07-14 02:23:49,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:49,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60944 synced till here 60928
2014-07-14 02:23:49,315 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329827803 with entries=90, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329829095
2014-07-14 02:23:50,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:50,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329829095 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329830459
2014-07-14 02:23:50,870 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15087, memsize=245.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/873474755d964284904faf03a5b21ae0
2014-07-14 02:23:50,887 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/873474755d964284904faf03a5b21ae0 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/873474755d964284904faf03a5b21ae0
2014-07-14 02:23:51,015 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/873474755d964284904faf03a5b21ae0, entries=894070, sequenceid=15087, filesize=63.7m
2014-07-14 02:23:51,016 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~752.4m/788966480, currentsize=333.6m/349792880 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 14066ms, sequenceid=15087, compaction requested=true
2014-07-14 02:23:51,016 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:112), split_queue=0, merge_queue=0
2014-07-14 02:23:51,016 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 1.1g
2014-07-14 02:23:51,415 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:23:51,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:51,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61113 synced till here 61110
2014-07-14 02:23:52,025 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329830459 with entries=96, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329831698
2014-07-14 02:23:52,675 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:53,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:53,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329831698 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329833079
2014-07-14 02:23:54,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:54,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61266 synced till here 61258
2014-07-14 02:23:54,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329833079 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329834344
2014-07-14 02:23:55,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:56,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61352 synced till here 61343
2014-07-14 02:23:56,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329834344 with entries=86, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329835882
2014-07-14 02:23:56,707 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15231, memsize=199.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/e40737158bb447d6abf0dc540b6787b5
2014-07-14 02:23:56,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/e40737158bb447d6abf0dc540b6787b5 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e40737158bb447d6abf0dc540b6787b5
2014-07-14 02:23:56,751 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e40737158bb447d6abf0dc540b6787b5, entries=727410, sequenceid=15231, filesize=51.8m
2014-07-14 02:23:56,752 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~602.5m/631715920, currentsize=249.4m/261556480 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 10710ms, sequenceid=15231, compaction requested=true
2014-07-14 02:23:56,752 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:113), split_queue=0, merge_queue=0
2014-07-14 02:23:56,752 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 654.0m
2014-07-14 02:23:57,587 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:23:57,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:57,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61437 synced till here 61425
2014-07-14 02:23:57,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329835882 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329837757
2014-07-14 02:23:57,950 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:23:59,300 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:23:59,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61516 synced till here 61509
2014-07-14 02:23:59,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329837757 with entries=79, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329839300
2014-07-14 02:24:00,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:00,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329839300 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329840597
2014-07-14 02:24:02,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:02,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61690 synced till here 61687
2014-07-14 02:24:02,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329840597 with entries=100, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329842535
2014-07-14 02:24:04,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:04,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61772 synced till here 61771
2014-07-14 02:24:04,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329842535 with entries=82, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329844712
2014-07-14 02:24:06,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:06,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61848 synced till here 61846
2014-07-14 02:24:06,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329844712 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329846264
2014-07-14 02:24:07,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:07,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61927 synced till here 61918
2014-07-14 02:24:08,041 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329846264 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329847710
2014-07-14 02:24:09,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:09,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62006 synced till here 62001
2014-07-14 02:24:09,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329847710 with entries=79, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329849416
2014-07-14 02:24:11,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:11,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62086 synced till here 62079
2014-07-14 02:24:11,170 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329849416 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329851055
2014-07-14 02:24:12,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:12,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62161 synced till here 62158
2014-07-14 02:24:13,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329851055 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329852964
2014-07-14 02:24:13,072 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15385, memsize=337.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/c55a7dfa5db149bf8e5c2796d9971b6e
2014-07-14 02:24:13,083 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/c55a7dfa5db149bf8e5c2796d9971b6e as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c55a7dfa5db149bf8e5c2796d9971b6e
2014-07-14 02:24:13,091 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c55a7dfa5db149bf8e5c2796d9971b6e, entries=1227760, sequenceid=15385, filesize=87.4m
2014-07-14 02:24:13,092 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~672.6m/705243760, currentsize=290.8m/304914320 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 16340ms, sequenceid=15385, compaction requested=true
2014-07-14 02:24:13,092 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:114), split_queue=0, merge_queue=0
2014-07-14 02:24:13,092 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 760.0m
2014-07-14 02:24:13,105 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:24:14,038 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:24:14,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:14,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62238 synced till here 62235
2014-07-14 02:24:14,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329852964 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329854295
2014-07-14 02:24:14,981 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15308, memsize=403.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bbadbdbaf13c4247a779b3e00f7bfe2b
2014-07-14 02:24:15,050 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/bbadbdbaf13c4247a779b3e00f7bfe2b as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bbadbdbaf13c4247a779b3e00f7bfe2b
2014-07-14 02:24:15,059 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bbadbdbaf13c4247a779b3e00f7bfe2b, entries=1468250, sequenceid=15308, filesize=104.6m
2014-07-14 02:24:15,059 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1132934640, currentsize=465.8m/488414640 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 24043ms, sequenceid=15308, compaction requested=true
2014-07-14 02:24:15,059 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:115), split_queue=0, merge_queue=0
2014-07-14 02:24:15,059 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 587.7m
2014-07-14 02:24:15,124 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:24:15,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:15,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62314 synced till here 62312
2014-07-14 02:24:15,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329854295 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329855863
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329763695
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329765014
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329766385
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329767781
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329769435
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329771125
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329772684
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329774578
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329776640
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329778791
2014-07-14 02:24:15,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329781078
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329783197
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329785401
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329787300
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329788953
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329790943
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329792556
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329800058
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329802747
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329806085
2014-07-14 02:24:15,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329808287
2014-07-14 02:24:16,001 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:24:17,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:17,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62412 synced till here 62411
2014-07-14 02:24:17,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329855863 with entries=98, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329857263
2014-07-14 02:24:19,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:19,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62488 synced till here 62486
2014-07-14 02:24:19,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329857263 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329859015
2014-07-14 02:24:20,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:20,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62571 synced till here 62570
2014-07-14 02:24:20,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329859015 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329860475
2014-07-14 02:24:23,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:23,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62643 synced till here 62642
2014-07-14 02:24:23,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329860475 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329863297
2014-07-14 02:24:25,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:25,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62717 synced till here 62715
2014-07-14 02:24:25,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329863297 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329865659
2014-07-14 02:24:27,266 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:27,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62802 synced till here 62793
2014-07-14 02:24:27,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329865659 with entries=85, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329867267
2014-07-14 02:24:29,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:30,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62899 synced till here 62894
2014-07-14 02:24:30,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329867267 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329869176
2014-07-14 02:24:32,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:32,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62992 synced till here 62980
2014-07-14 02:24:32,835 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329869176 with entries=93, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329872474
2014-07-14 02:24:35,128 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1224ms
GC pool 'ParNew' had collection(s): count=1 time=1337ms
2014-07-14 02:24:35,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:35,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63086 synced till here 63068
2014-07-14 02:24:35,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329872474 with entries=94, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329875291
2014-07-14 02:24:37,824 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1694ms
GC pool 'ParNew' had collection(s): count=1 time=1728ms
2014-07-14 02:24:38,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:38,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63190 synced till here 63167
2014-07-14 02:24:38,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329875291 with entries=104, filesize=88.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329878340
2014-07-14 02:24:41,348 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:42,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329878340 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329881351
2014-07-14 02:24:45,345 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1439ms
GC pool 'ParNew' had collection(s): count=1 time=1616ms
2014-07-14 02:24:45,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:45,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63406 synced till here 63375
2014-07-14 02:24:45,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329881351 with entries=101, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329885390
2014-07-14 02:24:47,664 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,664 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,667 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,674 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,675 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,675 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,676 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,677 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:47,845 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,849 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,849 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,849 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,850 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:47,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63514 synced till here 63486
2014-07-14 02:24:48,128 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,128 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,131 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,131 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,131 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,132 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,133 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,133 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,134 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,134 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,134 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,134 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,135 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,135 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,137 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,137 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,138 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,139 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,139 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,139 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,140 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,140 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,140 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,140 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,141 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,141 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,142 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,143 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,146 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,146 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,146 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,146 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:24:48,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329885390 with entries=108, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329887841
2014-07-14 02:24:51,038 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1019ms
GC pool 'ParNew' had collection(s): count=1 time=1404ms
2014-07-14 02:24:52,664 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:24:52,665 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,667 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,675 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:24:52,675 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:24:52,675 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:24:52,676 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,677 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,692 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15615, memsize=581.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b34cc1ad7def4637b727d3712e97eaa8
2014-07-14 02:24:52,712 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b34cc1ad7def4637b727d3712e97eaa8 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b34cc1ad7def4637b727d3712e97eaa8
2014-07-14 02:24:52,727 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b34cc1ad7def4637b727d3712e97eaa8, entries=2118040, sequenceid=15615, filesize=150.7m
2014-07-14 02:24:52,728 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~595.5m/624399680, currentsize=498.4m/522643600 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 37669ms, sequenceid=15615, compaction requested=true
2014-07-14 02:24:52,729 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:116), split_queue=0, merge_queue=0
2014-07-14 02:24:52,729 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5052ms
2014-07-14 02:24:52,729 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:24:52,729 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,729 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-14 02:24:52,729 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5053ms
2014-07-14 02:24:52,730 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,730 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5056ms
2014-07-14 02:24:52,730 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 960.1m
2014-07-14 02:24:52,730 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,730 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5056ms
2014-07-14 02:24:52,730 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,730 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5057ms
2014-07-14 02:24:52,731 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,745 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-14 02:24:52,745 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,745 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5081ms
2014-07-14 02:24:52,745 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,745 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-14 02:24:52,745 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,745 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4604ms
2014-07-14 02:24:52,746 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,749 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4603ms
2014-07-14 02:24:52,750 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,750 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4610ms
2014-07-14 02:24:52,750 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,753 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4607ms
2014-07-14 02:24:52,753 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,757 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4614ms
2014-07-14 02:24:52,757 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,757 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4615ms
2014-07-14 02:24:52,757 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,757 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4616ms
2014-07-14 02:24:52,758 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,759 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4618ms
2014-07-14 02:24:52,759 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,760 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4619ms
2014-07-14 02:24:52,777 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,777 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4637ms
2014-07-14 02:24:52,777 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,777 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4637ms
2014-07-14 02:24:52,777 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,778 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4638ms
2014-07-14 02:24:52,778 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,783 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-14 02:24:52,783 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,783 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-14 02:24:52,783 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,783 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-14 02:24:52,783 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,790 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4652ms
2014-07-14 02:24:52,790 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,791 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4654ms
2014-07-14 02:24:52,791 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,791 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4654ms
2014-07-14 02:24:52,791 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,791 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4656ms
2014-07-14 02:24:52,792 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,793 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4659ms
2014-07-14 02:24:52,793 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,795 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4661ms
2014-07-14 02:24:52,795 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,797 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4663ms
2014-07-14 02:24:52,797 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,845 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,845 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,849 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,850 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,850 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:24:52,850 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,850 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:24:52,850 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,853 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 02:24:52,853 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,869 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4736ms
2014-07-14 02:24:52,869 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,877 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4743ms
2014-07-14 02:24:52,877 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,877 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4744ms
2014-07-14 02:24:52,877 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,877 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4744ms
2014-07-14 02:24:52,878 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,885 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4753ms
2014-07-14 02:24:52,885 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,887 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4755ms
2014-07-14 02:24:52,887 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,887 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4756ms
2014-07-14 02:24:52,887 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,887 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4756ms
2014-07-14 02:24:52,887 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,897 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4769ms
2014-07-14 02:24:52,897 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,905 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4777ms
2014-07-14 02:24:52,905 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,913 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-14 02:24:52,913 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,913 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-14 02:24:52,913 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,921 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5071ms
2014-07-14 02:24:52,921 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,921 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-14 02:24:52,921 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:52,929 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 02:24:52,929 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:24:53,420 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:24:53,425 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883289,"queuetimems":373,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 02:24:53,428 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883286,"queuetimems":420,"class":"HRegionServer","responsesize":16005,"method":"Multi"}
2014-07-14 02:24:53,428 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10146,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883282,"queuetimems":458,"class":"HRegionServer","responsesize":15729,"method":"Multi"}
2014-07-14 02:24:53,429 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10105,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883322,"queuetimems":7,"class":"HRegionServer","responsesize":16080,"method":"Multi"}
2014-07-14 02:24:53,660 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15580, memsize=619.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/e130117f58464a819eafa215aa8099b5
2014-07-14 02:24:53,676 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/e130117f58464a819eafa215aa8099b5 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e130117f58464a819eafa215aa8099b5
2014-07-14 02:24:53,688 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e130117f58464a819eafa215aa8099b5, entries=2256390, sequenceid=15580, filesize=160.6m
2014-07-14 02:24:53,688 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~761.4m/798427200, currentsize=513.4m/538377200 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 40596ms, sequenceid=15580, compaction requested=true
2014-07-14 02:24:53,689 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-14 02:24:53,689 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:24:53,689 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-14 02:24:53,934 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:24:53,935 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10612,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883322,"queuetimems":69,"class":"HRegionServer","responsesize":15619,"method":"Multi"}
2014-07-14 02:24:53,949 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 517.9m
2014-07-14 02:24:53,949 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883298,"queuetimems":180,"class":"HRegionServer","responsesize":15787,"method":"Multi"}
2014-07-14 02:24:53,949 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329883298,"queuetimems":121,"class":"HRegionServer","responsesize":15981,"method":"Multi"}
2014-07-14 02:24:54,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:54,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63613 synced till here 63594
2014-07-14 02:24:54,834 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:24:55,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329887841 with entries=99, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329894719
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329810631
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329817965
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329819988
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329821549
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329823239
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329824951
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329826461
2014-07-14 02:24:55,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329827803
2014-07-14 02:24:55,181 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329829095
2014-07-14 02:24:57,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:57,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63719 synced till here 63683
2014-07-14 02:24:57,202 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:24:57,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329894719 with entries=106, filesize=91.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329897019
2014-07-14 02:24:58,504 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:58,529 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63812 synced till here 63796
2014-07-14 02:24:58,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329897019 with entries=93, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329898504
2014-07-14 02:24:59,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:24:59,595 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329898504 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329899565
2014-07-14 02:25:07,989 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15927, memsize=299.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/6af9ae8dee774360b8dd0056b2f498b1
2014-07-14 02:25:08,164 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/6af9ae8dee774360b8dd0056b2f498b1 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6af9ae8dee774360b8dd0056b2f498b1
2014-07-14 02:25:09,164 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6af9ae8dee774360b8dd0056b2f498b1, entries=1091620, sequenceid=15927, filesize=77.7m
2014-07-14 02:25:09,164 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~536.5m/562516640, currentsize=150.0m/157321600 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 15215ms, sequenceid=15927, compaction requested=true
2014-07-14 02:25:09,165 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-14 02:25:09,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:09,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63963 synced till here 63957
2014-07-14 02:25:09,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329899565 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909200
2014-07-14 02:25:09,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:10,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64045 synced till here 64034
2014-07-14 02:25:10,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909200 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909979
2014-07-14 02:25:11,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:11,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64121 synced till here 64117
2014-07-14 02:25:12,015 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909979 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329911918
2014-07-14 02:25:13,531 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:13,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64207 synced till here 64200
2014-07-14 02:25:13,721 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329911918 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329913531
2014-07-14 02:25:14,362 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:25:14,362 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 256.7m
2014-07-14 02:25:14,555 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:25:15,012 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:15,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64282 synced till here 64280
2014-07-14 02:25:15,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329913531 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329915012
2014-07-14 02:25:16,583 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64359 synced till here 64353
2014-07-14 02:25:16,664 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329915012 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329916583
2014-07-14 02:25:18,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:18,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64440 synced till here 64430
2014-07-14 02:25:18,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329916583 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329918048
2014-07-14 02:25:19,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:19,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64519 synced till here 64513
2014-07-14 02:25:19,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329918048 with entries=79, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329919567
2014-07-14 02:25:21,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:21,249 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16094, memsize=129.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/22f53f9eb5b4444eb6ee0ef679dc15f4
2014-07-14 02:25:21,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64596 synced till here 64593
2014-07-14 02:25:21,326 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/22f53f9eb5b4444eb6ee0ef679dc15f4 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22f53f9eb5b4444eb6ee0ef679dc15f4
2014-07-14 02:25:21,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329919567 with entries=77, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329921238
2014-07-14 02:25:21,345 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22f53f9eb5b4444eb6ee0ef679dc15f4, entries=472950, sequenceid=16094, filesize=33.7m
2014-07-14 02:25:21,346 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269217760, currentsize=147.4m/154528240 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 6984ms, sequenceid=16094, compaction requested=true
2014-07-14 02:25:21,346 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:121), split_queue=0, merge_queue=0
2014-07-14 02:25:22,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:22,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64681 synced till here 64675
2014-07-14 02:25:22,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329921238 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329922855
2014-07-14 02:25:24,267 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:25:24,639 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files, but is 1.3g vs best flushable region's 195.4m. Choosing the bigger.
2014-07-14 02:25:24,640 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. due to global heap pressure
2014-07-14 02:25:24,640 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 1.3g
2014-07-14 02:25:24,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:24,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64767 synced till here 64754
2014-07-14 02:25:24,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329922855 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329924651
2014-07-14 02:25:26,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:26,824 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,824 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,824 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,824 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,824 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,825 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,825 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,825 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,826 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,828 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,828 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,828 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,829 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,834 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,858 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,888 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,918 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:26,935 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:25:27,924 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64876 synced till here 64860
2014-07-14 02:25:27,935 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,944 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,945 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,945 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,945 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,947 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,948 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,948 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,948 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,949 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,950 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,954 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,954 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,956 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:27,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329924651 with entries=109, filesize=93.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329926674
2014-07-14 02:25:27,985 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,014 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,044 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,072 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,102 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,131 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,161 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,191 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,222 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,251 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,280 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,310 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,338 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,368 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,398 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,427 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,457 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,486 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:28,518 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:29,133 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15926, memsize=711.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/da763b8100124b8ea6cf6b74af843c83
2014-07-14 02:25:29,144 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/da763b8100124b8ea6cf6b74af843c83 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/da763b8100124b8ea6cf6b74af843c83
2014-07-14 02:25:29,153 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/da763b8100124b8ea6cf6b74af843c83, entries=2590280, sequenceid=15926, filesize=184.4m
2014-07-14 02:25:29,154 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~960.1m/1006686240, currentsize=527.6m/553192480 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 36424ms, sequenceid=15926, compaction requested=true
2014-07-14 02:25:29,154 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-14 02:25:29,154 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 636ms
2014-07-14 02:25:29,154 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,154 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 668ms
2014-07-14 02:25:29,154 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 698ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 728ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 757ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 787ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 817ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,155 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 845ms
2014-07-14 02:25:29,155 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,156 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 875ms
2014-07-14 02:25:29,156 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,165 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 914ms
2014-07-14 02:25:29,165 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,165 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 943ms
2014-07-14 02:25:29,165 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,167 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 976ms
2014-07-14 02:25:29,167 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,167 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1006ms
2014-07-14 02:25:29,167 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,168 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1037ms
2014-07-14 02:25:29,168 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,169 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1067ms
2014-07-14 02:25:29,169 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,169 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1097ms
2014-07-14 02:25:29,169 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,169 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1126ms
2014-07-14 02:25:29,169 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,169 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1155ms
2014-07-14 02:25:29,169 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,170 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1185ms
2014-07-14 02:25:29,170 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,170 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1214ms
2014-07-14 02:25:29,170 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,174 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1220ms
2014-07-14 02:25:29,174 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,174 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1220ms
2014-07-14 02:25:29,175 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,175 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1225ms
2014-07-14 02:25:29,175 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,175 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1226ms
2014-07-14 02:25:29,175 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,175 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1227ms
2014-07-14 02:25:29,175 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,175 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1227ms
2014-07-14 02:25:29,175 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,180 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1232ms
2014-07-14 02:25:29,180 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,180 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1233ms
2014-07-14 02:25:29,180 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,180 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1235ms
2014-07-14 02:25:29,180 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,181 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1236ms
2014-07-14 02:25:29,181 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,182 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1238ms
2014-07-14 02:25:29,182 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,182 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1238ms
2014-07-14 02:25:29,182 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,188 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1253ms
2014-07-14 02:25:29,188 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,188 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2270ms
2014-07-14 02:25:29,188 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,193 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2305ms
2014-07-14 02:25:29,193 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,193 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2335ms
2014-07-14 02:25:29,193 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,193 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2359ms
2014-07-14 02:25:29,193 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,193 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2364ms
2014-07-14 02:25:29,193 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,197 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2369ms
2014-07-14 02:25:29,197 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,197 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2369ms
2014-07-14 02:25:29,197 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,197 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2369ms
2014-07-14 02:25:29,197 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,197 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2371ms
2014-07-14 02:25:29,197 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,201 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2376ms
2014-07-14 02:25:29,201 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,201 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2376ms
2014-07-14 02:25:29,201 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,201 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2376ms
2014-07-14 02:25:29,201 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,206 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2382ms
2014-07-14 02:25:29,206 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,206 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2382ms
2014-07-14 02:25:29,206 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,206 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2382ms
2014-07-14 02:25:29,207 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,207 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2383ms
2014-07-14 02:25:29,207 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,207 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2384ms
2014-07-14 02:25:29,207 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:29,335 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:25:29,335 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:25:29,336 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-14 02:25:30,949 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1524ms
GC pool 'ParNew' had collection(s): count=1 time=1550ms
2014-07-14 02:25:31,670 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:25:31,671 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 256.4m
2014-07-14 02:25:32,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:33,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64998 synced till here 64974
2014-07-14 02:25:33,429 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:25:33,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329926674 with entries=122, filesize=103.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329932108
2014-07-14 02:25:33,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329830459
2014-07-14 02:25:33,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329831698
2014-07-14 02:25:33,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329833079
2014-07-14 02:25:33,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329834344
2014-07-14 02:25:35,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:36,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65125 synced till here 65098
2014-07-14 02:25:36,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329932108 with entries=127, filesize=109.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329935675
2014-07-14 02:25:38,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:39,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65223 synced till here 65204
2014-07-14 02:25:40,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329935675 with entries=98, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329938601
2014-07-14 02:25:42,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:42,400 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65330 synced till here 65298
2014-07-14 02:25:42,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329938601 with entries=107, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329942385
2014-07-14 02:25:44,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:44,822 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65430 synced till here 65405
2014-07-14 02:25:45,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329942385 with entries=100, filesize=85.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329944759
2014-07-14 02:25:46,718 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,719 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,722 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,723 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,724 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,725 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,726 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,728 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,730 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,730 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,730 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,734 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,735 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,737 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,738 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,738 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,739 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,740 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,740 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,740 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,740 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,741 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:46,939 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,939 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,943 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,943 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,944 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,947 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,948 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,948 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,948 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,948 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,948 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,950 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,951 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,951 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,951 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,951 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,952 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,952 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,952 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,953 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,954 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,955 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:46,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65510 synced till here 65504
2014-07-14 02:25:47,010 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,011 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,011 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,011 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,011 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,013 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:47,025 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329944759 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329946936
2014-07-14 02:25:48,362 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16269, memsize=220.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f8757c32724a4411af318306756f7437
2014-07-14 02:25:48,381 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/f8757c32724a4411af318306756f7437 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f8757c32724a4411af318306756f7437
2014-07-14 02:25:48,395 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f8757c32724a4411af318306756f7437, entries=803530, sequenceid=16269, filesize=57.3m
2014-07-14 02:25:48,396 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~270.4m/283547040, currentsize=213.5m/223875120 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 16724ms, sequenceid=16269, compaction requested=true
2014-07-14 02:25:48,396 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-14 02:25:48,396 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1383ms
2014-07-14 02:25:48,397 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 95291ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:25:48,397 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,397 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1386ms
2014-07-14 02:25:48,397 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,397 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., flushing=true, writesEnabled=true
2014-07-14 02:25:48,397 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1386ms
2014-07-14 02:25:48,397 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,400 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1389ms
2014-07-14 02:25:48,400 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,401 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1391ms
2014-07-14 02:25:48,402 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,402 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1392ms
2014-07-14 02:25:48,402 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,402 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1447ms
2014-07-14 02:25:48,402 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,405 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1451ms
2014-07-14 02:25:48,405 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,405 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1452ms
2014-07-14 02:25:48,405 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,405 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1453ms
2014-07-14 02:25:48,405 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,413 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1462ms
2014-07-14 02:25:48,413 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,413 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1462ms
2014-07-14 02:25:48,413 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,417 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1469ms
2014-07-14 02:25:48,417 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,417 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1466ms
2014-07-14 02:25:48,417 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,417 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1466ms
2014-07-14 02:25:48,417 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,429 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1478ms
2014-07-14 02:25:48,429 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,430 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1479ms
2014-07-14 02:25:48,430 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,430 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1482ms
2014-07-14 02:25:48,430 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,431 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1483ms
2014-07-14 02:25:48,431 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,431 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1483ms
2014-07-14 02:25:48,431 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,431 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1483ms
2014-07-14 02:25:48,431 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,431 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1484ms
2014-07-14 02:25:48,432 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,432 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1485ms
2014-07-14 02:25:48,432 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,437 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1493ms
2014-07-14 02:25:48,437 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,438 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1494ms
2014-07-14 02:25:48,438 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,438 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1495ms
2014-07-14 02:25:48,438 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:48,449 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1510ms
2014-07-14 02:25:48,449 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,346 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2407ms
2014-07-14 02:25:49,346 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,346 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2605ms
2014-07-14 02:25:49,346 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,347 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2609ms
2014-07-14 02:25:49,347 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,347 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2609ms
2014-07-14 02:25:49,347 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,361 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2621ms
2014-07-14 02:25:49,361 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,361 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2621ms
2014-07-14 02:25:49,361 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,361 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2622ms
2014-07-14 02:25:49,361 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,361 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2626ms
2014-07-14 02:25:49,362 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,373 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2635ms
2014-07-14 02:25:49,373 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,373 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2636ms
2014-07-14 02:25:49,373 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,373 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-14 02:25:49,373 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,373 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2639ms
2014-07-14 02:25:49,374 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,377 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-14 02:25:49,377 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,377 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-14 02:25:49,377 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,377 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-14 02:25:49,377 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,385 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2658ms
2014-07-14 02:25:49,385 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,393 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2667ms
2014-07-14 02:25:49,393 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,393 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2669ms
2014-07-14 02:25:49,393 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,401 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2678ms
2014-07-14 02:25:49,401 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,401 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2678ms
2014-07-14 02:25:49,401 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,401 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2679ms
2014-07-14 02:25:49,401 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,405 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2686ms
2014-07-14 02:25:49,405 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,406 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2688ms
2014-07-14 02:25:49,406 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:25:49,889 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:25:49,889 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files, but is 1.2g vs best flushable region's 232.4m. Choosing the bigger.
2014-07-14 02:25:49,889 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. due to global heap pressure
2014-07-14 02:25:49,889 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.2g
2014-07-14 02:25:51,731 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:25:51,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65625 synced till here 65596
2014-07-14 02:25:52,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329946936 with entries=115, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329951731
2014-07-14 02:25:52,537 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,544 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,545 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,546 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,547 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,549 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,550 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,550 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,551 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,552 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,554 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,555 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,557 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,558 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,567 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,567 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,574 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,575 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,577 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,578 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,578 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,579 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,580 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,580 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,581 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,583 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,585 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,586 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,600 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,678 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,678 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,678 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,681 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,682 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,682 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,682 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,685 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,686 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,688 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,688 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,688 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,689 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,749 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:25:52,755 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,756 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,756 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,756 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,756 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,756 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,758 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,761 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:25:52,905 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:25:57,537 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,544 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,546 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,546 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,547 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,549 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,550 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,550 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,551 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,552 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,555 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,557 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,558 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,567 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,568 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,574 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,576 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,577 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,578 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,579 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,580 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:25:57,581 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,581 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 02:25:57,581 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,583 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,585 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,587 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,600 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,678 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,679 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,679 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,682 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,682 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,683 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,685 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,686 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,688 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,688 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5010ms
2014-07-14 02:25:57,689 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,689 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,755 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,756 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,756 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,757 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,757 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,757 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:25:57,758 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:25:57,761 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:26:02,538 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:26:02,544 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,546 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,547 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,547 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,550 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,550 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,550 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,552 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,552 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,555 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,557 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,559 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,568 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,568 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,575 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,576 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,577 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,578 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,580 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,581 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-14 02:26:02,581 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-14 02:26:02,581 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,582 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,583 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,585 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,587 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,600 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,679 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,680 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:26:02,680 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:26:02,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,683 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,683 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,683 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,686 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,686 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,688 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:26:02,688 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10010ms
2014-07-14 02:26:02,690 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,690 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,756 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,757 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,757 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,757 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,757 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,758 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:26:02,759 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:02,762 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:26:07,539 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,545 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,547 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,547 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,548 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,550 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,551 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 02:26:07,552 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,552 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,553 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,556 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,558 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,560 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,569 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,569 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,575 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,576 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,578 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,579 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,580 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,581 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-14 02:26:07,581 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-14 02:26:07,582 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,582 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,584 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,586 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 02:26:07,587 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,601 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,680 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,680 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,681 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-14 02:26:07,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 02:26:07,683 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,684 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,684 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,686 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,687 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 02:26:07,688 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 02:26:07,689 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15011ms
2014-07-14 02:26:07,690 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,690 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,756 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,757 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,757 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,758 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,759 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:26:07,759 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-14 02:26:07,760 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:07,762 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:26:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.41 MB, free=3.95 GB, max=3.96 GB, blocks=12, accesses=353252, hits=104140, hitRatio=29.48%, , cachingAccesses=104181, cachingHits=104099, cachingHitsRatio=99.92%, evictions=0, evicted=70, evictedPerRun=Infinity
2014-07-14 02:26:12,367 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16225, memsize=851.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/bf2813c99aac4e9f9e422102cb25c6e8
2014-07-14 02:26:12,385 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/bf2813c99aac4e9f9e422102cb25c6e8 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/bf2813c99aac4e9f9e422102cb25c6e8
2014-07-14 02:26:12,403 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/bf2813c99aac4e9f9e422102cb25c6e8, entries=3099330, sequenceid=16225, filesize=220.6m
2014-07-14 02:26:12,404 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1365998480, currentsize=356.5m/373855360 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 47763ms, sequenceid=16225, compaction requested=true
2014-07-14 02:26:12,404 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:125), split_queue=0, merge_queue=0
2014-07-14 02:26:12,404 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19643ms
2014-07-14 02:26:12,405 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,405 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 260.7m
2014-07-14 02:26:12,405 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19647ms
2014-07-14 02:26:12,405 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,405 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19649ms
2014-07-14 02:26:12,405 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,405 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19649ms
2014-07-14 02:26:12,405 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,406 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19650ms
2014-07-14 02:26:12,406 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,406 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19650ms
2014-07-14 02:26:12,406 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,409 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19652ms
2014-07-14 02:26:12,409 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,409 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19654ms
2014-07-14 02:26:12,409 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,410 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19720ms
2014-07-14 02:26:12,410 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,410 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19722ms
2014-07-14 02:26:12,410 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,412 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19734ms
2014-07-14 02:26:12,412 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,413 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19725ms
2014-07-14 02:26:12,413 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,413 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19727ms
2014-07-14 02:26:12,413 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,413 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19728ms
2014-07-14 02:26:12,413 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,417 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19735ms
2014-07-14 02:26:12,417 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,419 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19737ms
2014-07-14 02:26:12,422 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,422 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19740ms
2014-07-14 02:26:12,422 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,423 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19742ms
2014-07-14 02:26:12,423 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,425 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19746ms
2014-07-14 02:26:12,425 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,426 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19747ms
2014-07-14 02:26:12,426 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,429 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19751ms
2014-07-14 02:26:12,429 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,430 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19830ms
2014-07-14 02:26:12,430 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,430 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19844ms
2014-07-14 02:26:12,430 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,433 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19848ms
2014-07-14 02:26:12,434 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,437 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19853ms
2014-07-14 02:26:12,437 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,437 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19856ms
2014-07-14 02:26:12,437 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,441 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19861ms
2014-07-14 02:26:12,441 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,441 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19863ms
2014-07-14 02:26:12,442 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,447 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19869ms
2014-07-14 02:26:12,447 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,447 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19868ms
2014-07-14 02:26:12,447 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,453 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19875ms
2014-07-14 02:26:12,453 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,457 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19880ms
2014-07-14 02:26:12,457 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,457 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19882ms
2014-07-14 02:26:12,458 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,458 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19884ms
2014-07-14 02:26:12,458 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,460 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19893ms
2014-07-14 02:26:12,460 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,460 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19893ms
2014-07-14 02:26:12,460 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,461 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19903ms
2014-07-14 02:26:12,461 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,461 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19904ms
2014-07-14 02:26:12,461 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,461 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19906ms
2014-07-14 02:26:12,461 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,463 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19909ms
2014-07-14 02:26:12,463 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,469 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19917ms
2014-07-14 02:26:12,469 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,473 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19922ms
2014-07-14 02:26:12,473 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,473 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19923ms
2014-07-14 02:26:12,473 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,477 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19927ms
2014-07-14 02:26:12,477 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,479 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19930ms
2014-07-14 02:26:12,479 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,481 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19934ms
2014-07-14 02:26:12,481 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,481 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19935ms
2014-07-14 02:26:12,481 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,483 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19938ms
2014-07-14 02:26:12,483 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,484 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19939ms
2014-07-14 02:26:12,484 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,489 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19953ms
2014-07-14 02:26:12,489 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:26:12,863 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:26:13,074 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:13,076 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:26:13,078 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949894,"queuetimems":7383,"class":"HRegionServer","responsesize":15416,"method":"Multi"}
2014-07-14 02:26:13,078 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23188,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949889,"queuetimems":7438,"class":"HRegionServer","responsesize":15996,"method":"Multi"}
2014-07-14 02:26:13,145 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23261,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949883,"queuetimems":7525,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 02:26:13,145 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949872,"queuetimems":7677,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 02:26:13,147 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26428,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946718,"queuetimems":6798,"class":"HRegionServer","responsesize":15774,"method":"Multi"}
2014-07-14 02:26:13,148 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26422,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946725,"queuetimems":6388,"class":"HRegionServer","responsesize":16052,"method":"Multi"}
2014-07-14 02:26:13,150 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946718,"queuetimems":6701,"class":"HRegionServer","responsesize":15577,"method":"Multi"}
2014-07-14 02:26:13,150 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26427,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946723,"queuetimems":6504,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:26:13,150 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949882,"queuetimems":7584,"class":"HRegionServer","responsesize":15897,"method":"Multi"}
2014-07-14 02:26:13,155 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26213,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946941,"queuetimems":6350,"class":"HRegionServer","responsesize":15782,"method":"Multi"}
2014-07-14 02:26:13,150 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26421,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946729,"queuetimems":6352,"class":"HRegionServer","responsesize":15577,"method":"Multi"}
2014-07-14 02:26:13,160 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946945,"queuetimems":6149,"class":"HRegionServer","responsesize":15827,"method":"Multi"}
2014-07-14 02:26:13,161 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946945,"queuetimems":6195,"class":"HRegionServer","responsesize":15653,"method":"Multi"}
2014-07-14 02:26:13,166 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23295,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949870,"queuetimems":8964,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 02:26:13,169 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946719,"queuetimems":6590,"class":"HRegionServer","responsesize":15917,"method":"Multi"}
2014-07-14 02:26:13,160 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26429,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946730,"queuetimems":6274,"class":"HRegionServer","responsesize":15983,"method":"Multi"}
2014-07-14 02:26:13,169 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26455,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946714,"queuetimems":8097,"class":"HRegionServer","responsesize":15729,"method":"Multi"}
2014-07-14 02:26:13,174 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26225,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946949,"queuetimems":6119,"class":"HRegionServer","responsesize":15541,"method":"Multi"}
2014-07-14 02:26:13,174 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946944,"queuetimems":6290,"class":"HRegionServer","responsesize":15956,"method":"Multi"}
2014-07-14 02:26:13,174 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946717,"queuetimems":6809,"class":"HRegionServer","responsesize":15801,"method":"Multi"}
2014-07-14 02:26:13,176 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26463,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946713,"queuetimems":8130,"class":"HRegionServer","responsesize":16108,"method":"Multi"}
2014-07-14 02:26:13,177 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23295,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949882,"queuetimems":7555,"class":"HRegionServer","responsesize":15454,"method":"Multi"}
2014-07-14 02:26:13,175 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26439,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946735,"queuetimems":6210,"class":"HRegionServer","responsesize":15882,"method":"Multi"}
2014-07-14 02:26:13,181 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26462,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946719,"queuetimems":6642,"class":"HRegionServer","responsesize":15808,"method":"Multi"}
2014-07-14 02:26:13,183 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946725,"queuetimems":6425,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 02:26:13,176 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946729,"queuetimems":6313,"class":"HRegionServer","responsesize":15915,"method":"Multi"}
2014-07-14 02:26:13,186 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949870,"queuetimems":8914,"class":"HRegionServer","responsesize":15896,"method":"Multi"}
2014-07-14 02:26:13,256 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22960,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950296,"queuetimems":7450,"class":"HRegionServer","responsesize":16410,"method":"Multi"}
2014-07-14 02:26:13,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65744 synced till here 65742
2014-07-14 02:26:13,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329951731 with entries=119, filesize=101.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329973075
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329835882
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329837757
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329839300
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329840597
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329842535
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329844712
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329846264
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329847710
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329849416
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329851055
2014-07-14 02:26:13,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329852964
2014-07-14 02:26:14,213 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950313,"queuetimems":7325,"class":"HRegionServer","responsesize":15814,"method":"Multi"}
2014-07-14 02:26:14,218 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949900,"queuetimems":7355,"class":"HRegionServer","responsesize":15808,"method":"Multi"}
2014-07-14 02:26:14,218 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949905,"queuetimems":7230,"class":"HRegionServer","responsesize":15765,"method":"Multi"}
2014-07-14 02:26:14,218 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950306,"queuetimems":7426,"class":"HRegionServer","responsesize":15760,"method":"Multi"}
2014-07-14 02:26:14,221 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23926,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950295,"queuetimems":7514,"class":"HRegionServer","responsesize":16014,"method":"Multi"}
2014-07-14 02:26:14,221 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23908,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950313,"queuetimems":7355,"class":"HRegionServer","responsesize":15896,"method":"Multi"}
2014-07-14 02:26:14,229 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24328,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949901,"queuetimems":7293,"class":"HRegionServer","responsesize":15978,"method":"Multi"}
2014-07-14 02:26:14,229 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949883,"queuetimems":7477,"class":"HRegionServer","responsesize":15560,"method":"Multi"}
2014-07-14 02:26:14,238 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24337,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949900,"queuetimems":7325,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 02:26:14,238 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949873,"queuetimems":7666,"class":"HRegionServer","responsesize":15720,"method":"Multi"}
2014-07-14 02:26:14,245 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22223,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952022,"queuetimems":8967,"class":"HRegionServer","responsesize":15541,"method":"Multi"}
2014-07-14 02:26:14,246 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24352,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949894,"queuetimems":7413,"class":"HRegionServer","responsesize":15859,"method":"Multi"}
2014-07-14 02:26:14,246 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27524,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329946722,"queuetimems":6544,"class":"HRegionServer","responsesize":15897,"method":"Multi"}
2014-07-14 02:26:14,253 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329949905,"queuetimems":7191,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 02:26:14,253 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23943,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329950310,"queuetimems":7381,"class":"HRegionServer","responsesize":15773,"method":"Multi"}
2014-07-14 02:26:14,288 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22266,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952022,"queuetimems":8996,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 02:26:14,288 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22242,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952046,"queuetimems":8962,"class":"HRegionServer","responsesize":15827,"method":"Multi"}
2014-07-14 02:26:14,399 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21649,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952749,"queuetimems":9605,"class":"HRegionServer","responsesize":15956,"method":"Multi"}
2014-07-14 02:26:14,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:14,624 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952749,"queuetimems":9635,"class":"HRegionServer","responsesize":15653,"method":"Multi"}
2014-07-14 02:26:14,624 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952750,"queuetimems":8401,"class":"HRegionServer","responsesize":15887,"method":"Multi"}
2014-07-14 02:26:14,628 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952750,"queuetimems":8391,"class":"HRegionServer","responsesize":15917,"method":"Multi"}
2014-07-14 02:26:14,630 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21879,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47196","starttimems":1405329952750,"queuetimems":9570,"class":"HRegionServer","responsesize":15919,"method":"Multi"}
2014-07-14 02:26:14,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65851 synced till here 65824
2014-07-14 02:26:14,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329973075 with entries=107, filesize=92.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329974622
2014-07-14 02:26:16,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:16,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65980 synced till here 65942
2014-07-14 02:26:17,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329974622 with entries=129, filesize=110.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329976278
2014-07-14 02:26:18,204 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16437, memsize=73.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ea2a2a2095f44ff08c541c974883db04
2014-07-14 02:26:18,231 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ea2a2a2095f44ff08c541c974883db04 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ea2a2a2095f44ff08c541c974883db04
2014-07-14 02:26:18,250 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ea2a2a2095f44ff08c541c974883db04, entries=266750, sequenceid=16437, filesize=19.0m
2014-07-14 02:26:18,251 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.7m/273361040, currentsize=157.0m/164672400 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 5846ms, sequenceid=16437, compaction requested=true
2014-07-14 02:26:18,252 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-14 02:26:18,252 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:26:18,252 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:127), split_queue=0, merge_queue=0
2014-07-14 02:26:18,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:18,944 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16459, memsize=545.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/2e72b3d834cf40c79b422b1169d61146
2014-07-14 02:26:18,982 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/2e72b3d834cf40c79b422b1169d61146 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e72b3d834cf40c79b422b1169d61146
2014-07-14 02:26:19,030 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e72b3d834cf40c79b422b1169d61146, entries=1987150, sequenceid=16459, filesize=141.5m
2014-07-14 02:26:19,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66083 synced till here 66057
2014-07-14 02:26:19,704 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1375469920, currentsize=197.2m/206820560 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 29815ms, sequenceid=16459, compaction requested=true
2014-07-14 02:26:19,704 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:128), split_queue=0, merge_queue=0
2014-07-14 02:26:19,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329976278 with entries=103, filesize=87.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329978941
2014-07-14 02:26:19,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329854295
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329855863
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329857263
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329859015
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329860475
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329863297
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329865659
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329867267
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329869176
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329872474
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329875291
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329878340
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329881351
2014-07-14 02:26:19,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329885390
2014-07-14 02:26:20,773 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:21,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66194 synced till here 66155
2014-07-14 02:26:21,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329978941 with entries=111, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329980774
2014-07-14 02:26:23,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:23,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66289 synced till here 66266
2014-07-14 02:26:23,242 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:26:23,243 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:26:23,248 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:129), split_queue=0, merge_queue=0
2014-07-14 02:26:23,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329980774 with entries=95, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329983012
2014-07-14 02:26:24,279 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:26:24,279 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:26:24,279 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-14 02:26:24,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:24,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66399 synced till here 66381
2014-07-14 02:26:25,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329983012 with entries=110, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329984752
2014-07-14 02:26:26,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:26,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66500 synced till here 66499
2014-07-14 02:26:26,756 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329984752 with entries=101, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329986275
2014-07-14 02:26:29,944 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:29,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66575 synced till here 66571
2014-07-14 02:26:30,022 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329986275 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329989945
2014-07-14 02:26:31,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:31,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66649 synced till here 66646
2014-07-14 02:26:31,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329989945 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329991258
2014-07-14 02:26:31,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:33,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:33,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66728 synced till here 66723
2014-07-14 02:26:33,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329991258 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329993803
2014-07-14 02:26:33,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:35,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:35,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66818 synced till here 66801
2014-07-14 02:26:35,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329993803 with entries=90, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329995326
2014-07-14 02:26:35,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:37,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:37,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66892 synced till here 66890
2014-07-14 02:26:37,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329995326 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329997303
2014-07-14 02:26:37,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:38,231 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:38,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66966 synced till here 66962
2014-07-14 02:26:38,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329997303 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329998232
2014-07-14 02:26:38,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:39,646 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:39,670 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329998232 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329999647
2014-07-14 02:26:39,670 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:41,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:41,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67111 synced till here 67109
2014-07-14 02:26:41,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329999647 with entries=74, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330001389
2014-07-14 02:26:41,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:43,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:43,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67183 synced till here 67182
2014-07-14 02:26:43,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330001389 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330003364
2014-07-14 02:26:43,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:48,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:26:48,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330003364 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330008011
2014-07-14 02:26:48,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:26:59,722 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90387ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:26:59,723 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 1.4g
2014-07-14 02:27:00,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:00,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330008011 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330020461
2014-07-14 02:27:01,370 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:27:12,913 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/eb0e768a68f640b5acf6c73937dc89f9 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/eb0e768a68f640b5acf6c73937dc89f9
2014-07-14 02:27:12,928 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:27:12,939 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/e9f696eaf68c416ebe8809b2133e602b, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/e9f696eaf68c416ebe8809b2133e602b
2014-07-14 02:27:12,941 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9df395f96931448b9c44ec84eff560bc, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9df395f96931448b9c44ec84eff560bc
2014-07-14 02:27:12,943 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dad233ef821430482a41291d899aca6, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/5dad233ef821430482a41291d899aca6
2014-07-14 02:27:12,945 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2098f5ba4484c06bdb126498fcdb59a, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2098f5ba4484c06bdb126498fcdb59a
2014-07-14 02:27:12,948 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4914e6e85054428f8de6e9f176aef83f, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/4914e6e85054428f8de6e9f176aef83f
2014-07-14 02:27:12,950 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/21598f7b008245dfbbb89bfb3a636272, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/21598f7b008245dfbbb89bfb3a636272
2014-07-14 02:27:12,952 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/feb479aa1c8d464bbc17e66dffe61976, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/feb479aa1c8d464bbc17e66dffe61976
2014-07-14 02:27:12,962 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fb45c0592fdc452ab93b55308947c1a4, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fb45c0592fdc452ab93b55308947c1a4
2014-07-14 02:27:12,964 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/be630ea895634f67b12fb9ca4c340970, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/be630ea895634f67b12fb9ca4c340970
2014-07-14 02:27:12,967 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/340f4f35b2444adcbedd13182d6ea725, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/340f4f35b2444adcbedd13182d6ea725
2014-07-14 02:27:12,967 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into eb0e768a68f640b5acf6c73937dc89f9(size=995.7m), total size for store is 3.1g. This selection was in queue for 0sec, and took 3mins, 27sec to execute.
2014-07-14 02:27:12,967 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=10, fileSize=1.0g, priority=2, time=283732783932996; duration=3mins, 27sec
2014-07-14 02:27:12,967 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-14 02:27:12,968 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:27:12,969 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 191852516 starting at candidate #9 after considering 132 permutations with 124 in ratio
2014-07-14 02:27:12,969 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:27:12,970 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:27:12,970 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=183.0m
2014-07-14 02:27:12,970 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/21e1271c0b7f40aaa48f73d446f1331b, keycount=94370, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=10486
2014-07-14 02:27:12,970 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/eadc46ac44924819b40391aa22a69614, keycount=88954, bloomtype=ROW, size=63.4m, encoding=NONE, seqNum=10782
2014-07-14 02:27:12,970 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1a426a310f08412d9ee85a81a3ab0ebe, keycount=73534, bloomtype=ROW, size=52.4m, encoding=NONE, seqNum=11119
2014-07-14 02:27:13,026 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:27:23,204 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16869, memsize=580.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/d6a55640bb1a4a7facc36c65fbe4c8c9
2014-07-14 02:27:23,216 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/d6a55640bb1a4a7facc36c65fbe4c8c9 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/d6a55640bb1a4a7facc36c65fbe4c8c9
2014-07-14 02:27:23,232 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/d6a55640bb1a4a7facc36c65fbe4c8c9, entries=2115150, sequenceid=16869, filesize=150.6m
2014-07-14 02:27:23,233 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.4g/1532318480, currentsize=17.1m/17909840 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 23510ms, sequenceid=16869, compaction requested=true
2014-07-14 02:27:23,233 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-14 02:27:35,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:35,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330020461 with entries=74, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330055439
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329887841
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329894719
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329897019
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329898504
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329899565
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909200
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329909979
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329911918
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329913531
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329915012
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329916583
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329918048
2014-07-14 02:27:35,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329919567
2014-07-14 02:27:35,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329921238
2014-07-14 02:27:35,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329922855
2014-07-14 02:27:37,342 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:37,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67479 synced till here 67477
2014-07-14 02:27:37,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330055439 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330057343
2014-07-14 02:27:38,073 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/d533394788c040daa3ce4af201f1e8a1 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d533394788c040daa3ce4af201f1e8a1
2014-07-14 02:27:38,161 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:27:38,172 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/21e1271c0b7f40aaa48f73d446f1331b, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/21e1271c0b7f40aaa48f73d446f1331b
2014-07-14 02:27:38,174 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/eadc46ac44924819b40391aa22a69614, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/eadc46ac44924819b40391aa22a69614
2014-07-14 02:27:38,177 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1a426a310f08412d9ee85a81a3ab0ebe, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1a426a310f08412d9ee85a81a3ab0ebe
2014-07-14 02:27:38,177 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into d533394788c040daa3ce4af201f1e8a1(size=162.7m), total size for store is 3.2g. This selection was in queue for 0sec, and took 25sec to execute.
2014-07-14 02:27:38,178 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=183.0m, priority=-2, time=283940396627673; duration=25sec
2014-07-14 02:27:38,178 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-14 02:27:38,178 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-14 02:27:38,179 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:27:38,181 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 258550529 starting at candidate #13 after considering 132 permutations with 129 in ratio
2014-07-14 02:27:38,181 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:27:38,181 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:27:38,182 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=246.6m
2014-07-14 02:27:38,182 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b19dda52643646089257745fc5ef5279, keycount=127053, bloomtype=ROW, size=90.4m, encoding=NONE, seqNum=12287
2014-07-14 02:27:38,182 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/148666336011420eb5836cdf3a6faed5, keycount=105887, bloomtype=ROW, size=75.3m, encoding=NONE, seqNum=12820
2014-07-14 02:27:38,182 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/16af1e7052094d8ca9624c18f274fcd3, keycount=113602, bloomtype=ROW, size=80.8m, encoding=NONE, seqNum=13111
2014-07-14 02:27:38,247 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:27:39,191 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 1.1g
2014-07-14 02:27:39,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:39,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67555 synced till here 67552
2014-07-14 02:27:39,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330057343 with entries=76, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330059219
2014-07-14 02:27:40,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:40,364 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:27:40,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67638 synced till here 67629
2014-07-14 02:27:41,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330059219 with entries=83, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330060275
2014-07-14 02:27:43,356 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1102ms
GC pool 'ParNew' had collection(s): count=1 time=1216ms
2014-07-14 02:27:43,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:43,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67739 synced till here 67720
2014-07-14 02:27:43,855 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330060275 with entries=101, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330063502
2014-07-14 02:27:44,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:44,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67812 synced till here 67810
2014-07-14 02:27:44,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330063502 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330064588
2014-07-14 02:27:45,957 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:45,997 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67894 synced till here 67883
2014-07-14 02:27:46,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330064588 with entries=82, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330065957
2014-07-14 02:27:48,054 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:27:48,055 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 257.4m
2014-07-14 02:27:48,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:48,249 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67978 synced till here 67967
2014-07-14 02:27:49,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330065957 with entries=84, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330068207
2014-07-14 02:27:49,945 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:27:51,820 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1109ms
GC pool 'ParNew' had collection(s): count=1 time=1220ms
2014-07-14 02:27:51,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:51,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68077 synced till here 68058
2014-07-14 02:27:52,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330068207 with entries=99, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330071854
2014-07-14 02:27:54,144 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:54,214 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68181 synced till here 68154
2014-07-14 02:27:54,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330071854 with entries=104, filesize=88.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330074144
2014-07-14 02:27:56,639 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:27:58,124 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1199ms
GC pool 'ParNew' had collection(s): count=1 time=1292ms
2014-07-14 02:27:58,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68319 synced till here 68303
2014-07-14 02:27:58,380 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330074144 with entries=138, filesize=118.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330076639
2014-07-14 02:28:00,938 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1313ms
GC pool 'ParNew' had collection(s): count=1 time=1683ms
2014-07-14 02:28:01,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:01,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68419 synced till here 68390
2014-07-14 02:28:01,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330076639 with entries=100, filesize=86.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330081033
2014-07-14 02:28:01,674 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,708 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,744 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,774 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,805 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,834 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,863 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,894 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,911 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,912 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,912 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,912 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,912 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,913 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,913 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,915 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,915 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,916 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,917 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,917 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,918 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,918 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,920 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,922 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,922 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:01,924 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,040 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,041 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,042 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,043 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,044 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1096ms
GC pool 'ParNew' had collection(s): count=1 time=1109ms
2014-07-14 02:28:03,044 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,044 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,045 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,045 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,045 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,046 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,046 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,047 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,049 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,060 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,072 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,107 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,107 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,107 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,107 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,109 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,169 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,204 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17039, memsize=147.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/87dddea4d192497eade41fe4187d8df6
2014-07-14 02:28:03,205 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:03,217 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/87dddea4d192497eade41fe4187d8df6 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/87dddea4d192497eade41fe4187d8df6
2014-07-14 02:28:03,228 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/87dddea4d192497eade41fe4187d8df6, entries=536750, sequenceid=17039, filesize=38.2m
2014-07-14 02:28:03,228 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.1m/274818400, currentsize=193.2m/202566960 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 15173ms, sequenceid=17039, compaction requested=true
2014-07-14 02:28:03,229 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-14 02:28:03,229 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24ms
2014-07-14 02:28:03,229 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,229 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:28:03,229 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 60ms
2014-07-14 02:28:03,229 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,229 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files, but is 1.1g vs best flushable region's 193.2m. Choosing the bigger.
2014-07-14 02:28:03,229 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 120ms
2014-07-14 02:28:03,229 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. due to global heap pressure
2014-07-14 02:28:03,229 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,230 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 123ms
2014-07-14 02:28:03,230 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,230 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.1g
2014-07-14 02:28:03,230 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 123ms
2014-07-14 02:28:03,230 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,230 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 123ms
2014-07-14 02:28:03,230 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,230 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 123ms
2014-07-14 02:28:03,230 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,231 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 159ms
2014-07-14 02:28:03,231 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,231 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 172ms
2014-07-14 02:28:03,231 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,233 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 184ms
2014-07-14 02:28:03,233 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,233 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 186ms
2014-07-14 02:28:03,233 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,233 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 187ms
2014-07-14 02:28:03,233 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,234 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 188ms
2014-07-14 02:28:03,234 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,253 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 208ms
2014-07-14 02:28:03,253 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,253 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 208ms
2014-07-14 02:28:03,253 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,253 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 208ms
2014-07-14 02:28:03,253 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,265 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 223ms
2014-07-14 02:28:03,265 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,266 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 222ms
2014-07-14 02:28:03,266 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,266 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 223ms
2014-07-14 02:28:03,267 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,267 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 225ms
2014-07-14 02:28:03,267 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,267 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 226ms
2014-07-14 02:28:03,267 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,267 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 227ms
2014-07-14 02:28:03,267 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,267 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1343ms
2014-07-14 02:28:03,267 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,268 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1346ms
2014-07-14 02:28:03,268 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,268 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1346ms
2014-07-14 02:28:03,268 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,269 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1349ms
2014-07-14 02:28:03,269 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,269 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1351ms
2014-07-14 02:28:03,269 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,276 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1358ms
2014-07-14 02:28:03,276 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,276 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1359ms
2014-07-14 02:28:03,276 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,276 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1359ms
2014-07-14 02:28:03,277 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,277 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1361ms
2014-07-14 02:28:03,277 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,277 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1362ms
2014-07-14 02:28:03,277 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,278 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1362ms
2014-07-14 02:28:03,279 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,280 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1366ms
2014-07-14 02:28:03,280 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,280 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1367ms
2014-07-14 02:28:03,280 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,282 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1370ms
2014-07-14 02:28:03,282 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,282 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1370ms
2014-07-14 02:28:03,282 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,284 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1372ms
2014-07-14 02:28:03,284 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,284 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1373ms
2014-07-14 02:28:03,284 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,285 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1373ms
2014-07-14 02:28:03,285 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,286 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1392ms
2014-07-14 02:28:03,286 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,289 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1426ms
2014-07-14 02:28:03,289 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,290 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1455ms
2014-07-14 02:28:03,290 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,290 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1485ms
2014-07-14 02:28:03,290 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,297 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1523ms
2014-07-14 02:28:03,297 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,297 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1553ms
2014-07-14 02:28:03,297 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,297 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1589ms
2014-07-14 02:28:03,297 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,297 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1623ms
2014-07-14 02:28:03,298 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:03,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:03,642 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68525 synced till here 68502
2014-07-14 02:28:04,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330081033 with entries=106, filesize=91.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330083509
2014-07-14 02:28:05,532 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:28:06,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:06,094 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,094 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,096 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,096 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,096 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,098 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,099 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,102 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,102 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,102 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,103 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,103 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,104 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,104 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,105 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,106 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,106 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,106 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,107 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,111 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,114 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,114 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,117 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68635 synced till here 68613
2014-07-14 02:28:06,283 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,286 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:28:06,291 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,292 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,292 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,293 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,294 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,296 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,300 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,300 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,300 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,300 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,301 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,302 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,302 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,336 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330083509 with entries=110, filesize=93.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330086078
2014-07-14 02:28:06,371 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,396 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,418 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,418 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,419 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:06,420 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:07,355 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:07,364 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:11,094 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,095 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,096 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,096 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,097 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,098 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,099 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,102 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,103 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,103 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,103 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,103 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,104 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,105 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,106 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,106 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,107 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,107 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,107 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,112 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,114 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,114 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,283 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,291 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,293 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,293 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,293 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,294 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,300 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-14 02:28:11,300 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,300 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 02:28:11,301 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 02:28:11,302 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 02:28:11,302 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,302 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:28:11,302 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 02:28:11,303 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 02:28:11,371 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,396 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,418 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:11,419 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,419 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:28:11,420 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:28:12,371 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-14 02:28:12,371 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5016ms
2014-07-14 02:28:13,210 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16924, memsize=388.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/95054e28386c4574b0a242f0c13506e7
2014-07-14 02:28:13,232 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/95054e28386c4574b0a242f0c13506e7 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/95054e28386c4574b0a242f0c13506e7
2014-07-14 02:28:13,250 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/95054e28386c4574b0a242f0c13506e7, entries=1415870, sequenceid=16924, filesize=100.8m
2014-07-14 02:28:13,251 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1134793920, currentsize=418.7m/439011360 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 34060ms, sequenceid=16924, compaction requested=true
2014-07-14 02:28:13,251 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:132), split_queue=0, merge_queue=0
2014-07-14 02:28:13,252 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5897ms
2014-07-14 02:28:13,252 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 108973ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:28:13,252 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,252 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.1g
2014-07-14 02:28:13,252 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5888ms
2014-07-14 02:28:13,253 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,253 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6833ms
2014-07-14 02:28:13,253 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,253 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6835ms
2014-07-14 02:28:13,253 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,257 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6839ms
2014-07-14 02:28:13,257 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,257 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6839ms
2014-07-14 02:28:13,257 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,257 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6861ms
2014-07-14 02:28:13,257 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,272 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6901ms
2014-07-14 02:28:13,272 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,273 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6973ms
2014-07-14 02:28:13,273 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,273 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6977ms
2014-07-14 02:28:13,273 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,273 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6973ms
2014-07-14 02:28:13,273 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,278 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6976ms
2014-07-14 02:28:13,278 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,285 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6989ms
2014-07-14 02:28:13,285 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,285 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6987ms
2014-07-14 02:28:13,285 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,286 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6988ms
2014-07-14 02:28:13,286 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,293 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6994ms
2014-07-14 02:28:13,293 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,294 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6994ms
2014-07-14 02:28:13,294 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,295 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6994ms
2014-07-14 02:28:13,295 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,295 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6995ms
2014-07-14 02:28:13,296 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,297 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6996ms
2014-07-14 02:28:13,297 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,298 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6998ms
2014-07-14 02:28:13,298 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,306 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7012ms
2014-07-14 02:28:13,306 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,313 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7020ms
2014-07-14 02:28:13,313 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,314 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7020ms
2014-07-14 02:28:13,314 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,315 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7022ms
2014-07-14 02:28:13,315 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,317 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7025ms
2014-07-14 02:28:13,317 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,318 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7026ms
2014-07-14 02:28:13,318 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,319 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7035ms
2014-07-14 02:28:13,319 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,319 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7205ms
2014-07-14 02:28:13,319 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,319 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7205ms
2014-07-14 02:28:13,319 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,320 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7209ms
2014-07-14 02:28:13,320 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,321 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7213ms
2014-07-14 02:28:13,321 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,325 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7219ms
2014-07-14 02:28:13,326 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,326 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7220ms
2014-07-14 02:28:13,326 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,328 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7222ms
2014-07-14 02:28:13,328 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,330 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7224ms
2014-07-14 02:28:13,330 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,330 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7226ms
2014-07-14 02:28:13,330 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,333 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7229ms
2014-07-14 02:28:13,333 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,333 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7230ms
2014-07-14 02:28:13,334 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,334 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7231ms
2014-07-14 02:28:13,334 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,334 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7232ms
2014-07-14 02:28:13,334 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,334 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7232ms
2014-07-14 02:28:13,334 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,336 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7235ms
2014-07-14 02:28:13,336 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,337 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7237ms
2014-07-14 02:28:13,337 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,338 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7241ms
2014-07-14 02:28:13,338 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,339 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7243ms
2014-07-14 02:28:13,339 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,344 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7248ms
2014-07-14 02:28:13,344 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,349 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7254ms
2014-07-14 02:28:13,349 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,353 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7259ms
2014-07-14 02:28:13,353 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,357 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7263ms
2014-07-14 02:28:13,357 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:13,454 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10204,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083249,"queuetimems":0,"class":"HRegionServer","responsesize":16098,"method":"Multi"}
2014-07-14 02:28:13,623 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:28:13,624 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10458,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083166,"queuetimems":0,"class":"HRegionServer","responsesize":15752,"method":"Multi"}
2014-07-14 02:28:13,925 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10855,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083069,"queuetimems":0,"class":"HRegionServer","responsesize":15781,"method":"Multi"}
2014-07-14 02:28:13,953 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12212,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081741,"queuetimems":1,"class":"HRegionServer","responsesize":15909,"method":"Multi"}
2014-07-14 02:28:13,957 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081892,"queuetimems":0,"class":"HRegionServer","responsesize":16240,"method":"Multi"}
2014-07-14 02:28:13,962 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10917,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083044,"queuetimems":1,"class":"HRegionServer","responsesize":15537,"method":"Multi"}
2014-07-14 02:28:13,962 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081801,"queuetimems":0,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 02:28:13,962 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10656,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083306,"queuetimems":0,"class":"HRegionServer","responsesize":15557,"method":"Multi"}
2014-07-14 02:28:13,963 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081831,"queuetimems":0,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:28:13,962 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081771,"queuetimems":0,"class":"HRegionServer","responsesize":15615,"method":"Multi"}
2014-07-14 02:28:13,963 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12102,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081861,"queuetimems":0,"class":"HRegionServer","responsesize":16091,"method":"Multi"}
2014-07-14 02:28:13,966 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10908,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083057,"queuetimems":0,"class":"HRegionServer","responsesize":15255,"method":"Multi"}
2014-07-14 02:28:13,963 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10760,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330083202,"queuetimems":1,"class":"HRegionServer","responsesize":16146,"method":"Multi"}
2014-07-14 02:28:13,973 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330081705,"queuetimems":0,"class":"HRegionServer","responsesize":15558,"method":"Multi"}
2014-07-14 02:28:14,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:14,462 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10235,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330084226,"queuetimems":607,"class":"HRegionServer","responsesize":16036,"method":"Multi"}
2014-07-14 02:28:14,466 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330084214,"queuetimems":764,"class":"HRegionServer","responsesize":15749,"method":"Multi"}
2014-07-14 02:28:14,466 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10239,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330084226,"queuetimems":554,"class":"HRegionServer","responsesize":16091,"method":"Multi"}
2014-07-14 02:28:14,482 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10260,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330084221,"queuetimems":646,"class":"HRegionServer","responsesize":15904,"method":"Multi"}
2014-07-14 02:28:15,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68756 synced till here 68727
2014-07-14 02:28:15,041 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:28:15,153 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10923,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330084229,"queuetimems":482,"class":"HRegionServer","responsesize":15810,"method":"Multi"}
2014-07-14 02:28:15,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330086078 with entries=121, filesize=103.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330094460
2014-07-14 02:28:15,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329924651
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329926674
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329932108
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329935675
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329938601
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329942385
2014-07-14 02:28:15,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329944759
2014-07-14 02:28:15,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:16,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68863 synced till here 68830
2014-07-14 02:28:16,226 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086086,"queuetimems":764,"class":"HRegionServer","responsesize":16146,"method":"Multi"}
2014-07-14 02:28:16,227 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10130,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086096,"queuetimems":553,"class":"HRegionServer","responsesize":15956,"method":"Multi"}
2014-07-14 02:28:16,227 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086086,"queuetimems":781,"class":"HRegionServer","responsesize":15752,"method":"Multi"}
2014-07-14 02:28:16,226 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086093,"queuetimems":677,"class":"HRegionServer","responsesize":15781,"method":"Multi"}
2014-07-14 02:28:16,229 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086098,"queuetimems":503,"class":"HRegionServer","responsesize":15944,"method":"Multi"}
2014-07-14 02:28:16,229 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086087,"queuetimems":701,"class":"HRegionServer","responsesize":16240,"method":"Multi"}
2014-07-14 02:28:16,229 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086094,"queuetimems":649,"class":"HRegionServer","responsesize":15537,"method":"Multi"}
2014-07-14 02:28:16,230 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330086095,"queuetimems":617,"class":"HRegionServer","responsesize":15255,"method":"Multi"}
2014-07-14 02:28:16,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330094460 with entries=107, filesize=91.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330095964
2014-07-14 02:28:18,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:18,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330095964 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330098102
2014-07-14 02:28:19,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:19,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69012 synced till here 69008
2014-07-14 02:28:19,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330098102 with entries=76, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330099634
2014-07-14 02:28:21,669 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:21,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69095 synced till here 69086
2014-07-14 02:28:22,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330099634 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330101669
2014-07-14 02:28:23,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:24,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69186 synced till here 69173
2014-07-14 02:28:24,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330101669 with entries=91, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330103798
2014-07-14 02:28:25,858 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:25,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69262 synced till here 69258
2014-07-14 02:28:25,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330103798 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330105859
2014-07-14 02:28:27,187 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,205 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,205 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,226 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,226 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,248 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,248 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,248 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,292 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,334 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,768 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,926 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:27,963 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:28,052 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,459 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,505 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,544 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,605 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,645 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,699 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:29,747 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:30,406 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:31,056 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:31,088 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:28:31,103 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17186, memsize=465.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/01b1d41e3bbf4f1da9d1821657737897
2014-07-14 02:28:31,117 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/01b1d41e3bbf4f1da9d1821657737897 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/01b1d41e3bbf4f1da9d1821657737897
2014-07-14 02:28:31,127 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/01b1d41e3bbf4f1da9d1821657737897, entries=1693700, sequenceid=17186, filesize=120.6m
2014-07-14 02:28:31,127 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1189121120, currentsize=293.0m/307263360 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 27897ms, sequenceid=17186, compaction requested=true
2014-07-14 02:28:31,128 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-14 02:28:31,128 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-14 02:28:31,128 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,128 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 72ms
2014-07-14 02:28:31,128 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 519.2m
2014-07-14 02:28:31,128 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,128 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 722ms
2014-07-14 02:28:31,128 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,128 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1381ms
2014-07-14 02:28:31,128 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,129 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1430ms
2014-07-14 02:28:31,129 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,136 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1491ms
2014-07-14 02:28:31,136 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,137 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1532ms
2014-07-14 02:28:31,137 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,138 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1595ms
2014-07-14 02:28:31,138 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,145 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1640ms
2014-07-14 02:28:31,145 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,145 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1686ms
2014-07-14 02:28:31,145 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,153 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3101ms
2014-07-14 02:28:31,153 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,153 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3190ms
2014-07-14 02:28:31,153 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,153 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3227ms
2014-07-14 02:28:31,153 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,153 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3385ms
2014-07-14 02:28:31,153 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,154 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3820ms
2014-07-14 02:28:31,154 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,154 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3862ms
2014-07-14 02:28:31,154 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,154 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3906ms
2014-07-14 02:28:31,154 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,157 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3909ms
2014-07-14 02:28:31,157 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,157 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3909ms
2014-07-14 02:28:31,157 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,160 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3934ms
2014-07-14 02:28:31,161 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,161 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3935ms
2014-07-14 02:28:31,161 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,166 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3961ms
2014-07-14 02:28:31,166 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,166 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3961ms
2014-07-14 02:28:31,166 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,166 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3980ms
2014-07-14 02:28:31,166 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:28:31,350 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:28:31,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:31,631 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:28:31,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69386 synced till here 69374
2014-07-14 02:28:32,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330105859 with entries=124, filesize=104.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330111469
2014-07-14 02:28:32,076 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329946936
2014-07-14 02:28:33,421 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:33,678 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69480 synced till here 69476
2014-07-14 02:28:33,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330111469 with entries=94, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330113421
2014-07-14 02:28:36,635 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:36,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69577 synced till here 69558
2014-07-14 02:28:37,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330113421 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330116635
2014-07-14 02:28:37,554 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/9f4b67abbc534839890687e071851d70 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/9f4b67abbc534839890687e071851d70
2014-07-14 02:28:37,739 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:28:37,824 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b19dda52643646089257745fc5ef5279, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b19dda52643646089257745fc5ef5279
2014-07-14 02:28:37,827 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/148666336011420eb5836cdf3a6faed5, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/148666336011420eb5836cdf3a6faed5
2014-07-14 02:28:37,831 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/16af1e7052094d8ca9624c18f274fcd3, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/16af1e7052094d8ca9624c18f274fcd3
2014-07-14 02:28:37,831 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 9f4b67abbc534839890687e071851d70(size=219.0m), total size for store is 3.4g. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-14 02:28:37,832 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=3, fileSize=246.6m, priority=-2, time=283965608094589; duration=59sec
2014-07-14 02:28:37,832 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-14 02:28:37,832 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-14 02:28:37,833 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:28:37,834 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 115278124 starting at candidate #18 after considering 124 permutations with 85 in ratio
2014-07-14 02:28:37,835 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating minor compaction
2014-07-14 02:28:37,835 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:28:37,835 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=109.9m
2014-07-14 02:28:37,835 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22f53f9eb5b4444eb6ee0ef679dc15f4, keycount=47295, bloomtype=ROW, size=33.7m, encoding=NONE, seqNum=16094
2014-07-14 02:28:37,835 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f8757c32724a4411af318306756f7437, keycount=80353, bloomtype=ROW, size=57.3m, encoding=NONE, seqNum=16269
2014-07-14 02:28:37,836 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ea2a2a2095f44ff08c541c974883db04, keycount=26675, bloomtype=ROW, size=19.0m, encoding=NONE, seqNum=16437
2014-07-14 02:28:37,907 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:28:38,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:39,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69653 synced till here 69652
2014-07-14 02:28:39,048 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330116635 with entries=76, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330118972
2014-07-14 02:28:39,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:40,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69731 synced till here 69727
2014-07-14 02:28:40,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330118972 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330119936
2014-07-14 02:28:41,548 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:41,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69806 synced till here 69804
2014-07-14 02:28:41,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330119936 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330121549
2014-07-14 02:28:41,717 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17375, memsize=123.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/844bf4b8fa2d4e39a90fc25e2039d118
2014-07-14 02:28:41,734 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/844bf4b8fa2d4e39a90fc25e2039d118 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/844bf4b8fa2d4e39a90fc25e2039d118
2014-07-14 02:28:41,746 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/844bf4b8fa2d4e39a90fc25e2039d118, entries=450810, sequenceid=17375, filesize=32.1m
2014-07-14 02:28:41,746 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~519.2m/544398240, currentsize=191.8m/201069680 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 10618ms, sequenceid=17375, compaction requested=true
2014-07-14 02:28:41,747 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-14 02:28:41,747 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:28:41,747 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:135), split_queue=0, merge_queue=0
2014-07-14 02:28:41,747 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:28:41,747 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-14 02:28:42,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:43,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69904 synced till here 69903
2014-07-14 02:28:43,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330121549 with entries=98, filesize=83.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330122988
2014-07-14 02:28:44,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:44,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69978 synced till here 69976
2014-07-14 02:28:44,813 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:28:44,814 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 256.8m
2014-07-14 02:28:44,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330122988 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330124785
2014-07-14 02:28:44,946 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17189, memsize=465.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/69286036448e41c3949cacb0cad5350f
2014-07-14 02:28:44,960 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/69286036448e41c3949cacb0cad5350f as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/69286036448e41c3949cacb0cad5350f
2014-07-14 02:28:44,974 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/69286036448e41c3949cacb0cad5350f, entries=1692980, sequenceid=17189, filesize=120.6m
2014-07-14 02:28:44,977 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1222870000, currentsize=539.6m/565845040 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 31725ms, sequenceid=17189, compaction requested=true
2014-07-14 02:28:44,977 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:137), split_queue=0, merge_queue=0
2014-07-14 02:28:45,024 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:28:45,024 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:28:45,025 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:138), split_queue=0, merge_queue=0
2014-07-14 02:28:45,033 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:28:46,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:46,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70058 synced till here 70055
2014-07-14 02:28:46,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330124785 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330126718
2014-07-14 02:28:46,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329951731
2014-07-14 02:28:46,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329973075
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329974622
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329976278
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329978941
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329980774
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329983012
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329984752
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329986275
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329989945
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329991258
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329993803
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329995326
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329997303
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329998232
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405329999647
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330001389
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330003364
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330008011
2014-07-14 02:28:46,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330020461
2014-07-14 02:28:46,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330055439
2014-07-14 02:28:46,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330057343
2014-07-14 02:28:48,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:48,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330126718 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330128195
2014-07-14 02:28:50,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:50,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70214 synced till here 70211
2014-07-14 02:28:50,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330128195 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330130498
2014-07-14 02:28:52,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:52,055 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70294 synced till here 70288
2014-07-14 02:28:52,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330130498 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330132011
2014-07-14 02:28:53,401 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17542, memsize=170.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9aaef6d259c941b398b9176cefe2ec94
2014-07-14 02:28:53,442 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/9aaef6d259c941b398b9176cefe2ec94 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9aaef6d259c941b398b9176cefe2ec94
2014-07-14 02:28:53,457 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9aaef6d259c941b398b9176cefe2ec94, entries=620250, sequenceid=17542, filesize=44.2m
2014-07-14 02:28:53,458 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269312080, currentsize=142.9m/149834800 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 8644ms, sequenceid=17542, compaction requested=true
2014-07-14 02:28:53,458 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:139), split_queue=0, merge_queue=0
2014-07-14 02:28:53,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:54,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70404 synced till here 70394
2014-07-14 02:28:54,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330132011 with entries=110, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330133728
2014-07-14 02:28:55,925 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:55,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70488 synced till here 70476
2014-07-14 02:28:56,078 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330133728 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330135925
2014-07-14 02:28:58,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:28:58,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70590 synced till here 70568
2014-07-14 02:28:59,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330135925 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330138036
2014-07-14 02:28:59,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:28:59,840 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:28:59,841 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 263.2m
2014-07-14 02:28:59,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:00,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70677 synced till here 70667
2014-07-14 02:29:01,755 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1182ms
GC pool 'ParNew' had collection(s): count=1 time=1552ms
2014-07-14 02:29:01,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330138036 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330139882
2014-07-14 02:29:01,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:01,834 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:02,856 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/c04453dc844b4767a6eecc8980c61d67 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c04453dc844b4767a6eecc8980c61d67
2014-07-14 02:29:03,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:03,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70776 synced till here 70753
2014-07-14 02:29:03,990 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:29:04,011 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22f53f9eb5b4444eb6ee0ef679dc15f4, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/22f53f9eb5b4444eb6ee0ef679dc15f4
2014-07-14 02:29:04,015 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f8757c32724a4411af318306756f7437, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f8757c32724a4411af318306756f7437
2014-07-14 02:29:04,018 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ea2a2a2095f44ff08c541c974883db04, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ea2a2a2095f44ff08c541c974883db04
2014-07-14 02:29:04,018 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into c04453dc844b4767a6eecc8980c61d67(size=91.7m), total size for store is 3.4g. This selection was in queue for 0sec, and took 26sec to execute.
2014-07-14 02:29:04,018 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=3, fileSize=109.9m, priority=-1, time=284025261937512; duration=26sec
2014-07-14 02:29:04,019 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-14 02:29:04,019 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-14 02:29:04,019 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:29:04,021 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 245312459 starting at candidate #6 after considering 124 permutations with 116 in ratio
2014-07-14 02:29:04,021 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:29:04,021 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:29:04,021 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=233.9m
2014-07-14 02:29:04,022 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b6ea7c73b401438693fe546ee4433061, keycount=134584, bloomtype=ROW, size=95.8m, encoding=NONE, seqNum=9818
2014-07-14 02:29:04,022 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/941c29429a8f4d5899a3f92610bd9827, keycount=100050, bloomtype=ROW, size=71.2m, encoding=NONE, seqNum=10151
2014-07-14 02:29:04,022 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6e28b13211a545909f02f50365a01407, keycount=93938, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=10318
2014-07-14 02:29:04,097 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:04,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330139882 with entries=99, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330143922
2014-07-14 02:29:04,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:04,818 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 837.3m
2014-07-14 02:29:05,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:05,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70857 synced till here 70849
2014-07-14 02:29:06,141 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330143922 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330145148
2014-07-14 02:29:06,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:06,605 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:06,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:06,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70937 synced till here 70931
2014-07-14 02:29:06,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330145148 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330146796
2014-07-14 02:29:06,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:08,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:08,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71012 synced till here 71009
2014-07-14 02:29:08,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330146796 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330148560
2014-07-14 02:29:08,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:10,132 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:10,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71101 synced till here 71098
2014-07-14 02:29:10,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330148560 with entries=89, filesize=75.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330150133
2014-07-14 02:29:10,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:11,073 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17722, memsize=168.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f4ac5ff29de9466e96e99c0469be5e81
2014-07-14 02:29:11,104 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f4ac5ff29de9466e96e99c0469be5e81 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f4ac5ff29de9466e96e99c0469be5e81
2014-07-14 02:29:11,125 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f4ac5ff29de9466e96e99c0469be5e81, entries=612960, sequenceid=17722, filesize=43.7m
2014-07-14 02:29:11,126 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~276.8m/290265760, currentsize=164.7m/172714880 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 11285ms, sequenceid=17722, compaction requested=true
2014-07-14 02:29:11,126 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-14 02:29:11,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:11,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71183 synced till here 71182
2014-07-14 02:29:12,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330150133 with entries=82, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330151746
2014-07-14 02:29:12,819 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:13,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:15,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71280 synced till here 71265
2014-07-14 02:29:15,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330151746 with entries=97, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330153798
2014-07-14 02:29:15,183 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:29:15,738 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:29:15,738 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files, but is 1.4g vs best flushable region's 254.6m. Choosing the bigger.
2014-07-14 02:29:15,739 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. due to global heap pressure
2014-07-14 02:29:15,739 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 1.4g
2014-07-14 02:29:16,804 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:16,996 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:29:17,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71379 synced till here 71366
2014-07-14 02:29:17,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330153798 with entries=99, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330156805
2014-07-14 02:29:19,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:19,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71482 synced till here 71459
2014-07-14 02:29:19,684 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,685 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,685 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,686 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,688 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,688 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,689 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,689 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,689 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,691 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,694 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,695 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,695 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,697 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,700 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,701 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,703 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,729 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,753 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,753 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,754 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,754 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,754 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,756 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,757 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,761 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330156805 with entries=103, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330159554
2014-07-14 02:29:19,809 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,809 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,812 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,812 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,812 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,850 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,879 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,911 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,943 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:19,973 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,006 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,035 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,064 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,096 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,125 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,155 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,184 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,196 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:20,214 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,243 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,274 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,303 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,332 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,365 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,395 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:20,427 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:24,685 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,685 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,685 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,687 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,688 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,689 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,689 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,689 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,689 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,692 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,695 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,695 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,695 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,698 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:24,701 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:29:24,701 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:29:25,675 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5248ms
2014-07-14 02:29:25,676 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5612ms
2014-07-14 02:29:25,677 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5733ms
2014-07-14 02:29:25,677 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5924ms
2014-07-14 02:29:25,677 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5704ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5672ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5643ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5582ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5553ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5523ms
2014-07-14 02:29:25,678 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5494ms
2014-07-14 02:29:25,679 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5465ms
2014-07-14 02:29:25,679 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5436ms
2014-07-14 02:29:25,679 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5406ms
2014-07-14 02:29:25,679 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5376ms
2014-07-14 02:29:25,680 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5347ms
2014-07-14 02:29:25,680 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5285ms
2014-07-14 02:29:25,680 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5315ms
2014-07-14 02:29:25,681 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5979ms
2014-07-14 02:29:25,681 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5952ms
2014-07-14 02:29:25,681 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5928ms
2014-07-14 02:29:25,681 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5928ms
2014-07-14 02:29:25,682 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5929ms
2014-07-14 02:29:25,682 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5928ms
2014-07-14 02:29:25,682 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5926ms
2014-07-14 02:29:25,682 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5925ms
2014-07-14 02:29:25,682 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5874ms
2014-07-14 02:29:25,683 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5873ms
2014-07-14 02:29:25,683 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5871ms
2014-07-14 02:29:25,683 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5871ms
2014-07-14 02:29:25,684 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5872ms
2014-07-14 02:29:25,684 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5834ms
2014-07-14 02:29:25,684 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5805ms
2014-07-14 02:29:25,684 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5774ms
2014-07-14 02:29:30,226 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10526ms
2014-07-14 02:29:30,226 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10540ms
2014-07-14 02:29:30,227 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10540ms
2014-07-14 02:29:30,227 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10539ms
2014-07-14 02:29:30,227 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10539ms
2014-07-14 02:29:30,227 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10538ms
2014-07-14 02:29:30,228 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10538ms
2014-07-14 02:29:30,228 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10537ms
2014-07-14 02:29:30,228 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10534ms
2014-07-14 02:29:30,229 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10534ms
2014-07-14 02:29:30,229 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10534ms
2014-07-14 02:29:30,229 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10532ms
2014-07-14 02:29:30,229 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10529ms
2014-07-14 02:29:30,230 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10546ms
2014-07-14 02:29:30,231 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10545ms
2014-07-14 02:29:30,231 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10546ms
2014-07-14 02:29:30,676 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10249ms
2014-07-14 02:29:30,676 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10612ms
2014-07-14 02:29:30,677 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10734ms
2014-07-14 02:29:30,677 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10924ms
2014-07-14 02:29:30,678 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10705ms
2014-07-14 02:29:30,678 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10672ms
2014-07-14 02:29:30,678 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10643ms
2014-07-14 02:29:30,679 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10582ms
2014-07-14 02:29:30,679 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10495ms
2014-07-14 02:29:30,679 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10524ms
2014-07-14 02:29:30,679 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10554ms
2014-07-14 02:29:30,680 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10436ms
2014-07-14 02:29:30,680 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10466ms
2014-07-14 02:29:30,680 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10348ms
2014-07-14 02:29:30,680 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10377ms
2014-07-14 02:29:30,680 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10407ms
2014-07-14 02:29:30,681 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10286ms
2014-07-14 02:29:30,681 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10316ms
2014-07-14 02:29:30,682 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10979ms
2014-07-14 02:29:30,682 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10929ms
2014-07-14 02:29:30,683 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10930ms
2014-07-14 02:29:30,684 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10930ms
2014-07-14 02:29:30,684 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10955ms
2014-07-14 02:29:30,684 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10774ms
2014-07-14 02:29:30,685 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10806ms
2014-07-14 02:29:30,685 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10835ms
2014-07-14 02:29:30,686 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10873ms
2014-07-14 02:29:30,686 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10874ms
2014-07-14 02:29:30,686 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10874ms
2014-07-14 02:29:30,687 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10878ms
2014-07-14 02:29:30,687 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10879ms
2014-07-14 02:29:30,687 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10930ms
2014-07-14 02:29:30,688 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10931ms
2014-07-14 02:29:30,688 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10934ms
2014-07-14 02:29:31,060 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17745, memsize=419.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/3880b5634922490aad507617fecd1265
2014-07-14 02:29:31,081 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/3880b5634922490aad507617fecd1265 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/3880b5634922490aad507617fecd1265
2014-07-14 02:29:31,095 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/3880b5634922490aad507617fecd1265, entries=1525800, sequenceid=17745, filesize=108.6m
2014-07-14 02:29:31,095 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~859.2m/900932320, currentsize=247.5m/259532480 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 26277ms, sequenceid=17745, compaction requested=true
2014-07-14 02:29:31,096 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-14 02:29:31,096 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11342ms
2014-07-14 02:29:31,096 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,096 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11340ms
2014-07-14 02:29:31,096 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 308.7m
2014-07-14 02:29:31,096 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,096 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11339ms
2014-07-14 02:29:31,096 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,101 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11293ms
2014-07-14 02:29:31,101 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,101 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11292ms
2014-07-14 02:29:31,101 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,101 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11289ms
2014-07-14 02:29:31,101 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,109 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11297ms
2014-07-14 02:29:31,109 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,109 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11297ms
2014-07-14 02:29:31,109 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,112 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11259ms
2014-07-14 02:29:31,112 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,113 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11234ms
2014-07-14 02:29:31,113 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,113 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11203ms
2014-07-14 02:29:31,113 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,113 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11384ms
2014-07-14 02:29:31,113 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,125 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11372ms
2014-07-14 02:29:31,125 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,125 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11372ms
2014-07-14 02:29:31,125 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,129 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11376ms
2014-07-14 02:29:31,129 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,129 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11427ms
2014-07-14 02:29:31,129 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,129 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10764ms
2014-07-14 02:29:31,129 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,129 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10734ms
2014-07-14 02:29:31,130 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,137 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10864ms
2014-07-14 02:29:31,137 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,137 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10834ms
2014-07-14 02:29:31,137 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,142 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10810ms
2014-07-14 02:29:31,142 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,142 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10928ms
2014-07-14 02:29:31,142 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,150 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10907ms
2014-07-14 02:29:31,151 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,151 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11026ms
2014-07-14 02:29:31,151 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,152 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10997ms
2014-07-14 02:29:31,152 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,153 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10969ms
2014-07-14 02:29:31,153 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,154 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11058ms
2014-07-14 02:29:31,154 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,154 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11119ms
2014-07-14 02:29:31,154 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,154 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11148ms
2014-07-14 02:29:31,154 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,154 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11181ms
2014-07-14 02:29:31,154 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,155 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11402ms
2014-07-14 02:29:31,155 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,165 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11222ms
2014-07-14 02:29:31,165 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,167 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11103ms
2014-07-14 02:29:31,167 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,169 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10742ms
2014-07-14 02:29:31,169 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,169 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11484ms
2014-07-14 02:29:31,169 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,169 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11484ms
2014-07-14 02:29:31,169 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,169 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11485ms
2014-07-14 02:29:31,169 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,171 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11471ms
2014-07-14 02:29:31,171 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,172 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11474ms
2014-07-14 02:29:31,172 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,172 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11477ms
2014-07-14 02:29:31,172 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,177 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11483ms
2014-07-14 02:29:31,177 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,177 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11483ms
2014-07-14 02:29:31,177 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,178 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11487ms
2014-07-14 02:29:31,178 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,178 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11489ms
2014-07-14 02:29:31,178 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,186 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11496ms
2014-07-14 02:29:31,186 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,187 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11499ms
2014-07-14 02:29:31,187 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,187 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11499ms
2014-07-14 02:29:31,187 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,193 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11506ms
2014-07-14 02:29:31,193 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,197 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11511ms
2014-07-14 02:29:31,198 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,200 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11500ms
2014-07-14 02:29:31,200 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:31,543 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:31,649 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157380,"queuetimems":1,"class":"HRegionServer","responsesize":15721,"method":"Multi"}
2014-07-14 02:29:31,650 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14740,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330156909,"queuetimems":0,"class":"HRegionServer","responsesize":15573,"method":"Multi"}
2014-07-14 02:29:31,650 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157438,"queuetimems":0,"class":"HRegionServer","responsesize":15940,"method":"Multi"}
2014-07-14 02:29:31,658 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157338,"queuetimems":0,"class":"HRegionServer","responsesize":15927,"method":"Multi"}
2014-07-14 02:29:31,857 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157125,"queuetimems":0,"class":"HRegionServer","responsesize":15641,"method":"Multi"}
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330156945,"queuetimems":0,"class":"HRegionServer","responsesize":16431,"method":"Multi"}
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157294,"queuetimems":0,"class":"HRegionServer","responsesize":15613,"method":"Multi"}
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157718,"queuetimems":0,"class":"HRegionServer","responsesize":15630,"method":"Multi"}
2014-07-14 02:29:31,859 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14646,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157212,"queuetimems":0,"class":"HRegionServer","responsesize":15971,"method":"Multi"}
2014-07-14 02:29:31,859 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157080,"queuetimems":0,"class":"HRegionServer","responsesize":15795,"method":"Multi"}
2014-07-14 02:29:31,859 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157607,"queuetimems":1,"class":"HRegionServer","responsesize":15919,"method":"Multi"}
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14695,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157163,"queuetimems":1,"class":"HRegionServer","responsesize":15633,"method":"Multi"}
2014-07-14 02:29:31,858 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157653,"queuetimems":0,"class":"HRegionServer","responsesize":15939,"method":"Multi"}
2014-07-14 02:29:31,870 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14610,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157259,"queuetimems":1,"class":"HRegionServer","responsesize":15814,"method":"Multi"}
2014-07-14 02:29:31,870 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330156983,"queuetimems":0,"class":"HRegionServer","responsesize":15842,"method":"Multi"}
2014-07-14 02:29:32,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:32,237 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12597,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159639,"queuetimems":0,"class":"HRegionServer","responsesize":16199,"method":"Multi"}
2014-07-14 02:29:32,237 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157572,"queuetimems":1,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 02:29:33,050 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13488,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159561,"queuetimems":0,"class":"HRegionServer","responsesize":15821,"method":"Multi"}
2014-07-14 02:29:33,050 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330157505,"queuetimems":1,"class":"HRegionServer","responsesize":15624,"method":"Multi"}
2014-07-14 02:29:33,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71577 synced till here 71559
2014-07-14 02:29:33,281 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159468,"queuetimems":0,"class":"HRegionServer","responsesize":15541,"method":"Multi"}
2014-07-14 02:29:33,281 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13753,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159528,"queuetimems":1,"class":"HRegionServer","responsesize":15584,"method":"Multi"}
2014-07-14 02:29:33,281 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13676,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159605,"queuetimems":1,"class":"HRegionServer","responsesize":15959,"method":"Multi"}
2014-07-14 02:29:33,281 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13842,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159439,"queuetimems":1,"class":"HRegionServer","responsesize":14946,"method":"Multi"}
2014-07-14 02:29:33,281 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14824,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330158457,"queuetimems":687,"class":"HRegionServer","responsesize":15535,"method":"Multi"}
2014-07-14 02:29:33,294 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159331,"queuetimems":0,"class":"HRegionServer","responsesize":15807,"method":"Multi"}
2014-07-14 02:29:33,318 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330159554 with entries=95, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330172207
2014-07-14 02:29:33,570 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14159,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159411,"queuetimems":1,"class":"HRegionServer","responsesize":15820,"method":"Multi"}
2014-07-14 02:29:33,581 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14201,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159380,"queuetimems":1,"class":"HRegionServer","responsesize":15970,"method":"Multi"}
2014-07-14 02:29:33,581 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14238,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159343,"queuetimems":0,"class":"HRegionServer","responsesize":15671,"method":"Multi"}
2014-07-14 02:29:35,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:35,155 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71680 synced till here 71659
2014-07-14 02:29:35,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330172207 with entries=103, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330175046
2014-07-14 02:29:35,662 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160212,"queuetimems":0,"class":"HRegionServer","responsesize":15582,"method":"Multi"}
2014-07-14 02:29:35,662 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15690,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159971,"queuetimems":0,"class":"HRegionServer","responsesize":15633,"method":"Multi"}
2014-07-14 02:29:35,662 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15814,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159847,"queuetimems":0,"class":"HRegionServer","responsesize":16431,"method":"Multi"}
2014-07-14 02:29:35,663 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159727,"queuetimems":1,"class":"HRegionServer","responsesize":15573,"method":"Multi"}
2014-07-14 02:29:35,665 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160123,"queuetimems":0,"class":"HRegionServer","responsesize":15364,"method":"Multi"}
2014-07-14 02:29:35,665 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160301,"queuetimems":0,"class":"HRegionServer","responsesize":15630,"method":"Multi"}
2014-07-14 02:29:35,665 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15662,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160003,"queuetimems":0,"class":"HRegionServer","responsesize":15971,"method":"Multi"}
2014-07-14 02:29:35,666 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15974,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159692,"queuetimems":0,"class":"HRegionServer","responsesize":15337,"method":"Multi"}
2014-07-14 02:29:35,666 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160271,"queuetimems":0,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 02:29:35,667 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160363,"queuetimems":0,"class":"HRegionServer","responsesize":15919,"method":"Multi"}
2014-07-14 02:29:35,668 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15336,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160331,"queuetimems":0,"class":"HRegionServer","responsesize":15535,"method":"Multi"}
2014-07-14 02:29:35,669 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15760,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159908,"queuetimems":0,"class":"HRegionServer","responsesize":15795,"method":"Multi"}
2014-07-14 02:29:35,669 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15574,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160094,"queuetimems":0,"class":"HRegionServer","responsesize":15956,"method":"Multi"}
2014-07-14 02:29:35,669 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159877,"queuetimems":0,"class":"HRegionServer","responsesize":15616,"method":"Multi"}
2014-07-14 02:29:35,675 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15432,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160242,"queuetimems":1,"class":"HRegionServer","responsesize":15671,"method":"Multi"}
2014-07-14 02:29:35,684 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15501,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160182,"queuetimems":0,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 02:29:35,669 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15727,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330159941,"queuetimems":0,"class":"HRegionServer","responsesize":15842,"method":"Multi"}
2014-07-14 02:29:35,687 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15260,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160426,"queuetimems":1,"class":"HRegionServer","responsesize":15613,"method":"Multi"}
2014-07-14 02:29:35,688 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15295,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160393,"queuetimems":0,"class":"HRegionServer","responsesize":15939,"method":"Multi"}
2014-07-14 02:29:35,689 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15652,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160032,"queuetimems":0,"class":"HRegionServer","responsesize":15620,"method":"Multi"}
2014-07-14 02:29:35,695 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160153,"queuetimems":0,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 02:29:35,699 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330160062,"queuetimems":0,"class":"HRegionServer","responsesize":15641,"method":"Multi"}
2014-07-14 02:29:36,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:37,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71792 synced till here 71763
2014-07-14 02:29:37,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330175046 with entries=112, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330177000
2014-07-14 02:29:39,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:39,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71902 synced till here 71879
2014-07-14 02:29:39,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330177000 with entries=110, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330179205
2014-07-14 02:29:41,305 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:41,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71994 synced till here 71979
2014-07-14 02:29:41,672 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330179205 with entries=92, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330181305
2014-07-14 02:29:42,665 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,666 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,668 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,670 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,671 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,754 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,769 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,769 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,785 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,827 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:42,925 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17922, memsize=145.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/c05e033805be49dcb9006dae4c518526
2014-07-14 02:29:42,943 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/c05e033805be49dcb9006dae4c518526 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/c05e033805be49dcb9006dae4c518526
2014-07-14 02:29:42,957 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/c05e033805be49dcb9006dae4c518526, entries=529910, sequenceid=17922, filesize=37.7m
2014-07-14 02:29:42,959 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~308.7m/323694240, currentsize=187.0m/196127280 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 11862ms, sequenceid=17922, compaction requested=true
2014-07-14 02:29:42,959 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:142), split_queue=0, merge_queue=0
2014-07-14 02:29:42,959 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 132ms
2014-07-14 02:29:42,959 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:29:42,959 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,960 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-14 02:29:42,960 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 175ms
2014-07-14 02:29:42,960 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,960 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 191ms
2014-07-14 02:29:42,960 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,961 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 192ms
2014-07-14 02:29:42,961 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,965 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 212ms
2014-07-14 02:29:42,965 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,969 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 298ms
2014-07-14 02:29:42,969 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,969 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 299ms
2014-07-14 02:29:42,969 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,969 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 301ms
2014-07-14 02:29:42,969 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,970 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 304ms
2014-07-14 02:29:42,971 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:42,971 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 306ms
2014-07-14 02:29:42,971 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:43,860 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90237ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:29:43,861 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., flushing=true, writesEnabled=true
2014-07-14 02:29:43,982 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:44,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72090 synced till here 72078
2014-07-14 02:29:44,195 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:29:44,195 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 258.1m
2014-07-14 02:29:44,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330181305 with entries=96, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330183982
2014-07-14 02:29:45,695 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:45,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:45,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72200 synced till here 72169
2014-07-14 02:29:46,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330183982 with entries=110, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330185734
2014-07-14 02:29:46,771 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,773 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,773 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,776 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,776 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,779 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,779 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,779 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,779 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,787 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,911 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:46,923 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,923 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,924 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,924 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,924 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,927 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,928 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,929 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,929 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,930 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,931 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,931 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,933 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,933 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,933 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,936 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,936 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,937 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,937 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,938 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,938 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,938 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,939 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,940 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,940 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,941 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,942 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,942 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,944 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,945 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:46,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72278 synced till here 72271
2014-07-14 02:29:46,954 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,004 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,004 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,005 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,005 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,005 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,006 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:47,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330185734 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330186911
2014-07-14 02:29:47,007 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:48,917 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18091, memsize=60.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/b13980fe70dc4468ae85480f11d4c3c0
2014-07-14 02:29:48,934 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/b13980fe70dc4468ae85480f11d4c3c0 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b13980fe70dc4468ae85480f11d4c3c0
2014-07-14 02:29:48,948 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b13980fe70dc4468ae85480f11d4c3c0, entries=218820, sequenceid=18091, filesize=15.6m
2014-07-14 02:29:48,948 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.7m/272274640, currentsize=38.6m/40430960 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 4753ms, sequenceid=18091, compaction requested=true
2014-07-14 02:29:48,948 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-14 02:29:48,948 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1941ms
2014-07-14 02:29:48,948 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:29:48,949 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,949 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files, but is 1.4g vs best flushable region's 38.6m. Choosing the bigger.
2014-07-14 02:29:48,949 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1944ms
2014-07-14 02:29:48,949 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,949 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. due to global heap pressure
2014-07-14 02:29:48,949 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1944ms
2014-07-14 02:29:48,949 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,949 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.4g
2014-07-14 02:29:48,953 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-14 02:29:48,953 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,953 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-14 02:29:48,953 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,953 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1949ms
2014-07-14 02:29:48,954 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,957 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1953ms
2014-07-14 02:29:48,957 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,957 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2004ms
2014-07-14 02:29:48,957 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,960 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2015ms
2014-07-14 02:29:48,960 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,960 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2016ms
2014-07-14 02:29:48,960 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,963 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2021ms
2014-07-14 02:29:48,963 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,963 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2021ms
2014-07-14 02:29:48,963 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,965 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2024ms
2014-07-14 02:29:48,965 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,968 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2028ms
2014-07-14 02:29:48,968 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,968 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2028ms
2014-07-14 02:29:48,968 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,968 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2029ms
2014-07-14 02:29:48,968 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,968 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2030ms
2014-07-14 02:29:48,968 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,977 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2039ms
2014-07-14 02:29:48,977 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,977 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2039ms
2014-07-14 02:29:48,977 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,977 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2040ms
2014-07-14 02:29:48,977 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,977 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2040ms
2014-07-14 02:29:48,977 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,979 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2043ms
2014-07-14 02:29:48,979 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,979 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2043ms
2014-07-14 02:29:48,979 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,979 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2048ms
2014-07-14 02:29:48,979 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,989 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2056ms
2014-07-14 02:29:48,989 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,989 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-14 02:29:48,989 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,989 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2058ms
2014-07-14 02:29:48,989 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,989 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2058ms
2014-07-14 02:29:48,989 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,989 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2059ms
2014-07-14 02:29:48,989 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,995 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2067ms
2014-07-14 02:29:48,995 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,995 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2067ms
2014-07-14 02:29:48,995 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,995 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2067ms
2014-07-14 02:29:48,995 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:48,995 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2068ms
2014-07-14 02:29:48,995 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,013 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2089ms
2014-07-14 02:29:49,013 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,025 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2101ms
2014-07-14 02:29:49,025 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,025 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2102ms
2014-07-14 02:29:49,025 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,029 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2106ms
2014-07-14 02:29:49,029 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,034 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2112ms
2014-07-14 02:29:49,034 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,044 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2257ms
2014-07-14 02:29:49,044 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,044 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2265ms
2014-07-14 02:29:49,044 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,045 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2269ms
2014-07-14 02:29:49,045 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,053 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2280ms
2014-07-14 02:29:49,053 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,061 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2282ms
2014-07-14 02:29:49,061 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,061 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2288ms
2014-07-14 02:29:49,061 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,073 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2297ms
2014-07-14 02:29:49,073 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,073 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2300ms
2014-07-14 02:29:49,073 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,073 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2300ms
2014-07-14 02:29:49,073 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,073 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2302ms
2014-07-14 02:29:49,073 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:49,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:49,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72368 synced till here 72352
2014-07-14 02:29:49,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330186911 with entries=90, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330189776
2014-07-14 02:29:51,138 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:52,710 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,713 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,721 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,749 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,759 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,772 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,786 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,819 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,820 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,849 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,878 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,908 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,949 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:52,981 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:53,174 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:53,204 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:53,241 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,265 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,311 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,343 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,383 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,416 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,459 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,495 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,541 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:54,592 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,275 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,823 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,870 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,913 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,952 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:55,991 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,034 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,080 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,111 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,143 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,179 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:29:56,180 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/f09479c2197e42a7a74bb81543ef4bc8 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/f09479c2197e42a7a74bb81543ef4bc8
2014-07-14 02:29:56,197 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:29:56,205 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b6ea7c73b401438693fe546ee4433061, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/b6ea7c73b401438693fe546ee4433061
2014-07-14 02:29:56,212 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/941c29429a8f4d5899a3f92610bd9827, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/941c29429a8f4d5899a3f92610bd9827
2014-07-14 02:29:56,215 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6e28b13211a545909f02f50365a01407, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/6e28b13211a545909f02f50365a01407
2014-07-14 02:29:56,216 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into f09479c2197e42a7a74bb81543ef4bc8(size=228.6m), total size for store is 3.3g. This selection was in queue for 0sec, and took 52sec to execute.
2014-07-14 02:29:56,216 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=233.9m, priority=-1, time=284051448196827; duration=52sec
2014-07-14 02:29:56,216 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-14 02:29:56,216 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:29:56,218 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 246900861 starting at candidate #15 after considering 124 permutations with 122 in ratio
2014-07-14 02:29:56,218 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:29:56,218 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:29:56,219 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=235.5m
2014-07-14 02:29:56,219 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f2ff5c6f0e724786b85486f26e2e7dc6, keycount=78528, bloomtype=ROW, size=55.9m, encoding=NONE, seqNum=14191
2014-07-14 02:29:56,219 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5e50ff5de7864737a4831a171510dd2a, keycount=179260, bloomtype=ROW, size=127.7m, encoding=NONE, seqNum=14841
2014-07-14 02:29:56,219 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e40737158bb447d6abf0dc540b6787b5, keycount=72741, bloomtype=ROW, size=51.8m, encoding=NONE, seqNum=15231
2014-07-14 02:29:56,284 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:56,457 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17877, memsize=539.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1dd339c974f24aa9ad4242c790bad097
2014-07-14 02:29:56,475 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/1dd339c974f24aa9ad4242c790bad097 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1dd339c974f24aa9ad4242c790bad097
2014-07-14 02:29:56,488 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1dd339c974f24aa9ad4242c790bad097, entries=1962610, sequenceid=17877, filesize=139.7m
2014-07-14 02:29:56,488 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.4g/1547391200, currentsize=399.7m/419074320 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 40749ms, sequenceid=17877, compaction requested=true
2014-07-14 02:29:56,488 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-14 02:29:56,489 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 309ms
2014-07-14 02:29:56,489 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,489 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 346ms
2014-07-14 02:29:56,489 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,489 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 378ms
2014-07-14 02:29:56,489 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,489 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 409ms
2014-07-14 02:29:56,489 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,493 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 459ms
2014-07-14 02:29:56,493 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,493 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 502ms
2014-07-14 02:29:56,493 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,493 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 542ms
2014-07-14 02:29:56,493 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,493 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 580ms
2014-07-14 02:29:56,493 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,496 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 626ms
2014-07-14 02:29:56,496 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,496 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 673ms
2014-07-14 02:29:56,496 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,497 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1222ms
2014-07-14 02:29:56,497 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,497 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1905ms
2014-07-14 02:29:56,497 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,497 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1956ms
2014-07-14 02:29:56,497 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,497 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2002ms
2014-07-14 02:29:56,497 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,501 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2042ms
2014-07-14 02:29:56,502 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,502 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2086ms
2014-07-14 02:29:56,502 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,502 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2119ms
2014-07-14 02:29:56,502 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,502 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2159ms
2014-07-14 02:29:56,502 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,504 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2193ms
2014-07-14 02:29:56,504 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,504 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2239ms
2014-07-14 02:29:56,504 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,505 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3263ms
2014-07-14 02:29:56,505 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,505 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3301ms
2014-07-14 02:29:56,505 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,506 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3332ms
2014-07-14 02:29:56,506 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,507 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3526ms
2014-07-14 02:29:56,507 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,507 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3558ms
2014-07-14 02:29:56,507 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,508 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3599ms
2014-07-14 02:29:56,508 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,509 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3630ms
2014-07-14 02:29:56,509 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,510 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3661ms
2014-07-14 02:29:56,510 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,510 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3690ms
2014-07-14 02:29:56,510 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,511 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3692ms
2014-07-14 02:29:56,511 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,511 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3725ms
2014-07-14 02:29:56,511 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,512 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3739ms
2014-07-14 02:29:56,512 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,513 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3754ms
2014-07-14 02:29:56,514 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,514 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3765ms
2014-07-14 02:29:56,514 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,514 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3793ms
2014-07-14 02:29:56,514 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,514 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3801ms
2014-07-14 02:29:56,514 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,517 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3806ms
2014-07-14 02:29:56,517 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:29:56,711 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:29:56,712 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 401.2m
2014-07-14 02:29:56,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:56,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72447 synced till here 72443
2014-07-14 02:29:57,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330189776 with entries=79, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330196917
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330059219
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330060275
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330063502
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330064588
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330065957
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330068207
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330071854
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330074144
2014-07-14 02:29:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330076639
2014-07-14 02:29:57,319 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:29:58,360 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:29:58,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72534 synced till here 72524
2014-07-14 02:29:58,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330196917 with entries=87, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330198360
2014-07-14 02:30:01,057 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18144, memsize=60.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/effef5d76b2842c39d77b8199dc6679e
2014-07-14 02:30:01,076 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/effef5d76b2842c39d77b8199dc6679e as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/effef5d76b2842c39d77b8199dc6679e
2014-07-14 02:30:01,091 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/effef5d76b2842c39d77b8199dc6679e, entries=219890, sequenceid=18144, filesize=15.7m
2014-07-14 02:30:01,092 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~402.8m/422374640, currentsize=49.6m/52003040 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 4380ms, sequenceid=18144, compaction requested=true
2014-07-14 02:30:01,092 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-14 02:30:06,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:06,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330198360 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330206917
2014-07-14 02:30:07,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:08,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72685 synced till here 72680
2014-07-14 02:30:08,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330206917 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330207850
2014-07-14 02:30:09,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:09,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72759 synced till here 72755
2014-07-14 02:30:09,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330207850 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330209240
2014-07-14 02:30:10,523 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1127ms
GC pool 'ParNew' had collection(s): count=1 time=1139ms
2014-07-14 02:30:11,312 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:11,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72846 synced till here 72835
2014-07-14 02:30:11,378 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:30:11,379 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 257.2m
2014-07-14 02:30:11,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330209240 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330211313
2014-07-14 02:30:12,396 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:30:12,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:12,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72919 synced till here 72918
2014-07-14 02:30:12,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330211313 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330212872
2014-07-14 02:30:14,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:14,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72991 synced till here 72990
2014-07-14 02:30:14,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330212872 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330214365
2014-07-14 02:30:16,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:16,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73070 synced till here 73065
2014-07-14 02:30:16,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330214365 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330216603
2014-07-14 02:30:16,816 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:30:17,786 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18262, memsize=119.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/83218b751b0645d3a066b87180bcb6d3
2014-07-14 02:30:17,805 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/83218b751b0645d3a066b87180bcb6d3 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/83218b751b0645d3a066b87180bcb6d3
2014-07-14 02:30:17,825 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/83218b751b0645d3a066b87180bcb6d3, entries=434780, sequenceid=18262, filesize=30.9m
2014-07-14 02:30:17,825 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~263.7m/276522640, currentsize=90.1m/94527360 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 6446ms, sequenceid=18262, compaction requested=true
2014-07-14 02:30:17,826 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:146), split_queue=0, merge_queue=0
2014-07-14 02:30:17,826 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:30:17,826 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-14 02:30:18,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:18,829 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18140, memsize=522.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0d2bdeb807914855bfc4f10b1c92c3b2
2014-07-14 02:30:18,845 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0d2bdeb807914855bfc4f10b1c92c3b2 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d2bdeb807914855bfc4f10b1c92c3b2
2014-07-14 02:30:18,847 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73162 synced till here 73159
2014-07-14 02:30:18,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330216603 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330218517
2014-07-14 02:30:18,923 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d2bdeb807914855bfc4f10b1c92c3b2, entries=1900880, sequenceid=18140, filesize=135.4m
2014-07-14 02:30:18,924 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.4g/1548548480, currentsize=301.4m/316046560 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 29975ms, sequenceid=18140, compaction requested=true
2014-07-14 02:30:18,924 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-14 02:30:18,926 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:30:18,926 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:30:18,927 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:149), split_queue=0, merge_queue=0
2014-07-14 02:30:20,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:20,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73236 synced till here 73234
2014-07-14 02:30:20,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330218517 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330220129
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330081033
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330083509
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330086078
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330094460
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330095964
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330098102
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330099634
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330101669
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330103798
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330105859
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330111469
2014-07-14 02:30:20,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330113421
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330116635
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330118972
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330119936
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330121549
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330122988
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330124785
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330126718
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330128195
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330130498
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330132011
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330133728
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330135925
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330138036
2014-07-14 02:30:20,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330139882
2014-07-14 02:30:21,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:21,886 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330220129 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330221862
2014-07-14 02:30:24,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:24,603 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330221862 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330224565
2014-07-14 02:30:27,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:27,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73453 synced till here 73452
2014-07-14 02:30:27,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330224565 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330227231
2014-07-14 02:30:28,671 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:30:28,672 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 256.4m
2014-07-14 02:30:28,735 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:28,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73525 synced till here 73524
2014-07-14 02:30:28,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330227231 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330228736
2014-07-14 02:30:28,811 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:30:31,217 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:31,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330228736 with entries=72, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231218
2014-07-14 02:30:31,249 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:31,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:32,055 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73672 synced till here 73669
2014-07-14 02:30:32,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231218 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231998
2014-07-14 02:30:32,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:34,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:34,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73750 synced till here 73745
2014-07-14 02:30:35,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231998 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330234561
2014-07-14 02:30:35,092 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:35,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:35,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73826 synced till here 73822
2014-07-14 02:30:35,991 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/8a0183a500e94e07864b4c7482dfe157 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/8a0183a500e94e07864b4c7482dfe157
2014-07-14 02:30:36,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330234561 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330235920
2014-07-14 02:30:36,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:36,538 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:30:36,564 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f2ff5c6f0e724786b85486f26e2e7dc6, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f2ff5c6f0e724786b85486f26e2e7dc6
2014-07-14 02:30:36,567 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5e50ff5de7864737a4831a171510dd2a, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5e50ff5de7864737a4831a171510dd2a
2014-07-14 02:30:36,571 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e40737158bb447d6abf0dc540b6787b5, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e40737158bb447d6abf0dc540b6787b5
2014-07-14 02:30:36,572 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 8a0183a500e94e07864b4c7482dfe157(size=215.3m), total size for store is 3.5g. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-14 02:30:36,573 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=3, fileSize=235.5m, priority=-1, time=284103645442176; duration=40sec
2014-07-14 02:30:36,574 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 02:30:36,574 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 02:30:36,576 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:30:36,580 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 361043934 starting at candidate #8 after considering 124 permutations with 118 in ratio
2014-07-14 02:30:36,580 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:30:36,580 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:30:36,580 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=344.3m
2014-07-14 02:30:36,581 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/ceef6c706b5540de91fed47c3c2c0be5, keycount=97331, bloomtype=ROW, size=69.3m, encoding=NONE, seqNum=11523
2014-07-14 02:30:36,581 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d374c28962f84d7fb2697ecd767cec48, keycount=177813, bloomtype=ROW, size=126.5m, encoding=NONE, seqNum=12090
2014-07-14 02:30:36,581 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/db43f7b0cf784c26baa94eb30c7d9e01, keycount=128289, bloomtype=ROW, size=91.3m, encoding=NONE, seqNum=12657
2014-07-14 02:30:36,581 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d68fbd3748804553b48e79cbfce2883f, keycount=80274, bloomtype=ROW, size=57.2m, encoding=NONE, seqNum=13036
2014-07-14 02:30:37,105 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 565.1m
2014-07-14 02:30:37,208 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:30:37,615 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:30:38,464 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18428, memsize=254.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/78d89773952643209f590f7a1b25463f
2014-07-14 02:30:38,487 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/78d89773952643209f590f7a1b25463f as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/78d89773952643209f590f7a1b25463f
2014-07-14 02:30:38,508 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/78d89773952643209f590f7a1b25463f, entries=928250, sequenceid=18428, filesize=66.1m
2014-07-14 02:30:38,508 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268900800, currentsize=144.8m/151869360 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 9836ms, sequenceid=18428, compaction requested=true
2014-07-14 02:30:38,508 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 02:30:38,657 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:38,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330235920 with entries=72, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330238657
2014-07-14 02:30:38,692 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:40,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:40,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73984 synced till here 73980
2014-07-14 02:30:40,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330238657 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330240286
2014-07-14 02:30:40,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:41,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:41,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74059 synced till here 74056
2014-07-14 02:30:42,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330240286 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330241979
2014-07-14 02:30:42,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:43,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:43,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74149 synced till here 74146
2014-07-14 02:30:43,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330241979 with entries=90, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330243507
2014-07-14 02:30:43,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:44,514 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:30:44,514 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:30:44,515 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-14 02:30:45,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:45,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330243507 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330245153
2014-07-14 02:30:45,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:47,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:47,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74296 synced till here 74295
2014-07-14 02:30:47,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330245153 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330247819
2014-07-14 02:30:47,868 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:49,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:49,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330247819 with entries=73, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330249906
2014-07-14 02:30:49,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:51,384 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:51,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74443 synced till here 74442
2014-07-14 02:30:51,421 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330249906 with entries=74, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330251384
2014-07-14 02:30:51,422 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:53,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:53,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74516 synced till here 74515
2014-07-14 02:30:53,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330251384 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330253029
2014-07-14 02:30:53,092 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:54,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:54,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74591 synced till here 74588
2014-07-14 02:30:54,509 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330253029 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330254434
2014-07-14 02:30:54,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:54,851 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18506, memsize=470.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/93950a5ae16c46d6b560ad6a8afcb622
2014-07-14 02:30:54,866 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/93950a5ae16c46d6b560ad6a8afcb622 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/93950a5ae16c46d6b560ad6a8afcb622
2014-07-14 02:30:54,877 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/93950a5ae16c46d6b560ad6a8afcb622, entries=1711630, sequenceid=18506, filesize=121.8m
2014-07-14 02:30:54,877 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~566.6m/594169520, currentsize=299.0m/313521760 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 17772ms, sequenceid=18506, compaction requested=true
2014-07-14 02:30:54,878 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:152), split_queue=0, merge_queue=0
2014-07-14 02:30:54,927 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:30:54,927 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:30:54,927 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-14 02:30:55,980 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:56,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330254434 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330255980
2014-07-14 02:30:56,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:30:58,777 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:30:58,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74750 synced till here 74749
2014-07-14 02:30:58,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330255980 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330258778
2014-07-14 02:30:58,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:31:01,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:01,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74822 synced till here 74821
2014-07-14 02:31:01,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330258778 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330261113
2014-07-14 02:31:01,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:31:02,114 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90257ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:31:02,115 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.5g
2014-07-14 02:31:02,852 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:02,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74897 synced till here 74893
2014-07-14 02:31:02,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330261113 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330262852
2014-07-14 02:31:03,919 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:31:04,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:04,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74973 synced till here 74970
2014-07-14 02:31:04,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330262852 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330264469
2014-07-14 02:31:05,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:05,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75048 synced till here 75046
2014-07-14 02:31:05,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330264469 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330265436
2014-07-14 02:31:07,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:07,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75122 synced till here 75120
2014-07-14 02:31:07,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330265436 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330267081
2014-07-14 02:31:07,236 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:31:07,237 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files, but is 1.0g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:31:07,237 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. due to global heap pressure
2014-07-14 02:31:07,237 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 1.0g
2014-07-14 02:31:08,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:08,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75197 synced till here 75195
2014-07-14 02:31:08,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330267081 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330268403
2014-07-14 02:31:08,519 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:31:10,241 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,242 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,251 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,269 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,269 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,300 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,387 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,418 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,450 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,483 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,520 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,549 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,580 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,613 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,645 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.65 MB, free=3.95 GB, max=3.96 GB, blocks=6, accesses=431162, hits=128649, hitRatio=29.83%, , cachingAccesses=128698, cachingHits=128595, cachingHitsRatio=99.91%, evictions=0, evicted=97, evictedPerRun=Infinity
2014-07-14 02:31:11,360 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,132 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,150 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,180 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,213 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,247 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,286 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,329 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,364 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,402 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,438 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,481 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,518 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,763 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,822 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,877 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,941 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:12,991 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,065 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,114 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,160 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,194 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,376 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,430 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,484 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,528 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,567 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,595 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,631 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,665 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:13,978 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:14,037 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:14,364 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:14,404 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:14,440 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:31:15,631 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5017ms
2014-07-14 02:31:15,631 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-14 02:31:15,631 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-14 02:31:15,632 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5331ms
2014-07-14 02:31:15,632 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5245ms
2014-07-14 02:31:15,632 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5182ms
2014-07-14 02:31:15,633 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5215ms
2014-07-14 02:31:15,633 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5150ms
2014-07-14 02:31:15,633 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5084ms
2014-07-14 02:31:15,634 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5114ms
2014-07-14 02:31:15,634 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5054ms
2014-07-14 02:31:15,635 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5393ms
2014-07-14 02:31:15,635 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5394ms
2014-07-14 02:31:15,635 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5384ms
2014-07-14 02:31:15,645 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:16,377 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5017ms
2014-07-14 02:31:17,133 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,150 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,181 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,213 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,247 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,286 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,329 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,364 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,403 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,439 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,481 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,518 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,763 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,822 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,878 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:17,941 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:17,992 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:18,065 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,116 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:18,161 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:18,194 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,376 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,431 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,484 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,528 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,568 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:18,595 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,631 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:31:18,666 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:31:19,707 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5267ms
2014-07-14 02:31:19,707 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5729ms
2014-07-14 02:31:19,707 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5670ms
2014-07-14 02:31:19,707 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5343ms
2014-07-14 02:31:19,707 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5303ms
2014-07-14 02:31:20,631 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10018ms
2014-07-14 02:31:20,632 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10362ms
2014-07-14 02:31:20,632 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10332ms
2014-07-14 02:31:20,632 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10363ms
2014-07-14 02:31:20,633 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10182ms
2014-07-14 02:31:20,633 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10246ms
2014-07-14 02:31:20,633 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10216ms
2014-07-14 02:31:20,633 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10150ms
2014-07-14 02:31:20,634 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10085ms
2014-07-14 02:31:20,634 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10114ms
2014-07-14 02:31:20,635 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10055ms
2014-07-14 02:31:20,636 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10394ms
2014-07-14 02:31:20,636 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10385ms
2014-07-14 02:31:20,636 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10395ms
2014-07-14 02:31:20,646 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:21,378 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10018ms
2014-07-14 02:31:22,134 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:31:22,150 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,182 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:31:22,214 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,248 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,286 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,330 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,364 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,403 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,439 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,482 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,518 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,763 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:31:22,822 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,878 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,942 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:22,992 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:23,943 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:31:23,943 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10513ms
2014-07-14 02:31:23,943 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10459ms
2014-07-14 02:31:23,944 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10416ms
2014-07-14 02:31:23,944 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10377ms
2014-07-14 02:31:23,944 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10349ms
2014-07-14 02:31:23,945 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10314ms
2014-07-14 02:31:23,945 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10280ms
2014-07-14 02:31:23,946 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10831ms
2014-07-14 02:31:23,946 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10786ms
2014-07-14 02:31:23,946 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10752ms
2014-07-14 02:31:23,947 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10571ms
2014-07-14 02:31:24,707 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10267ms
2014-07-14 02:31:24,708 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10344ms
2014-07-14 02:31:24,708 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10671ms
2014-07-14 02:31:24,708 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10730ms
2014-07-14 02:31:24,708 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10304ms
2014-07-14 02:31:25,632 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15018ms
2014-07-14 02:31:25,632 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15363ms
2014-07-14 02:31:25,633 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15332ms
2014-07-14 02:31:25,633 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15364ms
2014-07-14 02:31:25,633 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15183ms
2014-07-14 02:31:25,634 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15151ms
2014-07-14 02:31:25,634 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15217ms
2014-07-14 02:31:25,634 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15247ms
2014-07-14 02:31:25,634 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15114ms
2014-07-14 02:31:25,635 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15086ms
2014-07-14 02:31:25,635 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15055ms
2014-07-14 02:31:25,636 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15395ms
2014-07-14 02:31:25,637 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15385ms
2014-07-14 02:31:25,637 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15396ms
2014-07-14 02:31:25,646 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:31:26,379 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15019ms
2014-07-14 02:31:27,134 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:31:27,151 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:31:27,183 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-14 02:31:28,162 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15171ms
2014-07-14 02:31:28,163 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15222ms
2014-07-14 02:31:28,165 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15647ms
2014-07-14 02:31:28,165 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15402ms
2014-07-14 02:31:28,165 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15801ms
2014-07-14 02:31:28,165 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15952ms
2014-07-14 02:31:28,165 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15344ms
2014-07-14 02:31:28,166 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15288ms
2014-07-14 02:31:28,166 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15919ms
2014-07-14 02:31:28,166 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15881ms
2014-07-14 02:31:28,166 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15837ms
2014-07-14 02:31:28,177 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15775ms
2014-07-14 02:31:28,178 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15740ms
2014-07-14 02:31:28,178 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15697ms
2014-07-14 02:31:28,943 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15878ms
2014-07-14 02:31:28,944 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15460ms
2014-07-14 02:31:28,944 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15514ms
2014-07-14 02:31:28,944 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15377ms
2014-07-14 02:31:28,945 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15417ms
2014-07-14 02:31:28,945 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15350ms
2014-07-14 02:31:28,946 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15314ms
2014-07-14 02:31:28,946 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15281ms
2014-07-14 02:31:28,946 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15832ms
2014-07-14 02:31:28,947 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15787ms
2014-07-14 02:31:28,947 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15571ms
2014-07-14 02:31:28,947 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15753ms
2014-07-14 02:31:29,708 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15268ms
2014-07-14 02:31:29,708 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15344ms
2014-07-14 02:31:29,709 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15305ms
2014-07-14 02:31:29,709 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15731ms
2014-07-14 02:31:29,709 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15672ms
2014-07-14 02:31:30,632 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20019ms
2014-07-14 02:31:30,633 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20364ms
2014-07-14 02:31:30,633 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20364ms
2014-07-14 02:31:30,634 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20333ms
2014-07-14 02:31:30,634 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20151ms
2014-07-14 02:31:30,634 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20184ms
2014-07-14 02:31:30,635 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20248ms
2014-07-14 02:31:30,635 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20218ms
2014-07-14 02:31:30,636 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20086ms
2014-07-14 02:31:30,636 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20116ms
2014-07-14 02:31:30,636 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20056ms
2014-07-14 02:31:30,636 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20395ms
2014-07-14 02:31:30,637 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20386ms
2014-07-14 02:31:30,637 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20396ms
2014-07-14 02:31:30,646 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 02:31:31,379 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20019ms
2014-07-14 02:31:32,404 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20224ms
2014-07-14 02:31:32,404 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20272ms
2014-07-14 02:31:32,405 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20255ms
2014-07-14 02:31:33,163 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20171ms
2014-07-14 02:31:33,164 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20222ms
2014-07-14 02:31:33,165 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20647ms
2014-07-14 02:31:33,165 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20402ms
2014-07-14 02:31:33,165 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20801ms
2014-07-14 02:31:33,165 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20952ms
2014-07-14 02:31:33,166 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20345ms
2014-07-14 02:31:33,166 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20289ms
2014-07-14 02:31:33,166 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20919ms
2014-07-14 02:31:33,167 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20881ms
2014-07-14 02:31:33,167 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20838ms
2014-07-14 02:31:33,178 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20776ms
2014-07-14 02:31:33,178 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20740ms
2014-07-14 02:31:33,178 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20697ms
2014-07-14 02:31:33,495 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/4a434c7dd72946edb994ccb017acf8ab as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4a434c7dd72946edb994ccb017acf8ab
2014-07-14 02:31:33,510 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:31:33,517 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/ceef6c706b5540de91fed47c3c2c0be5, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/ceef6c706b5540de91fed47c3c2c0be5
2014-07-14 02:31:33,519 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d374c28962f84d7fb2697ecd767cec48, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d374c28962f84d7fb2697ecd767cec48
2014-07-14 02:31:33,521 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/db43f7b0cf784c26baa94eb30c7d9e01, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/db43f7b0cf784c26baa94eb30c7d9e01
2014-07-14 02:31:33,523 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d68fbd3748804553b48e79cbfce2883f, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d68fbd3748804553b48e79cbfce2883f
2014-07-14 02:31:33,523 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into 4a434c7dd72946edb994ccb017acf8ab(size=315.8m), total size for store is 3.4g. This selection was in queue for 0sec, and took 56sec to execute.
2014-07-14 02:31:33,523 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=4, fileSize=344.3m, priority=-1, time=284144007028325; duration=56sec
2014-07-14 02:31:33,524 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-14 02:31:33,524 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:31:33,526 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 368878706 starting at candidate #6 after considering 124 permutations with 122 in ratio
2014-07-14 02:31:33,526 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:31:33,526 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:31:33,526 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=351.8m
2014-07-14 02:31:33,526 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0ee42f82cc7c42cbb9f3a847f3c21321, keycount=124346, bloomtype=ROW, size=88.5m, encoding=NONE, seqNum=9094
2014-07-14 02:31:33,527 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e7d09c7f7a754c2e8f9186b30e27708d, keycount=170791, bloomtype=ROW, size=121.7m, encoding=NONE, seqNum=9723
2014-07-14 02:31:33,527 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8e36cd8a367406da52207db5f07f9ea, keycount=105824, bloomtype=ROW, size=75.3m, encoding=NONE, seqNum=10080
2014-07-14 02:31:33,527 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/7c27c463683641ffac247eab70f72b3d, keycount=93104, bloomtype=ROW, size=66.3m, encoding=NONE, seqNum=10247
2014-07-14 02:31:33,701 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:31:33,946 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20879ms
2014-07-14 02:31:33,946 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20281ms
2014-07-14 02:31:33,946 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20315ms
2014-07-14 02:31:33,946 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20351ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20419ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20380ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20517ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20463ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20833ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20787ms
2014-07-14 02:31:33,947 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20571ms
2014-07-14 02:31:33,948 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20754ms
2014-07-14 02:31:34,708 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20268ms
2014-07-14 02:31:34,709 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20345ms
2014-07-14 02:31:34,709 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20305ms
2014-07-14 02:31:34,709 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20731ms
2014-07-14 02:31:34,709 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20672ms
2014-07-14 02:31:35,633 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25020ms
2014-07-14 02:31:35,633 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25364ms
2014-07-14 02:31:35,634 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25365ms
2014-07-14 02:31:35,634 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25334ms
2014-07-14 02:31:35,635 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25152ms
2014-07-14 02:31:35,635 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25185ms
2014-07-14 02:31:35,636 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25219ms
2014-07-14 02:31:35,636 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25249ms
2014-07-14 02:31:35,636 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25087ms
2014-07-14 02:31:35,637 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25116ms
2014-07-14 02:31:35,637 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25396ms
2014-07-14 02:31:35,637 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25057ms
2014-07-14 02:31:35,637 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25386ms
2014-07-14 02:31:35,637 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25396ms
2014-07-14 02:31:35,647 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 02:31:37,033 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25673ms
2014-07-14 02:31:37,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25224ms
2014-07-14 02:31:37,405 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25255ms
2014-07-14 02:31:37,405 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25273ms
2014-07-14 02:31:38,164 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25172ms
2014-07-14 02:31:38,164 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25223ms
2014-07-14 02:31:38,166 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25647ms
2014-07-14 02:31:38,166 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25953ms
2014-07-14 02:31:38,166 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25802ms
2014-07-14 02:31:38,167 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25403ms
2014-07-14 02:31:38,167 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25882ms
2014-07-14 02:31:38,167 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25920ms
2014-07-14 02:31:38,167 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25290ms
2014-07-14 02:31:38,168 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25347ms
2014-07-14 02:31:38,168 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25839ms
2014-07-14 02:31:38,178 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25776ms
2014-07-14 02:31:38,178 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25740ms
2014-07-14 02:31:38,178 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25697ms
2014-07-14 02:31:38,946 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25881ms
2014-07-14 02:31:38,947 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25315ms
2014-07-14 02:31:38,947 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25282ms
2014-07-14 02:31:38,947 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25517ms
2014-07-14 02:31:38,947 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25463ms
2014-07-14 02:31:38,947 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25380ms
2014-07-14 02:31:38,948 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25420ms
2014-07-14 02:31:38,948 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25572ms
2014-07-14 02:31:38,948 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25353ms
2014-07-14 02:31:38,948 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25754ms
2014-07-14 02:31:38,948 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25788ms
2014-07-14 02:31:38,949 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25834ms
2014-07-14 02:31:39,709 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25269ms
2014-07-14 02:31:39,709 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25345ms
2014-07-14 02:31:39,709 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25305ms
2014-07-14 02:31:39,710 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25673ms
2014-07-14 02:31:39,710 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25732ms
2014-07-14 02:31:40,633 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30020ms
2014-07-14 02:31:40,634 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30365ms
2014-07-14 02:31:40,634 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30365ms
2014-07-14 02:31:40,635 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30335ms
2014-07-14 02:31:40,635 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30152ms
2014-07-14 02:31:40,636 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30186ms
2014-07-14 02:31:40,636 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30219ms
2014-07-14 02:31:40,636 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30249ms
2014-07-14 02:31:40,637 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30087ms
2014-07-14 02:31:40,637 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30117ms
2014-07-14 02:31:40,637 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30396ms
2014-07-14 02:31:40,637 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30057ms
2014-07-14 02:31:40,638 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30397ms
2014-07-14 02:31:40,638 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30387ms
2014-07-14 02:31:40,647 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30002ms
2014-07-14 02:31:42,034 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30674ms
2014-07-14 02:31:42,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30225ms
2014-07-14 02:31:42,406 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30274ms
2014-07-14 02:31:42,406 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30256ms
2014-07-14 02:31:43,164 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30173ms
2014-07-14 02:31:43,165 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30224ms
2014-07-14 02:31:43,166 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30648ms
2014-07-14 02:31:43,166 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30953ms
2014-07-14 02:31:43,167 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30803ms
2014-07-14 02:31:43,167 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30404ms
2014-07-14 02:31:43,168 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30882ms
2014-07-14 02:31:43,168 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30291ms
2014-07-14 02:31:43,168 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30921ms
2014-07-14 02:31:43,168 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30347ms
2014-07-14 02:31:43,169 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30839ms
2014-07-14 02:31:43,178 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30776ms
2014-07-14 02:31:43,179 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30741ms
2014-07-14 02:31:43,179 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30698ms
2014-07-14 02:31:43,947 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30882ms
2014-07-14 02:31:43,947 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30316ms
2014-07-14 02:31:43,947 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30282ms
2014-07-14 02:31:43,948 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30517ms
2014-07-14 02:31:43,948 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30381ms
2014-07-14 02:31:43,948 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30464ms
2014-07-14 02:31:43,948 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30420ms
2014-07-14 02:31:43,949 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30353ms
2014-07-14 02:31:43,949 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30573ms
2014-07-14 02:31:43,949 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30835ms
2014-07-14 02:31:43,949 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30789ms
2014-07-14 02:31:43,949 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30755ms
2014-07-14 02:31:44,709 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30269ms
2014-07-14 02:31:44,709 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30345ms
2014-07-14 02:31:44,710 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30306ms
2014-07-14 02:31:44,710 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30673ms
2014-07-14 02:31:44,710 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30732ms
2014-07-14 02:31:45,634 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35021ms
2014-07-14 02:31:45,634 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35365ms
2014-07-14 02:31:45,634 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35365ms
2014-07-14 02:31:45,635 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35335ms
2014-07-14 02:31:45,636 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35153ms
2014-07-14 02:31:45,636 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35186ms
2014-07-14 02:31:45,636 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35219ms
2014-07-14 02:31:45,637 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35250ms
2014-07-14 02:31:45,637 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35088ms
2014-07-14 02:31:45,637 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35117ms
2014-07-14 02:31:45,638 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35397ms
2014-07-14 02:31:45,638 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35058ms
2014-07-14 02:31:45,638 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35397ms
2014-07-14 02:31:45,639 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35388ms
2014-07-14 02:31:45,647 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35002ms
2014-07-14 02:31:47,035 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35675ms
2014-07-14 02:31:47,406 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35226ms
2014-07-14 02:31:47,406 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35274ms
2014-07-14 02:31:47,406 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35256ms
2014-07-14 02:31:48,493 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36012ms
2014-07-14 02:31:48,494 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36056ms
2014-07-14 02:31:48,494 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35503ms
2014-07-14 02:31:48,494 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35553ms
2014-07-14 02:31:48,494 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35976ms
2014-07-14 02:31:48,494 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36281ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36131ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35732ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36210ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35618ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36248ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35674ms
2014-07-14 02:31:48,495 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36166ms
2014-07-14 02:31:48,496 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36093ms
2014-07-14 02:31:48,638 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18767, memsize=952.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/27608c4b79f945d7bf4e35c02a1a5e8c
2014-07-14 02:31:48,829 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/27608c4b79f945d7bf4e35c02a1a5e8c as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/27608c4b79f945d7bf4e35c02a1a5e8c
2014-07-14 02:31:48,840 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/27608c4b79f945d7bf4e35c02a1a5e8c, entries=3469120, sequenceid=18767, filesize=246.8m
2014-07-14 02:31:48,840 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.5g/1650296000, currentsize=150.6m/157946000 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 46725ms, sequenceid=18767, compaction requested=true
2014-07-14 02:31:48,841 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-14 02:31:48,841 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36439ms
2014-07-14 02:31:48,841 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,841 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36512ms
2014-07-14 02:31:48,841 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,842 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36021ms
2014-07-14 02:31:48,842 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,842 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36595ms
2014-07-14 02:31:48,842 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,843 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35966ms
2014-07-14 02:31:48,843 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,843 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36558ms
2014-07-14 02:31:48,843 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,844 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36081ms
2014-07-14 02:31:48,844 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,845 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36481ms
2014-07-14 02:31:48,845 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,845 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36632ms
2014-07-14 02:31:48,845 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,845 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36327ms
2014-07-14 02:31:48,845 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,845 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35904ms
2014-07-14 02:31:48,845 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,845 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35854ms
2014-07-14 02:31:48,845 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,846 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36408ms
2014-07-14 02:31:48,846 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,846 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36365ms
2014-07-14 02:31:48,846 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,846 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36696ms
2014-07-14 02:31:48,846 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,846 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36714ms
2014-07-14 02:31:48,846 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,847 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36667ms
2014-07-14 02:31:48,847 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,847 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 37487ms
2014-07-14 02:31:48,847 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,847 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38202ms
2014-07-14 02:31:48,848 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,848 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38597ms
2014-07-14 02:31:48,848 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,848 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38607ms
2014-07-14 02:31:48,848 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,851 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38271ms
2014-07-14 02:31:48,851 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,853 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38611ms
2014-07-14 02:31:48,853 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,853 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38333ms
2014-07-14 02:31:48,853 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,854 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38305ms
2014-07-14 02:31:48,854 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,854 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38467ms
2014-07-14 02:31:48,854 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,854 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38437ms
2014-07-14 02:31:48,854 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,854 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38404ms
2014-07-14 02:31:48,854 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,857 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38374ms
2014-07-14 02:31:48,858 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,859 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38559ms
2014-07-14 02:31:48,859 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,859 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38590ms
2014-07-14 02:31:48,859 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,859 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38590ms
2014-07-14 02:31:48,859 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,861 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38248ms
2014-07-14 02:31:48,861 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,861 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34883ms
2014-07-14 02:31:48,862 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,862 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34825ms
2014-07-14 02:31:48,862 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,862 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34458ms
2014-07-14 02:31:48,862 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,862 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34498ms
2014-07-14 02:31:48,862 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,862 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34422ms
2014-07-14 02:31:48,862 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,862 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35668ms
2014-07-14 02:31:48,863 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,863 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35703ms
2014-07-14 02:31:48,863 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,863 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35749ms
2014-07-14 02:31:48,863 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,863 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35487ms
2014-07-14 02:31:48,863 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,863 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35268ms
2014-07-14 02:31:48,864 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,869 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35341ms
2014-07-14 02:31:48,869 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,870 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35385ms
2014-07-14 02:31:48,870 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,870 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35303ms
2014-07-14 02:31:48,870 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,873 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35442ms
2014-07-14 02:31:48,873 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,873 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35208ms
2014-07-14 02:31:48,873 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,874 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35243ms
2014-07-14 02:31:48,874 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,874 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35809ms
2014-07-14 02:31:48,874 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:31:48,921 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18825, memsize=967.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/649c642706d846abbcc80191ee5fd4eb
2014-07-14 02:31:48,934 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/649c642706d846abbcc80191ee5fd4eb as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/649c642706d846abbcc80191ee5fd4eb
2014-07-14 02:31:48,954 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/649c642706d846abbcc80191ee5fd4eb, entries=3522950, sequenceid=18825, filesize=250.6m
2014-07-14 02:31:48,954 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1107305120, currentsize=49.8m/52259200 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 41717ms, sequenceid=18825, compaction requested=true
2014-07-14 02:31:48,955 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-14 02:31:49,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:49,028 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38990,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270036,"queuetimems":1,"class":"HRegionServer","responsesize":15619,"method":"Multi"}
2014-07-14 02:31:49,032 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330269986,"queuetimems":0,"class":"HRegionServer","responsesize":16037,"method":"Multi"}
2014-07-14 02:31:49,048 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75271 synced till here 75269
2014-07-14 02:31:49,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330268403 with entries=74, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330309024
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330143922
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330145148
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330146796
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330148560
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330150133
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330151746
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330153798
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330156805
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330159554
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330172207
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330175046
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330177000
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330179205
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330181305
2014-07-14 02:31:49,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330183982
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330185734
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330186911
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330189776
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330196917
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330198360
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330206917
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330207850
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330209240
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330211313
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330212872
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330214365
2014-07-14 02:31:49,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330216603
2014-07-14 02:31:49,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330218517
2014-07-14 02:31:49,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330220129
2014-07-14 02:31:49,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330221862
2014-07-14 02:31:49,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330224565
2014-07-14 02:31:49,148 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270086,"queuetimems":1,"class":"HRegionServer","responsesize":15529,"method":"Multi"}
2014-07-14 02:31:49,376 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39242,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270134,"queuetimems":0,"class":"HRegionServer","responsesize":15914,"method":"Multi"}
2014-07-14 02:31:49,528 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270226,"queuetimems":0,"class":"HRegionServer","responsesize":15702,"method":"Multi"}
2014-07-14 02:31:49,528 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270178,"queuetimems":0,"class":"HRegionServer","responsesize":15735,"method":"Multi"}
2014-07-14 02:31:50,008 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:50,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75374 synced till here 75347
2014-07-14 02:31:50,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330309024 with entries=103, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330310008
2014-07-14 02:31:51,100 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38778,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272322,"queuetimems":0,"class":"HRegionServer","responsesize":15697,"method":"Multi"}
2014-07-14 02:31:51,101 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272399,"queuetimems":1,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 02:31:51,101 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38954,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272147,"queuetimems":0,"class":"HRegionServer","responsesize":15818,"method":"Multi"}
2014-07-14 02:31:51,101 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272759,"queuetimems":0,"class":"HRegionServer","responsesize":15735,"method":"Multi"}
2014-07-14 02:31:51,102 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38857,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272244,"queuetimems":0,"class":"HRegionServer","responsesize":16139,"method":"Multi"}
2014-07-14 02:31:51,102 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38282,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272818,"queuetimems":1,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 02:31:51,507 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39295,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272211,"queuetimems":1,"class":"HRegionServer","responsesize":15745,"method":"Multi"}
2014-07-14 02:31:51,507 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272934,"queuetimems":0,"class":"HRegionServer","responsesize":15914,"method":"Multi"}
2014-07-14 02:31:51,717 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:51,719 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38529,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273190,"queuetimems":0,"class":"HRegionServer","responsesize":15619,"method":"Multi"}
2014-07-14 02:31:51,719 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273525,"queuetimems":1,"class":"HRegionServer","responsesize":15914,"method":"Multi"}
2014-07-14 02:31:51,720 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272178,"queuetimems":0,"class":"HRegionServer","responsesize":15721,"method":"Multi"}
2014-07-14 02:31:51,720 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270384,"queuetimems":0,"class":"HRegionServer","responsesize":15932,"method":"Multi"}
2014-07-14 02:31:51,720 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37745,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273975,"queuetimems":1,"class":"HRegionServer","responsesize":15757,"method":"Multi"}
2014-07-14 02:31:51,720 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272280,"queuetimems":0,"class":"HRegionServer","responsesize":15593,"method":"Multi"}
2014-07-14 02:31:51,720 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38732,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272988,"queuetimems":0,"class":"HRegionServer","responsesize":15927,"method":"Multi"}
2014-07-14 02:31:51,723 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270578,"queuetimems":0,"class":"HRegionServer","responsesize":15918,"method":"Multi"}
2014-07-14 02:31:51,723 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273628,"queuetimems":1,"class":"HRegionServer","responsesize":15662,"method":"Multi"}
2014-07-14 02:31:51,723 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273156,"queuetimems":0,"class":"HRegionServer","responsesize":16037,"method":"Multi"}
2014-07-14 02:31:51,724 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41274,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270449,"queuetimems":1,"class":"HRegionServer","responsesize":15861,"method":"Multi"}
2014-07-14 02:31:51,737 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38862,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272875,"queuetimems":0,"class":"HRegionServer","responsesize":15886,"method":"Multi"}
2014-07-14 02:31:51,738 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272476,"queuetimems":0,"class":"HRegionServer","responsesize":15894,"method":"Multi"}
2014-07-14 02:31:51,739 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37377,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330274361,"queuetimems":0,"class":"HRegionServer","responsesize":15727,"method":"Multi"}
2014-07-14 02:31:51,741 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273428,"queuetimems":0,"class":"HRegionServer","responsesize":15529,"method":"Multi"}
2014-07-14 02:31:51,742 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273592,"queuetimems":1,"class":"HRegionServer","responsesize":15881,"method":"Multi"}
2014-07-14 02:31:51,743 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38369,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273373,"queuetimems":0,"class":"HRegionServer","responsesize":15702,"method":"Multi"}
2014-07-14 02:31:51,749 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272361,"queuetimems":0,"class":"HRegionServer","responsesize":15357,"method":"Multi"}
2014-07-14 02:31:51,738 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37336,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330274402,"queuetimems":1,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-14 02:31:51,749 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270517,"queuetimems":0,"class":"HRegionServer","responsesize":16384,"method":"Multi"}
2014-07-14 02:31:51,739 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41322,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270416,"queuetimems":0,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-14 02:31:51,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75493 synced till here 75468
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270547,"queuetimems":0,"class":"HRegionServer","responsesize":16178,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38869,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273061,"queuetimems":0,"class":"HRegionServer","responsesize":16014,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272130,"queuetimems":0,"class":"HRegionServer","responsesize":15730,"method":"Multi"}
2014-07-14 02:31:51,931 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273481,"queuetimems":0,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41448,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270481,"queuetimems":1,"class":"HRegionServer","responsesize":15574,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":40572,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330271357,"queuetimems":1,"class":"HRegionServer","responsesize":15882,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38818,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273112,"queuetimems":1,"class":"HRegionServer","responsesize":15590,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270611,"queuetimems":0,"class":"HRegionServer","responsesize":15682,"method":"Multi"}
2014-07-14 02:31:51,930 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272434,"queuetimems":0,"class":"HRegionServer","responsesize":15634,"method":"Multi"}
2014-07-14 02:31:51,938 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39423,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330272515,"queuetimems":0,"class":"HRegionServer","responsesize":15523,"method":"Multi"}
2014-07-14 02:31:51,938 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38276,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273662,"queuetimems":0,"class":"HRegionServer","responsesize":15742,"method":"Multi"}
2014-07-14 02:31:51,939 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37906,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330274032,"queuetimems":0,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-14 02:31:51,938 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330273558,"queuetimems":0,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:31:51,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330310008 with entries=119, filesize=101.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330311718
2014-07-14 02:31:53,094 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330270643,"queuetimems":0,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-14 02:31:53,124 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38687,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330274437,"queuetimems":0,"class":"HRegionServer","responsesize":15697,"method":"Multi"}
2014-07-14 02:31:53,504 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:53,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75601 synced till here 75566
2014-07-14 02:31:53,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330311718 with entries=108, filesize=92.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330313504
2014-07-14 02:31:55,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:55,445 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:31:55,445 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:31:55,445 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:155), split_queue=0, merge_queue=0
2014-07-14 02:31:55,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75705 synced till here 75691
2014-07-14 02:31:55,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330313504 with entries=104, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330315437
2014-07-14 02:31:58,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:31:58,310 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75807 synced till here 75781
2014-07-14 02:31:58,495 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330315437 with entries=102, filesize=86.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330318141
2014-07-14 02:32:00,049 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:32:00,053 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 259.3m
2014-07-14 02:32:00,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75904 synced till here 75892
2014-07-14 02:32:00,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330318141 with entries=97, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330320521
2014-07-14 02:32:01,073 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:32:02,736 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:02,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76018 synced till here 75991
2014-07-14 02:32:02,960 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330320521 with entries=114, filesize=98.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330322736
2014-07-14 02:32:04,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:04,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76117 synced till here 76090
2014-07-14 02:32:04,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330322736 with entries=99, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330324380
2014-07-14 02:32:06,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:06,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76232 synced till here 76202
2014-07-14 02:32:06,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330324380 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330326531
2014-07-14 02:32:06,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:32:07,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:08,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76332 synced till here 76313
2014-07-14 02:32:08,750 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19020, memsize=110.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/4ad515a6388d4882be115e86a6928012
2014-07-14 02:32:08,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330326531 with entries=100, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330327734
2014-07-14 02:32:08,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:32:08,784 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/4ad515a6388d4882be115e86a6928012 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4ad515a6388d4882be115e86a6928012
2014-07-14 02:32:08,815 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4ad515a6388d4882be115e86a6928012, entries=401840, sequenceid=19020, filesize=28.6m
2014-07-14 02:32:08,819 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~299.7m/314309680, currentsize=144.6m/151608080 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 8766ms, sequenceid=19020, compaction requested=true
2014-07-14 02:32:08,819 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:156), split_queue=0, merge_queue=0
2014-07-14 02:32:10,978 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1535ms
GC pool 'ParNew' had collection(s): count=1 time=1544ms
2014-07-14 02:32:11,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:11,115 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76434 synced till here 76405
2014-07-14 02:32:11,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330327734 with entries=102, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330331040
2014-07-14 02:32:11,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:32:13,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:13,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76541 synced till here 76511
2014-07-14 02:32:13,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330331040 with entries=107, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330333386
2014-07-14 02:32:13,776 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:32:14,165 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:32:14,173 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 256.1m
2014-07-14 02:32:14,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:14,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76641 synced till here 76615
2014-07-14 02:32:14,756 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:32:15,333 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90819ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:32:15,333 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 1.2g
2014-07-14 02:32:15,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330333386 with entries=100, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330334545
2014-07-14 02:32:15,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:32:16,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:16,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76741 synced till here 76715
2014-07-14 02:32:16,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330334545 with entries=100, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330336205
2014-07-14 02:32:43,117 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 32139ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:32:43,117 WARN  [regionserver60020] util.Sleeper: We slept 26821ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:32:43,119 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26285ms
GC pool 'ParNew' had collection(s): count=1 time=997ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=25359ms
2014-07-14 02:32:43,120 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 32140ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:32:43,150 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334134,"queuetimems":5127,"class":"HRegionServer","responsesize":15574,"method":"Multi"}
2014-07-14 02:32:43,150 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31387 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,150 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334134,"queuetimems":5179,"class":"HRegionServer","responsesize":15721,"method":"Multi"}
2014-07-14 02:32:43,150 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29030,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334119,"queuetimems":5194,"class":"HRegionServer","responsesize":16037,"method":"Multi"}
2014-07-14 02:32:43,150 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28793,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334356,"queuetimems":5305,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-14 02:32:43,166 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31388 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,189 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,165 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,189 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31389 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,189 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,189 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31386 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,189 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,243 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28487,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334755,"queuetimems":5660,"class":"HRegionServer","responsesize":15730,"method":"Multi"}
2014-07-14 02:32:43,243 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31385 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,243 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,245 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:32:43,429 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334761,"queuetimems":3768,"class":"HRegionServer","responsesize":15634,"method":"Multi"}
2014-07-14 02:32:43,430 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31377 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,430 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28782,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334755,"queuetimems":5595,"class":"HRegionServer","responsesize":16139,"method":"Multi"}
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28782,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334755,"queuetimems":5624,"class":"HRegionServer","responsesize":15861,"method":"Multi"}
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31383 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31384 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,538 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,539 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27977,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335561,"queuetimems":4453,"class":"HRegionServer","responsesize":15357,"method":"Multi"}
2014-07-14 02:32:43,539 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31409 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,539 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,541 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28785,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334756,"queuetimems":5371,"class":"HRegionServer","responsesize":15745,"method":"Multi"}
2014-07-14 02:32:43,541 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335562,"queuetimems":4389,"class":"HRegionServer","responsesize":15662,"method":"Multi"}
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31379 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31408 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334756,"queuetimems":5426,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31380 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,542 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28785,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334757,"queuetimems":5338,"class":"HRegionServer","responsesize":15619,"method":"Multi"}
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31378 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334756,"queuetimems":5566,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330334756,"queuetimems":5535,"class":"HRegionServer","responsesize":15894,"method":"Multi"}
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335382,"queuetimems":4379,"class":"HRegionServer","responsesize":15918,"method":"Multi"}
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31382 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31381 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31376 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27992,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335552,"queuetimems":4478,"class":"HRegionServer","responsesize":15727,"method":"Multi"}
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335577,"queuetimems":4275,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-14 02:32:43,543 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27997,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335546,"queuetimems":4512,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31410 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,544 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27975,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335569,"queuetimems":4303,"class":"HRegionServer","responsesize":15590,"method":"Multi"}
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31405 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,545 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31406 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,546 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,546 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31395 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,546 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27964,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335593,"queuetimems":3865,"class":"HRegionServer","responsesize":15682,"method":"Multi"}
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27954,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335602,"queuetimems":3733,"class":"HRegionServer","responsesize":15698,"method":"Multi"}
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31399 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31396 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,557 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,601 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27999,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335602,"queuetimems":3771,"class":"HRegionServer","responsesize":15757,"method":"Multi"}
2014-07-14 02:32:43,602 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31397 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,602 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335565,"queuetimems":4340,"class":"HRegionServer","responsesize":15914,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28050,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335585,"queuetimems":3912,"class":"HRegionServer","responsesize":15886,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28053,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335583,"queuetimems":3953,"class":"HRegionServer","responsesize":15742,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31407 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31400 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335581,"queuetimems":4198,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28035,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335601,"queuetimems":3821,"class":"HRegionServer","responsesize":15927,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335580,"queuetimems":4239,"class":"HRegionServer","responsesize":15881,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47197","starttimems":1405330335582,"queuetimems":4148,"class":"HRegionServer","responsesize":16014,"method":"Multi"}
2014-07-14 02:32:43,636 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31401 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31404 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31402 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31398 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31403 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,637 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:43,792 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31413 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,792 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,805 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 31438 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47197: output error
2014-07-14 02:32:43,805 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:32:43,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330336205 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330363792
2014-07-14 02:32:44,489 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19193, memsize=65.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/89606190d7844a50a6a0df394c5b2106
2014-07-14 02:32:44,509 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/89606190d7844a50a6a0df394c5b2106 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/89606190d7844a50a6a0df394c5b2106
2014-07-14 02:32:44,520 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/89606190d7844a50a6a0df394c5b2106, entries=237510, sequenceid=19193, filesize=16.9m
2014-07-14 02:32:44,520 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~267.2m/280133600, currentsize=82.2m/86201840 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 30347ms, sequenceid=19193, compaction requested=true
2014-07-14 02:32:44,521 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 02:32:44,521 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 109594ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:32:44,521 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.1g
2014-07-14 02:32:45,347 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:32:56,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:56,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76887 synced till here 76885
2014-07-14 02:32:56,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330363792 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330376707
2014-07-14 02:32:58,003 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:58,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76961 synced till here 76960
2014-07-14 02:32:58,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330376707 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378004
2014-07-14 02:32:58,894 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:32:58,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77038 synced till here 77034
2014-07-14 02:32:59,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378004 with entries=77, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378894
2014-07-14 02:33:00,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:01,003 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77124 synced till here 77123
2014-07-14 02:33:01,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378894 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330380260
2014-07-14 02:33:02,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:02,134 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77197 synced till here 77196
2014-07-14 02:33:02,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330380260 with entries=73, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330382113
2014-07-14 02:33:03,462 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:33:03,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:03,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77271 synced till here 77269
2014-07-14 02:33:03,526 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330382113 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330383479
2014-07-14 02:33:04,668 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,671 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,690 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,735 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,779 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,826 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,862 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:04,908 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,194 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,254 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,301 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,361 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,423 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,470 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,528 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,574 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,622 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,811 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:05,853 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:06,322 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,066 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,078 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,088 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,115 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,145 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,187 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,213 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,246 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:07,276 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:08,350 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/17f35316da484cf4959d379ecc9868f8 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/17f35316da484cf4959d379ecc9868f8
2014-07-14 02:33:08,369 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:33:08,381 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0ee42f82cc7c42cbb9f3a847f3c21321, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0ee42f82cc7c42cbb9f3a847f3c21321
2014-07-14 02:33:08,385 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e7d09c7f7a754c2e8f9186b30e27708d, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/e7d09c7f7a754c2e8f9186b30e27708d
2014-07-14 02:33:08,390 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8e36cd8a367406da52207db5f07f9ea, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8e36cd8a367406da52207db5f07f9ea
2014-07-14 02:33:08,392 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/7c27c463683641ffac247eab70f72b3d, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/7c27c463683641ffac247eab70f72b3d
2014-07-14 02:33:08,392 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 17f35316da484cf4959d379ecc9868f8(size=330.9m), total size for store is 3.6g. This selection was in queue for 0sec, and took 1mins, 34sec to execute.
2014-07-14 02:33:08,392 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=4, fileSize=351.8m, priority=-1, time=284200953121237; duration=1mins, 34sec
2014-07-14 02:33:08,393 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 02:33:08,393 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:33:08,393 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 187593205 starting at candidate #7 after considering 132 permutations with 94 in ratio
2014-07-14 02:33:08,393 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating minor compaction
2014-07-14 02:33:08,394 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:33:08,394 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=178.9m
2014-07-14 02:33:08,394 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cf536ed0eeb94a7887da2d7328fdf69f, keycount=101941, bloomtype=ROW, size=72.6m, encoding=NONE, seqNum=10590
2014-07-14 02:33:08,394 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c394dc3cfb2240cc9b1980a8898fc798, keycount=37934, bloomtype=ROW, size=27.0m, encoding=NONE, seqNum=11009
2014-07-14 02:33:08,394 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/96cd7a2fe1714191b4f86ce9d03f81ca, keycount=111362, bloomtype=ROW, size=79.3m, encoding=NONE, seqNum=11284
2014-07-14 02:33:08,443 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:08,842 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:08,884 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:08,920 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:08,958 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:08,994 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,038 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,076 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,115 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,153 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,194 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,234 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,273 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,309 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,355 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,389 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,431 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,467 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:09,669 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:09,671 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:09,691 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:09,735 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:09,779 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:09,826 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:09,862 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:09,909 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,194 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,254 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,302 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,362 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,424 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,470 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,528 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,574 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,623 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:33:10,811 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,853 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:10,945 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:10,999 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19248, memsize=608.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/255a5a428e6f43b8a63a24f3671cb60f
2014-07-14 02:33:11,541 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5219ms
2014-07-14 02:33:11,544 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:11,553 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:11,556 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/255a5a428e6f43b8a63a24f3671cb60f as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/255a5a428e6f43b8a63a24f3671cb60f
2014-07-14 02:33:11,564 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:11,568 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/255a5a428e6f43b8a63a24f3671cb60f, entries=2215910, sequenceid=19248, filesize=157.7m
2014-07-14 02:33:11,568 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1206743920, currentsize=202.4m/212247200 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 27047ms, sequenceid=19248, compaction requested=true
2014-07-14 02:33:11,569 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 02:33:11,569 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5ms
2014-07-14 02:33:11,569 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,569 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:33:11,569 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16ms
2014-07-14 02:33:11,569 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,569 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:158), split_queue=0, merge_queue=0
2014-07-14 02:33:11,569 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25ms
2014-07-14 02:33:11,569 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:33:11,569 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,570 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:159), split_queue=0, merge_queue=0
2014-07-14 02:33:11,570 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5248ms
2014-07-14 02:33:11,570 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,570 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 625ms
2014-07-14 02:33:11,570 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,570 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5717ms
2014-07-14 02:33:11,570 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,570 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5759ms
2014-07-14 02:33:11,570 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,573 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5951ms
2014-07-14 02:33:11,573 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,573 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5999ms
2014-07-14 02:33:11,573 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,576 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6048ms
2014-07-14 02:33:11,576 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,580 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6109ms
2014-07-14 02:33:11,580 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,580 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6157ms
2014-07-14 02:33:11,580 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,581 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6219ms
2014-07-14 02:33:11,581 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,581 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6280ms
2014-07-14 02:33:11,581 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,581 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6327ms
2014-07-14 02:33:11,581 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,585 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6392ms
2014-07-14 02:33:11,585 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,593 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6685ms
2014-07-14 02:33:11,593 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,593 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6731ms
2014-07-14 02:33:11,593 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,599 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6774ms
2014-07-14 02:33:11,599 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,599 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6820ms
2014-07-14 02:33:11,599 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,601 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6866ms
2014-07-14 02:33:11,601 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,601 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6911ms
2014-07-14 02:33:11,602 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,602 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6931ms
2014-07-14 02:33:11,602 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,602 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6934ms
2014-07-14 02:33:11,602 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,602 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2135ms
2014-07-14 02:33:11,602 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,602 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2171ms
2014-07-14 02:33:11,603 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,607 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2219ms
2014-07-14 02:33:11,607 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,607 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2252ms
2014-07-14 02:33:11,607 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,610 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2300ms
2014-07-14 02:33:11,610 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,610 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2337ms
2014-07-14 02:33:11,611 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,611 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2377ms
2014-07-14 02:33:11,611 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,611 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2417ms
2014-07-14 02:33:11,611 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,611 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2458ms
2014-07-14 02:33:11,611 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,612 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2497ms
2014-07-14 02:33:11,612 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,613 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2538ms
2014-07-14 02:33:11,613 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,614 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2575ms
2014-07-14 02:33:11,614 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,614 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2620ms
2014-07-14 02:33:11,614 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,615 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2656ms
2014-07-14 02:33:11,615 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,615 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2695ms
2014-07-14 02:33:11,615 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,615 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2731ms
2014-07-14 02:33:11,615 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,616 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2773ms
2014-07-14 02:33:11,616 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,617 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4340ms
2014-07-14 02:33:11,617 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,617 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4371ms
2014-07-14 02:33:11,617 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,617 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4404ms
2014-07-14 02:33:11,617 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,617 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4430ms
2014-07-14 02:33:11,617 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,617 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4472ms
2014-07-14 02:33:11,618 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,618 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4503ms
2014-07-14 02:33:11,618 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,619 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4531ms
2014-07-14 02:33:11,619 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,619 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4541ms
2014-07-14 02:33:11,619 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:11,619 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4553ms
2014-07-14 02:33:11,619 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:12,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:12,076 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77382 synced till here 77364
2014-07-14 02:33:12,206 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:33:12,210 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 259.8m
2014-07-14 02:33:12,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330383479 with entries=111, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330392005
2014-07-14 02:33:13,573 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19221, memsize=734.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/ce0808e0b2a84502ac98109ebbf03f07
2014-07-14 02:33:13,600 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/ce0808e0b2a84502ac98109ebbf03f07 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ce0808e0b2a84502ac98109ebbf03f07
2014-07-14 02:33:13,617 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ce0808e0b2a84502ac98109ebbf03f07, entries=2673830, sequenceid=19221, filesize=190.3m
2014-07-14 02:33:13,619 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:13,629 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1281124160, currentsize=315.0m/330283040 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 58296ms, sequenceid=19221, compaction requested=true
2014-07-14 02:33:13,630 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:160), split_queue=0, merge_queue=0
2014-07-14 02:33:13,635 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:33:13,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:14,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77494 synced till here 77492
2014-07-14 02:33:14,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330392005 with entries=112, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330393920
2014-07-14 02:33:14,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330227231
2014-07-14 02:33:14,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330228736
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231218
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330231998
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330234561
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330235920
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330238657
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330240286
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330241979
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330243507
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330245153
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330247819
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330249906
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330251384
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330253029
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330254434
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330255980
2014-07-14 02:33:14,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330258778
2014-07-14 02:33:15,373 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10512,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330384860,"queuetimems":0,"class":"HRegionServer","responsesize":15959,"method":"Multi"}
2014-07-14 02:33:15,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:15,713 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10245,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330385468,"queuetimems":1,"class":"HRegionServer","responsesize":16049,"method":"Multi"}
2014-07-14 02:33:15,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77596 synced till here 77588
2014-07-14 02:33:15,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330393920 with entries=102, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330395708
2014-07-14 02:33:17,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:17,133 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77683 synced till here 77669
2014-07-14 02:33:17,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330395708 with entries=87, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330397107
2014-07-14 02:33:18,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:18,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77764 synced till here 77757
2014-07-14 02:33:19,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330397107 with entries=81, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330398887
2014-07-14 02:33:19,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:20,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77846 synced till here 77838
2014-07-14 02:33:20,606 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330398887 with entries=82, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330399871
2014-07-14 02:33:20,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:33:22,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:22,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77944 synced till here 77928
2014-07-14 02:33:22,598 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330399871 with entries=98, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330402372
2014-07-14 02:33:22,598 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:33:24,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:24,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78041 synced till here 78038
2014-07-14 02:33:24,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330402372 with entries=97, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330404391
2014-07-14 02:33:24,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:33:25,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:25,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78129 synced till here 78122
2014-07-14 02:33:25,966 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90522ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:33:25,967 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.2g
2014-07-14 02:33:26,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330404391 with entries=88, filesize=75.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330405777
2014-07-14 02:33:26,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:33:26,810 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19431, memsize=228.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0d868128736f4ab1a7c39168e4211478
2014-07-14 02:33:26,826 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/0d868128736f4ab1a7c39168e4211478 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d868128736f4ab1a7c39168e4211478
2014-07-14 02:33:26,837 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d868128736f4ab1a7c39168e4211478, entries=832310, sequenceid=19431, filesize=59.3m
2014-07-14 02:33:26,838 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~273.8m/287107840, currentsize=257.3m/269850800 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 14628ms, sequenceid=19431, compaction requested=true
2014-07-14 02:33:26,838 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:161), split_queue=0, merge_queue=0
2014-07-14 02:33:26,838 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:33:26,838 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:162), split_queue=0, merge_queue=0
2014-07-14 02:33:26,855 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:33:26,855 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 259.0m
2014-07-14 02:33:27,235 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:27,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78206 synced till here 78203
2014-07-14 02:33:27,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330405777 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330407235
2014-07-14 02:33:27,408 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:27,532 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:28,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:28,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78284 synced till here 78281
2014-07-14 02:33:28,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330407235 with entries=78, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330408153
2014-07-14 02:33:30,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:30,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78358 synced till here 78355
2014-07-14 02:33:30,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330408153 with entries=74, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330410432
2014-07-14 02:33:31,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:32,105 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78440 synced till here 78432
2014-07-14 02:33:32,183 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330410432 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330411587
2014-07-14 02:33:32,388 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19600, memsize=105.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/627afcb14b494faa980fb34c86ed9c91
2014-07-14 02:33:32,414 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/627afcb14b494faa980fb34c86ed9c91 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/627afcb14b494faa980fb34c86ed9c91
2014-07-14 02:33:32,428 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/627afcb14b494faa980fb34c86ed9c91, entries=385700, sequenceid=19600, filesize=27.5m
2014-07-14 02:33:32,428 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.6m/273292320, currentsize=105.4m/110533920 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 5573ms, sequenceid=19600, compaction requested=true
2014-07-14 02:33:32,429 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:163), split_queue=0, merge_queue=0
2014-07-14 02:33:33,031 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:33,055 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78516 synced till here 78514
2014-07-14 02:33:33,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330411587 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330413031
2014-07-14 02:33:34,336 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:34,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78597 synced till here 78593
2014-07-14 02:33:34,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330413031 with entries=81, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330414337
2014-07-14 02:33:36,912 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:36,955 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78692 synced till here 78689
2014-07-14 02:33:37,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330414337 with entries=95, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330416914
2014-07-14 02:33:37,793 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:37,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78781 synced till here 78771
2014-07-14 02:33:38,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330416914 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330417793
2014-07-14 02:33:39,305 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:33:39,305 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:33:39,306 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:164), split_queue=0, merge_queue=0
2014-07-14 02:33:39,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:39,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78869 synced till here 78857
2014-07-14 02:33:40,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330417793 with entries=88, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330419585
2014-07-14 02:33:41,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:41,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78963 synced till here 78951
2014-07-14 02:33:41,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330419585 with entries=94, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330421093
2014-07-14 02:33:43,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:43,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79054 synced till here 79038
2014-07-14 02:33:43,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330421093 with entries=91, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330423588
2014-07-14 02:33:44,276 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:33:44,276 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files, but is 947.1m vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:33:44,276 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. due to global heap pressure
2014-07-14 02:33:44,277 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 947.1m
2014-07-14 02:33:45,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:45,264 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79142 synced till here 79130
2014-07-14 02:33:45,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330423588 with entries=88, filesize=75.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330425233
2014-07-14 02:33:45,967 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:46,149 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/2e6fff9c982647a9ab52ac896684f91e as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2e6fff9c982647a9ab52ac896684f91e
2014-07-14 02:33:46,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:47,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79227 synced till here 79213
2014-07-14 02:33:47,154 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:33:47,167 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cf536ed0eeb94a7887da2d7328fdf69f, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cf536ed0eeb94a7887da2d7328fdf69f
2014-07-14 02:33:47,175 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c394dc3cfb2240cc9b1980a8898fc798, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c394dc3cfb2240cc9b1980a8898fc798
2014-07-14 02:33:47,180 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/96cd7a2fe1714191b4f86ce9d03f81ca, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/96cd7a2fe1714191b4f86ce9d03f81ca
2014-07-14 02:33:47,181 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into 2e6fff9c982647a9ab52ac896684f91e(size=162.7m), total size for store is 3.7g. This selection was in queue for 0sec, and took 38sec to execute.
2014-07-14 02:33:47,181 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=3, fileSize=178.9m, priority=-2, time=284295820787811; duration=38sec
2014-07-14 02:33:47,181 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:165), split_queue=0, merge_queue=0
2014-07-14 02:33:47,181 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:165), split_queue=0, merge_queue=0
2014-07-14 02:33:47,181 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:33:47,182 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 88347862 starting at candidate #17 after considering 132 permutations with 96 in ratio
2014-07-14 02:33:47,182 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:33:47,182 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:33:47,183 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=84.3m
2014-07-14 02:33:47,183 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/c05e033805be49dcb9006dae4c518526, keycount=52991, bloomtype=ROW, size=37.7m, encoding=NONE, seqNum=17922
2014-07-14 02:33:47,183 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b13980fe70dc4468ae85480f11d4c3c0, keycount=21882, bloomtype=ROW, size=15.6m, encoding=NONE, seqNum=18091
2014-07-14 02:33:47,183 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/83218b751b0645d3a066b87180bcb6d3, keycount=43478, bloomtype=ROW, size=30.9m, encoding=NONE, seqNum=18262
2014-07-14 02:33:47,205 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,207 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,207 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,207 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330425233 with entries=85, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330426205
2014-07-14 02:33:47,234 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,268 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,271 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,278 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,318 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,364 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,367 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,367 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,367 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,367 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,368 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,370 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,370 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,373 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,404 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,435 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,470 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,484 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:47,521 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,576 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,612 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,644 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,673 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,704 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,732 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,763 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,792 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,823 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,853 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,882 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,922 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,961 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:47,995 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,036 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,075 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,114 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,154 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,192 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,448 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,525 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,747 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:48,816 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:50,291 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:50,306 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:50,335 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:50,369 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:50,398 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:33:52,105 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19580, memsize=414.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/8fef34548ab64301b4e2c091e00ac407
2014-07-14 02:33:52,121 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/8fef34548ab64301b4e2c091e00ac407 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/8fef34548ab64301b4e2c091e00ac407
2014-07-14 02:33:52,141 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/8fef34548ab64301b4e2c091e00ac407, entries=1509280, sequenceid=19580, filesize=107.4m
2014-07-14 02:33:52,142 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1311300240, currentsize=428.1m/448904560 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 26175ms, sequenceid=19580, compaction requested=true
2014-07-14 02:33:52,142 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:165), split_queue=0, merge_queue=0
2014-07-14 02:33:52,142 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1745ms
2014-07-14 02:33:52,143 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 96729ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:33:52,143 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,143 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1774ms
2014-07-14 02:33:52,143 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,143 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 984.1m
2014-07-14 02:33:52,145 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1810ms
2014-07-14 02:33:52,145 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,145 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1839ms
2014-07-14 02:33:52,145 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,145 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1854ms
2014-07-14 02:33:52,145 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,146 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 02:33:52,146 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,146 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3399ms
2014-07-14 02:33:52,146 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,152 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3626ms
2014-07-14 02:33:52,152 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,152 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3704ms
2014-07-14 02:33:52,152 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,161 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3969ms
2014-07-14 02:33:52,161 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,161 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4007ms
2014-07-14 02:33:52,161 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4047ms
2014-07-14 02:33:52,161 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,165 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4090ms
2014-07-14 02:33:52,165 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,173 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4137ms
2014-07-14 02:33:52,173 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,173 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4178ms
2014-07-14 02:33:52,173 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,173 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4213ms
2014-07-14 02:33:52,173 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,176 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4254ms
2014-07-14 02:33:52,176 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,177 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4294ms
2014-07-14 02:33:52,177 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,177 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4324ms
2014-07-14 02:33:52,177 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,177 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4354ms
2014-07-14 02:33:52,177 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,177 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4385ms
2014-07-14 02:33:52,178 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,178 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4416ms
2014-07-14 02:33:52,179 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,179 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4447ms
2014-07-14 02:33:52,179 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,179 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4475ms
2014-07-14 02:33:52,179 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,182 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4508ms
2014-07-14 02:33:52,182 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,183 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4539ms
2014-07-14 02:33:52,183 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,184 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4572ms
2014-07-14 02:33:52,184 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,185 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4609ms
2014-07-14 02:33:52,185 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,186 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4665ms
2014-07-14 02:33:52,186 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,186 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4717ms
2014-07-14 02:33:52,186 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,186 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4751ms
2014-07-14 02:33:52,186 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,188 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4784ms
2014-07-14 02:33:52,188 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,188 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4815ms
2014-07-14 02:33:52,189 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,189 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4819ms
2014-07-14 02:33:52,189 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,189 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4819ms
2014-07-14 02:33:52,189 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,189 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4821ms
2014-07-14 02:33:52,189 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,190 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4822ms
2014-07-14 02:33:52,190 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,190 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4823ms
2014-07-14 02:33:52,190 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,193 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4826ms
2014-07-14 02:33:52,193 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,194 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4827ms
2014-07-14 02:33:52,195 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,204 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4832ms
2014-07-14 02:33:52,204 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,205 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4887ms
2014-07-14 02:33:52,205 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,205 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4927ms
2014-07-14 02:33:52,206 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,207 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:33:52,208 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,213 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-14 02:33:52,213 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,221 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4950ms
2014-07-14 02:33:52,221 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,221 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4953ms
2014-07-14 02:33:52,221 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,222 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4987ms
2014-07-14 02:33:52,222 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,222 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5015ms
2014-07-14 02:33:52,222 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:52,222 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5015ms
2014-07-14 02:33:52,223 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:33:53,741 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:33:54,187 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:33:54,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:54,283 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79343 synced till here 79307
2014-07-14 02:33:54,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330426205 with entries=116, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330434190
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330261113
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330262852
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330264469
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330265436
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330267081
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330268403
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330309024
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330310008
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330311718
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330313504
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330315437
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330318141
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330320521
2014-07-14 02:33:54,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330322736
2014-07-14 02:33:54,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330324380
2014-07-14 02:33:54,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330326531
2014-07-14 02:33:54,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330327734
2014-07-14 02:33:54,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330331040
2014-07-14 02:33:56,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:56,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79443 synced till here 79415
2014-07-14 02:33:57,526 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10249,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427276,"queuetimems":0,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 02:33:57,528 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10212,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427316,"queuetimems":0,"class":"HRegionServer","responsesize":16044,"method":"Multi"}
2014-07-14 02:33:57,528 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427519,"queuetimems":1,"class":"HRegionServer","responsesize":15623,"method":"Multi"}
2014-07-14 02:33:57,533 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10100,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427433,"queuetimems":0,"class":"HRegionServer","responsesize":15553,"method":"Multi"}
2014-07-14 02:33:57,538 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427467,"queuetimems":0,"class":"HRegionServer","responsesize":15888,"method":"Multi"}
2014-07-14 02:33:57,538 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10307,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427231,"queuetimems":0,"class":"HRegionServer","responsesize":15718,"method":"Multi"}
2014-07-14 02:33:57,545 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10174,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427371,"queuetimems":0,"class":"HRegionServer","responsesize":15897,"method":"Multi"}
2014-07-14 02:33:57,601 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330434190 with entries=100, filesize=85.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330436343
2014-07-14 02:33:57,921 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10347,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427574,"queuetimems":0,"class":"HRegionServer","responsesize":15783,"method":"Multi"}
2014-07-14 02:33:57,930 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10079,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427850,"queuetimems":0,"class":"HRegionServer","responsesize":15517,"method":"Multi"}
2014-07-14 02:33:57,934 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10531,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330427402,"queuetimems":0,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-14 02:33:59,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:33:59,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79561 synced till here 79545
2014-07-14 02:33:59,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330436343 with entries=118, filesize=98.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330439688
2014-07-14 02:34:01,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:01,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79662 synced till here 79632
2014-07-14 02:34:01,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330439688 with entries=101, filesize=86.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330441510
2014-07-14 02:34:03,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:04,109 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79769 synced till here 79734
2014-07-14 02:34:06,000 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1355ms
GC pool 'ParNew' had collection(s): count=2 time=895ms
2014-07-14 02:34:06,118 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330441510 with entries=107, filesize=91.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330443965
2014-07-14 02:34:06,596 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/866182f186d34d79aa30676d662ee3fe as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/866182f186d34d79aa30676d662ee3fe
2014-07-14 02:34:06,785 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:34:06,793 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/c05e033805be49dcb9006dae4c518526, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/c05e033805be49dcb9006dae4c518526
2014-07-14 02:34:06,796 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b13980fe70dc4468ae85480f11d4c3c0, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b13980fe70dc4468ae85480f11d4c3c0
2014-07-14 02:34:06,806 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/83218b751b0645d3a066b87180bcb6d3, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/83218b751b0645d3a066b87180bcb6d3
2014-07-14 02:34:06,807 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into 866182f186d34d79aa30676d662ee3fe(size=53.9m), total size for store is 3.7g. This selection was in queue for 0sec, and took 19sec to execute.
2014-07-14 02:34:06,807 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=84.3m, priority=-2, time=284334609538123; duration=19sec
2014-07-14 02:34:06,807 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:166), split_queue=0, merge_queue=0
2014-07-14 02:34:06,807 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:166), split_queue=0, merge_queue=0
2014-07-14 02:34:06,807 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:34:06,808 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 412835339 starting at candidate #13 after considering 124 permutations with 98 in ratio
2014-07-14 02:34:06,808 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: f7644f9dbefce312f180da53011ffa5c - family: Initiating minor compaction
2014-07-14 02:34:06,808 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:34:06,809 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp, totalSize=393.7m
2014-07-14 02:34:06,809 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/873474755d964284904faf03a5b21ae0, keycount=89407, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=15087
2014-07-14 02:34:06,809 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e130117f58464a819eafa215aa8099b5, keycount=225639, bloomtype=ROW, size=160.6m, encoding=NONE, seqNum=15580
2014-07-14 02:34:06,809 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6af9ae8dee774360b8dd0056b2f498b1, keycount=109162, bloomtype=ROW, size=77.7m, encoding=NONE, seqNum=15927
2014-07-14 02:34:06,809 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c04453dc844b4767a6eecc8980c61d67, keycount=128783, bloomtype=ROW, size=91.7m, encoding=NONE, seqNum=16437
2014-07-14 02:34:06,898 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:34:07,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:07,115 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79875 synced till here 79843
2014-07-14 02:34:08,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330443965 with entries=106, filesize=90.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330447098
2014-07-14 02:34:09,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:10,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79980 synced till here 79953
2014-07-14 02:34:10,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330447098 with entries=105, filesize=87.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330450349
2014-07-14 02:34:11,329 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,330 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,335 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,340 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,341 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,341 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,342 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,342 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:11,342 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:12,246 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,247 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,247 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,247 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,247 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,248 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,249 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,250 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,250 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,251 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,251 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,252 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,253 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,253 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,253 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,253 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,254 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,254 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,256 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80083 synced till here 80065
2014-07-14 02:34:12,382 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,383 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,383 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,384 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,385 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,386 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,386 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,386 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,387 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,388 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,388 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,388 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,388 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,388 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,389 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,389 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,389 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330450349 with entries=103, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330452243
2014-07-14 02:34:12,392 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,393 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,393 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,393 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:12,393 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:16,330 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:34:16,330 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,335 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,340 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,341 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,342 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:34:16,342 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,342 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,342 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:34:16,947 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19824, memsize=466.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/65bf62bd996e4abeae27529a6b8a05ce
2014-07-14 02:34:16,967 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/65bf62bd996e4abeae27529a6b8a05ce as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/65bf62bd996e4abeae27529a6b8a05ce
2014-07-14 02:34:16,986 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/65bf62bd996e4abeae27529a6b8a05ce, entries=1696640, sequenceid=19824, filesize=120.8m
2014-07-14 02:34:16,986 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~964.0m/1010832560, currentsize=370.8m/388815760 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 32709ms, sequenceid=19824, compaction requested=true
2014-07-14 02:34:16,986 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:166), split_queue=0, merge_queue=0
2014-07-14 02:34:16,987 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5645ms
2014-07-14 02:34:16,987 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,987 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5645ms
2014-07-14 02:34:16,987 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,987 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5645ms
2014-07-14 02:34:16,987 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,987 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5646ms
2014-07-14 02:34:16,987 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,989 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5648ms
2014-07-14 02:34:16,989 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,989 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5649ms
2014-07-14 02:34:16,989 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,992 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5657ms
2014-07-14 02:34:16,992 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,992 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5662ms
2014-07-14 02:34:16,992 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,992 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5663ms
2014-07-14 02:34:16,992 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,993 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4599ms
2014-07-14 02:34:16,993 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,993 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4600ms
2014-07-14 02:34:16,993 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,994 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4600ms
2014-07-14 02:34:16,994 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:16,994 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4601ms
2014-07-14 02:34:16,994 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,005 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4613ms
2014-07-14 02:34:17,005 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,005 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4616ms
2014-07-14 02:34:17,005 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,006 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4616ms
2014-07-14 02:34:17,006 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,006 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4623ms
2014-07-14 02:34:17,006 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,006 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4623ms
2014-07-14 02:34:17,006 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,021 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4636ms
2014-07-14 02:34:17,021 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,021 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4639ms
2014-07-14 02:34:17,021 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,025 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4637ms
2014-07-14 02:34:17,025 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,025 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4637ms
2014-07-14 02:34:17,025 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,025 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4638ms
2014-07-14 02:34:17,025 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,025 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4639ms
2014-07-14 02:34:17,025 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,026 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4640ms
2014-07-14 02:34:17,026 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,026 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4640ms
2014-07-14 02:34:17,026 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,027 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4641ms
2014-07-14 02:34:17,027 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,027 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-14 02:34:17,027 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,027 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-14 02:34:17,027 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,028 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4645ms
2014-07-14 02:34:17,028 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,028 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4646ms
2014-07-14 02:34:17,028 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,028 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4772ms
2014-07-14 02:34:17,029 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,037 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4783ms
2014-07-14 02:34:17,037 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,037 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4784ms
2014-07-14 02:34:17,037 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,047 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4794ms
2014-07-14 02:34:17,047 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,047 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4794ms
2014-07-14 02:34:17,048 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,048 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4795ms
2014-07-14 02:34:17,048 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,048 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4795ms
2014-07-14 02:34:17,048 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,048 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4796ms
2014-07-14 02:34:17,048 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,049 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4797ms
2014-07-14 02:34:17,049 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,056 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4805ms
2014-07-14 02:34:17,057 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,065 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4815ms
2014-07-14 02:34:17,065 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,065 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4815ms
2014-07-14 02:34:17,065 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,065 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4816ms
2014-07-14 02:34:17,065 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,066 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4817ms
2014-07-14 02:34:17,066 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,066 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4819ms
2014-07-14 02:34:17,066 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,073 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4826ms
2014-07-14 02:34:17,073 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,073 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4826ms
2014-07-14 02:34:17,073 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,081 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4834ms
2014-07-14 02:34:17,081 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,081 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4835ms
2014-07-14 02:34:17,081 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:17,199 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:34:17,209 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:34:17,209 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:167), split_queue=0, merge_queue=0
2014-07-14 02:34:18,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:19,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80202 synced till here 80196
2014-07-14 02:34:19,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330452243 with entries=119, filesize=102.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330458936
2014-07-14 02:34:19,263 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330333386
2014-07-14 02:34:19,902 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10692,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330449209,"queuetimems":6001,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 02:34:20,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:20,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80323 synced till here 80289
2014-07-14 02:34:21,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330458936 with entries=121, filesize=103.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330460919
2014-07-14 02:34:23,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:23,134 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80420 synced till here 80397
2014-07-14 02:34:23,302 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330460919 with entries=97, filesize=83.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330463096
2014-07-14 02:34:24,810 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:24,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80494 synced till here 80492
2014-07-14 02:34:24,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330463096 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330464811
2014-07-14 02:34:25,728 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:34:25,728 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files, but is 926.6m vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:34:25,728 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. due to global heap pressure
2014-07-14 02:34:25,728 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 926.6m
2014-07-14 02:34:26,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:26,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80569 synced till here 80567
2014-07-14 02:34:26,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330464811 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330466353
2014-07-14 02:34:26,595 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:34:26,748 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19860, memsize=493.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f45cecbc22104d4dbd33fa31c4b87aaa
2014-07-14 02:34:26,759 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/f45cecbc22104d4dbd33fa31c4b87aaa as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f45cecbc22104d4dbd33fa31c4b87aaa
2014-07-14 02:34:26,768 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f45cecbc22104d4dbd33fa31c4b87aaa, entries=1796750, sequenceid=19860, filesize=127.9m
2014-07-14 02:34:26,769 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~984.1m/1031865280, currentsize=516.3m/541395360 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 34626ms, sequenceid=19860, compaction requested=true
2014-07-14 02:34:26,769 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:168), split_queue=0, merge_queue=0
2014-07-14 02:34:26,777 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:34:26,777 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:34:26,777 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:169), split_queue=0, merge_queue=0
2014-07-14 02:34:27,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:27,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80644 synced till here 80641
2014-07-14 02:34:28,038 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330466353 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330467959
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330334545
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330336205
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330363792
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330376707
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378004
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330378894
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330380260
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330382113
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330383479
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330392005
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330393920
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330395708
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330397107
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330398887
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330399871
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330402372
2014-07-14 02:34:28,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330404391
2014-07-14 02:34:29,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:29,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80721 synced till here 80716
2014-07-14 02:34:29,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330467959 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330469210
2014-07-14 02:34:30,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:30,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80804 synced till here 80793
2014-07-14 02:34:31,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330469210 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330470785
2014-07-14 02:34:32,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:32,391 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80881 synced till here 80878
2014-07-14 02:34:32,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330470785 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330472358
2014-07-14 02:34:33,991 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90529ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:34:33,992 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 706.8m
2014-07-14 02:34:34,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:34,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80958 synced till here 80955
2014-07-14 02:34:34,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330472358 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330474118
2014-07-14 02:34:34,644 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:34:35,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:35,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81037 synced till here 81030
2014-07-14 02:34:35,976 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330474118 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330475840
2014-07-14 02:34:37,634 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:37,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81120 synced till here 81111
2014-07-14 02:34:37,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330475840 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330477635
2014-07-14 02:34:37,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:39,372 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:39,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81201 synced till here 81193
2014-07-14 02:34:39,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330477635 with entries=81, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330479372
2014-07-14 02:34:39,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:41,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:41,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81293 synced till here 81277
2014-07-14 02:34:41,506 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,507 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,507 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,507 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330479372 with entries=92, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330481223
2014-07-14 02:34:41,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:41,552 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,602 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,658 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,688 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,688 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,689 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,689 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,690 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,692 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,692 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,712 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,750 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,804 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,847 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,873 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,879 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,888 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,893 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,893 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,895 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,895 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,897 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,899 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,918 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:41,957 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:42,041 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:43,027 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:43,037 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:43,049 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:43,078 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,043 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,138 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,176 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,221 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,264 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,305 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,348 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,384 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,432 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,464 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,497 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,527 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,558 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,588 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,620 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:44,653 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:34:45,324 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20183, memsize=298.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/00c7b2b5dd9b433385379df2eb3c49f3
2014-07-14 02:34:45,348 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/00c7b2b5dd9b433385379df2eb3c49f3 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/00c7b2b5dd9b433385379df2eb3c49f3
2014-07-14 02:34:45,365 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/00c7b2b5dd9b433385379df2eb3c49f3, entries=1086490, sequenceid=20183, filesize=77.4m
2014-07-14 02:34:45,365 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~932.8m/978093840, currentsize=290.2m/304308480 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 19637ms, sequenceid=20183, compaction requested=true
2014-07-14 02:34:45,366 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:170), split_queue=0, merge_queue=0
2014-07-14 02:34:45,366 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 714ms
2014-07-14 02:34:45,366 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,366 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 746ms
2014-07-14 02:34:45,366 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,366 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 778ms
2014-07-14 02:34:45,367 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,367 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 809ms
2014-07-14 02:34:45,367 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,373 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 846ms
2014-07-14 02:34:45,373 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,373 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 876ms
2014-07-14 02:34:45,373 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,378 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 914ms
2014-07-14 02:34:45,378 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,378 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 946ms
2014-07-14 02:34:45,378 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,378 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 994ms
2014-07-14 02:34:45,379 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,379 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1031ms
2014-07-14 02:34:45,379 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,389 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1084ms
2014-07-14 02:34:45,389 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,389 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1125ms
2014-07-14 02:34:45,389 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,397 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1176ms
2014-07-14 02:34:45,397 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,398 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1221ms
2014-07-14 02:34:45,398 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,401 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1263ms
2014-07-14 02:34:45,401 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,401 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1358ms
2014-07-14 02:34:45,401 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,403 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2324ms
2014-07-14 02:34:45,403 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,403 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2354ms
2014-07-14 02:34:45,403 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,406 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2368ms
2014-07-14 02:34:45,406 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,406 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2379ms
2014-07-14 02:34:45,406 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,408 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3367ms
2014-07-14 02:34:45,409 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,411 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3453ms
2014-07-14 02:34:45,411 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,412 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3493ms
2014-07-14 02:34:45,412 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,412 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3513ms
2014-07-14 02:34:45,413 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,413 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3516ms
2014-07-14 02:34:45,413 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,413 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3518ms
2014-07-14 02:34:45,413 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,414 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3518ms
2014-07-14 02:34:45,414 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,414 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3521ms
2014-07-14 02:34:45,414 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,414 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3521ms
2014-07-14 02:34:45,414 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,425 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3538ms
2014-07-14 02:34:45,425 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,433 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3554ms
2014-07-14 02:34:45,433 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,433 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3560ms
2014-07-14 02:34:45,433 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,433 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3586ms
2014-07-14 02:34:45,433 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,441 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3637ms
2014-07-14 02:34:45,441 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,442 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3692ms
2014-07-14 02:34:45,442 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,444 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3731ms
2014-07-14 02:34:45,444 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,444 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3752ms
2014-07-14 02:34:45,444 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,444 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3752ms
2014-07-14 02:34:45,444 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,444 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3754ms
2014-07-14 02:34:45,445 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,445 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3756ms
2014-07-14 02:34:45,445 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,445 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3757ms
2014-07-14 02:34:45,445 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,445 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3757ms
2014-07-14 02:34:45,445 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,446 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3758ms
2014-07-14 02:34:45,446 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,457 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3800ms
2014-07-14 02:34:45,457 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,457 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3855ms
2014-07-14 02:34:45,457 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,458 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3906ms
2014-07-14 02:34:45,458 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,459 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3951ms
2014-07-14 02:34:45,459 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,459 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3952ms
2014-07-14 02:34:45,459 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,465 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3958ms
2014-07-14 02:34:45,465 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,465 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3960ms
2014-07-14 02:34:45,465 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:34:45,977 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:34:45,977 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:34:45,977 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:171), split_queue=0, merge_queue=0
2014-07-14 02:34:47,257 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:47,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81409 synced till here 81397
2014-07-14 02:34:47,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330481223 with entries=116, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330487257
2014-07-14 02:34:47,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:49,161 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20282, memsize=199.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/0f7d46abe6f748d1821c0900b9a53cbc
2014-07-14 02:34:49,203 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/0f7d46abe6f748d1821c0900b9a53cbc as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/0f7d46abe6f748d1821c0900b9a53cbc
2014-07-14 02:34:49,226 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/0f7d46abe6f748d1821c0900b9a53cbc, entries=725340, sequenceid=20282, filesize=51.6m
2014-07-14 02:34:49,227 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~710.0m/744524080, currentsize=191.1m/200333280 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 15236ms, sequenceid=20282, compaction requested=true
2014-07-14 02:34:49,229 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:172), split_queue=0, merge_queue=0
2014-07-14 02:34:49,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:49,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81517 synced till here 81515
2014-07-14 02:34:49,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330487257 with entries=108, filesize=91.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330489491
2014-07-14 02:34:49,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:51,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:51,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81605 synced till here 81591
2014-07-14 02:34:51,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330489491 with entries=88, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330491254
2014-07-14 02:34:51,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:51,745 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:34:51,745 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:34:51,746 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:173), split_queue=0, merge_queue=0
2014-07-14 02:34:52,748 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:52,776 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330491254 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330492748
2014-07-14 02:34:52,776 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:53,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:53,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81756 synced till here 81752
2014-07-14 02:34:53,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330492748 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330493844
2014-07-14 02:34:53,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:55,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:55,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81830 synced till here 81828
2014-07-14 02:34:55,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330493844 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330495359
2014-07-14 02:34:55,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:56,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:56,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81904 synced till here 81903
2014-07-14 02:34:56,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330495359 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330496900
2014-07-14 02:34:56,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:34:58,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:34:58,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81994 synced till here 81980
2014-07-14 02:34:58,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330496900 with entries=90, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330498706
2014-07-14 02:34:58,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:35:00,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:00,696 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82074 synced till here 82067
2014-07-14 02:35:00,785 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330498706 with entries=80, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330500681
2014-07-14 02:35:00,785 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:35:02,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:02,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82153 synced till here 82147
2014-07-14 02:35:02,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330500681 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330502683
2014-07-14 02:35:02,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:35:04,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:04,640 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:35:04,640 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files, but is 1.5g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:35:04,641 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. due to global heap pressure
2014-07-14 02:35:04,641 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.5g
2014-07-14 02:35:04,681 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82236 synced till here 82225
2014-07-14 02:35:04,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330502683 with entries=83, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330504637
2014-07-14 02:35:04,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:35:04,778 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:35:04,778 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:174), split_queue=0, merge_queue=0
2014-07-14 02:35:04,805 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:35:04,806 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files, but is 1.1g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:35:04,806 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. due to global heap pressure
2014-07-14 02:35:04,806 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 1.1g
2014-07-14 02:35:06,837 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:06,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82330 synced till here 82316
2014-07-14 02:35:07,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330504637 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330506838
2014-07-14 02:35:07,096 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:35:07,340 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,343 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,348 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,349 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,351 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,353 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,356 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,356 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,356 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,356 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,359 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,361 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,365 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,370 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,422 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,481 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,481 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,482 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,487 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,488 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,488 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,493 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,507 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,511 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,518 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,520 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,522 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,528 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,534 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,588 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,644 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,651 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:35:07,699 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,755 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,797 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,844 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,889 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,928 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:07,973 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,239 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,242 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1077ms
GC pool 'ParNew' had collection(s): count=1 time=1229ms
2014-07-14 02:35:09,250 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,262 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,290 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,320 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,350 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,701 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,743 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,778 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,814 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,848 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:09,886 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:12,341 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,349 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,349 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,351 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,354 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5010ms
2014-07-14 02:35:12,354 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5011ms
2014-07-14 02:35:12,356 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,357 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,357 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-14 02:35:12,357 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,360 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,362 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,366 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5009ms
2014-07-14 02:35:12,371 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,423 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,481 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,482 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,482 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,487 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,488 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,488 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,493 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5011ms
2014-07-14 02:35:12,508 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:12,511 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,519 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,520 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,522 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,528 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,534 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,589 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:12,645 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:13,424 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5451ms
2014-07-14 02:35:13,424 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5725ms
2014-07-14 02:35:13,425 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5670ms
2014-07-14 02:35:13,425 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5628ms
2014-07-14 02:35:13,425 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5536ms
2014-07-14 02:35:13,425 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5581ms
2014-07-14 02:35:13,426 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5498ms
2014-07-14 02:35:14,239 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,250 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,263 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:14,290 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,320 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,351 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,702 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:14,743 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,778 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,814 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:35:14,849 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:14,887 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:35:17,341 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,349 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,350 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,352 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,354 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10011ms
2014-07-14 02:35:17,354 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10011ms
2014-07-14 02:35:17,356 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,357 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,358 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10009ms
2014-07-14 02:35:17,358 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 02:35:17,360 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,362 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,366 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10010ms
2014-07-14 02:35:17,371 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:17,423 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:18,072 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10427ms
2014-07-14 02:35:18,072 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10591ms
2014-07-14 02:35:18,073 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10592ms
2014-07-14 02:35:18,073 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10592ms
2014-07-14 02:35:18,074 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10586ms
2014-07-14 02:35:18,074 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10586ms
2014-07-14 02:35:18,074 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10586ms
2014-07-14 02:35:18,075 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10592ms
2014-07-14 02:35:18,075 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10568ms
2014-07-14 02:35:18,075 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10564ms
2014-07-14 02:35:18,076 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10558ms
2014-07-14 02:35:18,077 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10554ms
2014-07-14 02:35:18,078 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10557ms
2014-07-14 02:35:18,078 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10550ms
2014-07-14 02:35:18,078 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10544ms
2014-07-14 02:35:18,078 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10490ms
2014-07-14 02:35:18,425 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10451ms
2014-07-14 02:35:18,425 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10726ms
2014-07-14 02:35:18,426 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10628ms
2014-07-14 02:35:18,426 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10671ms
2014-07-14 02:35:18,426 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10498ms
2014-07-14 02:35:18,426 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10582ms
2014-07-14 02:35:18,427 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10538ms
2014-07-14 02:35:19,239 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:35:19,251 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,264 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,291 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,321 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,351 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,703 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,744 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:35:19,779 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,815 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:35:19,849 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:19,887 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:35:22,746 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15324ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15398ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15398ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15396ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15404ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15404ms
2014-07-14 02:35:22,747 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15392ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15391ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15399ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15392ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15389ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15387ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15392ms
2014-07-14 02:35:22,748 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15378ms
2014-07-14 02:35:22,749 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15409ms
2014-07-14 02:35:23,072 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15428ms
2014-07-14 02:35:23,073 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15592ms
2014-07-14 02:35:23,073 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15592ms
2014-07-14 02:35:23,074 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15593ms
2014-07-14 02:35:23,074 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15587ms
2014-07-14 02:35:23,074 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15586ms
2014-07-14 02:35:23,075 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15586ms
2014-07-14 02:35:23,075 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15593ms
2014-07-14 02:35:23,075 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15568ms
2014-07-14 02:35:23,076 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15565ms
2014-07-14 02:35:23,076 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15558ms
2014-07-14 02:35:23,077 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15555ms
2014-07-14 02:35:23,078 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15558ms
2014-07-14 02:35:23,078 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15550ms
2014-07-14 02:35:23,078 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15544ms
2014-07-14 02:35:23,079 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15490ms
2014-07-14 02:35:23,425 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15452ms
2014-07-14 02:35:23,426 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15727ms
2014-07-14 02:35:23,426 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15629ms
2014-07-14 02:35:23,426 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15671ms
2014-07-14 02:35:23,427 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15499ms
2014-07-14 02:35:23,427 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15583ms
2014-07-14 02:35:23,427 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15538ms
2014-07-14 02:35:24,240 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,251 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,264 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:35:24,291 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,321 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,351 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,703 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:35:24,744 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,779 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,815 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,849 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:35:24,888 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:35:26,500 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20612, memsize=416.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/474a661aa08a4b15b219ba60cfc74c58
2014-07-14 02:35:26,518 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/474a661aa08a4b15b219ba60cfc74c58 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/474a661aa08a4b15b219ba60cfc74c58
2014-07-14 02:35:26,537 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/474a661aa08a4b15b219ba60cfc74c58, entries=1515440, sequenceid=20612, filesize=107.8m
2014-07-14 02:35:26,538 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1224892480, currentsize=47.3m/49555440 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 21732ms, sequenceid=20612, compaction requested=true
2014-07-14 02:35:26,538 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:175), split_queue=0, merge_queue=0
2014-07-14 02:35:26,538 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 107233ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:35:26,538 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16652ms
2014-07-14 02:35:26,539 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,539 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., flushing=true, writesEnabled=true
2014-07-14 02:35:26,539 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16691ms
2014-07-14 02:35:26,539 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,539 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16725ms
2014-07-14 02:35:26,539 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,539 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16761ms
2014-07-14 02:35:26,539 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,539 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16796ms
2014-07-14 02:35:26,539 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,541 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16840ms
2014-07-14 02:35:26,541 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,541 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17191ms
2014-07-14 02:35:26,541 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,541 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17221ms
2014-07-14 02:35:26,541 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,541 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17251ms
2014-07-14 02:35:26,541 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,542 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17280ms
2014-07-14 02:35:26,542 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,545 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17295ms
2014-07-14 02:35:26,545 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,545 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17306ms
2014-07-14 02:35:26,545 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,550 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18660ms
2014-07-14 02:35:26,550 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,550 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18706ms
2014-07-14 02:35:26,550 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,557 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18629ms
2014-07-14 02:35:26,557 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,557 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18802ms
2014-07-14 02:35:26,557 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,557 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18760ms
2014-07-14 02:35:26,557 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,561 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18862ms
2014-07-14 02:35:26,561 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,564 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18590ms
2014-07-14 02:35:26,564 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,564 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18976ms
2014-07-14 02:35:26,564 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,564 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19030ms
2014-07-14 02:35:26,564 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,566 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19038ms
2014-07-14 02:35:26,566 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,567 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19047ms
2014-07-14 02:35:26,567 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,577 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19055ms
2014-07-14 02:35:26,578 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,578 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19060ms
2014-07-14 02:35:26,579 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,579 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19068ms
2014-07-14 02:35:26,579 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,579 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19072ms
2014-07-14 02:35:26,579 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,580 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19097ms
2014-07-14 02:35:26,580 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,581 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19092ms
2014-07-14 02:35:26,582 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,582 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19094ms
2014-07-14 02:35:26,582 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,582 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19095ms
2014-07-14 02:35:26,582 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,589 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19108ms
2014-07-14 02:35:26,589 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,590 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19108ms
2014-07-14 02:35:26,590 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,590 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19109ms
2014-07-14 02:35:26,590 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,593 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18949ms
2014-07-14 02:35:26,593 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,593 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19253ms
2014-07-14 02:35:26,593 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,593 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19223ms
2014-07-14 02:35:26,593 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,593 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19237ms
2014-07-14 02:35:26,594 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,601 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19240ms
2014-07-14 02:35:26,601 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,602 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19243ms
2014-07-14 02:35:26,602 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,602 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19246ms
2014-07-14 02:35:26,602 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,609 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19260ms
2014-07-14 02:35:26,609 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,609 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19253ms
2014-07-14 02:35:26,609 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,613 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19258ms
2014-07-14 02:35:26,613 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,614 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19271ms
2014-07-14 02:35:26,614 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,621 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19278ms
2014-07-14 02:35:26,621 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,625 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19274ms
2014-07-14 02:35:26,625 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,625 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19276ms
2014-07-14 02:35:26,625 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,625 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19277ms
2014-07-14 02:35:26,625 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:26,625 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19203ms
2014-07-14 02:35:26,626 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:27,531 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:27,534 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22188,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505345,"queuetimems":0,"class":"HRegionServer","responsesize":15765,"method":"Multi"}
2014-07-14 02:35:27,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82442 synced till here 82400
2014-07-14 02:35:27,932 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506684,"queuetimems":0,"class":"HRegionServer","responsesize":15898,"method":"Multi"}
2014-07-14 02:35:27,933 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22726,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505206,"queuetimems":0,"class":"HRegionServer","responsesize":15948,"method":"Multi"}
2014-07-14 02:35:27,934 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22622,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505311,"queuetimems":0,"class":"HRegionServer","responsesize":15616,"method":"Multi"}
2014-07-14 02:35:27,944 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506888,"queuetimems":0,"class":"HRegionServer","responsesize":15960,"method":"Multi"}
2014-07-14 02:35:27,944 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506801,"queuetimems":0,"class":"HRegionServer","responsesize":15804,"method":"Multi"}
2014-07-14 02:35:27,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330506838 with entries=112, filesize=96.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330527532
2014-07-14 02:35:28,190 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21105,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507084,"queuetimems":1,"class":"HRegionServer","responsesize":15656,"method":"Multi"}
2014-07-14 02:35:28,447 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21675,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506771,"queuetimems":1,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21872,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507284,"queuetimems":0,"class":"HRegionServer","responsesize":15938,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506925,"queuetimems":0,"class":"HRegionServer","responsesize":15954,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21919,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507238,"queuetimems":0,"class":"HRegionServer","responsesize":15985,"method":"Multi"}
2014-07-14 02:35:29,158 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505469,"queuetimems":0,"class":"HRegionServer","responsesize":15812,"method":"Multi"}
2014-07-14 02:35:29,161 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505428,"queuetimems":0,"class":"HRegionServer","responsesize":16096,"method":"Multi"}
2014-07-14 02:35:29,162 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22329,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506833,"queuetimems":1,"class":"HRegionServer","responsesize":16154,"method":"Multi"}
2014-07-14 02:35:29,162 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506663,"queuetimems":0,"class":"HRegionServer","responsesize":15811,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506738,"queuetimems":1,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22106,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507050,"queuetimems":1,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507133,"queuetimems":3,"class":"HRegionServer","responsesize":16036,"method":"Multi"}
2014-07-14 02:35:29,169 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330505375,"queuetimems":0,"class":"HRegionServer","responsesize":15564,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22137,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507019,"queuetimems":0,"class":"HRegionServer","responsesize":16187,"method":"Multi"}
2014-07-14 02:35:29,173 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507189,"queuetimems":1,"class":"HRegionServer","responsesize":16109,"method":"Multi"}
2014-07-14 02:35:29,161 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506704,"queuetimems":0,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 02:35:29,157 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22171,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506986,"queuetimems":0,"class":"HRegionServer","responsesize":15721,"method":"Multi"}
2014-07-14 02:35:29,185 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22229,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330506956,"queuetimems":0,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 02:35:29,322 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19544,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509777,"queuetimems":1,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 02:35:29,322 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20062,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509259,"queuetimems":1,"class":"HRegionServer","responsesize":15811,"method":"Multi"}
2014-07-14 02:35:29,322 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509885,"queuetimems":1,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 02:35:29,333 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19521,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509812,"queuetimems":0,"class":"HRegionServer","responsesize":16154,"method":"Multi"}
2014-07-14 02:35:29,497 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/a38f7bc6ffde47519c390ccedea9d579 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a38f7bc6ffde47519c390ccedea9d579
2014-07-14 02:35:29,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:29,616 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20267,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509348,"queuetimems":0,"class":"HRegionServer","responsesize":15954,"method":"Multi"}
2014-07-14 02:35:29,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82556 synced till here 82538
2014-07-14 02:35:29,807 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330508005,"queuetimems":0,"class":"HRegionServer","responsesize":15898,"method":"Multi"}
2014-07-14 02:35:29,807 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20489,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509318,"queuetimems":0,"class":"HRegionServer","responsesize":15765,"method":"Multi"}
2014-07-14 02:35:29,809 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509846,"queuetimems":0,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 02:35:29,809 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20520,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509289,"queuetimems":1,"class":"HRegionServer","responsesize":15616,"method":"Multi"}
2014-07-14 02:35:29,809 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20069,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509740,"queuetimems":0,"class":"HRegionServer","responsesize":16187,"method":"Multi"}
2014-07-14 02:35:29,809 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20110,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509699,"queuetimems":0,"class":"HRegionServer","responsesize":15610,"method":"Multi"}
2014-07-14 02:35:29,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330527532 with entries=114, filesize=96.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330529614
2014-07-14 02:35:29,832 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:35:29,849 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/873474755d964284904faf03a5b21ae0, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/873474755d964284904faf03a5b21ae0
2014-07-14 02:35:29,852 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e130117f58464a819eafa215aa8099b5, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/e130117f58464a819eafa215aa8099b5
2014-07-14 02:35:29,855 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6af9ae8dee774360b8dd0056b2f498b1, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6af9ae8dee774360b8dd0056b2f498b1
2014-07-14 02:35:29,857 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c04453dc844b4767a6eecc8980c61d67, to hdfs://master:54310/hbase/archive/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c04453dc844b4767a6eecc8980c61d67
2014-07-14 02:35:29,858 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. into a38f7bc6ffde47519c390ccedea9d579(size=363.7m), total size for store is 3.8g. This selection was in queue for 0sec, and took 1mins, 23sec to execute.
2014-07-14 02:35:29,858 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., storeName=family, fileCount=4, fileSize=393.7m, priority=-1, time=284354235425919; duration=1mins, 23sec
2014-07-14 02:35:29,858 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:175), split_queue=0, merge_queue=0
2014-07-14 02:35:29,858 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-14 02:35:29,859 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 174426099 starting at candidate #19 after considering 140 permutations with 125 in ratio
2014-07-14 02:35:29,859 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:35:29,859 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:35:29,859 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=166.3m
2014-07-14 02:35:29,860 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4ad515a6388d4882be115e86a6928012, keycount=40184, bloomtype=ROW, size=28.6m, encoding=NONE, seqNum=19020
2014-07-14 02:35:29,860 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/89606190d7844a50a6a0df394c5b2106, keycount=23751, bloomtype=ROW, size=16.9m, encoding=NONE, seqNum=19193
2014-07-14 02:35:29,860 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/65bf62bd996e4abeae27529a6b8a05ce, keycount=169664, bloomtype=ROW, size=120.8m, encoding=NONE, seqNum=19824
2014-07-14 02:35:29,897 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:35:30,144 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 751.5m
2014-07-14 02:35:30,267 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507474,"queuetimems":0,"class":"HRegionServer","responsesize":16030,"method":"Multi"}
2014-07-14 02:35:30,278 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21029,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330509248,"queuetimems":0,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 02:35:30,278 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507694,"queuetimems":0,"class":"HRegionServer","responsesize":15948,"method":"Multi"}
2014-07-14 02:35:30,278 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22861,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507417,"queuetimems":0,"class":"HRegionServer","responsesize":15957,"method":"Multi"}
2014-07-14 02:35:30,278 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507970,"queuetimems":0,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 02:35:30,279 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22697,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507581,"queuetimems":1,"class":"HRegionServer","responsesize":15857,"method":"Multi"}
2014-07-14 02:35:30,286 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22650,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507636,"queuetimems":0,"class":"HRegionServer","responsesize":15552,"method":"Multi"}
2014-07-14 02:35:30,289 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22363,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507926,"queuetimems":1,"class":"HRegionServer","responsesize":15564,"method":"Multi"}
2014-07-14 02:35:30,292 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507328,"queuetimems":0,"class":"HRegionServer","responsesize":15656,"method":"Multi"}
2014-07-14 02:35:30,293 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22408,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507885,"queuetimems":1,"class":"HRegionServer","responsesize":15812,"method":"Multi"}
2014-07-14 02:35:31,077 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507529,"queuetimems":0,"class":"HRegionServer","responsesize":15952,"method":"Multi"}
2014-07-14 02:35:31,077 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507792,"queuetimems":0,"class":"HRegionServer","responsesize":15960,"method":"Multi"}
2014-07-14 02:35:31,081 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507840,"queuetimems":0,"class":"HRegionServer","responsesize":16096,"method":"Multi"}
2014-07-14 02:35:31,085 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507750,"queuetimems":1,"class":"HRegionServer","responsesize":15630,"method":"Multi"}
2014-07-14 02:35:31,077 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330507366,"queuetimems":0,"class":"HRegionServer","responsesize":15752,"method":"Multi"}
2014-07-14 02:35:31,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:31,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82666 synced till here 82656
2014-07-14 02:35:31,754 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:35:31,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330529614 with entries=110, filesize=94.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330531636
2014-07-14 02:35:34,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:34,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82782 synced till here 82779
2014-07-14 02:35:34,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330531636 with entries=116, filesize=99.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330534055
2014-07-14 02:35:35,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:35,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82888 synced till here 82867
2014-07-14 02:35:36,250 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:35:36,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330534055 with entries=106, filesize=90.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330535916
2014-07-14 02:35:38,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:38,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83004 synced till here 82974
2014-07-14 02:35:39,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330535916 with entries=116, filesize=99.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330538010
2014-07-14 02:35:40,267 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:40,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83117 synced till here 83085
2014-07-14 02:35:40,401 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,405 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,405 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330538010 with entries=113, filesize=97.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330540267
2014-07-14 02:35:40,413 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,415 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,418 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,420 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,443 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,450 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,452 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,453 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,453 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,454 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,460 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,461 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,465 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,466 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:40,978 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,035 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,035 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,036 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,036 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,119 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,119 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,178 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,178 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,179 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,179 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,179 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,179 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,180 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,181 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,909 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,948 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:41,968 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20622, memsize=614.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/a06416db3b28457abfec150e5362d3e2
2014-07-14 02:35:41,983 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/a06416db3b28457abfec150e5362d3e2 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a06416db3b28457abfec150e5362d3e2
2014-07-14 02:35:41,983 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:35:42,022 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a06416db3b28457abfec150e5362d3e2, entries=2238810, sequenceid=20622, filesize=159.3m
2014-07-14 02:35:42,023 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.5g/1648432720, currentsize=355.1m/372378960 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 37382ms, sequenceid=20622, compaction requested=true
2014-07-14 02:35:42,023 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:175), split_queue=0, merge_queue=0
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 41ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,024 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 76ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,024 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:176), split_queue=0, merge_queue=0
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 115ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 844ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 844ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,024 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 845ms
2014-07-14 02:35:42,024 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,025 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 846ms
2014-07-14 02:35:42,025 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,025 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 846ms
2014-07-14 02:35:42,025 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,025 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 847ms
2014-07-14 02:35:42,025 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,026 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 848ms
2014-07-14 02:35:42,027 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,027 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 849ms
2014-07-14 02:35:42,027 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,029 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 910ms
2014-07-14 02:35:42,029 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,029 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 910ms
2014-07-14 02:35:42,029 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,029 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 994ms
2014-07-14 02:35:42,029 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,033 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 997ms
2014-07-14 02:35:42,033 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,041 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1006ms
2014-07-14 02:35:42,041 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,042 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1007ms
2014-07-14 02:35:42,043 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,043 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1066ms
2014-07-14 02:35:42,043 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,043 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1577ms
2014-07-14 02:35:42,043 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,043 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1578ms
2014-07-14 02:35:42,043 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,043 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1582ms
2014-07-14 02:35:42,043 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,045 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1585ms
2014-07-14 02:35:42,045 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,053 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1599ms
2014-07-14 02:35:42,053 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,053 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1600ms
2014-07-14 02:35:42,053 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,057 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1604ms
2014-07-14 02:35:42,057 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,057 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1605ms
2014-07-14 02:35:42,057 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,057 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1607ms
2014-07-14 02:35:42,057 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,057 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1614ms
2014-07-14 02:35:42,058 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,058 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1638ms
2014-07-14 02:35:42,058 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,059 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1641ms
2014-07-14 02:35:42,059 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,060 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1645ms
2014-07-14 02:35:42,060 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,061 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1647ms
2014-07-14 02:35:42,061 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,061 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1656ms
2014-07-14 02:35:42,061 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,061 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1656ms
2014-07-14 02:35:42,061 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,063 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1661ms
2014-07-14 02:35:42,063 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:35:42,177 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:35:42,178 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:35:42,178 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:177), split_queue=0, merge_queue=0
2014-07-14 02:35:42,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:42,728 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83201 synced till here 83189
2014-07-14 02:35:42,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330540267 with entries=84, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330542698
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330405777
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330407235
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330408153
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330410432
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330411587
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330413031
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330414337
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330416914
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330417793
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330419585
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330421093
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330423588
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330425233
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330426205
2014-07-14 02:35:42,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330434190
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330436343
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330439688
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330441510
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330443965
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330447098
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330450349
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330452243
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330458936
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330460919
2014-07-14 02:35:42,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330463096
2014-07-14 02:35:44,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:44,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83276 synced till here 83274
2014-07-14 02:35:44,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330542698 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330544774
2014-07-14 02:35:46,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:46,264 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330544774 with entries=74, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330546243
2014-07-14 02:35:47,834 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:47,905 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83426 synced till here 83424
2014-07-14 02:35:47,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330546243 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330547835
2014-07-14 02:35:49,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:49,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330547835 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330549544
2014-07-14 02:35:51,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:51,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83575 synced till here 83572
2014-07-14 02:35:51,229 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330549544 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330551131
2014-07-14 02:35:52,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:35:52,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83655 synced till here 83649
2014-07-14 02:35:52,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330551131 with entries=80, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330552796
2014-07-14 02:35:53,717 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20690, memsize=411.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/06f53cacdd574b399cf369b44cd912fa
2014-07-14 02:35:53,749 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/06f53cacdd574b399cf369b44cd912fa as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/06f53cacdd574b399cf369b44cd912fa
2014-07-14 02:35:53,772 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/06f53cacdd574b399cf369b44cd912fa, entries=1498910, sequenceid=20690, filesize=106.7m
2014-07-14 02:35:53,773 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~784.2m/822325760, currentsize=431.5m/452447520 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 23629ms, sequenceid=20690, compaction requested=true
2014-07-14 02:35:53,773 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:178), split_queue=0, merge_queue=0
2014-07-14 02:35:57,145 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90368ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:35:57,146 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 550.4m
2014-07-14 02:35:57,525 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:35:58,674 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/e82659f12ae241cc858db1ae8c520e5b as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e82659f12ae241cc858db1ae8c520e5b
2014-07-14 02:35:58,686 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:35:58,694 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4ad515a6388d4882be115e86a6928012, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4ad515a6388d4882be115e86a6928012
2014-07-14 02:35:58,696 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/89606190d7844a50a6a0df394c5b2106, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/89606190d7844a50a6a0df394c5b2106
2014-07-14 02:35:58,706 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/65bf62bd996e4abeae27529a6b8a05ce, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/65bf62bd996e4abeae27529a6b8a05ce
2014-07-14 02:35:58,706 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into e82659f12ae241cc858db1ae8c520e5b(size=132.5m), total size for store is 3.9g. This selection was in queue for 0sec, and took 28sec to execute.
2014-07-14 02:35:58,706 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=166.3m, priority=-3, time=284437286362401; duration=28sec
2014-07-14 02:35:58,707 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:179), split_queue=0, merge_queue=0
2014-07-14 02:35:58,707 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:179), split_queue=0, merge_queue=0
2014-07-14 02:35:58,707 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:35:58,708 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 120136635 starting at candidate #13 after considering 132 permutations with 98 in ratio
2014-07-14 02:35:58,708 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:35:58,708 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:35:58,708 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=114.6m
2014-07-14 02:35:58,708 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/87dddea4d192497eade41fe4187d8df6, keycount=53675, bloomtype=ROW, size=38.2m, encoding=NONE, seqNum=17039
2014-07-14 02:35:58,708 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/844bf4b8fa2d4e39a90fc25e2039d118, keycount=45081, bloomtype=ROW, size=32.1m, encoding=NONE, seqNum=17375
2014-07-14 02:35:58,708 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9aaef6d259c941b398b9176cefe2ec94, keycount=62025, bloomtype=ROW, size=44.2m, encoding=NONE, seqNum=17542
2014-07-14 02:35:58,774 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:00,684 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:36:00,685 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 432.0m
2014-07-14 02:36:01,044 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:01,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:01,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83733 synced till here 83732
2014-07-14 02:36:01,613 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330552796 with entries=78, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330561553
2014-07-14 02:36:01,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330464811
2014-07-14 02:36:01,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330466353
2014-07-14 02:36:01,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330467959
2014-07-14 02:36:01,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330469210
2014-07-14 02:36:01,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330470785
2014-07-14 02:36:04,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:04,702 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83812 synced till here 83810
2014-07-14 02:36:04,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330561553 with entries=79, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330564328
2014-07-14 02:36:04,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:04,742 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20965, memsize=181.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/27cd9bd0a0654403ade07afe6309e058
2014-07-14 02:36:04,756 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/27cd9bd0a0654403ade07afe6309e058 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/27cd9bd0a0654403ade07afe6309e058
2014-07-14 02:36:04,896 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/27cd9bd0a0654403ade07afe6309e058, entries=659940, sequenceid=20965, filesize=47.0m
2014-07-14 02:36:04,897 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~550.4m/577158240, currentsize=61.2m/64127600 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 7751ms, sequenceid=20965, compaction requested=true
2014-07-14 02:36:04,897 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:179), split_queue=0, merge_queue=0
2014-07-14 02:36:05,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:05,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83888 synced till here 83885
2014-07-14 02:36:05,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330564328 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330565638
2014-07-14 02:36:05,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:07,082 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:07,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83961 synced till here 83960
2014-07-14 02:36:07,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330565638 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330567083
2014-07-14 02:36:07,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:08,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:08,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330567083 with entries=75, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330568570
2014-07-14 02:36:08,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:09,350 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20972, memsize=183.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ec8ffafe7c7e4c00850cdb98e22cfb30
2014-07-14 02:36:09,367 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/ec8ffafe7c7e4c00850cdb98e22cfb30 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ec8ffafe7c7e4c00850cdb98e22cfb30
2014-07-14 02:36:09,384 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ec8ffafe7c7e4c00850cdb98e22cfb30, entries=667620, sequenceid=20972, filesize=47.6m
2014-07-14 02:36:09,385 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~433.6m/454627600, currentsize=147.7m/154836400 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 8701ms, sequenceid=20972, compaction requested=true
2014-07-14 02:36:09,385 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:180), split_queue=0, merge_queue=0
2014-07-14 02:36:10,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:10,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84110 synced till here 84108
2014-07-14 02:36:10,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330568570 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330570095
2014-07-14 02:36:10,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:10,699 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=490246, hits=141577, hitRatio=28.87%, , cachingAccesses=141630, cachingHits=141517, cachingHitsRatio=99.92%, evictions=0, evicted=111, evictedPerRun=Infinity
2014-07-14 02:36:11,583 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:11,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84183 synced till here 84182
2014-07-14 02:36:11,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330570095 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330571584
2014-07-14 02:36:11,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:13,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:13,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84260 synced till here 84257
2014-07-14 02:36:13,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330571584 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330573807
2014-07-14 02:36:13,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:16,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:16,306 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:36:16,306 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:36:16,306 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:181), split_queue=0, merge_queue=0
2014-07-14 02:36:16,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84357 synced till here 84353
2014-07-14 02:36:16,486 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:36:16,487 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:36:16,487 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-14 02:36:16,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330573807 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330576189
2014-07-14 02:36:16,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:16,882 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/a4c11f9bb048411ba514f167323a4abb as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/a4c11f9bb048411ba514f167323a4abb
2014-07-14 02:36:16,897 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:36:16,909 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/87dddea4d192497eade41fe4187d8df6, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/87dddea4d192497eade41fe4187d8df6
2014-07-14 02:36:16,911 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/844bf4b8fa2d4e39a90fc25e2039d118, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/844bf4b8fa2d4e39a90fc25e2039d118
2014-07-14 02:36:16,913 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9aaef6d259c941b398b9176cefe2ec94, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9aaef6d259c941b398b9176cefe2ec94
2014-07-14 02:36:16,914 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into a4c11f9bb048411ba514f167323a4abb(size=95.3m), total size for store is 4.0g. This selection was in queue for 0sec, and took 18sec to execute.
2014-07-14 02:36:16,914 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=114.6m, priority=-2, time=284466135027463; duration=18sec
2014-07-14 02:36:16,914 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 02:36:16,914 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 02:36:16,914 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:36:16,915 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 256325049 starting at candidate #18 after considering 132 permutations with 128 in ratio
2014-07-14 02:36:16,915 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:36:16,915 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:36:16,915 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=244.5m
2014-07-14 02:36:16,915 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/255a5a428e6f43b8a63a24f3671cb60f, keycount=221591, bloomtype=ROW, size=157.7m, encoding=NONE, seqNum=19248
2014-07-14 02:36:16,915 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d868128736f4ab1a7c39168e4211478, keycount=83231, bloomtype=ROW, size=59.3m, encoding=NONE, seqNum=19431
2014-07-14 02:36:16,916 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/627afcb14b494faa980fb34c86ed9c91, keycount=38570, bloomtype=ROW, size=27.5m, encoding=NONE, seqNum=19600
2014-07-14 02:36:17,344 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:18,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:18,386 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84456 synced till here 84453
2014-07-14 02:36:18,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330576189 with entries=99, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330578080
2014-07-14 02:36:18,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:20,044 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:20,061 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84534 synced till here 84528
2014-07-14 02:36:20,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330578080 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330580045
2014-07-14 02:36:20,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:21,577 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:21,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84620 synced till here 84606
2014-07-14 02:36:21,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330580045 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330581577
2014-07-14 02:36:21,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:22,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:22,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84693 synced till here 84692
2014-07-14 02:36:23,019 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330581577 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330582967
2014-07-14 02:36:23,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:24,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:24,276 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84773 synced till here 84766
2014-07-14 02:36:24,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330582967 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330584260
2014-07-14 02:36:24,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:26,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:26,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84856 synced till here 84848
2014-07-14 02:36:26,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330584260 with entries=83, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330586680
2014-07-14 02:36:26,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:28,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:28,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 84952 synced till here 84949
2014-07-14 02:36:28,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330586680 with entries=96, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330588141
2014-07-14 02:36:28,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:30,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:30,284 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85025 synced till here 85024
2014-07-14 02:36:30,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330588141 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330590263
2014-07-14 02:36:30,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:32,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:32,353 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85099 synced till here 85098
2014-07-14 02:36:32,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330590263 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330592329
2014-07-14 02:36:32,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:36:35,382 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 02:36:35,383 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files, but is 1.6g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 02:36:35,383 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. due to global heap pressure
2014-07-14 02:36:35,383 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 1.6g
2014-07-14 02:36:35,482 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90704ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:36:35,482 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 1.1g
2014-07-14 02:36:35,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:35,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85181 synced till here 85174
2014-07-14 02:36:36,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330592329 with entries=82, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330595925
2014-07-14 02:36:36,837 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:37,210 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:37,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:36:37,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85257 synced till here 85256
2014-07-14 02:36:38,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330595925 with entries=76, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330597704
2014-07-14 02:36:44,975 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:44,991 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:47,161 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:48,636 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:49,044 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:49,976 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:36:49,992 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:36:51,041 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:51,132 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:52,161 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:36:53,180 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:53,636 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:36:54,045 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:36:54,976 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:36:54,992 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:36:55,149 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:55,246 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:56,041 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:36:56,132 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:36:56,949 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/158f9bc8af9b49ef9afd5df26f27bdca as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/158f9bc8af9b49ef9afd5df26f27bdca
2014-07-14 02:36:56,967 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:36:56,974 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/255a5a428e6f43b8a63a24f3671cb60f, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/255a5a428e6f43b8a63a24f3671cb60f
2014-07-14 02:36:56,977 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d868128736f4ab1a7c39168e4211478, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d868128736f4ab1a7c39168e4211478
2014-07-14 02:36:56,979 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/627afcb14b494faa980fb34c86ed9c91, to hdfs://master:54310/hbase/archive/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/627afcb14b494faa980fb34c86ed9c91
2014-07-14 02:36:56,979 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into 158f9bc8af9b49ef9afd5df26f27bdca(size=212.5m), total size for store is 3.9g. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-14 02:36:56,979 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., storeName=family, fileCount=3, fileSize=244.5m, priority=-2, time=284484342171518; duration=40sec
2014-07-14 02:36:56,979 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 02:36:56,979 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 02:36:56,980 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 02:36:56,980 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 171612738 starting at candidate #14 after considering 124 permutations with 93 in ratio
2014-07-14 02:36:56,980 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: c8a1d10978c87bbc043a64b1893a75b1 - family: Initiating minor compaction
2014-07-14 02:36:56,980 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:36:56,981 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp, totalSize=163.7m
2014-07-14 02:36:56,981 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f4ac5ff29de9466e96e99c0469be5e81, keycount=61296, bloomtype=ROW, size=43.7m, encoding=NONE, seqNum=17722
2014-07-14 02:36:56,981 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/866182f186d34d79aa30676d662ee3fe, keycount=75636, bloomtype=ROW, size=53.9m, encoding=NONE, seqNum=18262
2014-07-14 02:36:56,981 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/78d89773952643209f590f7a1b25463f, keycount=92825, bloomtype=ROW, size=66.1m, encoding=NONE, seqNum=18428
2014-07-14 02:36:57,026 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:36:57,162 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:36:57,255 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:58,180 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:36:58,636 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:36:59,046 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:36:59,244 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:59,453 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:36:59,977 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:36:59,993 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 02:37:00,149 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:37:00,247 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:37:01,042 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 02:37:01,132 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 02:37:01,467 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405327870609: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:37:02,162 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 02:37:02,256 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:37:02,827 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21344, memsize=721.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/127fd3c9deff4a908dbcb05d88735c01
2014-07-14 02:37:02,837 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/127fd3c9deff4a908dbcb05d88735c01 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/127fd3c9deff4a908dbcb05d88735c01
2014-07-14 02:37:02,846 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/127fd3c9deff4a908dbcb05d88735c01, entries=2627230, sequenceid=21344, filesize=187.0m
2014-07-14 02:37:02,847 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1165759040, currentsize=42.6m/44641360 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 27364ms, sequenceid=21344, compaction requested=true
2014-07-14 02:37:02,847 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 02:37:02,847 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5592ms
2014-07-14 02:37:02,847 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,847 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15686ms
2014-07-14 02:37:02,847 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,847 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1381ms
2014-07-14 02:37:02,848 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,848 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11716ms
2014-07-14 02:37:02,848 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,848 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11807ms
2014-07-14 02:37:02,848 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,848 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7602ms
2014-07-14 02:37:02,848 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,849 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7699ms
2014-07-14 02:37:02,849 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,849 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17858ms
2014-07-14 02:37:02,849 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,849 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17874ms
2014-07-14 02:37:02,849 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,850 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3396ms
2014-07-14 02:37:02,850 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,850 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3606ms
2014-07-14 02:37:02,850 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,850 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13806ms
2014-07-14 02:37:02,850 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,850 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14214ms
2014-07-14 02:37:02,850 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:02,850 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9671ms
2014-07-14 02:37:02,850 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405327870609
2014-07-14 02:37:03,184 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330604929,"queuetimems":0,"class":"HRegionServer","responsesize":16283,"method":"Multi"}
2014-07-14 02:37:03,280 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330611038,"queuetimems":1,"class":"HRegionServer","responsesize":15725,"method":"Multi"}
2014-07-14 02:37:03,309 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330607159,"queuetimems":1,"class":"HRegionServer","responsesize":16283,"method":"Multi"}
2014-07-14 02:37:03,579 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12451,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330611128,"queuetimems":0,"class":"HRegionServer","responsesize":16283,"method":"Multi"}
2014-07-14 02:37:03,587 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18599,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330604988,"queuetimems":0,"class":"HRegionServer","responsesize":16120,"method":"Multi"}
2014-07-14 02:37:03,898 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:03,899 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330609039,"queuetimems":0,"class":"HRegionServer","responsesize":16120,"method":"Multi"}
2014-07-14 02:37:03,899 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330613178,"queuetimems":1,"class":"HRegionServer","responsesize":16120,"method":"Multi"}
2014-07-14 02:37:03,900 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47201","starttimems":1405330608632,"queuetimems":1,"class":"HRegionServer","responsesize":15725,"method":"Multi"}
2014-07-14 02:37:03,934 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330597704 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330623898
2014-07-14 02:37:06,448 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90199ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:37:06,449 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 652.2m
2014-07-14 02:37:06,928 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:37:08,930 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:08,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85410 synced till here 85408
2014-07-14 02:37:09,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330623898 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330628930
2014-07-14 02:37:10,943 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21332, memsize=921.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/77bf31c07654435e9149b697af072f46
2014-07-14 02:37:10,957 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/77bf31c07654435e9149b697af072f46 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/77bf31c07654435e9149b697af072f46
2014-07-14 02:37:10,970 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/77bf31c07654435e9149b697af072f46, entries=3354000, sequenceid=21332, filesize=238.7m
2014-07-14 02:37:10,971 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.6g/1697836000, currentsize=111.1m/116521840 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 35588ms, sequenceid=21332, compaction requested=true
2014-07-14 02:37:10,971 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:184), split_queue=0, merge_queue=0
2014-07-14 02:37:12,772 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90595ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:37:12,772 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc., current region memstore size 109.4m
2014-07-14 02:37:12,819 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:37:15,342 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21417, memsize=88.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b89aea7f89cb400880e8a70c51c1ff53
2014-07-14 02:37:15,358 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp/b89aea7f89cb400880e8a70c51c1ff53 as hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b89aea7f89cb400880e8a70c51c1ff53
2014-07-14 02:37:15,385 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b89aea7f89cb400880e8a70c51c1ff53, entries=323820, sequenceid=21417, filesize=23.1m
2014-07-14 02:37:15,385 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~109.4m/114673280, currentsize=0.0/0 for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. in 2613ms, sequenceid=21417, compaction requested=true
2014-07-14 02:37:15,385 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:185), split_queue=0, merge_queue=0
2014-07-14 02:37:18,981 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/113618597e08416d94873ddee7cadb74 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/113618597e08416d94873ddee7cadb74
2014-07-14 02:37:18,994 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:37:19,000 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f4ac5ff29de9466e96e99c0469be5e81, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f4ac5ff29de9466e96e99c0469be5e81
2014-07-14 02:37:19,002 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/866182f186d34d79aa30676d662ee3fe, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/866182f186d34d79aa30676d662ee3fe
2014-07-14 02:37:19,004 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/78d89773952643209f590f7a1b25463f, to hdfs://master:54310/hbase/archive/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/78d89773952643209f590f7a1b25463f
2014-07-14 02:37:19,004 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. into 113618597e08416d94873ddee7cadb74(size=144.3m), total size for store is 4.0g. This selection was in queue for 0sec, and took 22sec to execute.
2014-07-14 02:37:19,004 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., storeName=family, fileCount=3, fileSize=163.7m, priority=-1, time=284524407587044; duration=22sec
2014-07-14 02:37:19,004 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:185), split_queue=0, merge_queue=0
2014-07-14 02:37:19,005 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:37:19,005 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 268657097 starting at candidate #15 after considering 132 permutations with 120 in ratio
2014-07-14 02:37:19,005 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:37:19,006 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:37:19,006 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=256.2m
2014-07-14 02:37:19,006 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/95054e28386c4574b0a242f0c13506e7, keycount=141587, bloomtype=ROW, size=100.8m, encoding=NONE, seqNum=16924
2014-07-14 02:37:19,006 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1dd339c974f24aa9ad4242c790bad097, keycount=196261, bloomtype=ROW, size=139.7m, encoding=NONE, seqNum=17877
2014-07-14 02:37:19,006 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/effef5d76b2842c39d77b8199dc6679e, keycount=21989, bloomtype=ROW, size=15.7m, encoding=NONE, seqNum=18144
2014-07-14 02:37:19,060 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:37:19,887 DEBUG [MemStoreFlusher.1] regionserver.HRegion: NOT flushing memstore for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., flushing=true, writesEnabled=true
2014-07-14 02:37:21,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:21,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85485 synced till here 85484
2014-07-14 02:37:21,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330628930 with entries=75, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330641096
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330472358
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330474118
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330475840
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330477635
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330479372
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330481223
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330487257
2014-07-14 02:37:21,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330489491
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330491254
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330492748
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330493844
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330495359
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330496900
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330498706
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330500681
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330502683
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330504637
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330506838
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330527532
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330529614
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330531636
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330534055
2014-07-14 02:37:21,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330535916
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330538010
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330540267
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330542698
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330544774
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330546243
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330547835
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330549544
2014-07-14 02:37:21,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330551131
2014-07-14 02:37:23,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:23,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330641096 with entries=75, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330643341
2014-07-14 02:37:24,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:24,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85635 synced till here 85634
2014-07-14 02:37:25,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330643341 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330644469
2014-07-14 02:37:26,026 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21389, memsize=605.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/13188f0eeece4db2b2bfdffb2974f7ef
2014-07-14 02:37:26,039 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/13188f0eeece4db2b2bfdffb2974f7ef as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/13188f0eeece4db2b2bfdffb2974f7ef
2014-07-14 02:37:26,051 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/13188f0eeece4db2b2bfdffb2974f7ef, entries=2204210, sequenceid=21389, filesize=156.9m
2014-07-14 02:37:26,051 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~652.2m/683869520, currentsize=125.8m/131921360 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 19602ms, sequenceid=21389, compaction requested=true
2014-07-14 02:37:26,052 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:185), split_queue=0, merge_queue=0
2014-07-14 02:37:26,376 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:26,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85711 synced till here 85710
2014-07-14 02:37:26,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330644469 with entries=76, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330646377
2014-07-14 02:37:27,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:27,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330646377 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330647836
2014-07-14 02:37:32,534 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:37:32,534 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. has too many store files; delaying flush up to 90000ms
2014-07-14 02:37:32,534 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:186), split_queue=0, merge_queue=0
2014-07-14 02:37:33,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:33,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85862 synced till here 85861
2014-07-14 02:37:33,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330647836 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330653113
2014-07-14 02:37:34,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:35,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 85952 synced till here 85950
2014-07-14 02:37:35,407 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330653113 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330654781
2014-07-14 02:37:36,627 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:36,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330654781 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330656627
2014-07-14 02:37:36,888 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:37:36,889 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1., current region memstore size 257.4m
2014-07-14 02:37:37,487 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:37:38,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:38,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86107 synced till here 86105
2014-07-14 02:37:38,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330656627 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330658273
2014-07-14 02:37:38,543 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:37:38,543 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. has too many store files; delaying flush up to 90000ms
2014-07-14 02:37:38,544 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:187), split_queue=0, merge_queue=0
2014-07-14 02:37:40,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:40,246 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330658273 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330660186
2014-07-14 02:37:41,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:41,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330660186 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330661873
2014-07-14 02:37:41,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:37:43,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:43,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330661873 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330663316
2014-07-14 02:37:43,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:37:45,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:45,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86409 synced till here 86405
2014-07-14 02:37:45,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330663316 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330665011
2014-07-14 02:37:45,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:37:46,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:46,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330665011 with entries=86, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330666456
2014-07-14 02:37:46,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:37:47,347 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90861ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:37:47,348 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c., current region memstore size 1.1g
2014-07-14 02:37:48,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:48,210 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21559, memsize=258.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/79703c39e24448a892c0cd3490297877
2014-07-14 02:37:48,225 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86573 synced till here 86570
2014-07-14 02:37:48,229 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/.tmp/79703c39e24448a892c0cd3490297877 as hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/79703c39e24448a892c0cd3490297877
2014-07-14 02:37:48,249 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/79703c39e24448a892c0cd3490297877, entries=942440, sequenceid=21559, filesize=67.1m
2014-07-14 02:37:48,249 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.8m/271416000, currentsize=207.6m/217703840 for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. in 11360ms, sequenceid=21559, compaction requested=true
2014-07-14 02:37:48,249 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:188), split_queue=0, merge_queue=0
2014-07-14 02:37:48,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330666456 with entries=78, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330668200
2014-07-14 02:37:48,821 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:37:50,576 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1158ms
GC pool 'ParNew' had collection(s): count=1 time=1390ms
2014-07-14 02:37:50,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:50,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86648 synced till here 86644
2014-07-14 02:37:50,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330668200 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330670798
2014-07-14 02:37:51,552 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:37:51,552 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. has too many store files; delaying flush up to 90000ms
2014-07-14 02:37:51,552 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:189), split_queue=0, merge_queue=0
2014-07-14 02:37:52,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:52,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86725 synced till here 86722
2014-07-14 02:37:52,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330670798 with entries=77, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330672629
2014-07-14 02:37:53,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:53,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 86798 synced till here 86797
2014-07-14 02:37:53,739 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330672629 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330673690
2014-07-14 02:37:55,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:56,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330673690 with entries=95, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330675826
2014-07-14 02:37:58,083 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:37:58,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330675826 with entries=83, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330678084
2014-07-14 02:37:59,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:00,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87058 synced till here 87056
2014-07-14 02:38:00,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330678084 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330679984
2014-07-14 02:38:04,574 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/64151486dbfe4c3cae67e88b8c8f5af4 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/64151486dbfe4c3cae67e88b8c8f5af4
2014-07-14 02:38:04,587 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:38:04,594 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/95054e28386c4574b0a242f0c13506e7, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/95054e28386c4574b0a242f0c13506e7
2014-07-14 02:38:04,596 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1dd339c974f24aa9ad4242c790bad097, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/1dd339c974f24aa9ad4242c790bad097
2014-07-14 02:38:04,598 DEBUG [regionserver60020-smallCompactions-1405327910691] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/effef5d76b2842c39d77b8199dc6679e, to hdfs://master:54310/hbase/archive/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/effef5d76b2842c39d77b8199dc6679e
2014-07-14 02:38:04,599 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into 64151486dbfe4c3cae67e88b8c8f5af4(size=240.4m), total size for store is 4.1g. This selection was in queue for 0sec, and took 45sec to execute.
2014-07-14 02:38:04,599 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=256.2m, priority=-2, time=284546432660073; duration=45sec
2014-07-14 02:38:04,599 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 02:38:04,599 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 02:38:04,599 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:38:04,600 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 358991010 starting at candidate #7 after considering 132 permutations with 128 in ratio
2014-07-14 02:38:04,600 DEBUG [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: 3990157c1b6a259f95c53a0f0007d7bc - family: Initiating minor compaction
2014-07-14 02:38:04,600 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:38:04,601 INFO  [regionserver60020-smallCompactions-1405327910691] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/.tmp, totalSize=342.4m
2014-07-14 02:38:04,601 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/ec6850bff8f44c32bb8bdd7d3741719b, keycount=224631, bloomtype=ROW, size=159.9m, encoding=NONE, seqNum=11004
2014-07-14 02:38:04,601 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/5d0f48ca004442eebe0b95c8e5d8aac3, keycount=111371, bloomtype=ROW, size=79.3m, encoding=NONE, seqNum=11271
2014-07-14 02:38:04,601 DEBUG [regionserver60020-smallCompactions-1405327910691] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0081b9e8aea4465182c2283a157d7e6c, keycount=144981, bloomtype=ROW, size=103.2m, encoding=NONE, seqNum=11694
2014-07-14 02:38:04,700 DEBUG [regionserver60020-smallCompactions-1405327910691] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:38:04,750 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., current region memstore size 744.7m
2014-07-14 02:38:05,567 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:38:09,065 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:09,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330679984 with entries=74, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330689065
2014-07-14 02:38:10,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:10,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87208 synced till here 87207
2014-07-14 02:38:10,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330689065 with entries=76, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330690708
2014-07-14 02:38:12,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:12,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87284 synced till here 87283
2014-07-14 02:38:12,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330690708 with entries=76, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330692693
2014-07-14 02:38:14,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:15,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87372 synced till here 87370
2014-07-14 02:38:15,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330692693 with entries=88, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330694705
2014-07-14 02:38:18,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:18,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330694705 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330698101
2014-07-14 02:38:20,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:38:20,904 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330698101 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405327870609/slave1%2C60020%2C1405327870609.1405330700757
2014-07-14 02:38:31,619 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21818, memsize=707.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/125e1a35b00b40ef97e74ed13ec5c568
2014-07-14 02:38:31,635 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp/125e1a35b00b40ef97e74ed13ec5c568 as hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/125e1a35b00b40ef97e74ed13ec5c568
2014-07-14 02:38:31,649 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/125e1a35b00b40ef97e74ed13ec5c568, entries=2574320, sequenceid=21818, filesize=183.1m
2014-07-14 02:38:31,649 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~744.7m/780895680, currentsize=186.9m/195996160 for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. in 26899ms, sequenceid=21818, compaction requested=true
2014-07-14 02:38:31,650 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 02:38:32,542 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21688, memsize=1.0g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/885919622070466790802a2da30c0358
2014-07-14 02:38:32,563 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/.tmp/885919622070466790802a2da30c0358 as hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/885919622070466790802a2da30c0358
2014-07-14 02:38:32,578 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/885919622070466790802a2da30c0358, entries=3855830, sequenceid=21688, filesize=274.4m
2014-07-14 02:38:32,578 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1157808640, currentsize=393.0m/412041360 for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. in 45230ms, sequenceid=21688, compaction requested=true
2014-07-14 02:38:32,579 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:191), split_queue=0, merge_queue=0
