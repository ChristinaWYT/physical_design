Fri Jul 11 00:13:27 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-11 00:13:28,178 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-11 00:13:28,179 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-11 00:13:28,179 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-11 00:13:28,420 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-11 00:13:28,420 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-11 00:13:28,420 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-11 00:13:28,420 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 42742 22
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-11 00:13:28,421 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-11 00:13:28,422 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 42742 9.1.143.59 22
2014-07-11 00:13:28,423 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-11 00:13:28,423 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-11 00:13:28,423 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-11 00:13:28,425 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-11 00:13:28,425 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-11 00:13:28,425 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-11 00:13:28,426 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-11 00:13:28,427 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-11 00:13:28,427 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-11 00:13:28,427 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-11 00:13:28,427 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=193
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-11 00:13:28,428 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-11 00:13:28,431 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-11 00:13:28,431 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-11 00:13:28,701 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-11 00:13:29,143 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-11 00:13:29,238 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-11 00:13:29,251 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-11 00:13:29,313 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-11 00:13:29,314 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-11 00:13:29,314 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-11 00:13:29,319 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-11 00:13:29,324 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-11 00:13:29,406 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-11 00:13:29,406 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-11 00:13:29,410 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-11 00:13:29,413 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-11 00:13:29,492 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-11 00:13:29,550 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-11 00:13:29,560 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-11 00:13:29,562 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-11 00:13:29,562 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-11 00:13:29,562 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-11 00:13:29,862 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-11 00:13:29,906 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-11 00:13:29,906 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-11 00:13:29,906 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-11 00:13:29,906 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-11 00:13:29,906 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-11 00:13:29,907 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-11 00:13:29,909 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 00:13:29,909 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-11 00:13:29,932 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 00:13:29,935 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 00:13:29,939 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-11 00:13:29,950 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x472445031e0001, negotiated timeout = 90000
2014-07-11 00:14:00,087 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x76d5b222, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 00:14:00,088 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x76d5b222 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 00:14:00,089 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 00:14:00,089 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-11 00:14:00,113 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147244501e90002, negotiated timeout = 90000
2014-07-11 00:14:00,387 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@65028c44
2014-07-11 00:14:00,392 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-11 00:14:00,398 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-11 00:14:00,415 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-11 00:14:00,446 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-11 00:14:00,452 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-11 00:14:00,456 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-11 00:14:00,473 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405062807469 with port=60020, startcode=1405062809335
2014-07-11 00:14:00,826 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-11 00:14:00,826 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-11 00:14:00,826 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-11 00:14:00,852 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-11 00:14:00,861 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335
2014-07-11 00:14:00,900 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-11 00:14:00,911 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-11 00:14:01,001 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405062840925
2014-07-11 00:14:01,012 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-11 00:14:01,017 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-11 00:14:01,020 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-11 00:14:01,025 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-11 00:14:01,027 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-11 00:14:01,027 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-11 00:14:01,028 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-11 00:14:01,028 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-11 00:14:01,028 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-11 00:14:01,036 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1405062809409, slave1,60020,1405062809335] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1405062809409, slave1,60020,1405062809335]
2014-07-11 00:14:01,058 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-11 00:14:01,060 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x706c8123, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 00:14:01,061 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x706c8123 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 00:14:01,061 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 00:14:01,062 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-11 00:14:01,065 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x472445031e0003, negotiated timeout = 90000
2014-07-11 00:14:01,072 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-11 00:14:01,072 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-11 00:14:01,118 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405062809335, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x472445031e0001
2014-07-11 00:14:01,118 INFO  [SplitLogWorker-slave1,60020,1405062809335] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405062809335 starting
2014-07-11 00:14:01,118 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-11 00:14:01,118 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405062809335
2014-07-11 00:14:01,118 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405062809335'
2014-07-11 00:14:01,118 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-11 00:14:01,120 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-11 00:14:01,121 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-11 00:14:05,772 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:05,904 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5cb06e5da6171e7af34144523ae71d0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,905 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:05,905 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:05,906 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3e650a1993bb1a49e183adcbb9770b96 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,907 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 00:14:05,908 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a6b9b2a8688211770d19e0dceb93c590 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,921 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:05,921 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:05,928 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a6b9b2a8688211770d19e0dceb93c590 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,928 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5cb06e5da6171e7af34144523ae71d0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,928 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3e650a1993bb1a49e183adcbb9770b96 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:05,944 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => b5cb06e5da6171e7af34144523ae71d0, NAME => 'usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-11 00:14:05,944 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => a6b9b2a8688211770d19e0dceb93c590, NAME => 'usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-11 00:14:05,944 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 3e650a1993bb1a49e183adcbb9770b96, NAME => 'usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-11 00:14:05,971 INFO  [RS_OPEN_REGION-slave1:60020-2] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-11 00:14:05,972 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a6b9b2a8688211770d19e0dceb93c590
2014-07-11 00:14:05,972 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3e650a1993bb1a49e183adcbb9770b96
2014-07-11 00:14:05,972 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b5cb06e5da6171e7af34144523ae71d0
2014-07-11 00:14:05,973 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:05,973 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:05,973 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:05,982 INFO  [RS_OPEN_REGION-slave1:60020-2] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-11 00:14:05,983 INFO  [RS_OPEN_REGION-slave1:60020-2] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-11 00:14:05,986 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-11 00:14:05,986 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-11 00:14:05,986 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-11 00:14:06,060 INFO  [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 00:14:06,060 INFO  [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 00:14:06,066 INFO  [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 00:14:06,111 INFO  [StoreFileOpenerThread-family-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-11 00:14:06,181 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-11 00:14:06,181 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-11 00:14:06,199 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/071c6019848b41d4a9a5ddec9037bcb7, isReference=false, isBulkLoadResult=false, seqid=1948, majorCompaction=false
2014-07-11 00:14:06,199 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/216b821181424810996c5849e58f9a64, isReference=false, isBulkLoadResult=false, seqid=1753, majorCompaction=false
2014-07-11 00:14:06,219 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/1a408f1148bb437f88a98254c4a385dc, isReference=false, isBulkLoadResult=false, seqid=1915, majorCompaction=false
2014-07-11 00:14:06,225 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/0a57d393439f42d381a2ce23edd648f6, isReference=false, isBulkLoadResult=false, seqid=4328, majorCompaction=false
2014-07-11 00:14:06,234 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/32cdd3ea55de45a7bdaaa15d77d81afe, isReference=false, isBulkLoadResult=false, seqid=2411, majorCompaction=false
2014-07-11 00:14:06,249 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/35ed37915eff4500b8c9a7a317c7b94b, isReference=false, isBulkLoadResult=false, seqid=219, majorCompaction=false
2014-07-11 00:14:06,253 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/3001d866c54d48d2876e2b5ec40f54b2, isReference=false, isBulkLoadResult=false, seqid=4092, majorCompaction=false
2014-07-11 00:14:06,270 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/5dba4461ef524e468bb868403fb6b8b8, isReference=false, isBulkLoadResult=false, seqid=532, majorCompaction=false
2014-07-11 00:14:06,272 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/3856320b3c48411fb0760b90fdbc0c11, isReference=false, isBulkLoadResult=false, seqid=4826, majorCompaction=false
2014-07-11 00:14:06,274 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/3905d0cbd1544a369dd9582ab6c79bb6, isReference=false, isBulkLoadResult=false, seqid=1630, majorCompaction=false
2014-07-11 00:14:06,295 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/6e5043d6c7454689a150bfd8c936aad7, isReference=false, isBulkLoadResult=false, seqid=3764, majorCompaction=false
2014-07-11 00:14:06,299 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/4d3ae873b6a14ac297bb4f96da27652b, isReference=false, isBulkLoadResult=false, seqid=5460, majorCompaction=false
2014-07-11 00:14:06,322 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/56d74a0627ee4cb4a8ad18c05686feec, isReference=false, isBulkLoadResult=false, seqid=172, majorCompaction=false
2014-07-11 00:14:06,323 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/568dba2d04634ecf82e07af1fcaaeafa, isReference=false, isBulkLoadResult=false, seqid=987, majorCompaction=false
2014-07-11 00:14:06,329 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/8ea4052b1b7144129c4e836a7c619b92, isReference=false, isBulkLoadResult=false, seqid=1074, majorCompaction=false
2014-07-11 00:14:06,343 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/597f42214a4942d990a41c96b8b646cf, isReference=false, isBulkLoadResult=false, seqid=3139, majorCompaction=false
2014-07-11 00:14:06,359 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/657b4f0af450468c819ee6e5d29deb80, isReference=false, isBulkLoadResult=false, seqid=773, majorCompaction=false
2014-07-11 00:14:06,370 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/afa6455d4354485dbdfedcff477ebc82, isReference=false, isBulkLoadResult=false, seqid=3096, majorCompaction=false
2014-07-11 00:14:06,380 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/60a80f01b0dd4caa94e0e8c6d3aeb014, isReference=false, isBulkLoadResult=false, seqid=1310, majorCompaction=false
2014-07-11 00:14:06,390 DEBUG [StoreOpener-a6b9b2a8688211770d19e0dceb93c590-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590/family/db7263aa9076498bab600f0c93ee010b, isReference=false, isBulkLoadResult=false, seqid=4308, majorCompaction=false
2014-07-11 00:14:06,421 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/7121f4c02947425ab100f64535aadd0d, isReference=false, isBulkLoadResult=false, seqid=3501, majorCompaction=false
2014-07-11 00:14:06,430 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/7e20f92fc64d47169ad9001948896b68, isReference=false, isBulkLoadResult=false, seqid=2320, majorCompaction=false
2014-07-11 00:14:06,443 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a6b9b2a8688211770d19e0dceb93c590
2014-07-11 00:14:06,449 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/80c29d7d9d6441eda267283ff5b1afeb, isReference=false, isBulkLoadResult=false, seqid=4310, majorCompaction=false
2014-07-11 00:14:06,455 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined a6b9b2a8688211770d19e0dceb93c590; next sequenceid=4309
2014-07-11 00:14:06,455 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a6b9b2a8688211770d19e0dceb93c590
2014-07-11 00:14:06,458 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/830a55321fc34fc3b5eb1d866b83dd20, isReference=false, isBulkLoadResult=false, seqid=2678, majorCompaction=false
2014-07-11 00:14:06,460 INFO  [PostOpenDeployTasks:a6b9b2a8688211770d19e0dceb93c590] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:06,463 DEBUG [PostOpenDeployTasks:a6b9b2a8688211770d19e0dceb93c590] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:06,464 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-11 00:14:06,464 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-11 00:14:06,466 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/9f9436733a43450b900f5a34a6b14015, isReference=false, isBulkLoadResult=false, seqid=680, majorCompaction=false
2014-07-11 00:14:06,466 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:06,466 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:06,469 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590. because compaction request was cancelled
2014-07-11 00:14:06,475 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/b6a844bbe9874e98be9a198360e4e29f, isReference=false, isBulkLoadResult=false, seqid=5927, majorCompaction=false
2014-07-11 00:14:06,498 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/a3b1706e609e4f18b8dee70f91c12c6d, isReference=false, isBulkLoadResult=false, seqid=2782, majorCompaction=false
2014-07-11 00:14:06,520 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/dfae33ad4ce14b26acdb298e475e8593, isReference=false, isBulkLoadResult=false, seqid=4176, majorCompaction=false
2014-07-11 00:14:06,534 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/adcca7eae5b04e79a4d115ff38feb438, isReference=false, isBulkLoadResult=false, seqid=3616, majorCompaction=false
2014-07-11 00:14:06,550 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/e931f60df75c434c9939891a50d870fd, isReference=false, isBulkLoadResult=false, seqid=5827, majorCompaction=false
2014-07-11 00:14:06,569 INFO  [PostOpenDeployTasks:a6b9b2a8688211770d19e0dceb93c590] catalog.MetaEditor: Updated row usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590. with server=slave1,60020,1405062809335
2014-07-11 00:14:06,569 INFO  [PostOpenDeployTasks:a6b9b2a8688211770d19e0dceb93c590] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:06,569 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a6b9b2a8688211770d19e0dceb93c590 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,575 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a6b9b2a8688211770d19e0dceb93c590 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,575 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned a6b9b2a8688211770d19e0dceb93c590 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:06,575 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590. on slave1,60020,1405062809335
2014-07-11 00:14:06,575 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,580 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,580 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-11 00:14:06,581 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-11 00:14:06,581 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 00:14:06,608 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:14:06,617 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/ae1568b5c8cf4f76a10d50d63a4eefcf, isReference=false, isBulkLoadResult=false, seqid=498, majorCompaction=false
2014-07-11 00:14:06,619 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/ec2446140294416495472fa05a0d923c, isReference=false, isBulkLoadResult=false, seqid=421, majorCompaction=false
2014-07-11 00:14:06,644 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-11 00:14:06,646 DEBUG [StoreOpener-3e650a1993bb1a49e183adcbb9770b96-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96/family/ed9a4b0760374f6885b306e53491c637, isReference=false, isBulkLoadResult=false, seqid=1440, majorCompaction=false
2014-07-11 00:14:06,648 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-11 00:14:06,649 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3e650a1993bb1a49e183adcbb9770b96
2014-07-11 00:14:06,651 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-11 00:14:06,651 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-11 00:14:06,651 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/af17a17dd872451f9fb7d949e7cf3eec, isReference=false, isBulkLoadResult=false, seqid=346, majorCompaction=false
2014-07-11 00:14:06,652 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 3e650a1993bb1a49e183adcbb9770b96; next sequenceid=5928
2014-07-11 00:14:06,652 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3e650a1993bb1a49e183adcbb9770b96
2014-07-11 00:14:06,654 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 00:14:06,654 INFO  [PostOpenDeployTasks:3e650a1993bb1a49e183adcbb9770b96] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:06,655 DEBUG [PostOpenDeployTasks:3e650a1993bb1a49e183adcbb9770b96] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:06,657 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-11 00:14:06,657 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-11 00:14:06,657 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:06,658 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:06,658 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96. because compaction request was cancelled
2014-07-11 00:14:06,665 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405062809335
2014-07-11 00:14:06,665 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 00:14:06,666 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,666 INFO  [PostOpenDeployTasks:3e650a1993bb1a49e183adcbb9770b96] catalog.MetaEditor: Updated row usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96. with server=slave1,60020,1405062809335
2014-07-11 00:14:06,666 INFO  [PostOpenDeployTasks:3e650a1993bb1a49e183adcbb9770b96] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:06,667 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3e650a1993bb1a49e183adcbb9770b96 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:06,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405062809335
2014-07-11 00:14:06,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1231dfaa320930fef79c95c3c97a0c48 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,672 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3e650a1993bb1a49e183adcbb9770b96 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,672 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 3e650a1993bb1a49e183adcbb9770b96 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:06,672 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96. on slave1,60020,1405062809335
2014-07-11 00:14:06,672 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d3859e2dcf154a4a686686041e068bf5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,676 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1231dfaa320930fef79c95c3c97a0c48 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,677 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 1231dfaa320930fef79c95c3c97a0c48, NAME => 'usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-11 00:14:06,677 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 1231dfaa320930fef79c95c3c97a0c48
2014-07-11 00:14:06,677 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:06,678 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d3859e2dcf154a4a686686041e068bf5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:14:06,678 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => d3859e2dcf154a4a686686041e068bf5, NAME => 'usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-11 00:14:06,679 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d3859e2dcf154a4a686686041e068bf5
2014-07-11 00:14:06,679 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:06,685 INFO  [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 00:14:06,688 INFO  [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 00:14:06,708 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/da36da6df34647399ffe62283514bded, isReference=false, isBulkLoadResult=false, seqid=988, majorCompaction=false
2014-07-11 00:14:06,718 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/02a1ff8b95e946e68582c6f09c974323, isReference=false, isBulkLoadResult=false, seqid=3235, majorCompaction=false
2014-07-11 00:14:06,722 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/086557e2fffa41c290456639d757d624, isReference=false, isBulkLoadResult=false, seqid=893, majorCompaction=false
2014-07-11 00:14:06,733 DEBUG [StoreOpener-b5cb06e5da6171e7af34144523ae71d0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0/family/e7e8cba3bd5f4866bf12a31de5d25e85, isReference=false, isBulkLoadResult=false, seqid=823, majorCompaction=false
2014-07-11 00:14:06,738 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b5cb06e5da6171e7af34144523ae71d0
2014-07-11 00:14:06,745 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/13b8731fcb774169acd87b5c9b10d652, isReference=false, isBulkLoadResult=false, seqid=4330, majorCompaction=false
2014-07-11 00:14:06,746 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined b5cb06e5da6171e7af34144523ae71d0; next sequenceid=4329
2014-07-11 00:14:06,746 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b5cb06e5da6171e7af34144523ae71d0
2014-07-11 00:14:06,748 INFO  [PostOpenDeployTasks:b5cb06e5da6171e7af34144523ae71d0] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:06,749 DEBUG [PostOpenDeployTasks:b5cb06e5da6171e7af34144523ae71d0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:06,749 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-11 00:14:06,749 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-11 00:14:06,749 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:06,749 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:06,750 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0. because compaction request was cancelled
2014-07-11 00:14:06,750 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/065316e8ca8e41c98c78603bd11aec5e, isReference=false, isBulkLoadResult=false, seqid=840, majorCompaction=false
2014-07-11 00:14:06,757 INFO  [PostOpenDeployTasks:b5cb06e5da6171e7af34144523ae71d0] catalog.MetaEditor: Updated row usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0. with server=slave1,60020,1405062809335
2014-07-11 00:14:06,758 INFO  [PostOpenDeployTasks:b5cb06e5da6171e7af34144523ae71d0] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:06,758 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5cb06e5da6171e7af34144523ae71d0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,763 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5cb06e5da6171e7af34144523ae71d0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:06,763 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned b5cb06e5da6171e7af34144523ae71d0 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:06,763 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0. on slave1,60020,1405062809335
2014-07-11 00:14:06,776 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/1b8d99a8b0724529a2baebc603c1b9a4, isReference=false, isBulkLoadResult=false, seqid=2133, majorCompaction=false
2014-07-11 00:14:06,786 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/1c3599bf9acf4cf789c197c595c707a5, isReference=false, isBulkLoadResult=false, seqid=696, majorCompaction=false
2014-07-11 00:14:06,827 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/22c39a4a6e544dc7ab2b70d6b2b23d74, isReference=false, isBulkLoadResult=false, seqid=2609, majorCompaction=false
2014-07-11 00:14:06,830 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/23904dcf3a0943c684bd75acbb8d56b5, isReference=false, isBulkLoadResult=false, seqid=2733, majorCompaction=false
2014-07-11 00:14:06,852 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/30cfa5993c134a0cb8fb70cf575462c9, isReference=false, isBulkLoadResult=false, seqid=3916, majorCompaction=false
2014-07-11 00:14:06,856 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/2f36e342a1064876b98565e66e6b49dd, isReference=false, isBulkLoadResult=false, seqid=3715, majorCompaction=false
2014-07-11 00:14:06,884 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/3d20d6a18eed4ab3aa6ba79ba54373df, isReference=false, isBulkLoadResult=false, seqid=1448, majorCompaction=false
2014-07-11 00:14:06,887 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/3b071e3e372e457e85009700a54fba4a, isReference=false, isBulkLoadResult=false, seqid=4332, majorCompaction=false
2014-07-11 00:14:06,923 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/503924f26e4e45f6be739c693eb32b3d, isReference=false, isBulkLoadResult=false, seqid=736, majorCompaction=false
2014-07-11 00:14:06,932 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/607a4286dbdf4495ade473f786a43442, isReference=false, isBulkLoadResult=false, seqid=407, majorCompaction=false
2014-07-11 00:14:06,951 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/57c667d25fd14a56828662ca5d35bf0b, isReference=false, isBulkLoadResult=false, seqid=240, majorCompaction=false
2014-07-11 00:14:06,960 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/675bcfea6b7c46459ec790fb80728dcc, isReference=false, isBulkLoadResult=false, seqid=550, majorCompaction=false
2014-07-11 00:14:07,006 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/57e2e64761cd470880f1e9dc7adcd343, isReference=false, isBulkLoadResult=false, seqid=598, majorCompaction=false
2014-07-11 00:14:07,015 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/6809699dfcb142c9a5c175d4460a4ab8, isReference=false, isBulkLoadResult=false, seqid=1063, majorCompaction=false
2014-07-11 00:14:07,045 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/65cebe432d9845bcbfb5d8aa6ffffdb7, isReference=false, isBulkLoadResult=false, seqid=3371, majorCompaction=false
2014-07-11 00:14:07,056 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/72466359f7a045929bf527b23d7d8a92, isReference=false, isBulkLoadResult=false, seqid=1612, majorCompaction=false
2014-07-11 00:14:07,071 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/696327b8c8fa41e7b2028df89c2b74a7, isReference=false, isBulkLoadResult=false, seqid=2933, majorCompaction=false
2014-07-11 00:14:07,074 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/91c82e7f276e44a2b0042d811299becb, isReference=false, isBulkLoadResult=false, seqid=4112, majorCompaction=false
2014-07-11 00:14:07,119 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/7b329b2437ad429e9e3cdbafbbbcdaa6, isReference=false, isBulkLoadResult=false, seqid=411, majorCompaction=false
2014-07-11 00:14:07,122 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/ae3ccf3ee3e8442fb76b2f04bc8c0a5f, isReference=false, isBulkLoadResult=false, seqid=2218, majorCompaction=false
2014-07-11 00:14:07,160 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/7bdbb61a645c49d49b5ac4da0a60c1f3, isReference=false, isBulkLoadResult=false, seqid=1150, majorCompaction=false
2014-07-11 00:14:07,171 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/e4ec0c2a626e48c88604d7fbb3aaf203, isReference=false, isBulkLoadResult=false, seqid=1860, majorCompaction=false
2014-07-11 00:14:07,236 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/7e20e07a0c844a499ff502043d2ca7bd, isReference=false, isBulkLoadResult=false, seqid=1793, majorCompaction=false
2014-07-11 00:14:07,238 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/f742d21ff4384a40a4ab9c79986ae71b, isReference=false, isBulkLoadResult=false, seqid=247, majorCompaction=false
2014-07-11 00:14:07,246 DEBUG [StoreOpener-d3859e2dcf154a4a686686041e068bf5-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5/family/9ad5125befc24eeba063d77e7b113ed7, isReference=false, isBulkLoadResult=false, seqid=4189, majorCompaction=false
2014-07-11 00:14:07,248 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d3859e2dcf154a4a686686041e068bf5
2014-07-11 00:14:07,251 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined d3859e2dcf154a4a686686041e068bf5; next sequenceid=4331
2014-07-11 00:14:07,252 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d3859e2dcf154a4a686686041e068bf5
2014-07-11 00:14:07,254 INFO  [PostOpenDeployTasks:d3859e2dcf154a4a686686041e068bf5] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:07,255 DEBUG [PostOpenDeployTasks:d3859e2dcf154a4a686686041e068bf5] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:07,255 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-11 00:14:07,255 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-11 00:14:07,255 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:07,256 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:07,256 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5. because compaction request was cancelled
2014-07-11 00:14:07,257 DEBUG [StoreOpener-1231dfaa320930fef79c95c3c97a0c48-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48/family/f8ce8bd8c75c4751a39ecbabc38b964f, isReference=false, isBulkLoadResult=false, seqid=1309, majorCompaction=false
2014-07-11 00:14:07,261 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/1231dfaa320930fef79c95c3c97a0c48
2014-07-11 00:14:07,263 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 1231dfaa320930fef79c95c3c97a0c48; next sequenceid=4333
2014-07-11 00:14:07,263 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1231dfaa320930fef79c95c3c97a0c48
2014-07-11 00:14:07,264 INFO  [PostOpenDeployTasks:d3859e2dcf154a4a686686041e068bf5] catalog.MetaEditor: Updated row usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5. with server=slave1,60020,1405062809335
2014-07-11 00:14:07,264 INFO  [PostOpenDeployTasks:d3859e2dcf154a4a686686041e068bf5] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:07,265 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d3859e2dcf154a4a686686041e068bf5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:07,266 INFO  [PostOpenDeployTasks:1231dfaa320930fef79c95c3c97a0c48] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:07,266 DEBUG [PostOpenDeployTasks:1231dfaa320930fef79c95c3c97a0c48] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:07,266 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-11 00:14:07,266 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-11 00:14:07,267 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:07,267 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:07,267 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48. because compaction request was cancelled
2014-07-11 00:14:07,270 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d3859e2dcf154a4a686686041e068bf5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:07,270 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned d3859e2dcf154a4a686686041e068bf5 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:07,270 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5. on slave1,60020,1405062809335
2014-07-11 00:14:07,274 INFO  [PostOpenDeployTasks:1231dfaa320930fef79c95c3c97a0c48] catalog.MetaEditor: Updated row usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48. with server=slave1,60020,1405062809335
2014-07-11 00:14:07,274 INFO  [PostOpenDeployTasks:1231dfaa320930fef79c95c3c97a0c48] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:07,275 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1231dfaa320930fef79c95c3c97a0c48 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:07,282 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1231dfaa320930fef79c95c3c97a0c48 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:14:07,282 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 1231dfaa320930fef79c95c3c97a0c48 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:14:07,282 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48. on slave1,60020,1405062809335
2014-07-11 00:14:11,031 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:14:11,031 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-11 00:14:11,031 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-11 00:14:11,031 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 00:14:11,031 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:11,031 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:11,031 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 00:14:11,031 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48. because compaction request was cancelled
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 15 files from compaction candidates
2014-07-11 00:14:11,032 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:11,032 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5. because compaction request was cancelled
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 16 files from compaction candidates
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0. because compaction request was cancelled
2014-07-11 00:14:11,032 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 13 files from compaction candidates
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96. because compaction request was cancelled
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 00:14:11,033 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Not compacting usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590. because compaction request was cancelled
2014-07-11 00:14:36,123 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close b5cb06e5da6171e7af34144523ae71d0, via zk=yes, znode version=0, on null
2014-07-11 00:14:36,123 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close a6b9b2a8688211770d19e0dceb93c590, via zk=yes, znode version=0, on null
2014-07-11 00:14:36,124 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 1231dfaa320930fef79c95c3c97a0c48, via zk=yes, znode version=0, on null
2014-07-11 00:14:36,124 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 3e650a1993bb1a49e183adcbb9770b96, via zk=yes, znode version=0, on null
2014-07-11 00:14:36,125 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close d3859e2dcf154a4a686686041e068bf5, via zk=yes, znode version=0, on null
2014-07-11 00:14:36,127 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:36,127 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:36,127 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:36,130 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.: disabling compactions & flushes
2014-07-11 00:14:36,130 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:36,131 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.: disabling compactions & flushes
2014-07-11 00:14:36,131 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.: disabling compactions & flushes
2014-07-11 00:14:36,131 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:36,131 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:36,175 INFO  [StoreCloserThread-usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.-1] regionserver.HStore: Closed family
2014-07-11 00:14:36,177 INFO  [StoreCloserThread-usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.-1] regionserver.HStore: Closed family
2014-07-11 00:14:36,178 INFO  [StoreCloserThread-usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.-1] regionserver.HStore: Closed family
2014-07-11 00:14:36,179 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:36,179 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:36,179 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:36,180 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b5cb06e5da6171e7af34144523ae71d0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,180 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1231dfaa320930fef79c95c3c97a0c48 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,180 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a6b9b2a8688211770d19e0dceb93c590 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,186 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b5cb06e5da6171e7af34144523ae71d0 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,186 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0. on slave1,60020,1405062809335
2014-07-11 00:14:36,186 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user4,1405062122530.b5cb06e5da6171e7af34144523ae71d0.
2014-07-11 00:14:36,186 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1231dfaa320930fef79c95c3c97a0c48 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48. on slave1,60020,1405062809335
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user6,1405062122530.1231dfaa320930fef79c95c3c97a0c48.
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a6b9b2a8688211770d19e0dceb93c590 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590. on slave1,60020,1405062809335
2014-07-11 00:14:36,187 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user9,1405062122530.a6b9b2a8688211770d19e0dceb93c590.
2014-07-11 00:14:36,189 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.: disabling compactions & flushes
2014-07-11 00:14:36,189 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:36,189 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.: disabling compactions & flushes
2014-07-11 00:14:36,189 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:36,192 INFO  [StoreCloserThread-usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.-1] regionserver.HStore: Closed family
2014-07-11 00:14:36,192 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:36,193 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3e650a1993bb1a49e183adcbb9770b96 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,193 INFO  [StoreCloserThread-usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.-1] regionserver.HStore: Closed family
2014-07-11 00:14:36,194 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:14:36,194 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d3859e2dcf154a4a686686041e068bf5 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,198 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3e650a1993bb1a49e183adcbb9770b96 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,199 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96. on slave1,60020,1405062809335
2014-07-11 00:14:36,199 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user1,1405062122529.3e650a1993bb1a49e183adcbb9770b96.
2014-07-11 00:14:36,199 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d3859e2dcf154a4a686686041e068bf5 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 00:14:36,199 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5. on slave1,60020,1405062809335
2014-07-11 00:14:36,199 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user5,1405062122530.d3859e2dcf154a4a686686041e068bf5.
2014-07-11 00:18:29,424 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=5, hits=3, hitRatio=60.00%, , cachingAccesses=5, cachingHits=3, cachingHitsRatio=60.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-11 00:19:46,525 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:19:46,535 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:19:46,535 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 7f41c69805823d0232eb4305b0b41c7e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,535 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:19:46,535 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:19:46,536 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 600e47c8102c939894f95b55fbbe3a1e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,536 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:19:46,538 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a814c9f2554f95576d7e3f7dd25bb826 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,544 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 7f41c69805823d0232eb4305b0b41c7e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,544 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 7f41c69805823d0232eb4305b0b41c7e, NAME => 'usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-11 00:19:46,545 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 600e47c8102c939894f95b55fbbe3a1e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,545 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 7f41c69805823d0232eb4305b0b41c7e
2014-07-11 00:19:46,546 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:19:46,546 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 600e47c8102c939894f95b55fbbe3a1e, NAME => 'usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-11 00:19:46,546 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a814c9f2554f95576d7e3f7dd25bb826 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,547 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 600e47c8102c939894f95b55fbbe3a1e
2014-07-11 00:19:46,547 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:19:46,547 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => a814c9f2554f95576d7e3f7dd25bb826, NAME => 'usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-11 00:19:46,548 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a814c9f2554f95576d7e3f7dd25bb826
2014-07-11 00:19:46,548 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:19:46,558 INFO  [StoreOpener-600e47c8102c939894f95b55fbbe3a1e-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:19:46,559 INFO  [StoreOpener-7f41c69805823d0232eb4305b0b41c7e-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:19:46,561 INFO  [StoreOpener-a814c9f2554f95576d7e3f7dd25bb826-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:19:46,564 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e
2014-07-11 00:19:46,565 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e
2014-07-11 00:19:46,566 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826
2014-07-11 00:19:46,567 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 600e47c8102c939894f95b55fbbe3a1e; next sequenceid=1
2014-07-11 00:19:46,567 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 600e47c8102c939894f95b55fbbe3a1e
2014-07-11 00:19:46,568 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 7f41c69805823d0232eb4305b0b41c7e; next sequenceid=1
2014-07-11 00:19:46,568 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 7f41c69805823d0232eb4305b0b41c7e
2014-07-11 00:19:46,569 INFO  [PostOpenDeployTasks:600e47c8102c939894f95b55fbbe3a1e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:19:46,570 INFO  [PostOpenDeployTasks:7f41c69805823d0232eb4305b0b41c7e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:19:46,583 INFO  [PostOpenDeployTasks:600e47c8102c939894f95b55fbbe3a1e] catalog.MetaEditor: Updated row usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. with server=slave1,60020,1405062809335
2014-07-11 00:19:46,583 INFO  [PostOpenDeployTasks:600e47c8102c939894f95b55fbbe3a1e] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:19:46,584 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 600e47c8102c939894f95b55fbbe3a1e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,588 INFO  [PostOpenDeployTasks:7f41c69805823d0232eb4305b0b41c7e] catalog.MetaEditor: Updated row usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. with server=slave1,60020,1405062809335
2014-07-11 00:19:46,588 INFO  [PostOpenDeployTasks:7f41c69805823d0232eb4305b0b41c7e] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:19:46,589 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 7f41c69805823d0232eb4305b0b41c7e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,590 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 600e47c8102c939894f95b55fbbe3a1e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,591 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 600e47c8102c939894f95b55fbbe3a1e to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:19:46,591 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. on slave1,60020,1405062809335
2014-07-11 00:19:46,591 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a575cf61a8e56ddc4885c72863b830c2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,596 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 7f41c69805823d0232eb4305b0b41c7e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,596 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 7f41c69805823d0232eb4305b0b41c7e to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:19:46,596 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. on slave1,60020,1405062809335
2014-07-11 00:19:46,596 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cee2ff08fd3c0bc377dccf8be24cbd0f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,598 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a575cf61a8e56ddc4885c72863b830c2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,598 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => a575cf61a8e56ddc4885c72863b830c2, NAME => 'usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-11 00:19:46,599 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a575cf61a8e56ddc4885c72863b830c2
2014-07-11 00:19:46,599 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:19:46,600 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined a814c9f2554f95576d7e3f7dd25bb826; next sequenceid=1
2014-07-11 00:19:46,600 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a814c9f2554f95576d7e3f7dd25bb826
2014-07-11 00:19:46,603 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cee2ff08fd3c0bc377dccf8be24cbd0f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 00:19:46,603 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => cee2ff08fd3c0bc377dccf8be24cbd0f, NAME => 'usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-11 00:19:46,604 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable cee2ff08fd3c0bc377dccf8be24cbd0f
2014-07-11 00:19:46,604 INFO  [PostOpenDeployTasks:a814c9f2554f95576d7e3f7dd25bb826] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:19:46,604 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:19:46,611 INFO  [PostOpenDeployTasks:a814c9f2554f95576d7e3f7dd25bb826] catalog.MetaEditor: Updated row usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. with server=slave1,60020,1405062809335
2014-07-11 00:19:46,611 INFO  [PostOpenDeployTasks:a814c9f2554f95576d7e3f7dd25bb826] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:19:46,612 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a814c9f2554f95576d7e3f7dd25bb826 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,612 INFO  [StoreOpener-a575cf61a8e56ddc4885c72863b830c2-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:19:46,615 INFO  [StoreOpener-cee2ff08fd3c0bc377dccf8be24cbd0f-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 00:19:46,619 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a814c9f2554f95576d7e3f7dd25bb826 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,619 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned a814c9f2554f95576d7e3f7dd25bb826 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:19:46,619 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. on slave1,60020,1405062809335
2014-07-11 00:19:46,620 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2
2014-07-11 00:19:46,621 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f
2014-07-11 00:19:46,624 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined a575cf61a8e56ddc4885c72863b830c2; next sequenceid=1
2014-07-11 00:19:46,624 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a575cf61a8e56ddc4885c72863b830c2
2014-07-11 00:19:46,627 INFO  [PostOpenDeployTasks:a575cf61a8e56ddc4885c72863b830c2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:19:46,637 INFO  [PostOpenDeployTasks:a575cf61a8e56ddc4885c72863b830c2] catalog.MetaEditor: Updated row usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. with server=slave1,60020,1405062809335
2014-07-11 00:19:46,637 INFO  [PostOpenDeployTasks:a575cf61a8e56ddc4885c72863b830c2] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:19:46,638 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a575cf61a8e56ddc4885c72863b830c2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,648 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a575cf61a8e56ddc4885c72863b830c2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,648 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned a575cf61a8e56ddc4885c72863b830c2 to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:19:46,648 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. on slave1,60020,1405062809335
2014-07-11 00:19:46,661 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined cee2ff08fd3c0bc377dccf8be24cbd0f; next sequenceid=1
2014-07-11 00:19:46,661 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node cee2ff08fd3c0bc377dccf8be24cbd0f
2014-07-11 00:19:46,664 INFO  [PostOpenDeployTasks:cee2ff08fd3c0bc377dccf8be24cbd0f] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:19:46,675 INFO  [PostOpenDeployTasks:cee2ff08fd3c0bc377dccf8be24cbd0f] catalog.MetaEditor: Updated row usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. with server=slave1,60020,1405062809335
2014-07-11 00:19:46,675 INFO  [PostOpenDeployTasks:cee2ff08fd3c0bc377dccf8be24cbd0f] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:19:46,676 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cee2ff08fd3c0bc377dccf8be24cbd0f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,684 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x472445031e0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cee2ff08fd3c0bc377dccf8be24cbd0f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 00:19:46,684 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned cee2ff08fd3c0bc377dccf8be24cbd0f to OPENED in zk on slave1,60020,1405062809335
2014-07-11 00:19:46,684 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. on slave1,60020,1405062809335
2014-07-11 00:20:05,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:06,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 91 synced till here 79
2014-07-11 00:20:06,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405062840925 with entries=91, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063205872
2014-07-11 00:20:08,374 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:08,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 201 synced till here 177
2014-07-11 00:20:09,028 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063205872 with entries=110, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063208374
2014-07-11 00:20:11,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:11,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 343 synced till here 309
2014-07-11 00:20:12,545 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063208374 with entries=142, filesize=121.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063211174
2014-07-11 00:20:14,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:14,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 434 synced till here 428
2014-07-11 00:20:14,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063211174 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063214092
2014-07-11 00:20:16,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:16,619 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 541 synced till here 507
2014-07-11 00:20:17,390 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063214092 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063216595
2014-07-11 00:20:19,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:19,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 658 synced till here 626
2014-07-11 00:20:20,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063216595 with entries=117, filesize=100.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063219481
2014-07-11 00:20:22,072 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:20:22,077 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 256.2m
2014-07-11 00:20:22,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:22,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 768 synced till here 733
2014-07-11 00:20:23,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063219481 with entries=110, filesize=94.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063222557
2014-07-11 00:20:24,068 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:20:24,068 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 259.0m
2014-07-11 00:20:24,074 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:24,579 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:20:24,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:24,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 870 synced till here 842
2014-07-11 00:20:25,191 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:25,198 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 00:20:25,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063222557 with entries=102, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063224868
2014-07-11 00:20:25,968 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:20:26,430 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:20:26,816 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:26,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 971 synced till here 947
2014-07-11 00:20:27,352 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063224868 with entries=101, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063226816
2014-07-11 00:20:29,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:29,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1059 synced till here 1045
2014-07-11 00:20:29,542 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063226816 with entries=88, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063229119
2014-07-11 00:20:29,798 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=168, memsize=46.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4005697f5fd74f238997b1d38e145080
2014-07-11 00:20:29,814 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4005697f5fd74f238997b1d38e145080 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4005697f5fd74f238997b1d38e145080
2014-07-11 00:20:29,827 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4005697f5fd74f238997b1d38e145080, entries=170760, sequenceid=168, filesize=12.2m
2014-07-11 00:20:29,828 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.4m/271967200, currentsize=96.8m/101526640 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 7751ms, sequenceid=168, compaction requested=false
2014-07-11 00:20:29,830 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 327.3m
2014-07-11 00:20:29,898 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=171, memsize=46.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/22e7def2cb6a4339ac74a721e23708a3
2014-07-11 00:20:29,912 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/22e7def2cb6a4339ac74a721e23708a3 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/22e7def2cb6a4339ac74a721e23708a3
2014-07-11 00:20:29,985 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/22e7def2cb6a4339ac74a721e23708a3, entries=169450, sequenceid=171, filesize=12.1m
2014-07-11 00:20:29,992 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.2m/274916160, currentsize=82.2m/86163680 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 5924ms, sequenceid=171, compaction requested=false
2014-07-11 00:20:29,992 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 325.7m
2014-07-11 00:20:30,801 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:31,006 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:31,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1144 synced till here 1130
2014-07-11 00:20:31,259 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063229119 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063231007
2014-07-11 00:20:31,421 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:33,835 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=220, memsize=46.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/dc85969136564cd6ae7ec8fc6871e819
2014-07-11 00:20:33,846 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/dc85969136564cd6ae7ec8fc6871e819 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/dc85969136564cd6ae7ec8fc6871e819
2014-07-11 00:20:33,859 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/dc85969136564cd6ae7ec8fc6871e819, entries=169460, sequenceid=220, filesize=12.1m
2014-07-11 00:20:33,859 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~338.3m/354754240, currentsize=34.0m/35667520 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 4029ms, sequenceid=220, compaction requested=false
2014-07-11 00:20:33,860 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 373.3m
2014-07-11 00:20:33,975 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=220, memsize=46.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/633e7787fa754611aff27543779186b6
2014-07-11 00:20:33,986 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/633e7787fa754611aff27543779186b6 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/633e7787fa754611aff27543779186b6
2014-07-11 00:20:33,995 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/633e7787fa754611aff27543779186b6, entries=168560, sequenceid=220, filesize=12.0m
2014-07-11 00:20:33,995 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~336.5m/352845840, currentsize=33.9m/35510000 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 4003ms, sequenceid=220, compaction requested=false
2014-07-11 00:20:34,141 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:36,750 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=242, memsize=46.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/02f32495b1dc4c7daff0803939ed75d6
2014-07-11 00:20:36,765 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/02f32495b1dc4c7daff0803939ed75d6 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/02f32495b1dc4c7daff0803939ed75d6
2014-07-11 00:20:36,787 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/02f32495b1dc4c7daff0803939ed75d6, entries=169880, sequenceid=242, filesize=12.1m
2014-07-11 00:20:36,787 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~373.3m/391399680, currentsize=0.0/0 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 2927ms, sequenceid=242, compaction requested=false
2014-07-11 00:20:39,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:39,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063231007 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063239013
2014-07-11 00:20:39,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405062840925
2014-07-11 00:20:39,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063205872
2014-07-11 00:20:39,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063208374
2014-07-11 00:20:39,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063211174
2014-07-11 00:20:39,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063214092
2014-07-11 00:20:39,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063216595
2014-07-11 00:20:41,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:41,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1296 synced till here 1288
2014-07-11 00:20:41,983 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063239013 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063241653
2014-07-11 00:20:43,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:43,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1383 synced till here 1371
2014-07-11 00:20:43,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063241653 with entries=87, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063243791
2014-07-11 00:20:45,440 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:45,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063243791 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063245441
2014-07-11 00:20:47,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:47,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1530 synced till here 1529
2014-07-11 00:20:47,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063245441 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063247259
2014-07-11 00:20:49,312 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:49,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1604 synced till here 1603
2014-07-11 00:20:49,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063247259 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063249312
2014-07-11 00:20:50,297 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:20:50,297 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 258.8m
2014-07-11 00:20:50,678 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:51,784 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:20:51,784 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 256.2m
2014-07-11 00:20:52,076 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:52,105 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1681 synced till here 1678
2014-07-11 00:20:52,147 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:20:52,147 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063249312 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063252076
2014-07-11 00:20:54,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:54,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1766 synced till here 1752
2014-07-11 00:20:55,326 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063252076 with entries=85, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063254974
2014-07-11 00:20:58,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:20:58,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1870 synced till here 1846
2014-07-11 00:20:59,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063254974 with entries=104, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063258517
2014-07-11 00:20:59,605 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=335, memsize=136.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/aab78bfa66a64044ad399589dcca4e81
2014-07-11 00:20:59,689 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/aab78bfa66a64044ad399589dcca4e81 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/aab78bfa66a64044ad399589dcca4e81
2014-07-11 00:20:59,820 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/aab78bfa66a64044ad399589dcca4e81, entries=497680, sequenceid=335, filesize=35.5m
2014-07-11 00:20:59,821 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.8m/271413760, currentsize=87.8m/92071680 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 9524ms, sequenceid=335, compaction requested=false
2014-07-11 00:21:01,361 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:21:01,369 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 256.2m
2014-07-11 00:21:02,592 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=340, memsize=144.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/097c92abbe4743d4b7ecd7e11274d297
2014-07-11 00:21:02,773 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/097c92abbe4743d4b7ecd7e11274d297 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/097c92abbe4743d4b7ecd7e11274d297
2014-07-11 00:21:02,816 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/097c92abbe4743d4b7ecd7e11274d297, entries=525950, sequenceid=340, filesize=37.5m
2014-07-11 00:21:02,817 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.9m/273532720, currentsize=91.9m/96390560 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 11033ms, sequenceid=340, compaction requested=false
2014-07-11 00:21:02,989 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:03,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1974 synced till here 1944
2014-07-11 00:21:03,321 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:03,524 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:21:03,524 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 256.8m
2014-07-11 00:21:03,705 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063258517 with entries=104, filesize=89.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063262990
2014-07-11 00:21:03,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063219481
2014-07-11 00:21:03,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063222557
2014-07-11 00:21:03,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063224868
2014-07-11 00:21:03,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063226816
2014-07-11 00:21:04,437 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:06,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:06,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2071 synced till here 2054
2014-07-11 00:21:06,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063262990 with entries=97, filesize=83.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063266240
2014-07-11 00:21:08,289 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:21:09,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:09,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2188 synced till here 2165
2014-07-11 00:21:09,446 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063266240 with entries=117, filesize=100.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063269064
2014-07-11 00:21:10,777 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:10,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2276 synced till here 2261
2014-07-11 00:21:11,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063269064 with entries=88, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063270777
2014-07-11 00:21:13,025 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:13,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2354 synced till here 2349
2014-07-11 00:21:13,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063270777 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063273026
2014-07-11 00:21:14,844 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:15,889 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:21:16,596 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:21:17,014 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=398, memsize=170.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/226d14df7ae44f0db64b5eafd4a6ae9c
2014-07-11 00:21:17,014 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=391, memsize=170.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/48ebdec7872642b6bfdff0bcef5a3516
2014-07-11 00:21:17,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2517 synced till here 2512
2014-07-11 00:21:17,033 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/226d14df7ae44f0db64b5eafd4a6ae9c as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/226d14df7ae44f0db64b5eafd4a6ae9c
2014-07-11 00:21:17,034 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/48ebdec7872642b6bfdff0bcef5a3516 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/48ebdec7872642b6bfdff0bcef5a3516
2014-07-11 00:21:17,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063273026 with entries=163, filesize=140.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063274845
2014-07-11 00:21:17,058 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/226d14df7ae44f0db64b5eafd4a6ae9c, entries=620310, sequenceid=398, filesize=44.2m
2014-07-11 00:21:17,059 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/48ebdec7872642b6bfdff0bcef5a3516, entries=621910, sequenceid=391, filesize=44.4m
2014-07-11 00:21:17,059 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~273.7m/286959440, currentsize=165.4m/173398880 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 13535ms, sequenceid=398, compaction requested=false
2014-07-11 00:21:17,059 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.0m/276867440, currentsize=181.7m/190486720 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 15690ms, sequenceid=391, compaction requested=false
2014-07-11 00:21:17,059 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 400.3m
2014-07-11 00:21:17,059 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 273.2m
2014-07-11 00:21:17,870 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:18,032 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:18,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:18,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2590 synced till here 2589
2014-07-11 00:21:18,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063274845 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063278562
2014-07-11 00:21:18,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063229119
2014-07-11 00:21:21,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:21,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2679 synced till here 2671
2014-07-11 00:21:21,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063278562 with entries=89, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063281147
2014-07-11 00:21:23,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:23,607 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:21:23,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2780 synced till here 2757
2014-07-11 00:21:24,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063281147 with entries=101, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063283470
2014-07-11 00:21:26,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:26,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2890 synced till here 2861
2014-07-11 00:21:26,705 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:21:27,071 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063283470 with entries=110, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063286135
2014-07-11 00:21:29,442 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:29,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3011 synced till here 2987
2014-07-11 00:21:30,095 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=512, memsize=120.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4dde38687622401eb20a34a1343be0f7
2014-07-11 00:21:30,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063286135 with entries=121, filesize=104.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063289443
2014-07-11 00:21:30,128 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4dde38687622401eb20a34a1343be0f7 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4dde38687622401eb20a34a1343be0f7
2014-07-11 00:21:30,206 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4dde38687622401eb20a34a1343be0f7, entries=437160, sequenceid=512, filesize=31.2m
2014-07-11 00:21:30,207 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~274.8m/288117200, currentsize=178.5m/187203600 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 13148ms, sequenceid=512, compaction requested=true
2014-07-11 00:21:30,209 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 00:21:30,209 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 82617461 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 00:21:30,209 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: cee2ff08fd3c0bc377dccf8be24cbd0f - family: Initiating major compaction
2014-07-11 00:21:30,209 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:21:30,210 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp, totalSize=78.8m
2014-07-11 00:21:30,210 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 00:21:30,211 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 426.3m
2014-07-11 00:21:30,213 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4005697f5fd74f238997b1d38e145080, keycount=17076, bloomtype=ROW, size=12.2m, encoding=NONE, seqNum=168, earliestPutTs=1405063218287
2014-07-11 00:21:30,213 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/aab78bfa66a64044ad399589dcca4e81, keycount=49768, bloomtype=ROW, size=35.5m, encoding=NONE, seqNum=335, earliestPutTs=1405063230376
2014-07-11 00:21:30,213 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4dde38687622401eb20a34a1343be0f7, keycount=43716, bloomtype=ROW, size=31.2m, encoding=NONE, seqNum=512, earliestPutTs=1405063250404
2014-07-11 00:21:30,231 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:32,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:32,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3119 synced till here 3111
2014-07-11 00:21:32,658 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:32,681 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 00:21:32,681 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 00:21:32,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063289443 with entries=108, filesize=93.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063292206
2014-07-11 00:21:35,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:35,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3238 synced till here 3219
2014-07-11 00:21:35,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063292206 with entries=119, filesize=101.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063295030
2014-07-11 00:21:36,145 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:21:36,839 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:36,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3326 synced till here 3312
2014-07-11 00:21:37,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063295030 with entries=88, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063296839
2014-07-11 00:21:38,937 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=505, memsize=209.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/7604fba29ff54c53ad3f3831d7da2225
2014-07-11 00:21:38,960 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/7604fba29ff54c53ad3f3831d7da2225 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/7604fba29ff54c53ad3f3831d7da2225
2014-07-11 00:21:39,623 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/7604fba29ff54c53ad3f3831d7da2225, entries=761510, sequenceid=505, filesize=54.3m
2014-07-11 00:21:39,623 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~405.0m/424621280, currentsize=254.2m/266591280 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 22564ms, sequenceid=505, compaction requested=false
2014-07-11 00:21:39,625 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 447.1m
2014-07-11 00:21:39,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:39,680 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:21:40,532 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:41,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3490 synced till here 3484
2014-07-11 00:21:41,083 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063296839 with entries=164, filesize=140.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063299679
2014-07-11 00:21:41,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063231007
2014-07-11 00:21:41,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063239013
2014-07-11 00:21:41,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063241653
2014-07-11 00:21:41,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063243791
2014-07-11 00:21:41,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063245441
2014-07-11 00:21:41,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063247259
2014-07-11 00:21:43,207 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:43,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3563 synced till here 3562
2014-07-11 00:21:43,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063299679 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063303207
2014-07-11 00:21:45,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:45,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3641 synced till here 3635
2014-07-11 00:21:45,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063303207 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063305294
2014-07-11 00:21:47,149 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=626, memsize=167.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/f002e41910cd409e98c1a333e8c943a6
2014-07-11 00:21:47,272 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/f002e41910cd409e98c1a333e8c943a6 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/f002e41910cd409e98c1a333e8c943a6
2014-07-11 00:21:47,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:47,291 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/f002e41910cd409e98c1a333e8c943a6, entries=608840, sequenceid=626, filesize=43.4m
2014-07-11 00:21:47,291 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~445.6m/467223440, currentsize=193.5m/202949280 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 17080ms, sequenceid=626, compaction requested=true
2014-07-11 00:21:47,292 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 00:21:47,292 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 532.2m
2014-07-11 00:21:47,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3717 synced till here 3713
2014-07-11 00:21:47,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063305294 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063307275
2014-07-11 00:21:47,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063249312
2014-07-11 00:21:47,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063252076
2014-07-11 00:21:47,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063254974
2014-07-11 00:21:48,988 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:49,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:49,148 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3800 synced till here 3790
2014-07-11 00:21:49,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063307275 with entries=83, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063309128
2014-07-11 00:21:50,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:50,949 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3880 synced till here 3872
2014-07-11 00:21:51,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063309128 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063310915
2014-07-11 00:21:52,305 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:21:53,246 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:53,270 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3956 synced till here 3952
2014-07-11 00:21:53,284 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/207434236a904fba8048dbfc2b931ea2 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/207434236a904fba8048dbfc2b931ea2
2014-07-11 00:21:53,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063310915 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063313246
2014-07-11 00:21:53,647 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:21:53,668 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4005697f5fd74f238997b1d38e145080, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4005697f5fd74f238997b1d38e145080
2014-07-11 00:21:53,671 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/aab78bfa66a64044ad399589dcca4e81, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/aab78bfa66a64044ad399589dcca4e81
2014-07-11 00:21:53,673 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4dde38687622401eb20a34a1343be0f7, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4dde38687622401eb20a34a1343be0f7
2014-07-11 00:21:53,674 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. into 207434236a904fba8048dbfc2b931ea2(size=58.9m), total size for store is 58.9m. This selection was in queue for 0sec, and took 23sec to execute.
2014-07-11 00:21:53,677 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., storeName=family, fileCount=3, fileSize=78.8m, priority=17, time=17197636274099; duration=23sec
2014-07-11 00:21:53,678 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 00:21:53,678 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 00:21:53,678 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 97466345 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 00:21:53,678 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: 600e47c8102c939894f95b55fbbe3a1e - family: Initiating major compaction
2014-07-11 00:21:53,678 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:21:53,679 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp, totalSize=93.0m
2014-07-11 00:21:53,679 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/22e7def2cb6a4339ac74a721e23708a3, keycount=16945, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=171, earliestPutTs=1405063219142
2014-07-11 00:21:53,679 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/097c92abbe4743d4b7ecd7e11274d297, keycount=52595, bloomtype=ROW, size=37.5m, encoding=NONE, seqNum=340, earliestPutTs=1405063231017
2014-07-11 00:21:53,679 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/f002e41910cd409e98c1a333e8c943a6, keycount=60884, bloomtype=ROW, size=43.4m, encoding=NONE, seqNum=626, earliestPutTs=1405063252079
2014-07-11 00:21:53,698 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:55,109 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=689, memsize=157.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/e79d1228810a44439f61558f3faf215c
2014-07-11 00:21:55,132 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/e79d1228810a44439f61558f3faf215c as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/e79d1228810a44439f61558f3faf215c
2014-07-11 00:21:55,151 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/e79d1228810a44439f61558f3faf215c, entries=574330, sequenceid=689, filesize=40.9m
2014-07-11 00:21:55,152 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~460.7m/483095440, currentsize=185.9m/194976240 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 15527ms, sequenceid=689, compaction requested=true
2014-07-11 00:21:55,152 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 00:21:55,152 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 469.0m
2014-07-11 00:21:55,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:55,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4031 synced till here 4029
2014-07-11 00:21:55,302 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063313246 with entries=75, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063315155
2014-07-11 00:21:55,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063258517
2014-07-11 00:21:56,113 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:21:57,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:21:57,351 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4106 synced till here 4103
2014-07-11 00:21:57,407 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063315155 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063317279
2014-07-11 00:21:59,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:00,144 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4183 synced till here 4179
2014-07-11 00:22:00,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063317279 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063319999
2014-07-11 00:22:04,202 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:04,211 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:22:04,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4301 synced till here 4283
2014-07-11 00:22:05,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063319999 with entries=118, filesize=100.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063324204
2014-07-11 00:22:24,322 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 22856ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 00:22:24,322 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 22856ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 00:22:24,324 WARN  [regionserver60020] util.Sleeper: We slept 18136ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 00:22:24,371 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16544ms
GC pool 'ParNew' had collection(s): count=3 time=256ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=16623ms
2014-07-11 00:22:24,605 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:24,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4416 synced till here 4392
2014-07-11 00:22:24,767 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22827,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063321783,"queuetimems":0,"class":"HRegionServer","responsesize":20032,"method":"Multi"}
2014-07-11 00:22:24,768 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1297 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:24,769 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,184 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22682,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322502,"queuetimems":0,"class":"HRegionServer","responsesize":19783,"method":"Multi"}
2014-07-11 00:22:25,185 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1286 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,185 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,186 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322066,"queuetimems":0,"class":"HRegionServer","responsesize":19365,"method":"Multi"}
2014-07-11 00:22:25,187 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1291 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,187 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,188 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322032,"queuetimems":0,"class":"HRegionServer","responsesize":19672,"method":"Multi"}
2014-07-11 00:22:25,188 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22926,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322260,"queuetimems":0,"class":"HRegionServer","responsesize":19565,"method":"Multi"}
2014-07-11 00:22:25,188 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1294 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,188 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,189 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1290 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,189 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,190 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22726,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322463,"queuetimems":2,"class":"HRegionServer","responsesize":19510,"method":"Multi"}
2014-07-11 00:22:25,190 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1287 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,190 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,191 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23658,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063321531,"queuetimems":1,"class":"HRegionServer","responsesize":19597,"method":"Multi"}
2014-07-11 00:22:25,191 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1298 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,191 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,228 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=748, memsize=181.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/5f29fca19f0540268efff76d9747b6d5
2014-07-11 00:22:25,245 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063324204 with entries=115, filesize=98.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063344607
2014-07-11 00:22:25,266 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/5f29fca19f0540268efff76d9747b6d5 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/5f29fca19f0540268efff76d9747b6d5
2014-07-11 00:22:25,325 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/5f29fca19f0540268efff76d9747b6d5, entries=660600, sequenceid=748, filesize=47.1m
2014-07-11 00:22:25,326 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~540.0m/566274560, currentsize=203.2m/213028080 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 38034ms, sequenceid=748, compaction requested=true
2014-07-11 00:22:25,327 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 00:22:25,327 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 559.4m
2014-07-11 00:22:25,463 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22462,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323000,"queuetimems":1,"class":"HRegionServer","responsesize":19352,"method":"Multi"}
2014-07-11 00:22:25,463 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322750,"queuetimems":1,"class":"HRegionServer","responsesize":19793,"method":"Multi"}
2014-07-11 00:22:25,463 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1279 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,463 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323832,"queuetimems":1,"class":"HRegionServer","responsesize":19565,"method":"Multi"}
2014-07-11 00:22:25,463 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,464 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1283 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,464 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,464 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1267 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,464 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,635 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323216,"queuetimems":1,"class":"HRegionServer","responsesize":19822,"method":"Multi"}
2014-07-11 00:22:25,636 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1277 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,636 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,674 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323403,"queuetimems":0,"class":"HRegionServer","responsesize":19577,"method":"Multi"}
2014-07-11 00:22:25,675 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1275 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,675 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,675 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22502,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323172,"queuetimems":1,"class":"HRegionServer","responsesize":19760,"method":"Multi"}
2014-07-11 00:22:25,675 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1278 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,675 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,677 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22044,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323632,"queuetimems":1,"class":"HRegionServer","responsesize":19886,"method":"Multi"}
2014-07-11 00:22:25,677 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1270 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,677 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,677 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21993,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323683,"queuetimems":1,"class":"HRegionServer","responsesize":19927,"method":"Multi"}
2014-07-11 00:22:25,678 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324258,"queuetimems":0,"class":"HRegionServer","responsesize":19574,"method":"Multi"}
2014-07-11 00:22:25,678 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21805,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323873,"queuetimems":1,"class":"HRegionServer","responsesize":19765,"method":"Multi"}
2014-07-11 00:22:25,674 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21759,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323914,"queuetimems":0,"class":"HRegionServer","responsesize":19740,"method":"Multi"}
2014-07-11 00:22:25,679 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22314,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323364,"queuetimems":1,"class":"HRegionServer","responsesize":19811,"method":"Multi"}
2014-07-11 00:22:25,678 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1268 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,679 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1260 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22078,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063323598,"queuetimems":1,"class":"HRegionServer","responsesize":19655,"method":"Multi"}
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1276 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1272 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063322790,"queuetimems":0,"class":"HRegionServer","responsesize":20051,"method":"Multi"}
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1265 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,681 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,680 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,681 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1266 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,681 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,681 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1280 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,681 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,733 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21506,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324226,"queuetimems":0,"class":"HRegionServer","responsesize":19558,"method":"Multi"}
2014-07-11 00:22:25,734 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1264 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,734 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,773 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20905,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324868,"queuetimems":1,"class":"HRegionServer","responsesize":19565,"method":"Multi"}
2014-07-11 00:22:25,773 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325093,"queuetimems":1,"class":"HRegionServer","responsesize":19927,"method":"Multi"}
2014-07-11 00:22:25,774 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1335 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,774 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,774 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1332 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,774 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,775 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21325,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324449,"queuetimems":0,"class":"HRegionServer","responsesize":19740,"method":"Multi"}
2014-07-11 00:22:25,775 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1340 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,775 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,971 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324813,"queuetimems":1,"class":"HRegionServer","responsesize":19558,"method":"Multi"}
2014-07-11 00:22:25,971 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063324652,"queuetimems":0,"class":"HRegionServer","responsesize":19765,"method":"Multi"}
2014-07-11 00:22:25,972 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1338 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,972 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:25,972 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1339 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:25,972 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:26,039 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20439,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325599,"queuetimems":0,"class":"HRegionServer","responsesize":19822,"method":"Multi"}
2014-07-11 00:22:26,039 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1321 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,039 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,543 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4504 synced till here 4490
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20502,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326141,"queuetimems":6,"class":"HRegionServer","responsesize":19352,"method":"Multi"}
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325486,"queuetimems":0,"class":"HRegionServer","responsesize":19811,"method":"Multi"}
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21197,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325446,"queuetimems":0,"class":"HRegionServer","responsesize":19655,"method":"Multi"}
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325141,"queuetimems":1,"class":"HRegionServer","responsesize":19886,"method":"Multi"}
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20679,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325965,"queuetimems":1,"class":"HRegionServer","responsesize":19760,"method":"Multi"}
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1313 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326303,"queuetimems":0,"class":"HRegionServer","responsesize":19365,"method":"Multi"}
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326189,"queuetimems":1,"class":"HRegionServer","responsesize":20051,"method":"Multi"}
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1324 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21005,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325638,"queuetimems":1,"class":"HRegionServer","responsesize":20032,"method":"Multi"}
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326441,"queuetimems":0,"class":"HRegionServer","responsesize":19672,"method":"Multi"}
2014-07-11 00:22:26,646 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:26,644 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325302,"queuetimems":0,"class":"HRegionServer","responsesize":19577,"method":"Multi"}
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1311 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,648 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1326 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,645 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063325769,"queuetimems":0,"class":"HRegionServer","responsesize":19597,"method":"Multi"}
2014-07-11 00:22:26,648 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1310 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,648 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,648 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1318 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,648 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1312 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1316 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,649 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1329 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,650 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,650 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1325 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,650 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,650 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1317 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,650 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063344607 with entries=88, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063346037
2014-07-11 00:22:26,653 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063262990
2014-07-11 00:22:26,653 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063266240
2014-07-11 00:22:26,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063269064
2014-07-11 00:22:26,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063270777
2014-07-11 00:22:26,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063273026
2014-07-11 00:22:26,732 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063327218,"queuetimems":1,"class":"HRegionServer","responsesize":19927,"method":"Multi"}
2014-07-11 00:22:26,732 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326479,"queuetimems":0,"class":"HRegionServer","responsesize":19565,"method":"Multi"}
2014-07-11 00:22:26,732 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20109,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326622,"queuetimems":1,"class":"HRegionServer","responsesize":19510,"method":"Multi"}
2014-07-11 00:22:26,732 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1367 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,732 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,733 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1308 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,733 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,733 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1309 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,733 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,757 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326817,"queuetimems":0,"class":"HRegionServer","responsesize":19783,"method":"Multi"}
2014-07-11 00:22:26,757 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1304 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,757 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,763 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19982,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326780,"queuetimems":125,"class":"HRegionServer","responsesize":19793,"method":"Multi"}
2014-07-11 00:22:26,763 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1305 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,763 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19765,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063327023,"queuetimems":0,"class":"HRegionServer","responsesize":19765,"method":"Multi"}
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19728,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063327061,"queuetimems":0,"class":"HRegionServer","responsesize":19740,"method":"Multi"}
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326856,"queuetimems":0,"class":"HRegionServer","responsesize":19672,"method":"Multi"}
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063326986,"queuetimems":0,"class":"HRegionServer","responsesize":19565,"method":"Multi"}
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1369 service: ClientService methodName: Multi size: 3.5m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19327,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063327462,"queuetimems":37,"class":"HRegionServer","responsesize":19558,"method":"Multi"}
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1371 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,789 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1368 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1365 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1370 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,790 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:26,795 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19538,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44834","starttimems":1405063327256,"queuetimems":0,"class":"HRegionServer","responsesize":19365,"method":"Multi"}
2014-07-11 00:22:26,795 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1366 service: ClientService methodName: Multi size: 3.4m connection: 9.1.143.53:44834: output error
2014-07-11 00:22:26,795 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-11 00:22:27,996 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=815, memsize=159.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5acc5351502442a18347f6625a078bd2
2014-07-11 00:22:28,012 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5acc5351502442a18347f6625a078bd2 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5acc5351502442a18347f6625a078bd2
2014-07-11 00:22:28,031 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5acc5351502442a18347f6625a078bd2, entries=578830, sequenceid=815, filesize=41.3m
2014-07-11 00:22:28,032 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~470.6m/493422880, currentsize=148.0m/155150080 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 32880ms, sequenceid=815, compaction requested=false
2014-07-11 00:22:28,032 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 440.4m
2014-07-11 00:22:28,431 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:29,578 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:22:30,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:30,366 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4578 synced till here 4575
2014-07-11 00:22:30,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063346037 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063350339
2014-07-11 00:22:32,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:32,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063350339 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063352073
2014-07-11 00:22:33,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:33,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4724 synced till here 4721
2014-07-11 00:22:33,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063352073 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063353650
2014-07-11 00:22:34,323 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/cb7ecaa7cb4442948db523bbdf812e4e as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/cb7ecaa7cb4442948db523bbdf812e4e
2014-07-11 00:22:34,379 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:22:34,391 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/22e7def2cb6a4339ac74a721e23708a3, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/22e7def2cb6a4339ac74a721e23708a3
2014-07-11 00:22:34,395 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/097c92abbe4743d4b7ecd7e11274d297, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/097c92abbe4743d4b7ecd7e11274d297
2014-07-11 00:22:34,399 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/f002e41910cd409e98c1a333e8c943a6, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/f002e41910cd409e98c1a333e8c943a6
2014-07-11 00:22:34,399 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. into cb7ecaa7cb4442948db523bbdf812e4e(size=73.2m), total size for store is 73.2m. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-11 00:22:34,400 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., storeName=family, fileCount=3, fileSize=93.0m, priority=17, time=17221105432097; duration=40sec
2014-07-11 00:22:34,400 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 00:22:34,400 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 00:22:34,400 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 102086588 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 00:22:34,400 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: a814c9f2554f95576d7e3f7dd25bb826 - family: Initiating major compaction
2014-07-11 00:22:34,400 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:22:34,401 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp, totalSize=97.4m
2014-07-11 00:22:34,401 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/dc85969136564cd6ae7ec8fc6871e819, keycount=16946, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=220, earliestPutTs=1405063225418
2014-07-11 00:22:34,401 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/48ebdec7872642b6bfdff0bcef5a3516, keycount=62191, bloomtype=ROW, size=44.4m, encoding=NONE, seqNum=391, earliestPutTs=1405063231458
2014-07-11 00:22:34,401 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/e79d1228810a44439f61558f3faf215c, keycount=57433, bloomtype=ROW, size=40.9m, encoding=NONE, seqNum=689, earliestPutTs=1405063271488
2014-07-11 00:22:34,426 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:34,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:34,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063353650 with entries=73, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063354489
2014-07-11 00:22:35,895 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:22:35,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:36,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4871 synced till here 4869
2014-07-11 00:22:36,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063354489 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063355999
2014-07-11 00:22:37,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:37,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4948 synced till here 4944
2014-07-11 00:22:37,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063355999 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063357322
2014-07-11 00:22:38,669 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:38,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5023 synced till here 5019
2014-07-11 00:22:38,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063357322 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063358670
2014-07-11 00:22:38,937 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=880, memsize=214.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/92e43021dc274081a39ec23834533049
2014-07-11 00:22:38,951 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/92e43021dc274081a39ec23834533049 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/92e43021dc274081a39ec23834533049
2014-07-11 00:22:38,965 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/92e43021dc274081a39ec23834533049, entries=779600, sequenceid=880, filesize=55.6m
2014-07-11 00:22:38,965 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~580.8m/609056800, currentsize=201.8m/211607520 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 13638ms, sequenceid=880, compaction requested=true
2014-07-11 00:22:38,966 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 00:22:38,966 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 501.6m
2014-07-11 00:22:38,990 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=909, memsize=175.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/eccd0da660524f949214514e466c10b3
2014-07-11 00:22:39,612 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/eccd0da660524f949214514e466c10b3 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/eccd0da660524f949214514e466c10b3
2014-07-11 00:22:39,627 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/eccd0da660524f949214514e466c10b3, entries=639950, sequenceid=909, filesize=45.7m
2014-07-11 00:22:39,628 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~440.4m/461743120, currentsize=167.7m/175804560 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 11596ms, sequenceid=909, compaction requested=false
2014-07-11 00:22:39,628 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 408.2m
2014-07-11 00:22:40,025 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:40,048 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5101 synced till here 5093
2014-07-11 00:22:40,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063358670 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063360026
2014-07-11 00:22:40,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063274845
2014-07-11 00:22:40,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063278562
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063281147
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063283470
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063286135
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063289443
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063292206
2014-07-11 00:22:40,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063295030
2014-07-11 00:22:40,166 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:40,178 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:41,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:41,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5186 synced till here 5184
2014-07-11 00:22:41,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063360026 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063361482
2014-07-11 00:22:41,882 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:22:42,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:43,016 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5265 synced till here 5260
2014-07-11 00:22:43,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063361482 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063362937
2014-07-11 00:22:44,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:44,351 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5342 synced till here 5339
2014-07-11 00:22:44,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063362937 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063364319
2014-07-11 00:22:44,469 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:22:45,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:45,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5418 synced till here 5412
2014-07-11 00:22:45,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063364319 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063365819
2014-07-11 00:22:47,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:49,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5566 synced till here 5561
2014-07-11 00:22:49,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063365819 with entries=148, filesize=127.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063367684
2014-07-11 00:22:49,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:49,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5641 synced till here 5640
2014-07-11 00:22:49,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063367684 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063369878
2014-07-11 00:22:51,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:51,511 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5720 synced till here 5715
2014-07-11 00:22:51,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063369878 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063371483
2014-07-11 00:22:53,065 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:53,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5801 synced till here 5793
2014-07-11 00:22:53,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063371483 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063373066
2014-07-11 00:22:54,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:54,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5876 synced till here 5875
2014-07-11 00:22:54,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063373066 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063374751
2014-07-11 00:22:55,512 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1016, memsize=231.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f27af3fa260e4922aa1086f8429cd98d
2014-07-11 00:22:55,533 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f27af3fa260e4922aa1086f8429cd98d as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f27af3fa260e4922aa1086f8429cd98d
2014-07-11 00:22:55,551 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f27af3fa260e4922aa1086f8429cd98d, entries=841730, sequenceid=1016, filesize=60.0m
2014-07-11 00:22:55,552 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~412.9m/432930800, currentsize=260.2m/272789520 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 15924ms, sequenceid=1016, compaction requested=true
2014-07-11 00:22:55,552 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 00:22:55,552 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 579.2m
2014-07-11 00:22:56,199 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:22:56,484 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/1ad113eabac841508df3fa066cf2b986 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1ad113eabac841508df3fa066cf2b986
2014-07-11 00:22:56,586 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:56,626 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:22:56,638 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/dc85969136564cd6ae7ec8fc6871e819, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/dc85969136564cd6ae7ec8fc6871e819
2014-07-11 00:22:56,642 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/48ebdec7872642b6bfdff0bcef5a3516, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/48ebdec7872642b6bfdff0bcef5a3516
2014-07-11 00:22:56,647 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/e79d1228810a44439f61558f3faf215c, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/e79d1228810a44439f61558f3faf215c
2014-07-11 00:22:56,647 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. into 1ad113eabac841508df3fa066cf2b986(size=73.1m), total size for store is 73.1m. This selection was in queue for 0sec, and took 22sec to execute.
2014-07-11 00:22:56,647 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., storeName=family, fileCount=3, fileSize=97.4m, priority=17, time=17261827557112; duration=22sec
2014-07-11 00:22:56,647 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 00:22:56,648 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-11 00:22:56,648 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 171276518 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-11 00:22:56,648 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: a575cf61a8e56ddc4885c72863b830c2 - family: Initiating major compaction
2014-07-11 00:22:56,648 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:22:56,648 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp, totalSize=163.3m
2014-07-11 00:22:56,649 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/633e7787fa754611aff27543779186b6, keycount=16856, bloomtype=ROW, size=12.0m, encoding=NONE, seqNum=220, earliestPutTs=1405063226402
2014-07-11 00:22:56,649 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/226d14df7ae44f0db64b5eafd4a6ae9c, keycount=62031, bloomtype=ROW, size=44.2m, encoding=NONE, seqNum=398, earliestPutTs=1405063231664
2014-07-11 00:22:56,649 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/5f29fca19f0540268efff76d9747b6d5, keycount=66060, bloomtype=ROW, size=47.1m, encoding=NONE, seqNum=748, earliestPutTs=1405063271600
2014-07-11 00:22:56,649 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f27af3fa260e4922aa1086f8429cd98d, keycount=84173, bloomtype=ROW, size=60.0m, encoding=NONE, seqNum=1016, earliestPutTs=1405063310078
2014-07-11 00:22:56,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:56,691 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:22:56,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5959 synced till here 5950
2014-07-11 00:22:56,768 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063374751 with entries=83, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063376661
2014-07-11 00:22:58,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:22:58,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6049 synced till here 6034
2014-07-11 00:22:58,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063376661 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063378407
2014-07-11 00:22:59,725 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1015, memsize=270.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/6d51cbcc1c7a4e1499f3fba8b075a8a6
2014-07-11 00:22:59,744 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/6d51cbcc1c7a4e1499f3fba8b075a8a6 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/6d51cbcc1c7a4e1499f3fba8b075a8a6
2014-07-11 00:22:59,758 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/6d51cbcc1c7a4e1499f3fba8b075a8a6, entries=984160, sequenceid=1015, filesize=70.2m
2014-07-11 00:22:59,758 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~504.7m/529179120, currentsize=315.3m/330658320 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 20792ms, sequenceid=1015, compaction requested=false
2014-07-11 00:22:59,759 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 512.4m
2014-07-11 00:22:59,810 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:23:00,207 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:00,225 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:00,251 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6125 synced till here 6121
2014-07-11 00:23:00,466 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063378407 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063380208
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063296839
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063299679
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063303207
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063305294
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063307275
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063309128
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063310915
2014-07-11 00:23:00,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063313246
2014-07-11 00:23:01,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:03,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063380208 with entries=102, filesize=87.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063381797
2014-07-11 00:23:04,314 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:05,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6316 synced till here 6303
2014-07-11 00:23:05,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063381797 with entries=89, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063384315
2014-07-11 00:23:05,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:05,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6395 synced till here 6384
2014-07-11 00:23:06,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063384315 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063385848
2014-07-11 00:23:07,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:08,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6485 synced till here 6470
2014-07-11 00:23:08,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063385848 with entries=90, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063387717
2014-07-11 00:23:10,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:10,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6588 synced till here 6564
2014-07-11 00:23:10,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063387717 with entries=103, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063390556
2014-07-11 00:23:12,555 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:12,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6686 synced till here 6668
2014-07-11 00:23:12,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063390556 with entries=98, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063392556
2014-07-11 00:23:14,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:14,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6787 synced till here 6766
2014-07-11 00:23:14,771 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063392556 with entries=101, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063394565
2014-07-11 00:23:16,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:16,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6879 synced till here 6865
2014-07-11 00:23:16,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063394565 with entries=92, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063396471
2014-07-11 00:23:17,709 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1190, memsize=281.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/deb47dd47f3b4161bd16c25813b681a5
2014-07-11 00:23:17,734 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/deb47dd47f3b4161bd16c25813b681a5 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/deb47dd47f3b4161bd16c25813b681a5
2014-07-11 00:23:17,748 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/deb47dd47f3b4161bd16c25813b681a5, entries=1025840, sequenceid=1190, filesize=73.1m
2014-07-11 00:23:17,748 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~580.8m/609040480, currentsize=315.2m/330463280 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 22196ms, sequenceid=1190, compaction requested=true
2014-07-11 00:23:17,749 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 00:23:17,749 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 750.4m
2014-07-11 00:23:17,761 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:23:18,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:18,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6960 synced till here 6952
2014-07-11 00:23:18,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063396471 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063398014
2014-07-11 00:23:18,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063315155
2014-07-11 00:23:18,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063317279
2014-07-11 00:23:18,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063319999
2014-07-11 00:23:18,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063324204
2014-07-11 00:23:18,412 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:19,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:20,609 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1215, memsize=273.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/78c90eb324424cceac148d3664ebfa2c
2014-07-11 00:23:20,643 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/78c90eb324424cceac148d3664ebfa2c as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/78c90eb324424cceac148d3664ebfa2c
2014-07-11 00:23:20,766 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/78c90eb324424cceac148d3664ebfa2c, entries=996110, sequenceid=1215, filesize=71.0m
2014-07-11 00:23:20,767 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~518.5m/543642960, currentsize=325.8m/341623600 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 21008ms, sequenceid=1215, compaction requested=true
2014-07-11 00:23:20,767 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-11 00:23:20,768 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 639.7m
2014-07-11 00:23:20,791 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:23:20,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7123 synced till here 7116
2014-07-11 00:23:21,311 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:21,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063398014 with entries=163, filesize=140.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063399390
2014-07-11 00:23:21,566 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063344607
2014-07-11 00:23:23,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:23,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7210 synced till here 7194
2014-07-11 00:23:23,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063399390 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063403221
2014-07-11 00:23:26,157 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2297ms
GC pool 'ParNew' had collection(s): count=1 time=2441ms
2014-07-11 00:23:26,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:26,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7295 synced till here 7281
2014-07-11 00:23:26,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063403221 with entries=85, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063406654
2014-07-11 00:23:28,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:28,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7385 synced till here 7367
2014-07-11 00:23:29,131 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063406654 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063408887
2014-07-11 00:23:29,422 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=13026, hits=3, hitRatio=0.02%, , cachingAccesses=5, cachingHits=3, cachingHitsRatio=60.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-11 00:23:31,026 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1091ms
GC pool 'ParNew' had collection(s): count=1 time=1540ms
2014-07-11 00:23:31,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:31,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7468 synced till here 7456
2014-07-11 00:23:31,664 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063408887 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063411388
2014-07-11 00:23:33,787 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1759ms
GC pool 'ParNew' had collection(s): count=1 time=1851ms
2014-07-11 00:23:34,355 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:34,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7561 synced till here 7543
2014-07-11 00:23:34,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063411388 with entries=93, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063414355
2014-07-11 00:23:36,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:36,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7656 synced till here 7638
2014-07-11 00:23:36,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063414355 with entries=95, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063416453
2014-07-11 00:23:38,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:38,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7750 synced till here 7734
2014-07-11 00:23:38,717 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063416453 with entries=94, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063418578
2014-07-11 00:23:39,974 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:39,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7829 synced till here 7823
2014-07-11 00:23:40,084 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063418578 with entries=79, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063419974
2014-07-11 00:23:41,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:41,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7901 synced till here 7900
2014-07-11 00:23:41,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063419974 with entries=72, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063421702
2014-07-11 00:23:42,017 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/307b4d4bfec945a4916fa8daf240f68d as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/307b4d4bfec945a4916fa8daf240f68d
2014-07-11 00:23:42,029 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:23:42,036 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/633e7787fa754611aff27543779186b6, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/633e7787fa754611aff27543779186b6
2014-07-11 00:23:42,039 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/226d14df7ae44f0db64b5eafd4a6ae9c, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/226d14df7ae44f0db64b5eafd4a6ae9c
2014-07-11 00:23:42,042 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/5f29fca19f0540268efff76d9747b6d5, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/5f29fca19f0540268efff76d9747b6d5
2014-07-11 00:23:42,045 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f27af3fa260e4922aa1086f8429cd98d, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f27af3fa260e4922aa1086f8429cd98d
2014-07-11 00:23:42,046 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. into 307b4d4bfec945a4916fa8daf240f68d(size=130.9m), total size for store is 130.9m. This selection was in queue for 0sec, and took 45sec to execute.
2014-07-11 00:23:42,046 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., storeName=family, fileCount=4, fileSize=163.3m, priority=16, time=17284075155430; duration=45sec
2014-07-11 00:23:42,046 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-11 00:23:42,046 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-11 00:23:42,046 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 202286823 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-11 00:23:42,046 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: 7f41c69805823d0232eb4305b0b41c7e - family: Initiating major compaction
2014-07-11 00:23:42,047 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:23:42,047 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp, totalSize=192.9m
2014-07-11 00:23:42,047 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/02f32495b1dc4c7daff0803939ed75d6, keycount=16988, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=242, earliestPutTs=1405063230002
2014-07-11 00:23:42,047 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/7604fba29ff54c53ad3f3831d7da2225, keycount=76151, bloomtype=ROW, size=54.3m, encoding=NONE, seqNum=505, earliestPutTs=1405063238400
2014-07-11 00:23:42,047 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/92e43021dc274081a39ec23834533049, keycount=77960, bloomtype=ROW, size=55.6m, encoding=NONE, seqNum=880, earliestPutTs=1405063277259
2014-07-11 00:23:42,047 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/78c90eb324424cceac148d3664ebfa2c, keycount=99611, bloomtype=ROW, size=71.0m, encoding=NONE, seqNum=1215, earliestPutTs=1405063348819
2014-07-11 00:23:42,105 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:42,547 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:42,547 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,016 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,022 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,046 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,046 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,077 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,144 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,184 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,246 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,292 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,331 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,395 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,432 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,471 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,508 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,546 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,596 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,635 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,673 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,710 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,747 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,784 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,822 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,858 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,895 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,935 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:43,971 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,011 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,049 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,087 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,094 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1427, memsize=230.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/4344ece50c764275a27ba567417daf26
2014-07-11 00:23:44,105 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1394, memsize=325.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/0dc57bb144e34ae288ab494eef4a5812
2014-07-11 00:23:44,109 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/4344ece50c764275a27ba567417daf26 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/4344ece50c764275a27ba567417daf26
2014-07-11 00:23:44,123 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/0dc57bb144e34ae288ab494eef4a5812 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/0dc57bb144e34ae288ab494eef4a5812
2014-07-11 00:23:44,125 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,163 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,203 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:23:44,443 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/4344ece50c764275a27ba567417daf26, entries=838140, sequenceid=1427, filesize=59.7m
2014-07-11 00:23:44,444 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~639.7m/670787680, currentsize=257.8m/270354480 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 23675ms, sequenceid=1427, compaction requested=false
2014-07-11 00:23:44,444 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 242ms
2014-07-11 00:23:44,444 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 893.8m
2014-07-11 00:23:44,444 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,444 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 281ms
2014-07-11 00:23:44,445 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,445 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 320ms
2014-07-11 00:23:44,445 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,445 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 359ms
2014-07-11 00:23:44,445 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,446 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 397ms
2014-07-11 00:23:44,446 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,446 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 435ms
2014-07-11 00:23:44,446 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,449 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 478ms
2014-07-11 00:23:44,449 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,450 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 516ms
2014-07-11 00:23:44,450 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,451 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 556ms
2014-07-11 00:23:44,451 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,452 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 594ms
2014-07-11 00:23:44,452 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,453 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 630ms
2014-07-11 00:23:44,453 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,454 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 669ms
2014-07-11 00:23:44,454 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,454 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 707ms
2014-07-11 00:23:44,454 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,454 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 744ms
2014-07-11 00:23:44,454 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,455 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 782ms
2014-07-11 00:23:44,455 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,458 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 823ms
2014-07-11 00:23:44,458 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,460 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 863ms
2014-07-11 00:23:44,460 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,460 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 914ms
2014-07-11 00:23:44,461 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,461 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 953ms
2014-07-11 00:23:44,461 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,461 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 991ms
2014-07-11 00:23:44,461 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,461 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1029ms
2014-07-11 00:23:44,461 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,462 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1067ms
2014-07-11 00:23:44,462 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,463 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1131ms
2014-07-11 00:23:44,463 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,464 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1172ms
2014-07-11 00:23:44,464 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,466 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1219ms
2014-07-11 00:23:44,466 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,467 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1282ms
2014-07-11 00:23:44,467 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,472 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1329ms
2014-07-11 00:23:44,472 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,473 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1395ms
2014-07-11 00:23:44,473 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,473 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1427ms
2014-07-11 00:23:44,473 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,474 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1427ms
2014-07-11 00:23:44,474 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,480 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1457ms
2014-07-11 00:23:44,480 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,486 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1469ms
2014-07-11 00:23:44,486 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,487 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1940ms
2014-07-11 00:23:44,487 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,488 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1942ms
2014-07-11 00:23:44,488 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:23:44,644 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:23:44,721 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/0dc57bb144e34ae288ab494eef4a5812, entries=1186260, sequenceid=1394, filesize=84.5m
2014-07-11 00:23:44,721 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~750.4m/786875040, currentsize=310.9m/325953280 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 26972ms, sequenceid=1394, compaction requested=true
2014-07-11 00:23:44,721 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-11 00:23:44,722 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 629.1m
2014-07-11 00:23:44,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:46,157 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1138ms
GC pool 'ParNew' had collection(s): count=1 time=1241ms
2014-07-11 00:23:46,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7980 synced till here 7973
2014-07-11 00:23:46,231 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:23:46,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063421702 with entries=79, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063424870
2014-07-11 00:23:46,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063346037
2014-07-11 00:23:46,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063350339
2014-07-11 00:23:46,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063352073
2014-07-11 00:23:46,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063353650
2014-07-11 00:23:46,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063354489
2014-07-11 00:23:46,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063355999
2014-07-11 00:23:46,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063357322
2014-07-11 00:23:46,622 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:46,798 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:23:46,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:47,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8086 synced till here 8052
2014-07-11 00:23:48,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063424870 with entries=106, filesize=90.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063426998
2014-07-11 00:23:49,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:49,906 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8196 synced till here 8160
2014-07-11 00:23:50,242 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063426998 with entries=110, filesize=92.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063429865
2014-07-11 00:23:51,948 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:52,003 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8300 synced till here 8275
2014-07-11 00:23:52,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063429865 with entries=104, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063431948
2014-07-11 00:23:54,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:54,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8408 synced till here 8385
2014-07-11 00:23:55,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063431948 with entries=108, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063434131
2014-07-11 00:23:57,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:23:57,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8528 synced till here 8505
2014-07-11 00:23:58,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063434131 with entries=120, filesize=102.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063437783
2014-07-11 00:23:59,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:00,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8610 synced till here 8602
2014-07-11 00:24:00,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063437783 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063439958
2014-07-11 00:24:02,133 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:02,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8709 synced till here 8703
2014-07-11 00:24:02,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063439958 with entries=99, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063442133
2014-07-11 00:24:03,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:03,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8807 synced till here 8791
2014-07-11 00:24:04,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063442133 with entries=98, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063443827
2014-07-11 00:24:04,374 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,376 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,398 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,455 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,473 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,529 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,535 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,537 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,539 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,540 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,541 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,541 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,542 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,547 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,550 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,575 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,606 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,622 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,659 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,708 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,762 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,832 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,888 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:04,942 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:24:05,961 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1625, memsize=189.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5c58c7866d9b45bab4d7335398bd9d14
2014-07-11 00:24:05,977 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5c58c7866d9b45bab4d7335398bd9d14 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5c58c7866d9b45bab4d7335398bd9d14
2014-07-11 00:24:05,998 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5c58c7866d9b45bab4d7335398bd9d14, entries=689360, sequenceid=1625, filesize=49.2m
2014-07-11 00:24:05,998 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~672.7m/705347040, currentsize=244.5m/256426160 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 21276ms, sequenceid=1625, compaction requested=true
2014-07-11 00:24:05,998 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-11 00:24:05,998 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1057ms
2014-07-11 00:24:05,998 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:05,998 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1110ms
2014-07-11 00:24:05,998 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 858.3m
2014-07-11 00:24:05,999 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:05,999 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1168ms
2014-07-11 00:24:05,999 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:05,999 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1237ms
2014-07-11 00:24:05,999 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,000 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1292ms
2014-07-11 00:24:06,000 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,003 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1344ms
2014-07-11 00:24:06,003 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,004 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1381ms
2014-07-11 00:24:06,004 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,004 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1398ms
2014-07-11 00:24:06,004 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,005 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1430ms
2014-07-11 00:24:06,005 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,005 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1456ms
2014-07-11 00:24:06,005 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,005 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1458ms
2014-07-11 00:24:06,005 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,005 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1463ms
2014-07-11 00:24:06,005 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,005 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1464ms
2014-07-11 00:24:06,006 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,007 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1466ms
2014-07-11 00:24:06,015 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,015 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1475ms
2014-07-11 00:24:06,015 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,025 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1486ms
2014-07-11 00:24:06,025 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,029 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1492ms
2014-07-11 00:24:06,029 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,029 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1494ms
2014-07-11 00:24:06,029 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,029 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1501ms
2014-07-11 00:24:06,029 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,029 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1557ms
2014-07-11 00:24:06,029 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,029 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1574ms
2014-07-11 00:24:06,030 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,030 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1632ms
2014-07-11 00:24:06,030 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,030 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1654ms
2014-07-11 00:24:06,030 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,045 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1672ms
2014-07-11 00:24:06,045 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:24:06,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:06,673 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:24:06,708 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:07,093 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8933 synced till here 8918
2014-07-11 00:24:07,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063443827 with entries=126, filesize=108.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063446654
2014-07-11 00:24:08,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:08,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9007 synced till here 9005
2014-07-11 00:24:09,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063446654 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063448905
2014-07-11 00:24:10,450 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1594, memsize=272.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/1229755b8a954b6ab7f30cc301664634
2014-07-11 00:24:10,464 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/1229755b8a954b6ab7f30cc301664634 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1229755b8a954b6ab7f30cc301664634
2014-07-11 00:24:10,477 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1229755b8a954b6ab7f30cc301664634, entries=993110, sequenceid=1594, filesize=70.8m
2014-07-11 00:24:10,477 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~893.8m/937259040, currentsize=354.0m/371218480 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 26033ms, sequenceid=1594, compaction requested=true
2014-07-11 00:24:10,477 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-11 00:24:10,478 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 601.7m
2014-07-11 00:24:10,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:10,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063448905 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063450507
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063358670
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063360026
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063361482
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063362937
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063364319
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063365819
2014-07-11 00:24:10,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063367684
2014-07-11 00:24:10,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063369878
2014-07-11 00:24:10,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063371483
2014-07-11 00:24:10,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063373066
2014-07-11 00:24:10,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063374751
2014-07-11 00:24:10,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063376661
2014-07-11 00:24:10,678 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:24:10,975 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:12,164 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:12,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9161 synced till here 9154
2014-07-11 00:24:12,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063450507 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063452165
2014-07-11 00:24:13,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:13,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9240 synced till here 9234
2014-07-11 00:24:14,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063452165 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063453947
2014-07-11 00:24:15,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:15,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9315 synced till here 9314
2014-07-11 00:24:15,509 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063453947 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063455450
2014-07-11 00:24:16,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:17,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9403 synced till here 9399
2014-07-11 00:24:17,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063455450 with entries=88, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063456872
2014-07-11 00:24:18,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:18,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9477 synced till here 9475
2014-07-11 00:24:18,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063456872 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063458702
2014-07-11 00:24:19,687 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1825, memsize=124.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/7b5e2888e10d44ff9ad5e43d4b6ae45b
2014-07-11 00:24:19,706 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/7b5e2888e10d44ff9ad5e43d4b6ae45b as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/7b5e2888e10d44ff9ad5e43d4b6ae45b
2014-07-11 00:24:19,726 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/7b5e2888e10d44ff9ad5e43d4b6ae45b, entries=452920, sequenceid=1825, filesize=32.3m
2014-07-11 00:24:19,727 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~614.0m/643845520, currentsize=132.1m/138514560 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 9249ms, sequenceid=1825, compaction requested=true
2014-07-11 00:24:19,727 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 00:24:19,728 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 798.7m
2014-07-11 00:24:20,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:20,992 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:21,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9624 synced till here 9616
2014-07-11 00:24:21,830 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1773, memsize=187.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/f9826734df184391a990e18c5897f604
2014-07-11 00:24:21,847 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/f9826734df184391a990e18c5897f604 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/f9826734df184391a990e18c5897f604
2014-07-11 00:24:22,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063458702 with entries=147, filesize=126.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063460528
2014-07-11 00:24:22,503 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/f9826734df184391a990e18c5897f604, entries=683770, sequenceid=1773, filesize=48.8m
2014-07-11 00:24:22,504 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~858.3m/899994880, currentsize=242.1m/253872640 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 16506ms, sequenceid=1773, compaction requested=false
2014-07-11 00:24:22,504 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 478.4m
2014-07-11 00:24:23,320 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:24,477 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:24,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9713 synced till here 9704
2014-07-11 00:24:24,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063460528 with entries=89, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063464477
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063378407
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063380208
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063381797
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063384315
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063385848
2014-07-11 00:24:24,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063387717
2014-07-11 00:24:24,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063390556
2014-07-11 00:24:24,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063392556
2014-07-11 00:24:24,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063394565
2014-07-11 00:24:24,801 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:24:26,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:26,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9794 synced till here 9787
2014-07-11 00:24:26,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063464477 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063466023
2014-07-11 00:24:27,753 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:27,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9879 synced till here 9870
2014-07-11 00:24:27,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063466023 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063467754
2014-07-11 00:24:28,222 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/b4bb5f68e28a4046ac99011812c4d161 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/b4bb5f68e28a4046ac99011812c4d161
2014-07-11 00:24:28,286 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:24:28,295 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/02f32495b1dc4c7daff0803939ed75d6, to hdfs://master:54310/hbase/archive/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/02f32495b1dc4c7daff0803939ed75d6
2014-07-11 00:24:28,298 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/7604fba29ff54c53ad3f3831d7da2225, to hdfs://master:54310/hbase/archive/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/7604fba29ff54c53ad3f3831d7da2225
2014-07-11 00:24:28,303 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/92e43021dc274081a39ec23834533049, to hdfs://master:54310/hbase/archive/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/92e43021dc274081a39ec23834533049
2014-07-11 00:24:28,307 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/78c90eb324424cceac148d3664ebfa2c, to hdfs://master:54310/hbase/archive/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/78c90eb324424cceac148d3664ebfa2c
2014-07-11 00:24:28,307 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. into b4bb5f68e28a4046ac99011812c4d161(size=164.3m), total size for store is 213.0m. This selection was in queue for 0sec, and took 46sec to execute.
2014-07-11 00:24:28,308 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., storeName=family, fileCount=4, fileSize=192.9m, priority=16, time=17329473740941; duration=46sec
2014-07-11 00:24:28,308 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 00:24:28,308 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-11 00:24:28,308 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 233208158 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-11 00:24:28,309 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: cee2ff08fd3c0bc377dccf8be24cbd0f - family: Initiating major compaction
2014-07-11 00:24:28,309 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:24:28,309 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp, totalSize=222.4m
2014-07-11 00:24:28,309 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/207434236a904fba8048dbfc2b931ea2, keycount=82590, bloomtype=ROW, size=58.9m, encoding=NONE, seqNum=512, earliestPutTs=1405063230376
2014-07-11 00:24:28,310 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5acc5351502442a18347f6625a078bd2, keycount=57883, bloomtype=ROW, size=41.3m, encoding=NONE, seqNum=815, earliestPutTs=1405063277190
2014-07-11 00:24:28,310 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/deb47dd47f3b4161bd16c25813b681a5, keycount=102584, bloomtype=ROW, size=73.1m, encoding=NONE, seqNum=1190, earliestPutTs=1405063315266
2014-07-11 00:24:28,310 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5c58c7866d9b45bab4d7335398bd9d14, keycount=68936, bloomtype=ROW, size=49.2m, encoding=NONE, seqNum=1625, earliestPutTs=1405063376716
2014-07-11 00:24:28,312 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:24:28,396 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:28,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:28,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9959 synced till here 9954
2014-07-11 00:24:28,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063467754 with entries=80, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063468638
2014-07-11 00:24:30,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:30,069 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10032 synced till here 10030
2014-07-11 00:24:30,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063468638 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063470044
2014-07-11 00:24:31,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:31,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10105 synced till here 10104
2014-07-11 00:24:31,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063470044 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063471929
2014-07-11 00:24:33,360 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:33,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10198 synced till here 10195
2014-07-11 00:24:34,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063471929 with entries=93, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063473361
2014-07-11 00:24:35,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:36,227 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1947, memsize=194.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/f7ed972182334e87aef705eb42c6f381
2014-07-11 00:24:36,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10313 synced till here 10298
2014-07-11 00:24:36,297 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/f7ed972182334e87aef705eb42c6f381 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/f7ed972182334e87aef705eb42c6f381
2014-07-11 00:24:36,318 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/f7ed972182334e87aef705eb42c6f381, entries=709800, sequenceid=1947, filesize=50.6m
2014-07-11 00:24:36,319 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~497.1m/521230880, currentsize=202.0m/211819600 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 13815ms, sequenceid=1947, compaction requested=false
2014-07-11 00:24:36,320 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 727.3m
2014-07-11 00:24:36,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063473361 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063475993
2014-07-11 00:24:37,065 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:38,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:38,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10407 synced till here 10393
2014-07-11 00:24:38,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063475993 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063478275
2014-07-11 00:24:40,065 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:24:40,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:40,208 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10500 synced till here 10480
2014-07-11 00:24:40,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063478275 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063480175
2014-07-11 00:24:42,007 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1913, memsize=264.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/414141c7b25a44e48ede35397077a367
2014-07-11 00:24:42,038 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/414141c7b25a44e48ede35397077a367 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/414141c7b25a44e48ede35397077a367
2014-07-11 00:24:42,066 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/414141c7b25a44e48ede35397077a367, entries=962440, sequenceid=1913, filesize=68.6m
2014-07-11 00:24:42,067 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~801.8m/840747760, currentsize=333.7m/349862880 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 22339ms, sequenceid=1913, compaction requested=true
2014-07-11 00:24:42,068 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 00:24:42,069 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 513.8m
2014-07-11 00:24:42,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:42,187 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:24:42,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10598 synced till here 10577
2014-07-11 00:24:42,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063480175 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063482186
2014-07-11 00:24:42,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063396471
2014-07-11 00:24:42,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063398014
2014-07-11 00:24:42,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063399390
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063403221
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063406654
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063408887
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063411388
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063414355
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063416453
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063418578
2014-07-11 00:24:42,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063419974
2014-07-11 00:24:43,539 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:24:43,943 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:43,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10687 synced till here 10672
2014-07-11 00:24:44,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063482186 with entries=89, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063483944
2014-07-11 00:24:45,616 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:45,635 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10772 synced till here 10763
2014-07-11 00:24:45,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063483944 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063485617
2014-07-11 00:24:47,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:47,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10851 synced till here 10846
2014-07-11 00:24:47,235 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063485617 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063487160
2014-07-11 00:24:48,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:48,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10925 synced till here 10923
2014-07-11 00:24:48,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063487160 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063488356
2014-07-11 00:24:49,591 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:49,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11001 synced till here 10998
2014-07-11 00:24:49,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063488356 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063489591
2014-07-11 00:24:51,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:51,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11080 synced till here 11074
2014-07-11 00:24:51,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063489591 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063491212
2014-07-11 00:24:52,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:54,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11230 synced till here 11218
2014-07-11 00:24:54,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063491212 with entries=150, filesize=128.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063492846
2014-07-11 00:24:56,307 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:56,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11324 synced till here 11309
2014-07-11 00:24:56,545 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063492846 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063496308
2014-07-11 00:24:58,329 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:24:58,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11414 synced till here 11397
2014-07-11 00:24:58,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063496308 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063498329
2014-07-11 00:25:00,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:00,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11509 synced till here 11490
2014-07-11 00:25:00,363 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2068, memsize=292.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/34fb7d4a6a084a4b81bbf31b623779b3
2014-07-11 00:25:00,378 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/34fb7d4a6a084a4b81bbf31b623779b3 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/34fb7d4a6a084a4b81bbf31b623779b3
2014-07-11 00:25:00,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063498329 with entries=95, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063500153
2014-07-11 00:25:00,423 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/34fb7d4a6a084a4b81bbf31b623779b3, entries=1066260, sequenceid=2068, filesize=76.0m
2014-07-11 00:25:00,425 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~735.1m/770787360, currentsize=370.9m/388899840 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 24106ms, sequenceid=2068, compaction requested=true
2014-07-11 00:25:00,442 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-11 00:25:00,443 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 743.7m
2014-07-11 00:25:00,628 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:25:02,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:02,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11602 synced till here 11583
2014-07-11 00:25:02,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063500153 with entries=93, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063502004
2014-07-11 00:25:02,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063421702
2014-07-11 00:25:02,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063424870
2014-07-11 00:25:02,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063426998
2014-07-11 00:25:02,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063429865
2014-07-11 00:25:02,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063431948
2014-07-11 00:25:02,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063434131
2014-07-11 00:25:02,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063437783
2014-07-11 00:25:02,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063439958
2014-07-11 00:25:02,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063442133
2014-07-11 00:25:02,625 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:03,092 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2118, memsize=291.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/c312d4f5c4b44b1c825146ee795e0d2e
2014-07-11 00:25:04,057 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/c312d4f5c4b44b1c825146ee795e0d2e as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/c312d4f5c4b44b1c825146ee795e0d2e
2014-07-11 00:25:04,077 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/c312d4f5c4b44b1c825146ee795e0d2e, entries=1061740, sequenceid=2118, filesize=75.7m
2014-07-11 00:25:04,081 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~532.4m/558240480, currentsize=322.6m/338234000 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 22013ms, sequenceid=2118, compaction requested=true
2014-07-11 00:25:04,081 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-11 00:25:04,082 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 618.2m
2014-07-11 00:25:04,117 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:25:04,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:04,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11690 synced till here 11675
2014-07-11 00:25:04,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063502004 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063504368
2014-07-11 00:25:04,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063443827
2014-07-11 00:25:04,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063446654
2014-07-11 00:25:04,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063448905
2014-07-11 00:25:04,974 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:05,990 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:06,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11800 synced till here 11799
2014-07-11 00:25:06,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063504368 with entries=110, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063505990
2014-07-11 00:25:08,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:08,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11878 synced till here 11872
2014-07-11 00:25:08,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063505990 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063508496
2014-07-11 00:25:10,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:10,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11961 synced till here 11952
2014-07-11 00:25:10,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063508496 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063510087
2014-07-11 00:25:11,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:11,862 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12040 synced till here 12032
2014-07-11 00:25:11,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063510087 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063511840
2014-07-11 00:25:13,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:13,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12123 synced till here 12112
2014-07-11 00:25:13,744 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063511840 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063513565
2014-07-11 00:25:15,611 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:15,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12216 synced till here 12197
2014-07-11 00:25:15,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063513565 with entries=93, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063515612
2014-07-11 00:25:17,857 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:17,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12312 synced till here 12308
2014-07-11 00:25:18,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063515612 with entries=96, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063517857
2014-07-11 00:25:20,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:20,069 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12405 synced till here 12385
2014-07-11 00:25:20,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063517857 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063520023
2014-07-11 00:25:21,655 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,655 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,655 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,655 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,656 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,656 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,657 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,658 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,741 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,741 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,742 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,742 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,742 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,742 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,744 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,744 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,744 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,790 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,790 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,790 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,790 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,790 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,791 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,791 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:21,973 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:22,211 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2352, memsize=227.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4990788c26cd4828bae08f0210638689
2014-07-11 00:25:22,233 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4990788c26cd4828bae08f0210638689 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4990788c26cd4828bae08f0210638689
2014-07-11 00:25:22,248 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4990788c26cd4828bae08f0210638689, entries=826330, sequenceid=2352, filesize=58.9m
2014-07-11 00:25:22,249 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~627.5m/657934960, currentsize=252.7m/264926240 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 18167ms, sequenceid=2352, compaction requested=false
2014-07-11 00:25:22,249 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 276ms
2014-07-11 00:25:22,249 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,249 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 928.3m
2014-07-11 00:25:22,249 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 459ms
2014-07-11 00:25:22,249 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,250 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 460ms
2014-07-11 00:25:22,250 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,250 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 460ms
2014-07-11 00:25:22,250 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,250 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 461ms
2014-07-11 00:25:22,250 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,250 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 460ms
2014-07-11 00:25:22,250 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,265 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 475ms
2014-07-11 00:25:22,265 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,265 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 476ms
2014-07-11 00:25:22,265 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,265 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 521ms
2014-07-11 00:25:22,265 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,265 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 521ms
2014-07-11 00:25:22,265 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,265 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 521ms
2014-07-11 00:25:22,266 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,266 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 524ms
2014-07-11 00:25:22,266 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,266 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 525ms
2014-07-11 00:25:22,266 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,281 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 540ms
2014-07-11 00:25:22,281 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,281 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 539ms
2014-07-11 00:25:22,281 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,282 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 541ms
2014-07-11 00:25:22,282 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,289 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 548ms
2014-07-11 00:25:22,289 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,289 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 632ms
2014-07-11 00:25:22,289 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,289 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 632ms
2014-07-11 00:25:22,289 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,293 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 637ms
2014-07-11 00:25:22,293 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,293 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 638ms
2014-07-11 00:25:22,294 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,294 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 639ms
2014-07-11 00:25:22,294 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,294 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 639ms
2014-07-11 00:25:22,294 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,305 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 650ms
2014-07-11 00:25:22,305 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,305 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 651ms
2014-07-11 00:25:22,305 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:22,497 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:22,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12496 synced till here 12484
2014-07-11 00:25:23,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063520023 with entries=91, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063522497
2014-07-11 00:25:23,565 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:25:24,100 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:24,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:25,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12592 synced till here 12590
2014-07-11 00:25:25,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063522497 with entries=96, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063524560
2014-07-11 00:25:26,421 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/35c5a8fa30bc40fabbd5bb418e0d3ba2 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/35c5a8fa30bc40fabbd5bb418e0d3ba2
2014-07-11 00:25:26,567 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:25:26,578 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/207434236a904fba8048dbfc2b931ea2, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/207434236a904fba8048dbfc2b931ea2
2014-07-11 00:25:26,581 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5acc5351502442a18347f6625a078bd2, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5acc5351502442a18347f6625a078bd2
2014-07-11 00:25:26,585 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/deb47dd47f3b4161bd16c25813b681a5, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/deb47dd47f3b4161bd16c25813b681a5
2014-07-11 00:25:27,451 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5c58c7866d9b45bab4d7335398bd9d14, to hdfs://master:54310/hbase/archive/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5c58c7866d9b45bab4d7335398bd9d14
2014-07-11 00:25:27,451 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. into 35c5a8fa30bc40fabbd5bb418e0d3ba2(size=204.4m), total size for store is 313.8m. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-11 00:25:27,452 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., storeName=family, fileCount=4, fileSize=222.4m, priority=16, time=17375735933610; duration=59sec
2014-07-11 00:25:27,452 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-11 00:25:27,452 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-11 00:25:27,452 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 285106635 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-11 00:25:27,452 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: 600e47c8102c939894f95b55fbbe3a1e - family: Initiating major compaction
2014-07-11 00:25:27,453 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:25:27,453 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp, totalSize=271.9m
2014-07-11 00:25:27,453 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/cb7ecaa7cb4442948db523bbdf812e4e, keycount=102747, bloomtype=ROW, size=73.2m, encoding=NONE, seqNum=626, earliestPutTs=1405063231017
2014-07-11 00:25:27,453 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/eccd0da660524f949214514e466c10b3, keycount=63995, bloomtype=ROW, size=45.7m, encoding=NONE, seqNum=909, earliestPutTs=1405063301173
2014-07-11 00:25:27,453 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/0dc57bb144e34ae288ab494eef4a5812, keycount=118626, bloomtype=ROW, size=84.5m, encoding=NONE, seqNum=1394, earliestPutTs=1405063348394
2014-07-11 00:25:27,453 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/414141c7b25a44e48ede35397077a367, keycount=96244, bloomtype=ROW, size=68.6m, encoding=NONE, seqNum=1913, earliestPutTs=1405063397764
2014-07-11 00:25:27,489 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2311, memsize=357.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f3af3b782d074b5b9bafb9a83f1b1921
2014-07-11 00:25:27,518 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f3af3b782d074b5b9bafb9a83f1b1921 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f3af3b782d074b5b9bafb9a83f1b1921
2014-07-11 00:25:27,522 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:27,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:27,565 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f3af3b782d074b5b9bafb9a83f1b1921, entries=1299680, sequenceid=2311, filesize=92.6m
2014-07-11 00:25:27,566 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~753.0m/789580320, currentsize=359.4m/376862800 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 27123ms, sequenceid=2311, compaction requested=true
2014-07-11 00:25:27,566 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-11 00:25:27,566 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 730.1m
2014-07-11 00:25:27,642 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12692 synced till here 12680
2014-07-11 00:25:27,754 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:25:27,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063524560 with entries=100, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063527526
2014-07-11 00:25:27,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063450507
2014-07-11 00:25:27,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063452165
2014-07-11 00:25:27,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063453947
2014-07-11 00:25:27,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063455450
2014-07-11 00:25:27,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063456872
2014-07-11 00:25:28,352 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:29,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:29,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12771 synced till here 12764
2014-07-11 00:25:29,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063527526 with entries=79, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063529444
2014-07-11 00:25:31,021 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:31,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12848 synced till here 12842
2014-07-11 00:25:31,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063529444 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531021
2014-07-11 00:25:31,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:31,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12921 synced till here 12919
2014-07-11 00:25:31,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531021 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531881
2014-07-11 00:25:33,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:33,307 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531881 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063533277
2014-07-11 00:25:35,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:35,147 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13070 synced till here 13065
2014-07-11 00:25:35,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063533277 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063535112
2014-07-11 00:25:36,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:36,971 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13148 synced till here 13144
2014-07-11 00:25:37,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063535112 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063536916
2014-07-11 00:25:38,408 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:38,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13239 synced till here 13225
2014-07-11 00:25:38,631 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063536916 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063538408
2014-07-11 00:25:40,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:40,372 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13322 synced till here 13313
2014-07-11 00:25:40,487 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063538408 with entries=83, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063540320
2014-07-11 00:25:41,550 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,550 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,551 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,551 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,556 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,556 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,560 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,562 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,574 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,587 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,594 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,594 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,630 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,636 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,636 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,640 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,665 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,670 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,723 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,764 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,799 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:41,836 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:25:43,118 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2543, memsize=199.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/13083441607248d0a0bace212943021b
2014-07-11 00:25:43,140 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/13083441607248d0a0bace212943021b as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/13083441607248d0a0bace212943021b
2014-07-11 00:25:43,604 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/13083441607248d0a0bace212943021b, entries=727220, sequenceid=2543, filesize=51.8m
2014-07-11 00:25:43,605 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~731.7m/767277440, currentsize=202.4m/212244640 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 16039ms, sequenceid=2543, compaction requested=true
2014-07-11 00:25:43,605 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-11 00:25:43,606 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1770ms
2014-07-11 00:25:43,606 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,606 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1807ms
2014-07-11 00:25:43,606 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 864.5m
2014-07-11 00:25:43,606 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,606 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1842ms
2014-07-11 00:25:43,606 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,606 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1883ms
2014-07-11 00:25:43,607 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,609 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1940ms
2014-07-11 00:25:43,609 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,609 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1944ms
2014-07-11 00:25:43,609 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,609 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1970ms
2014-07-11 00:25:43,609 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,620 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1984ms
2014-07-11 00:25:43,621 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,621 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1986ms
2014-07-11 00:25:43,621 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,621 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1991ms
2014-07-11 00:25:43,621 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,621 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2027ms
2014-07-11 00:25:43,621 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,622 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2028ms
2014-07-11 00:25:43,622 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,622 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2035ms
2014-07-11 00:25:43,622 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,622 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2048ms
2014-07-11 00:25:43,622 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,623 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-11 00:25:43,623 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,623 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2064ms
2014-07-11 00:25:43,623 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,623 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2067ms
2014-07-11 00:25:43,623 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,623 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2067ms
2014-07-11 00:25:43,624 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,624 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2074ms
2014-07-11 00:25:43,624 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,624 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2073ms
2014-07-11 00:25:43,624 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,624 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2074ms
2014-07-11 00:25:43,624 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:43,624 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2074ms
2014-07-11 00:25:43,624 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:25:45,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:45,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13415 synced till here 13401
2014-07-11 00:25:45,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063540320 with entries=93, filesize=80.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063545151
2014-07-11 00:25:45,430 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:46,111 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2507, memsize=297.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/853799f9067549b08ac33ea47f3de7d4
2014-07-11 00:25:46,126 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/853799f9067549b08ac33ea47f3de7d4 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/853799f9067549b08ac33ea47f3de7d4
2014-07-11 00:25:46,140 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/853799f9067549b08ac33ea47f3de7d4, entries=1083560, sequenceid=2507, filesize=77.2m
2014-07-11 00:25:46,140 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~928.3m/973445040, currentsize=312.9m/328146320 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 23891ms, sequenceid=2507, compaction requested=false
2014-07-11 00:25:46,141 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 564.5m
2014-07-11 00:25:47,078 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:25:47,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:47,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13520 synced till here 13492
2014-07-11 00:25:47,461 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:25:47,487 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063545151 with entries=105, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063547222
2014-07-11 00:25:47,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063458702
2014-07-11 00:25:47,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063460528
2014-07-11 00:25:47,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063464477
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063466023
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063467754
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063468638
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063470044
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063471929
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063473361
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063475993
2014-07-11 00:25:47,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063478275
2014-07-11 00:25:48,679 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:25:48,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:48,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13602 synced till here 13591
2014-07-11 00:25:48,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063547222 with entries=82, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063548734
2014-07-11 00:25:50,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:50,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13687 synced till here 13677
2014-07-11 00:25:50,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063548734 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063550439
2014-07-11 00:25:51,506 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:51,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13760 synced till here 13759
2014-07-11 00:25:52,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063550439 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063551507
2014-07-11 00:25:52,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:52,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13837 synced till here 13834
2014-07-11 00:25:52,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063551507 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063552862
2014-07-11 00:25:54,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:55,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13923 synced till here 13921
2014-07-11 00:25:55,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063552862 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063554293
2014-07-11 00:25:55,877 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:55,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14006 synced till here 13997
2014-07-11 00:25:55,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063554293 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063555878
2014-07-11 00:25:57,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:25:58,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14146 synced till here 14134
2014-07-11 00:25:59,084 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063555878 with entries=140, filesize=120.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063557494
2014-07-11 00:26:00,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:00,753 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14227 synced till here 14218
2014-07-11 00:26:00,856 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063557494 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063560719
2014-07-11 00:26:02,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:02,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14328 synced till here 14322
2014-07-11 00:26:02,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063560719 with entries=101, filesize=86.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063562849
2014-07-11 00:26:04,665 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2720, memsize=221.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/25509d4e37d6445d887b57887777e5e0
2014-07-11 00:26:04,689 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/25509d4e37d6445d887b57887777e5e0 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/25509d4e37d6445d887b57887777e5e0
2014-07-11 00:26:04,705 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/25509d4e37d6445d887b57887777e5e0, entries=804580, sequenceid=2720, filesize=57.3m
2014-07-11 00:26:04,705 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~570.8m/598540560, currentsize=272.9m/286154800 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 18564ms, sequenceid=2720, compaction requested=true
2014-07-11 00:26:04,706 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-11 00:26:04,706 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 887.9m
2014-07-11 00:26:04,785 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:26:04,839 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:04,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14407 synced till here 14398
2014-07-11 00:26:04,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063562849 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063564839
2014-07-11 00:26:06,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:06,635 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:06,686 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14492 synced till here 14478
2014-07-11 00:26:06,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063564839 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063566629
2014-07-11 00:26:08,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:08,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14571 synced till here 14565
2014-07-11 00:26:08,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063566629 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063568304
2014-07-11 00:26:09,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:10,737 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2675, memsize=310.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/d1f09f89e8f0460c907901d66d93bca0
2014-07-11 00:26:10,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14668 synced till here 14662
2014-07-11 00:26:10,767 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/d1f09f89e8f0460c907901d66d93bca0 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/d1f09f89e8f0460c907901d66d93bca0
2014-07-11 00:26:10,789 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/d1f09f89e8f0460c907901d66d93bca0, entries=1129430, sequenceid=2675, filesize=80.5m
2014-07-11 00:26:10,790 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~864.5m/906502640, currentsize=408.4m/428214640 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 27183ms, sequenceid=2675, compaction requested=true
2014-07-11 00:26:10,790 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-11 00:26:10,791 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 675.1m
2014-07-11 00:26:10,799 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:26:10,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063568304 with entries=97, filesize=83.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063569849
2014-07-11 00:26:10,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063480175
2014-07-11 00:26:10,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063482186
2014-07-11 00:26:10,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063483944
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063485617
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063487160
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063488356
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063489591
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063491212
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063492846
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063496308
2014-07-11 00:26:10,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063498329
2014-07-11 00:26:12,505 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:12,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:12,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14775 synced till here 14762
2014-07-11 00:26:13,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063569849 with entries=107, filesize=92.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063572515
2014-07-11 00:26:16,155 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1339ms
GC pool 'ParNew' had collection(s): count=1 time=1392ms
2014-07-11 00:26:16,213 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:16,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14921 synced till here 14907
2014-07-11 00:26:16,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063572515 with entries=146, filesize=125.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063576213
2014-07-11 00:26:18,663 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:18,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15014 synced till here 14997
2014-07-11 00:26:18,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063576213 with entries=93, filesize=80.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063578664
2014-07-11 00:26:20,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:20,827 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15113 synced till here 15096
2014-07-11 00:26:21,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063578664 with entries=99, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063580752
2014-07-11 00:26:22,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:22,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15198 synced till here 15185
2014-07-11 00:26:22,606 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063580752 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063582490
2014-07-11 00:26:24,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:24,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15289 synced till here 15277
2014-07-11 00:26:24,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063582490 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063584160
2014-07-11 00:26:25,580 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,587 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,609 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,609 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,609 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,638 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,644 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,679 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,729 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:25,787 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,040 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,109 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,421 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,489 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,547 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,606 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,685 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:26,731 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,385 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,443 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,499 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,703 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,760 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,825 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,875 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:27,945 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:28,650 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:28,662 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:28,692 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:28,730 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:28,767 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:29,743 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:29,828 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:29,906 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:29,976 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:30,039 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:30,108 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:30,581 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:30,588 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:30,609 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:30,609 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:30,610 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:30,638 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:30,644 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:30,679 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:30,730 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:30,788 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,041 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:31,109 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 00:26:31,422 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,490 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,548 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,607 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,681 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2884, memsize=349.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f9477dd4a2cb4acd8fae3e1973a92564
2014-07-11 00:26:31,686 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,693 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/f9477dd4a2cb4acd8fae3e1973a92564 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f9477dd4a2cb4acd8fae3e1973a92564
2014-07-11 00:26:31,729 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f9477dd4a2cb4acd8fae3e1973a92564, entries=1273620, sequenceid=2884, filesize=90.7m
2014-07-11 00:26:31,729 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~889.5m/932660960, currentsize=298.8m/313277520 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 27023ms, sequenceid=2884, compaction requested=true
2014-07-11 00:26:31,730 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-11 00:26:31,730 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5045ms
2014-07-11 00:26:31,730 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,731 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5125ms
2014-07-11 00:26:31,731 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,731 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 819.9m
2014-07-11 00:26:31,732 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 00:26:31,733 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,745 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5198ms
2014-07-11 00:26:31,745 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,745 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5256ms
2014-07-11 00:26:31,745 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,745 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5324ms
2014-07-11 00:26:31,745 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,745 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5636ms
2014-07-11 00:26:31,745 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,746 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5706ms
2014-07-11 00:26:31,746 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,746 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5959ms
2014-07-11 00:26:31,746 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,746 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6017ms
2014-07-11 00:26:31,746 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,746 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6068ms
2014-07-11 00:26:31,746 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,760 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6116ms
2014-07-11 00:26:31,760 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,760 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6122ms
2014-07-11 00:26:31,760 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,773 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6164ms
2014-07-11 00:26:31,773 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,773 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6164ms
2014-07-11 00:26:31,773 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,773 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6164ms
2014-07-11 00:26:31,773 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,773 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6186ms
2014-07-11 00:26:31,773 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,774 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6194ms
2014-07-11 00:26:31,774 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,774 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1666ms
2014-07-11 00:26:31,775 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,775 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1737ms
2014-07-11 00:26:31,775 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,775 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1800ms
2014-07-11 00:26:31,775 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,775 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1869ms
2014-07-11 00:26:31,776 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,776 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-11 00:26:31,776 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,776 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2034ms
2014-07-11 00:26:31,776 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,789 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3022ms
2014-07-11 00:26:31,790 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,795 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3064ms
2014-07-11 00:26:31,795 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,796 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3103ms
2014-07-11 00:26:31,796 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,797 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3134ms
2014-07-11 00:26:31,797 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,798 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3147ms
2014-07-11 00:26:31,798 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,799 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3854ms
2014-07-11 00:26:31,799 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,801 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3926ms
2014-07-11 00:26:31,801 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,805 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3980ms
2014-07-11 00:26:31,805 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,805 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4045ms
2014-07-11 00:26:31,805 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,809 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4106ms
2014-07-11 00:26:31,809 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,810 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4310ms
2014-07-11 00:26:31,810 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,810 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4367ms
2014-07-11 00:26:31,810 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:31,810 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4425ms
2014-07-11 00:26:31,810 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:32,109 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:26:32,820 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:32,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15376 synced till here 15364
2014-07-11 00:26:32,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063584160 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063592820
2014-07-11 00:26:32,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063500153
2014-07-11 00:26:32,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063502004
2014-07-11 00:26:32,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063504368
2014-07-11 00:26:32,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063505990
2014-07-11 00:26:32,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063508496
2014-07-11 00:26:32,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063510087
2014-07-11 00:26:32,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063511840
2014-07-11 00:26:32,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063513565
2014-07-11 00:26:32,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063515612
2014-07-11 00:26:32,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063517857
2014-07-11 00:26:33,318 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:33,775 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/7e09f86840b84a43b84c0499a90f7ac8 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/7e09f86840b84a43b84c0499a90f7ac8
2014-07-11 00:26:34,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:34,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15494 synced till here 15457
2014-07-11 00:26:34,905 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:26:34,935 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/cb7ecaa7cb4442948db523bbdf812e4e, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/cb7ecaa7cb4442948db523bbdf812e4e
2014-07-11 00:26:34,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063592820 with entries=118, filesize=99.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063594544
2014-07-11 00:26:34,950 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/eccd0da660524f949214514e466c10b3, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/eccd0da660524f949214514e466c10b3
2014-07-11 00:26:34,971 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/0dc57bb144e34ae288ab494eef4a5812, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/0dc57bb144e34ae288ab494eef4a5812
2014-07-11 00:26:34,979 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2946, memsize=340.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/2ae9f0f2f00e4395a7d568676bbd2d0f
2014-07-11 00:26:34,987 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/414141c7b25a44e48ede35397077a367, to hdfs://master:54310/hbase/archive/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/414141c7b25a44e48ede35397077a367
2014-07-11 00:26:34,987 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. into 7e09f86840b84a43b84c0499a90f7ac8(size=236.1m), total size for store is 313.3m. This selection was in queue for 0sec, and took 1mins, 7sec to execute.
2014-07-11 00:26:34,988 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., storeName=family, fileCount=4, fileSize=271.9m, priority=16, time=17434879640601; duration=1mins, 7sec
2014-07-11 00:26:34,988 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-11 00:26:34,988 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-11 00:26:34,988 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 358430741 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-11 00:26:34,989 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: a814c9f2554f95576d7e3f7dd25bb826 - family: Initiating major compaction
2014-07-11 00:26:34,989 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:26:34,989 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp, totalSize=341.8m
2014-07-11 00:26:34,989 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1ad113eabac841508df3fa066cf2b986, keycount=102569, bloomtype=ROW, size=73.1m, encoding=NONE, seqNum=689, earliestPutTs=1405063231458
2014-07-11 00:26:34,990 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/6d51cbcc1c7a4e1499f3fba8b075a8a6, keycount=98416, bloomtype=ROW, size=70.2m, encoding=NONE, seqNum=1015, earliestPutTs=1405063301372
2014-07-11 00:26:34,990 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1229755b8a954b6ab7f30cc301664634, keycount=99311, bloomtype=ROW, size=70.8m, encoding=NONE, seqNum=1594, earliestPutTs=1405063358983
2014-07-11 00:26:34,990 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/34fb7d4a6a084a4b81bbf31b623779b3, keycount=106626, bloomtype=ROW, size=76.0m, encoding=NONE, seqNum=2068, earliestPutTs=1405063446921
2014-07-11 00:26:34,990 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/13083441607248d0a0bace212943021b, keycount=72722, bloomtype=ROW, size=51.8m, encoding=NONE, seqNum=2543, earliestPutTs=1405063484205
2014-07-11 00:26:35,001 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/2ae9f0f2f00e4395a7d568676bbd2d0f as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/2ae9f0f2f00e4395a7d568676bbd2d0f
2014-07-11 00:26:35,011 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/2ae9f0f2f00e4395a7d568676bbd2d0f, entries=1237970, sequenceid=2946, filesize=88.2m
2014-07-11 00:26:35,012 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~679.7m/712736880, currentsize=267.3m/280268240 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 24221ms, sequenceid=2946, compaction requested=true
2014-07-11 00:26:35,012 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-11 00:26:35,012 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 623.6m
2014-07-11 00:26:35,103 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:35,395 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:26:35,629 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:35,703 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:35,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15570 synced till here 15567
2014-07-11 00:26:35,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063594544 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063595703
2014-07-11 00:26:35,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063520023
2014-07-11 00:26:35,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063522497
2014-07-11 00:26:35,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063524560
2014-07-11 00:26:37,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:37,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15643 synced till here 15640
2014-07-11 00:26:37,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063595703 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063597136
2014-07-11 00:26:39,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:40,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15746 synced till here 15740
2014-07-11 00:26:40,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063597136 with entries=103, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063599326
2014-07-11 00:26:42,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:42,210 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15831 synced till here 15818
2014-07-11 00:26:42,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063599326 with entries=85, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063602175
2014-07-11 00:26:43,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:43,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15908 synced till here 15904
2014-07-11 00:26:43,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063602175 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063603138
2014-07-11 00:26:44,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:44,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15984 synced till here 15980
2014-07-11 00:26:44,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063603138 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063604602
2014-07-11 00:26:46,042 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:46,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16058 synced till here 16057
2014-07-11 00:26:46,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063604602 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063606043
2014-07-11 00:26:47,409 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:47,702 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16155 synced till here 16150
2014-07-11 00:26:47,742 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063606043 with entries=97, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063607410
2014-07-11 00:26:49,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:49,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16228 synced till here 16226
2014-07-11 00:26:49,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063607410 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063609464
2014-07-11 00:26:50,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:51,027 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16308 synced till here 16300
2014-07-11 00:26:51,128 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063609464 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063610995
2014-07-11 00:26:52,256 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,257 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,257 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,257 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,257 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,269 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,307 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,323 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3122, memsize=255.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5b0b6f61f9ec4cd8aa18081bee0f0db0
2014-07-11 00:26:52,334 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/5b0b6f61f9ec4cd8aa18081bee0f0db0 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5b0b6f61f9ec4cd8aa18081bee0f0db0
2014-07-11 00:26:52,344 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,382 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,405 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,405 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,406 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,406 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,407 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,407 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,408 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,408 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,408 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,409 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,409 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,410 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,411 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,415 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,419 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,453 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:26:52,485 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5b0b6f61f9ec4cd8aa18081bee0f0db0, entries=928990, sequenceid=3122, filesize=66.2m
2014-07-11 00:26:52,485 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.6m/653898240, currentsize=263.5m/276277280 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 17473ms, sequenceid=3122, compaction requested=true
2014-07-11 00:26:52,485 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-11 00:26:52,485 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32ms
2014-07-11 00:26:52,486 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,486 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 67ms
2014-07-11 00:26:52,486 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 930.2m
2014-07-11 00:26:52,486 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,486 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 71ms
2014-07-11 00:26:52,486 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,486 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 75ms
2014-07-11 00:26:52,486 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,486 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 76ms
2014-07-11 00:26:52,486 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,486 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 80ms
2014-07-11 00:26:52,487 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,487 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 81ms
2014-07-11 00:26:52,487 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,487 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 80ms
2014-07-11 00:26:52,487 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,491 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 86ms
2014-07-11 00:26:52,491 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,493 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-11 00:26:52,493 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,493 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 86ms
2014-07-11 00:26:52,493 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,497 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 90ms
2014-07-11 00:26:52,497 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,497 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 91ms
2014-07-11 00:26:52,497 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,497 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 91ms
2014-07-11 00:26:52,497 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,501 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 96ms
2014-07-11 00:26:52,501 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,501 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 96ms
2014-07-11 00:26:52,501 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,510 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 128ms
2014-07-11 00:26:52,510 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,510 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 166ms
2014-07-11 00:26:52,510 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,513 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 206ms
2014-07-11 00:26:52,513 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,513 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 244ms
2014-07-11 00:26:52,513 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,513 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 256ms
2014-07-11 00:26:52,513 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,513 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 256ms
2014-07-11 00:26:52,513 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,514 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 258ms
2014-07-11 00:26:52,514 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,525 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 268ms
2014-07-11 00:26:52,525 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,525 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 269ms
2014-07-11 00:26:52,525 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:26:52,598 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:26:52,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:53,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16407 synced till here 16380
2014-07-11 00:26:53,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063610995 with entries=99, filesize=85.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063612770
2014-07-11 00:26:54,370 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:54,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:55,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16496 synced till here 16486
2014-07-11 00:26:55,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063612770 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063614874
2014-07-11 00:26:56,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:56,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16572 synced till here 16568
2014-07-11 00:26:56,477 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3074, memsize=341.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/c4716a7609a24d0087faab417730bbfb
2014-07-11 00:26:56,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063614874 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063616390
2014-07-11 00:26:56,491 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/c4716a7609a24d0087faab417730bbfb as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/c4716a7609a24d0087faab417730bbfb
2014-07-11 00:26:56,500 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/c4716a7609a24d0087faab417730bbfb, entries=1241580, sequenceid=3074, filesize=88.4m
2014-07-11 00:26:56,501 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~819.9m/859724640, currentsize=385.2m/403948960 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 24770ms, sequenceid=3074, compaction requested=false
2014-07-11 00:26:56,501 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 680.4m
2014-07-11 00:26:56,536 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:26:57,711 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:26:57,830 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:57,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16648 synced till here 16645
2014-07-11 00:26:57,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063616390 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063617830
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063527526
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063529444
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531021
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063531881
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063533277
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063535112
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063536916
2014-07-11 00:26:57,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063538408
2014-07-11 00:26:59,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:26:59,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16729 synced till here 16726
2014-07-11 00:26:59,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063617830 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063619064
2014-07-11 00:27:00,436 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:00,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16803 synced till here 16801
2014-07-11 00:27:00,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063619064 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063620436
2014-07-11 00:27:01,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:01,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16888 synced till here 16882
2014-07-11 00:27:01,744 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063620436 with entries=85, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063621580
2014-07-11 00:27:02,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:02,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16961 synced till here 16959
2014-07-11 00:27:02,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063621580 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063622963
2014-07-11 00:27:04,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:05,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17060 synced till here 17054
2014-07-11 00:27:06,544 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1030ms
GC pool 'ParNew' had collection(s): count=1 time=1047ms
2014-07-11 00:27:06,548 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063622963 with entries=99, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063624908
2014-07-11 00:27:07,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:07,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17149 synced till here 17134
2014-07-11 00:27:08,373 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063624908 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063627411
2014-07-11 00:27:09,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:09,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17235 synced till here 17229
2014-07-11 00:27:09,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063627411 with entries=86, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063629240
2014-07-11 00:27:10,217 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,227 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,237 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,237 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,239 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,252 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,255 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,261 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,265 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,304 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,310 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,315 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,315 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,349 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,390 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,429 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,470 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,507 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,547 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,587 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,624 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:10,662 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:12,060 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:12,114 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:12,197 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:12,554 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,336 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,352 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,370 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,406 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,444 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,484 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,533 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,579 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,620 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,674 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,725 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,764 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,825 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,849 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3325, memsize=291.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/16b53f1aedaa4e609b1e2b7a86858a50
2014-07-11 00:27:13,870 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:13,873 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/16b53f1aedaa4e609b1e2b7a86858a50 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/16b53f1aedaa4e609b1e2b7a86858a50
2014-07-11 00:27:13,883 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/16b53f1aedaa4e609b1e2b7a86858a50, entries=1062530, sequenceid=3325, filesize=75.6m
2014-07-11 00:27:13,884 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~681.9m/715058000, currentsize=214.3m/224720880 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 17383ms, sequenceid=3325, compaction requested=true
2014-07-11 00:27:13,884 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-11 00:27:13,884 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14ms
2014-07-11 00:27:13,884 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,884 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 59ms
2014-07-11 00:27:13,884 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 809.0m
2014-07-11 00:27:13,884 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,885 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 120ms
2014-07-11 00:27:13,885 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,885 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 161ms
2014-07-11 00:27:13,885 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,885 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 211ms
2014-07-11 00:27:13,885 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,889 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 269ms
2014-07-11 00:27:13,890 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,890 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 311ms
2014-07-11 00:27:13,890 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,890 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 358ms
2014-07-11 00:27:13,890 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,890 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 406ms
2014-07-11 00:27:13,890 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,890 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 446ms
2014-07-11 00:27:13,890 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,893 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 487ms
2014-07-11 00:27:13,893 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,897 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 527ms
2014-07-11 00:27:13,897 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,900 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 548ms
2014-07-11 00:27:13,900 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,905 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 569ms
2014-07-11 00:27:13,905 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,905 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1351ms
2014-07-11 00:27:13,905 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,905 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1708ms
2014-07-11 00:27:13,905 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,909 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1795ms
2014-07-11 00:27:13,909 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,909 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1850ms
2014-07-11 00:27:13,909 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,909 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3248ms
2014-07-11 00:27:13,909 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,910 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3285ms
2014-07-11 00:27:13,910 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,910 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3323ms
2014-07-11 00:27:13,910 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,910 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3364ms
2014-07-11 00:27:13,910 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,910 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3403ms
2014-07-11 00:27:13,911 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,911 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3441ms
2014-07-11 00:27:13,911 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,912 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3483ms
2014-07-11 00:27:13,912 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,912 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3522ms
2014-07-11 00:27:13,912 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,912 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3563ms
2014-07-11 00:27:13,912 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,914 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3598ms
2014-07-11 00:27:13,914 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,914 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3599ms
2014-07-11 00:27:13,914 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,925 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3615ms
2014-07-11 00:27:13,925 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,925 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3621ms
2014-07-11 00:27:13,925 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,929 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3664ms
2014-07-11 00:27:13,929 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,930 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3668ms
2014-07-11 00:27:13,930 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,931 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3675ms
2014-07-11 00:27:13,931 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,933 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3680ms
2014-07-11 00:27:13,933 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,933 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3694ms
2014-07-11 00:27:13,933 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,941 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3704ms
2014-07-11 00:27:13,944 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,945 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3708ms
2014-07-11 00:27:13,945 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,945 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3718ms
2014-07-11 00:27:13,945 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:13,949 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3732ms
2014-07-11 00:27:13,949 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:14,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:14,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17337 synced till here 17313
2014-07-11 00:27:14,605 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:14,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063629240 with entries=102, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063634461
2014-07-11 00:27:16,492 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:16,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17459 synced till here 17410
2014-07-11 00:27:18,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063634461 with entries=122, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063636492
2014-07-11 00:27:18,373 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:27:19,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:19,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17567 synced till here 17544
2014-07-11 00:27:19,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063636492 with entries=108, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063639397
2014-07-11 00:27:20,148 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3275, memsize=429.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/ba2554eaaea74f6092781a089a442958
2014-07-11 00:27:20,162 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/ba2554eaaea74f6092781a089a442958 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/ba2554eaaea74f6092781a089a442958
2014-07-11 00:27:20,174 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/ba2554eaaea74f6092781a089a442958, entries=1564580, sequenceid=3275, filesize=111.4m
2014-07-11 00:27:20,175 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~930.2m/975407280, currentsize=388.2m/407030640 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 27689ms, sequenceid=3275, compaction requested=true
2014-07-11 00:27:20,175 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-11 00:27:20,175 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 652.4m
2014-07-11 00:27:20,185 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:27:20,801 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:20,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17651 synced till here 17640
2014-07-11 00:27:20,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063639397 with entries=84, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063640802
2014-07-11 00:27:20,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063540320
2014-07-11 00:27:20,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063545151
2014-07-11 00:27:20,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063547222
2014-07-11 00:27:20,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063548734
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063550439
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063551507
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063552862
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063554293
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063555878
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063557494
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063560719
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063562849
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063564839
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063566629
2014-07-11 00:27:20,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063568304
2014-07-11 00:27:21,126 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:22,767 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:22,790 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17725 synced till here 17723
2014-07-11 00:27:22,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063640802 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063642767
2014-07-11 00:27:23,540 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:23,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063642767 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063643540
2014-07-11 00:27:24,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:24,722 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063643540 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063644672
2014-07-11 00:27:25,912 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:25,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17945 synced till here 17943
2014-07-11 00:27:25,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063644672 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063645912
2014-07-11 00:27:27,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:27,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18023 synced till here 18018
2014-07-11 00:27:27,454 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063645912 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063647369
2014-07-11 00:27:29,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:30,270 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18137 synced till here 18120
2014-07-11 00:27:30,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063647369 with entries=114, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063649168
2014-07-11 00:27:32,226 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:32,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18235 synced till here 18214
2014-07-11 00:27:32,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063649168 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063652226
2014-07-11 00:27:34,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:34,132 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,133 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,135 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,135 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,136 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18320 synced till here 18311
2014-07-11 00:27:34,193 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,220 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,220 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,220 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,221 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,221 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,221 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,223 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,226 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,227 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063652226 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063654113
2014-07-11 00:27:34,240 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,275 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,312 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,345 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,346 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,346 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,346 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,347 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,347 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,347 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,348 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,351 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,351 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,351 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,352 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,390 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,432 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,469 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,506 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,542 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,579 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,615 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,652 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:34,688 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,083 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,504 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,576 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,644 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,713 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,781 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,846 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,906 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:37,983 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:38,020 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:38,066 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:38,237 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3467, memsize=386.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/16c6c07d6dbe43088914778e7a3bd323
2014-07-11 00:27:38,253 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/16c6c07d6dbe43088914778e7a3bd323 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/16c6c07d6dbe43088914778e7a3bd323
2014-07-11 00:27:38,265 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/16c6c07d6dbe43088914778e7a3bd323, entries=1406210, sequenceid=3467, filesize=100.1m
2014-07-11 00:27:38,265 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~809.0m/848299360, currentsize=333.9m/350165920 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 24381ms, sequenceid=3467, compaction requested=true
2014-07-11 00:27:38,265 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-11 00:27:38,266 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 200ms
2014-07-11 00:27:38,266 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,266 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 246ms
2014-07-11 00:27:38,266 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 932.9m
2014-07-11 00:27:38,266 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,269 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 286ms
2014-07-11 00:27:38,269 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,281 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 375ms
2014-07-11 00:27:38,281 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,281 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 435ms
2014-07-11 00:27:38,281 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,281 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 500ms
2014-07-11 00:27:38,281 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,281 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 568ms
2014-07-11 00:27:38,281 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,290 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 646ms
2014-07-11 00:27:38,290 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,297 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 722ms
2014-07-11 00:27:38,297 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,297 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 793ms
2014-07-11 00:27:38,297 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,297 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1215ms
2014-07-11 00:27:38,297 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,300 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3612ms
2014-07-11 00:27:38,300 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,305 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3653ms
2014-07-11 00:27:38,305 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,305 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3690ms
2014-07-11 00:27:38,305 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,305 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3727ms
2014-07-11 00:27:38,305 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,308 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3766ms
2014-07-11 00:27:38,308 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,309 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3804ms
2014-07-11 00:27:38,309 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,309 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3840ms
2014-07-11 00:27:38,309 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,310 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3877ms
2014-07-11 00:27:38,310 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,310 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3920ms
2014-07-11 00:27:38,310 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,311 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3959ms
2014-07-11 00:27:38,312 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,312 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3961ms
2014-07-11 00:27:38,312 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,314 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3962ms
2014-07-11 00:27:38,314 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,314 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3963ms
2014-07-11 00:27:38,314 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,314 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3966ms
2014-07-11 00:27:38,315 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,315 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3969ms
2014-07-11 00:27:38,315 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,321 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3974ms
2014-07-11 00:27:38,321 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,321 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3974ms
2014-07-11 00:27:38,321 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,321 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3975ms
2014-07-11 00:27:38,321 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,321 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3975ms
2014-07-11 00:27:38,321 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,322 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3976ms
2014-07-11 00:27:38,322 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,331 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3985ms
2014-07-11 00:27:38,331 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,331 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4019ms
2014-07-11 00:27:38,331 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,380 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4105ms
2014-07-11 00:27:38,380 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,381 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4142ms
2014-07-11 00:27:38,381 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,383 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4155ms
2014-07-11 00:27:38,383 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,383 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4157ms
2014-07-11 00:27:38,383 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,385 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4162ms
2014-07-11 00:27:38,386 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,386 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4165ms
2014-07-11 00:27:38,386 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,387 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4166ms
2014-07-11 00:27:38,387 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,392 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4172ms
2014-07-11 00:27:38,392 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,392 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4172ms
2014-07-11 00:27:38,392 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,392 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4172ms
2014-07-11 00:27:38,392 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,400 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4180ms
2014-07-11 00:27:38,400 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,401 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4207ms
2014-07-11 00:27:38,401 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,401 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4265ms
2014-07-11 00:27:38,401 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,402 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4270ms
2014-07-11 00:27:38,402 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,413 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4278ms
2014-07-11 00:27:38,413 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,414 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4280ms
2014-07-11 00:27:38,414 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,421 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4289ms
2014-07-11 00:27:38,422 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:38,645 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:27:38,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:39,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18398 synced till here 18396
2014-07-11 00:27:40,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063654113 with entries=78, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063658998
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063569849
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063572515
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063576213
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063578664
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063580752
2014-07-11 00:27:40,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063582490
2014-07-11 00:27:40,486 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:42,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:42,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18509 synced till here 18476
2014-07-11 00:27:42,054 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3546, memsize=363.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/0d432622e5ca43509891ab57cd5e0123
2014-07-11 00:27:42,068 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/0d432622e5ca43509891ab57cd5e0123 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/0d432622e5ca43509891ab57cd5e0123
2014-07-11 00:27:42,080 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/0d432622e5ca43509891ab57cd5e0123, entries=1323560, sequenceid=3546, filesize=94.2m
2014-07-11 00:27:42,080 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~652.4m/684109200, currentsize=276.2m/289640000 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 21905ms, sequenceid=3546, compaction requested=true
2014-07-11 00:27:42,080 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-11 00:27:42,081 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 568.9m
2014-07-11 00:27:42,265 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:27:42,286 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063658998 with entries=111, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063662019
2014-07-11 00:27:42,881 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:43,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:43,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18622 synced till here 18583
2014-07-11 00:27:44,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063662019 with entries=113, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063663732
2014-07-11 00:27:44,465 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44838","starttimems":1405063654129,"queuetimems":0,"class":"HRegionServer","responsesize":19412,"method":"Multi"}
2014-07-11 00:27:44,474 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10200,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44838","starttimems":1405063654273,"queuetimems":1,"class":"HRegionServer","responsesize":19937,"method":"Multi"}
2014-07-11 00:27:45,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:45,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18715 synced till here 18695
2014-07-11 00:27:46,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063663732 with entries=93, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063665809
2014-07-11 00:27:47,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:48,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18851 synced till here 18848
2014-07-11 00:27:50,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063665809 with entries=136, filesize=116.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063667514
2014-07-11 00:27:51,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:51,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18925 synced till here 18924
2014-07-11 00:27:51,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063667514 with entries=74, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063671073
2014-07-11 00:27:52,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:52,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19003 synced till here 18999
2014-07-11 00:27:52,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063671073 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063672702
2014-07-11 00:27:52,820 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/b02c07c0f39b433a80b7496e299caf4c as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/b02c07c0f39b433a80b7496e299caf4c
2014-07-11 00:27:52,871 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:27:52,883 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1ad113eabac841508df3fa066cf2b986, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1ad113eabac841508df3fa066cf2b986
2014-07-11 00:27:52,887 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/6d51cbcc1c7a4e1499f3fba8b075a8a6, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/6d51cbcc1c7a4e1499f3fba8b075a8a6
2014-07-11 00:27:52,891 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1229755b8a954b6ab7f30cc301664634, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/1229755b8a954b6ab7f30cc301664634
2014-07-11 00:27:52,895 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/34fb7d4a6a084a4b81bbf31b623779b3, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/34fb7d4a6a084a4b81bbf31b623779b3
2014-07-11 00:27:52,899 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/13083441607248d0a0bace212943021b, to hdfs://master:54310/hbase/archive/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/13083441607248d0a0bace212943021b
2014-07-11 00:27:52,900 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. into b02c07c0f39b433a80b7496e299caf4c(size=308.4m), total size for store is 396.8m. This selection was in queue for 0sec, and took 1mins, 17sec to execute.
2014-07-11 00:27:52,900 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., storeName=family, fileCount=5, fileSize=341.8m, priority=15, time=17502415903112; duration=1mins, 17sec
2014-07-11 00:27:52,900 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-11 00:27:52,901 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-11 00:27:52,901 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 6 files of size 505284174 starting at candidate #0 after considering 10 permutations with 10 in ratio
2014-07-11 00:27:52,901 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: a575cf61a8e56ddc4885c72863b830c2 - family: Initiating major compaction
2014-07-11 00:27:52,901 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:27:52,902 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 6 file(s) in family of usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp, totalSize=481.9m
2014-07-11 00:27:52,902 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/307b4d4bfec945a4916fa8daf240f68d, keycount=183627, bloomtype=ROW, size=130.9m, encoding=NONE, seqNum=1016, earliestPutTs=1405063231664
2014-07-11 00:27:52,902 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/4344ece50c764275a27ba567417daf26, keycount=83814, bloomtype=ROW, size=59.7m, encoding=NONE, seqNum=1427, earliestPutTs=1405063359637
2014-07-11 00:27:52,902 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/7b5e2888e10d44ff9ad5e43d4b6ae45b, keycount=45292, bloomtype=ROW, size=32.3m, encoding=NONE, seqNum=1825, earliestPutTs=1405063400843
2014-07-11 00:27:52,902 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f3af3b782d074b5b9bafb9a83f1b1921, keycount=129968, bloomtype=ROW, size=92.6m, encoding=NONE, seqNum=2311, earliestPutTs=1405063450681
2014-07-11 00:27:52,902 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f9477dd4a2cb4acd8fae3e1973a92564, keycount=127362, bloomtype=ROW, size=90.7m, encoding=NONE, seqNum=2884, earliestPutTs=1405063506270
2014-07-11 00:27:52,903 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/16b53f1aedaa4e609b1e2b7a86858a50, keycount=106253, bloomtype=ROW, size=75.6m, encoding=NONE, seqNum=3325, earliestPutTs=1405063567058
2014-07-11 00:27:52,996 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:54,050 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:54,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19079 synced till here 19076
2014-07-11 00:27:54,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063672702 with entries=76, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063674051
2014-07-11 00:27:55,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:55,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19152 synced till here 19151
2014-07-11 00:27:55,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063674051 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063675357
2014-07-11 00:27:56,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:56,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19229 synced till here 19223
2014-07-11 00:27:56,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063675357 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063676733
2014-07-11 00:27:57,122 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,144 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,170 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,180 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,181 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,228 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,243 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,260 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,261 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,326 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,405 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,469 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,543 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,587 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:57,601 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3698, memsize=261.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/a93bf6d55a3a45d5ad5341c3ae0d4df8
2014-07-11 00:27:58,133 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:58,137 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/a93bf6d55a3a45d5ad5341c3ae0d4df8 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/a93bf6d55a3a45d5ad5341c3ae0d4df8
2014-07-11 00:27:58,146 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:27:58,153 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/a93bf6d55a3a45d5ad5341c3ae0d4df8, entries=951810, sequenceid=3698, filesize=67.8m
2014-07-11 00:27:58,153 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~578.3m/606346400, currentsize=252.0m/264286720 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 16072ms, sequenceid=3698, compaction requested=false
2014-07-11 00:27:58,154 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8ms
2014-07-11 00:27:58,154 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,154 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21ms
2014-07-11 00:27:58,154 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,154 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 911.2m
2014-07-11 00:27:58,154 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 567ms
2014-07-11 00:27:58,154 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,154 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 611ms
2014-07-11 00:27:58,154 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,155 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 686ms
2014-07-11 00:27:58,155 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,155 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 750ms
2014-07-11 00:27:58,155 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,157 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 831ms
2014-07-11 00:27:58,157 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,157 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 896ms
2014-07-11 00:27:58,157 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,157 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 898ms
2014-07-11 00:27:58,157 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,157 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 914ms
2014-07-11 00:27:58,158 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,158 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 930ms
2014-07-11 00:27:58,158 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,164 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 983ms
2014-07-11 00:27:58,164 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,164 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 984ms
2014-07-11 00:27:58,164 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,164 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 994ms
2014-07-11 00:27:58,164 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,173 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1029ms
2014-07-11 00:27:58,173 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,173 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1051ms
2014-07-11 00:27:58,173 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:27:58,477 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:27:58,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:27:58,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19327 synced till here 19310
2014-07-11 00:27:59,082 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:27:59,195 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063676733 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063678780
2014-07-11 00:28:00,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:02,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19450 synced till here 19416
2014-07-11 00:28:02,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063678780 with entries=123, filesize=105.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063680799
2014-07-11 00:28:04,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:04,386 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19557 synced till here 19539
2014-07-11 00:28:04,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063680799 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063684315
2014-07-11 00:28:06,235 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1307ms
GC pool 'ParNew' had collection(s): count=1 time=1451ms
2014-07-11 00:28:06,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:06,817 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,819 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,822 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,823 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,824 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,824 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,825 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,825 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,826 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,828 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,828 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,831 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,832 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19646 synced till here 19629
2014-07-11 00:28:06,843 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,898 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:06,954 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,005 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,006 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,007 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,007 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,009 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,015 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,015 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,016 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,016 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,016 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,017 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,017 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,019 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,019 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063684315 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063686797
2014-07-11 00:28:07,019 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,019 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,019 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,020 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,020 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,040 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,047 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,081 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,083 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,099 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,108 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,108 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,108 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,152 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,207 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,264 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,311 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,364 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,410 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,459 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:07,510 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:08,826 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1089ms
GC pool 'ParNew' had collection(s): count=1 time=1240ms
2014-07-11 00:28:10,803 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3677, memsize=471.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/963f41d225bc4a8fb2b03b9acf82e8cc
2014-07-11 00:28:10,825 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/963f41d225bc4a8fb2b03b9acf82e8cc as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/963f41d225bc4a8fb2b03b9acf82e8cc
2014-07-11 00:28:10,838 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/963f41d225bc4a8fb2b03b9acf82e8cc, entries=1715290, sequenceid=3677, filesize=122.1m
2014-07-11 00:28:10,839 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~932.9m/978250400, currentsize=405.2m/424880400 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 32573ms, sequenceid=3677, compaction requested=true
2014-07-11 00:28:10,839 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-11 00:28:10,839 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-11 00:28:10,839 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,839 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 742.0m
2014-07-11 00:28:10,839 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3380ms
2014-07-11 00:28:10,840 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,840 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3431ms
2014-07-11 00:28:10,840 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,840 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3476ms
2014-07-11 00:28:10,840 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,840 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3529ms
2014-07-11 00:28:10,840 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,840 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3576ms
2014-07-11 00:28:10,841 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,841 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3634ms
2014-07-11 00:28:10,841 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,841 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3689ms
2014-07-11 00:28:10,841 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,842 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3733ms
2014-07-11 00:28:10,842 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,843 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3735ms
2014-07-11 00:28:10,843 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,849 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3741ms
2014-07-11 00:28:10,849 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,854 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3755ms
2014-07-11 00:28:10,854 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,854 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3771ms
2014-07-11 00:28:10,854 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,854 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3773ms
2014-07-11 00:28:10,855 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,858 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3811ms
2014-07-11 00:28:10,858 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,865 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3825ms
2014-07-11 00:28:10,865 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,873 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3853ms
2014-07-11 00:28:10,873 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,875 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3856ms
2014-07-11 00:28:10,885 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,886 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3866ms
2014-07-11 00:28:10,886 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,887 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3867ms
2014-07-11 00:28:10,887 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,887 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3869ms
2014-07-11 00:28:10,887 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,887 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3869ms
2014-07-11 00:28:10,888 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,888 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3872ms
2014-07-11 00:28:10,888 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,888 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3872ms
2014-07-11 00:28:10,888 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,888 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3875ms
2014-07-11 00:28:10,888 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,890 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3874ms
2014-07-11 00:28:10,890 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,891 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3876ms
2014-07-11 00:28:10,891 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,892 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3876ms
2014-07-11 00:28:10,892 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,896 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3886ms
2014-07-11 00:28:10,896 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,896 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3887ms
2014-07-11 00:28:10,896 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,905 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3898ms
2014-07-11 00:28:10,905 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,913 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3906ms
2014-07-11 00:28:10,913 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,914 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3907ms
2014-07-11 00:28:10,914 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,914 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3909ms
2014-07-11 00:28:10,914 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,915 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3960ms
2014-07-11 00:28:10,915 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,922 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4023ms
2014-07-11 00:28:10,922 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,923 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4079ms
2014-07-11 00:28:10,923 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,925 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4093ms
2014-07-11 00:28:10,925 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,926 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4095ms
2014-07-11 00:28:10,926 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,933 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4105ms
2014-07-11 00:28:10,933 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,933 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4106ms
2014-07-11 00:28:10,933 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,934 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4108ms
2014-07-11 00:28:10,934 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,935 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4110ms
2014-07-11 00:28:10,935 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,936 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4111ms
2014-07-11 00:28:10,936 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,937 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4112ms
2014-07-11 00:28:10,937 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,937 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4113ms
2014-07-11 00:28:10,937 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,938 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4114ms
2014-07-11 00:28:10,938 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,939 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4116ms
2014-07-11 00:28:10,939 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,941 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4122ms
2014-07-11 00:28:10,941 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:10,941 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4124ms
2014-07-11 00:28:10,941 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:12,262 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:28:12,306 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10094,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44838","starttimems":1405063682212,"queuetimems":1,"class":"HRegionServer","responsesize":19785,"method":"Multi"}
2014-07-11 00:28:12,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:12,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19753 synced till here 19723
2014-07-11 00:28:12,679 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10523,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44838","starttimems":1405063682155,"queuetimems":0,"class":"HRegionServer","responsesize":19706,"method":"Multi"}
2014-07-11 00:28:12,700 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:28:12,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063686797 with entries=107, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063692485
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063584160
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063592820
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063594544
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063595703
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063597136
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063599326
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063602175
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063603138
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063604602
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063606043
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063607410
2014-07-11 00:28:12,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063609464
2014-07-11 00:28:14,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:14,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19857 synced till here 19827
2014-07-11 00:28:14,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063692485 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063694160
2014-07-11 00:28:16,052 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:16,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19970 synced till here 19928
2014-07-11 00:28:16,678 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063694160 with entries=113, filesize=97.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063696052
2014-07-11 00:28:18,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:18,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20069 synced till here 20064
2014-07-11 00:28:18,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063696052 with entries=99, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063698900
2014-07-11 00:28:20,627 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:20,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063698900 with entries=72, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063700628
2014-07-11 00:28:22,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:22,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20219 synced till here 20215
2014-07-11 00:28:22,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063700628 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063702175
2014-07-11 00:28:22,375 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,376 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,377 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,378 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,383 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,397 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,412 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,417 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,434 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,453 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,453 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,467 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,477 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,537 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,579 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,621 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,666 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,709 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,751 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:22,792 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,334 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,373 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,410 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,449 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,487 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,582 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,620 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,660 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,701 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,739 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,776 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,813 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,851 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,889 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,926 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:24,963 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:25,037 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:28:25,593 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3863, memsize=346.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/a24c8a7011bd427892ce591778c92f1a
2014-07-11 00:28:25,613 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/a24c8a7011bd427892ce591778c92f1a as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/a24c8a7011bd427892ce591778c92f1a
2014-07-11 00:28:25,631 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/a24c8a7011bd427892ce591778c92f1a, entries=1262120, sequenceid=3863, filesize=89.9m
2014-07-11 00:28:25,632 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~911.2m/955431040, currentsize=300.8m/315363120 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 27478ms, sequenceid=3863, compaction requested=true
2014-07-11 00:28:25,632 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-11 00:28:25,633 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 595ms
2014-07-11 00:28:25,633 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,633 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 670ms
2014-07-11 00:28:25,633 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 806.2m
2014-07-11 00:28:25,633 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,633 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 707ms
2014-07-11 00:28:25,633 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,641 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 752ms
2014-07-11 00:28:25,641 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,647 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 795ms
2014-07-11 00:28:25,647 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,649 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 836ms
2014-07-11 00:28:25,649 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,649 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 873ms
2014-07-11 00:28:25,649 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,657 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 918ms
2014-07-11 00:28:25,657 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,657 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 956ms
2014-07-11 00:28:25,657 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,657 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 997ms
2014-07-11 00:28:25,657 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,663 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1043ms
2014-07-11 00:28:25,663 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,664 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1082ms
2014-07-11 00:28:25,664 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,665 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1178ms
2014-07-11 00:28:25,666 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,672 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1223ms
2014-07-11 00:28:25,672 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,672 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1262ms
2014-07-11 00:28:25,672 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,681 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1309ms
2014-07-11 00:28:25,681 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1347ms
2014-07-11 00:28:25,681 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,682 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2890ms
2014-07-11 00:28:25,682 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,682 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2931ms
2014-07-11 00:28:25,682 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,682 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2973ms
2014-07-11 00:28:25,683 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,684 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3017ms
2014-07-11 00:28:25,684 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,684 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3063ms
2014-07-11 00:28:25,684 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,689 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3111ms
2014-07-11 00:28:25,689 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,690 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3152ms
2014-07-11 00:28:25,690 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,691 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3214ms
2014-07-11 00:28:25,691 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,691 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3225ms
2014-07-11 00:28:25,691 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,705 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3252ms
2014-07-11 00:28:25,707 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,714 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3260ms
2014-07-11 00:28:25,714 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,715 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3280ms
2014-07-11 00:28:25,715 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,715 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3298ms
2014-07-11 00:28:25,715 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,722 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3309ms
2014-07-11 00:28:25,722 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,723 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3325ms
2014-07-11 00:28:25,723 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,724 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3340ms
2014-07-11 00:28:25,724 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,725 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3346ms
2014-07-11 00:28:25,725 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,725 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3348ms
2014-07-11 00:28:25,725 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,725 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3350ms
2014-07-11 00:28:25,725 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:25,737 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3362ms
2014-07-11 00:28:25,737 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:28:26,120 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:28:26,568 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:28,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20327 synced till here 20319
2014-07-11 00:28:28,092 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:28:28,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063702175 with entries=108, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063706575
2014-07-11 00:28:28,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063610995
2014-07-11 00:28:28,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063612770
2014-07-11 00:28:28,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063614874
2014-07-11 00:28:28,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063616390
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063617830
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063619064
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063620436
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063621580
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063622963
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063624908
2014-07-11 00:28:28,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063627411
2014-07-11 00:28:29,779 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.53 MB, free=3.95 GB, max=3.96 GB, blocks=5, accesses=73251, hits=19647, hitRatio=26.82%, , cachingAccesses=19659, cachingHits=19640, cachingHitsRatio=99.90%, evictions=0, evicted=14, evictedPerRun=Infinity
2014-07-11 00:28:29,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:29,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20422 synced till here 20404
2014-07-11 00:28:30,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063706575 with entries=95, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063709902
2014-07-11 00:28:30,743 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3949, memsize=248.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/61ce9d40c0a9431d8414250d6bbb9b09
2014-07-11 00:28:30,761 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/61ce9d40c0a9431d8414250d6bbb9b09 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/61ce9d40c0a9431d8414250d6bbb9b09
2014-07-11 00:28:30,774 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/61ce9d40c0a9431d8414250d6bbb9b09, entries=905750, sequenceid=3949, filesize=64.5m
2014-07-11 00:28:30,774 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~742.0m/778094640, currentsize=249.5m/261589040 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 19935ms, sequenceid=3949, compaction requested=true
2014-07-11 00:28:30,774 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-11 00:28:30,775 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 626.1m
2014-07-11 00:28:30,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:30,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20500 synced till here 20494
2014-07-11 00:28:31,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063709902 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063710878
2014-07-11 00:28:31,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063629240
2014-07-11 00:28:31,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063634461
2014-07-11 00:28:31,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063636492
2014-07-11 00:28:31,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063639397
2014-07-11 00:28:31,898 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:28:32,362 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:28:32,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:33,227 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20576 synced till here 20575
2014-07-11 00:28:33,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063710878 with entries=76, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063712870
2014-07-11 00:28:34,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:34,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063712870 with entries=75, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063714047
2014-07-11 00:28:35,471 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:35,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20724 synced till here 20722
2014-07-11 00:28:35,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063714047 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063715471
2014-07-11 00:28:37,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:37,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20808 synced till here 20805
2014-07-11 00:28:37,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063715471 with entries=84, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063717161
2014-07-11 00:28:38,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:39,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20905 synced till here 20904
2014-07-11 00:28:39,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063717161 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063718593
2014-07-11 00:28:41,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:41,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20992 synced till here 20979
2014-07-11 00:28:41,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063718593 with entries=87, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063721486
2014-07-11 00:28:42,260 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4106, memsize=169.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/022ae300f75446d4a4d120deb4ecd07c
2014-07-11 00:28:42,282 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/022ae300f75446d4a4d120deb4ecd07c as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/022ae300f75446d4a4d120deb4ecd07c
2014-07-11 00:28:42,303 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/022ae300f75446d4a4d120deb4ecd07c, entries=616450, sequenceid=4106, filesize=43.9m
2014-07-11 00:28:42,304 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~632.4m/663073760, currentsize=167.9m/176005200 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 11528ms, sequenceid=4106, compaction requested=false
2014-07-11 00:28:42,304 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 831.2m
2014-07-11 00:28:43,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:43,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21085 synced till here 21071
2014-07-11 00:28:43,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063721486 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063723381
2014-07-11 00:28:45,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:45,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21175 synced till here 21160
2014-07-11 00:28:45,343 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:28:45,454 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063723381 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063725311
2014-07-11 00:28:46,806 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4064, memsize=264.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4c600a5c560847feb18e1d583468989b
2014-07-11 00:28:46,831 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4c600a5c560847feb18e1d583468989b as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4c600a5c560847feb18e1d583468989b
2014-07-11 00:28:46,852 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4c600a5c560847feb18e1d583468989b, entries=963490, sequenceid=4064, filesize=68.6m
2014-07-11 00:28:46,853 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~806.2m/845350640, currentsize=316.5m/331862240 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 21220ms, sequenceid=4064, compaction requested=true
2014-07-11 00:28:46,853 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-11 00:28:46,854 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 600.6m
2014-07-11 00:28:46,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:46,901 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:28:46,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21266 synced till here 21252
2014-07-11 00:28:47,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063725311 with entries=91, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063726900
2014-07-11 00:28:47,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063640802
2014-07-11 00:28:47,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063642767
2014-07-11 00:28:47,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063643540
2014-07-11 00:28:47,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063644672
2014-07-11 00:28:47,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063645912
2014-07-11 00:28:47,053 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063647369
2014-07-11 00:28:47,053 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063649168
2014-07-11 00:28:47,053 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063652226
2014-07-11 00:28:47,620 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:28:47,730 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:28:47,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:47,840 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21341 synced till here 21337
2014-07-11 00:28:47,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063726900 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063727819
2014-07-11 00:28:49,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21421 synced till here 21415
2014-07-11 00:28:50,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063727819 with entries=80, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063729802
2014-07-11 00:28:51,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:52,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21513 synced till here 21495
2014-07-11 00:28:52,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063729802 with entries=92, filesize=79.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063731357
2014-07-11 00:28:53,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:53,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21599 synced till here 21590
2014-07-11 00:28:54,022 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063731357 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063733936
2014-07-11 00:28:54,834 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:54,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21673 synced till here 21670
2014-07-11 00:28:55,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063733936 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063734835
2014-07-11 00:28:56,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:28:58,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21821 synced till here 21810
2014-07-11 00:28:58,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063734835 with entries=148, filesize=126.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063736644
2014-07-11 00:28:59,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:00,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21900 synced till here 21893
2014-07-11 00:29:00,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063736644 with entries=79, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063739983
2014-07-11 00:29:01,393 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:01,413 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4263, memsize=172.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/4805382bb7aa4998a691f360370f5c3e
2014-07-11 00:29:01,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21978 synced till here 21971
2014-07-11 00:29:01,427 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/4805382bb7aa4998a691f360370f5c3e as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/4805382bb7aa4998a691f360370f5c3e
2014-07-11 00:29:01,442 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/4805382bb7aa4998a691f360370f5c3e, entries=629400, sequenceid=4263, filesize=44.9m
2014-07-11 00:29:01,443 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~619.3m/649380240, currentsize=218.8m/229459200 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 14590ms, sequenceid=4263, compaction requested=true
2014-07-11 00:29:01,443 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-11 00:29:01,444 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 706.4m
2014-07-11 00:29:01,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063739983 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063741393
2014-07-11 00:29:02,756 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:02,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:02,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22058 synced till here 22055
2014-07-11 00:29:02,842 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063741393 with entries=80, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063742770
2014-07-11 00:29:03,177 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:29:04,348 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:04,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22155 synced till here 22153
2014-07-11 00:29:04,657 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4228, memsize=271.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/98a18dedc24a4ef6bd99116d316084ca
2014-07-11 00:29:04,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063742770 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063744348
2014-07-11 00:29:04,714 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/98a18dedc24a4ef6bd99116d316084ca as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/98a18dedc24a4ef6bd99116d316084ca
2014-07-11 00:29:04,728 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/98a18dedc24a4ef6bd99116d316084ca, entries=987640, sequenceid=4228, filesize=70.3m
2014-07-11 00:29:04,729 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~844.9m/885955040, currentsize=334.4m/350670320 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 22424ms, sequenceid=4228, compaction requested=true
2014-07-11 00:29:04,729 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-11 00:29:04,730 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 593.4m
2014-07-11 00:29:04,781 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:29:05,749 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:05,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:05,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22239 synced till here 22228
2014-07-11 00:29:05,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063744348 with entries=84, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063745841
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063654113
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063658998
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063662019
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063663732
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063665809
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063667514
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063671073
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063672702
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063674051
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063675357
2014-07-11 00:29:05,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063676733
2014-07-11 00:29:05,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063678780
2014-07-11 00:29:05,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063680799
2014-07-11 00:29:05,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063684315
2014-07-11 00:29:07,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:07,354 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22316 synced till here 22312
2014-07-11 00:29:07,591 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063745841 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063747321
2014-07-11 00:29:09,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:10,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22444 synced till here 22433
2014-07-11 00:29:10,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063747321 with entries=128, filesize=107.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063749040
2014-07-11 00:29:12,689 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1016ms
GC pool 'ParNew' had collection(s): count=1 time=1094ms
2014-07-11 00:29:13,132 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:13,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22541 synced till here 22527
2014-07-11 00:29:13,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063749040 with entries=97, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063753132
2014-07-11 00:29:15,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:15,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22649 synced till here 22639
2014-07-11 00:29:15,557 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063753132 with entries=108, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063755357
2014-07-11 00:29:18,765 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:18,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22769 synced till here 22749
2014-07-11 00:29:18,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063755357 with entries=120, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063758766
2014-07-11 00:29:21,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:21,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22890 synced till here 22868
2014-07-11 00:29:21,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063758766 with entries=121, filesize=101.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063761052
2014-07-11 00:29:23,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:23,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23008 synced till here 22964
2014-07-11 00:29:24,753 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4408, memsize=267.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/a5e000d6d75f459e9c86df92f70b72e6
2014-07-11 00:29:24,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063761052 with entries=118, filesize=99.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063763147
2014-07-11 00:29:24,913 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/a5e000d6d75f459e9c86df92f70b72e6 as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/a5e000d6d75f459e9c86df92f70b72e6
2014-07-11 00:29:25,034 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/a5e000d6d75f459e9c86df92f70b72e6, entries=973640, sequenceid=4408, filesize=69.4m
2014-07-11 00:29:25,035 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~708.1m/742485360, currentsize=318.0m/333464160 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 23591ms, sequenceid=4408, compaction requested=true
2014-07-11 00:29:25,035 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-11 00:29:25,036 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 764.2m
2014-07-11 00:29:25,120 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:29:26,947 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:26,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23123 synced till here 23091
2014-07-11 00:29:27,417 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063763147 with entries=115, filesize=96.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063766948
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063686797
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063692485
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063694160
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063696052
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063698900
2014-07-11 00:29:27,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063700628
2014-07-11 00:29:27,489 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:29,345 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:29,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23231 synced till here 23197
2014-07-11 00:29:29,934 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063766948 with entries=108, filesize=91.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063769345
2014-07-11 00:29:31,192 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4451, memsize=297.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/cb6d28c3fff54f2b9485fbeeeb02d4b5
2014-07-11 00:29:31,207 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/cb6d28c3fff54f2b9485fbeeeb02d4b5 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/cb6d28c3fff54f2b9485fbeeeb02d4b5
2014-07-11 00:29:31,220 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/cb6d28c3fff54f2b9485fbeeeb02d4b5, entries=1083050, sequenceid=4451, filesize=77.1m
2014-07-11 00:29:31,220 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~596.5m/625526640, currentsize=343.0m/359711920 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 26490ms, sequenceid=4451, compaction requested=true
2014-07-11 00:29:31,220 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-11 00:29:31,221 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 585.2m
2014-07-11 00:29:31,303 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:29:31,860 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:31,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23336 synced till here 23304
2014-07-11 00:29:32,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063769345 with entries=105, filesize=88.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063771861
2014-07-11 00:29:32,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063702175
2014-07-11 00:29:32,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063706575
2014-07-11 00:29:33,362 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:33,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:33,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23440 synced till here 23413
2014-07-11 00:29:34,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063771861 with entries=104, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063773942
2014-07-11 00:29:35,598 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:35,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23534 synced till here 23516
2014-07-11 00:29:35,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063773942 with entries=94, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063775599
2014-07-11 00:29:37,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:37,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23610 synced till here 23608
2014-07-11 00:29:37,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063775599 with entries=76, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063777026
2014-07-11 00:29:39,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:39,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23685 synced till here 23684
2014-07-11 00:29:39,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063777026 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063779020
2014-07-11 00:29:40,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:41,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063779020 with entries=124, filesize=106.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063780708
2014-07-11 00:29:42,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:42,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23890 synced till here 23887
2014-07-11 00:29:43,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063780708 with entries=81, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063782801
2014-07-11 00:29:44,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:44,886 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23965 synced till here 23963
2014-07-11 00:29:44,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063782801 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063784865
2014-07-11 00:29:46,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:46,471 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,472 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,488 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,488 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,492 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,493 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24041 synced till here 24039
2014-07-11 00:29:46,514 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063784865 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063786463
2014-07-11 00:29:46,534 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,544 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,572 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,583 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,626 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,685 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,751 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,791 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:46,831 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:47,516 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:47,677 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:29:48,511 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4660, memsize=280.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/3ce306c09e9a411d87cdbb2413e6bb81
2014-07-11 00:29:48,526 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/3ce306c09e9a411d87cdbb2413e6bb81 as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/3ce306c09e9a411d87cdbb2413e6bb81
2014-07-11 00:29:48,537 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/3ce306c09e9a411d87cdbb2413e6bb81, entries=1021040, sequenceid=4660, filesize=72.7m
2014-07-11 00:29:48,537 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~610.2m/639830400, currentsize=246.1m/258008160 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 17317ms, sequenceid=4660, compaction requested=true
2014-07-11 00:29:48,538 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-11 00:29:48,538 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1010ms
2014-07-11 00:29:48,538 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,538 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 911.4m
2014-07-11 00:29:48,538 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1023ms
2014-07-11 00:29:48,538 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,541 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1710ms
2014-07-11 00:29:48,541 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,542 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1751ms
2014-07-11 00:29:48,543 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,543 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1792ms
2014-07-11 00:29:48,543 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,543 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1858ms
2014-07-11 00:29:48,543 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,543 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1917ms
2014-07-11 00:29:48,543 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,545 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1962ms
2014-07-11 00:29:48,545 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,545 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1973ms
2014-07-11 00:29:48,545 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,545 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2001ms
2014-07-11 00:29:48,545 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,545 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2011ms
2014-07-11 00:29:48,546 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,549 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2035ms
2014-07-11 00:29:48,549 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,553 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2060ms
2014-07-11 00:29:48,553 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,553 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-11 00:29:48,553 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,557 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2069ms
2014-07-11 00:29:48,557 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,558 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2070ms
2014-07-11 00:29:48,558 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,560 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2088ms
2014-07-11 00:29:48,560 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:48,561 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2090ms
2014-07-11 00:29:48,561 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:29:49,153 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:29:50,009 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:50,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24132 synced till here 24117
2014-07-11 00:29:50,055 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:50,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063786463 with entries=91, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063790010
2014-07-11 00:29:50,423 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4615, memsize=380.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/be0da109405045e3805a30efa99c852f
2014-07-11 00:29:50,437 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/be0da109405045e3805a30efa99c852f as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/be0da109405045e3805a30efa99c852f
2014-07-11 00:29:50,465 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/be0da109405045e3805a30efa99c852f, entries=1385600, sequenceid=4615, filesize=98.7m
2014-07-11 00:29:50,466 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~784.4m/822478000, currentsize=338.8m/355274560 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 25431ms, sequenceid=4615, compaction requested=true
2014-07-11 00:29:50,466 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-11 00:29:50,466 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 659.6m
2014-07-11 00:29:50,490 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:29:50,655 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/c20944c1a6bf444796765443e538dd1f as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/c20944c1a6bf444796765443e538dd1f
2014-07-11 00:29:50,711 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Removing store files after compaction...
2014-07-11 00:29:50,744 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/307b4d4bfec945a4916fa8daf240f68d, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/307b4d4bfec945a4916fa8daf240f68d
2014-07-11 00:29:50,763 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/4344ece50c764275a27ba567417daf26, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/4344ece50c764275a27ba567417daf26
2014-07-11 00:29:50,765 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/7b5e2888e10d44ff9ad5e43d4b6ae45b, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/7b5e2888e10d44ff9ad5e43d4b6ae45b
2014-07-11 00:29:50,768 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f3af3b782d074b5b9bafb9a83f1b1921, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f3af3b782d074b5b9bafb9a83f1b1921
2014-07-11 00:29:50,771 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f9477dd4a2cb4acd8fae3e1973a92564, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/f9477dd4a2cb4acd8fae3e1973a92564
2014-07-11 00:29:50,773 DEBUG [regionserver60020-smallCompactions-1405062846462] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/16b53f1aedaa4e609b1e2b7a86858a50, to hdfs://master:54310/hbase/archive/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/16b53f1aedaa4e609b1e2b7a86858a50
2014-07-11 00:29:50,774 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Completed major compaction of 6 file(s) in family of usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. into c20944c1a6bf444796765443e538dd1f(size=443.5m), total size for store is 653.9m. This selection was in queue for 0sec, and took 1mins, 57sec to execute.
2014-07-11 00:29:50,774 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., storeName=family, fileCount=6, fileSize=481.9m, priority=14, time=17580328384957; duration=1mins, 57sec
2014-07-11 00:29:50,774 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-11 00:29:50,774 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-11 00:29:50,775 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 8 files of size 710187747 starting at candidate #0 after considering 21 permutations with 19 in ratio
2014-07-11 00:29:50,775 DEBUG [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: cee2ff08fd3c0bc377dccf8be24cbd0f - family: Initiating major compaction
2014-07-11 00:29:50,776 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:29:50,776 INFO  [regionserver60020-smallCompactions-1405062846462] regionserver.HStore: Starting compaction of 8 file(s) in family of usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp, totalSize=677.3m
2014-07-11 00:29:50,776 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/35c5a8fa30bc40fabbd5bb418e0d3ba2, keycount=286876, bloomtype=ROW, size=204.4m, encoding=NONE, seqNum=1625, earliestPutTs=1405063230376
2014-07-11 00:29:50,776 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/f7ed972182334e87aef705eb42c6f381, keycount=70980, bloomtype=ROW, size=50.6m, encoding=NONE, seqNum=1947, earliestPutTs=1405063446202
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4990788c26cd4828bae08f0210638689, keycount=82633, bloomtype=ROW, size=58.9m, encoding=NONE, seqNum=2352, earliestPutTs=1405063464984
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/25509d4e37d6445d887b57887777e5e0, keycount=80458, bloomtype=ROW, size=57.3m, encoding=NONE, seqNum=2720, earliestPutTs=1405063505911
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/5b0b6f61f9ec4cd8aa18081bee0f0db0, keycount=92899, bloomtype=ROW, size=66.2m, encoding=NONE, seqNum=3122, earliestPutTs=1405063547402
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/0d432622e5ca43509891ab57cd5e0123, keycount=132356, bloomtype=ROW, size=94.2m, encoding=NONE, seqNum=3546, earliestPutTs=1405063595160
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4c600a5c560847feb18e1d583468989b, keycount=96349, bloomtype=ROW, size=68.6m, encoding=NONE, seqNum=4064, earliestPutTs=1405063641566
2014-07-11 00:29:50,777 DEBUG [regionserver60020-smallCompactions-1405062846462] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/cb6d28c3fff54f2b9485fbeeeb02d4b5, keycount=108305, bloomtype=ROW, size=77.1m, encoding=NONE, seqNum=4451, earliestPutTs=1405063709804
2014-07-11 00:29:51,054 DEBUG [regionserver60020-smallCompactions-1405062846462] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:51,226 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:51,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24207 synced till here 24204
2014-07-11 00:29:51,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063790010 with entries=75, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063791226
2014-07-11 00:29:51,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063709902
2014-07-11 00:29:51,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063710878
2014-07-11 00:29:51,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063712870
2014-07-11 00:29:51,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063714047
2014-07-11 00:29:51,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063715471
2014-07-11 00:29:51,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063717161
2014-07-11 00:29:51,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063718593
2014-07-11 00:29:51,379 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:29:52,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:53,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24327 synced till here 24322
2014-07-11 00:29:54,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063791226 with entries=120, filesize=102.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063792550
2014-07-11 00:29:55,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:55,578 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24402 synced till here 24399
2014-07-11 00:29:55,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063792550 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063795563
2014-07-11 00:29:57,070 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:57,093 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24478 synced till here 24474
2014-07-11 00:29:57,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063795563 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063797070
2014-07-11 00:29:58,534 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:58,565 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24554 synced till here 24552
2014-07-11 00:29:58,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063797070 with entries=76, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063798535
2014-07-11 00:29:59,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:29:59,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24635 synced till here 24632
2014-07-11 00:29:59,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063798535 with entries=81, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063799303
2014-07-11 00:30:01,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:01,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24718 synced till here 24711
2014-07-11 00:30:01,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063799303 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063801801
2014-07-11 00:30:03,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:03,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063801801 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063803016
2014-07-11 00:30:04,487 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:05,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24882 synced till here 24877
2014-07-11 00:30:05,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063803016 with entries=91, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063804487
2014-07-11 00:30:06,278 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,279 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,280 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,282 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,289 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,298 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,302 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,339 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,343 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,376 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,453 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,534 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,588 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,641 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,710 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,783 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:06,793 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4845, memsize=255.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/5c0a364b6b324f67a9be70feaba73f6f
2014-07-11 00:30:06,807 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/5c0a364b6b324f67a9be70feaba73f6f as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/5c0a364b6b324f67a9be70feaba73f6f
2014-07-11 00:30:06,850 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/5c0a364b6b324f67a9be70feaba73f6f, entries=931590, sequenceid=4845, filesize=66.4m
2014-07-11 00:30:06,851 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~664.3m/696577680, currentsize=241.9m/253642160 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 16385ms, sequenceid=4845, compaction requested=true
2014-07-11 00:30:06,851 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-11 00:30:06,851 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 69ms
2014-07-11 00:30:06,851 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,851 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 854.8m
2014-07-11 00:30:06,852 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 142ms
2014-07-11 00:30:06,852 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,852 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 211ms
2014-07-11 00:30:06,852 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,852 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 264ms
2014-07-11 00:30:06,853 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,853 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 319ms
2014-07-11 00:30:06,853 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,853 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 401ms
2014-07-11 00:30:06,853 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,853 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 477ms
2014-07-11 00:30:06,853 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,854 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 511ms
2014-07-11 00:30:06,854 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,854 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 515ms
2014-07-11 00:30:06,854 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,856 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 554ms
2014-07-11 00:30:06,856 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,856 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 559ms
2014-07-11 00:30:06,856 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:06,860 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 572ms
2014-07-11 00:30:06,860 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:07,697 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1415ms
2014-07-11 00:30:07,707 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:07,707 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1427ms
2014-07-11 00:30:07,707 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:07,707 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1429ms
2014-07-11 00:30:07,707 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:07,708 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1430ms
2014-07-11 00:30:07,708 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:07,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:07,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24966 synced till here 24953
2014-07-11 00:30:07,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063804487 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063807776
2014-07-11 00:30:08,140 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:30:08,445 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:30:09,596 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:09,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25054 synced till here 25038
2014-07-11 00:30:09,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063807776 with entries=88, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063809607
2014-07-11 00:30:10,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:10,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25128 synced till here 25127
2014-07-11 00:30:10,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063809607 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063810638
2014-07-11 00:30:11,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:12,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25203 synced till here 25202
2014-07-11 00:30:12,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063810638 with entries=75, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063811973
2014-07-11 00:30:12,872 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4820, memsize=371.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/cda66caa930a425f92036b4c6468117a
2014-07-11 00:30:12,887 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/cda66caa930a425f92036b4c6468117a as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/cda66caa930a425f92036b4c6468117a
2014-07-11 00:30:12,898 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/cda66caa930a425f92036b4c6468117a, entries=1354110, sequenceid=4820, filesize=96.4m
2014-07-11 00:30:12,899 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~911.4m/955647200, currentsize=364.4m/382048800 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 24361ms, sequenceid=4820, compaction requested=true
2014-07-11 00:30:12,899 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-11 00:30:12,899 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 614.6m
2014-07-11 00:30:12,947 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826.
2014-07-11 00:30:13,372 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:30:13,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:13,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25279 synced till here 25275
2014-07-11 00:30:13,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063811973 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063813501
2014-07-11 00:30:13,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063721486
2014-07-11 00:30:13,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063723381
2014-07-11 00:30:13,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063725311
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063726900
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063727819
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063729802
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063731357
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063733936
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063734835
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063736644
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063739983
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063741393
2014-07-11 00:30:13,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063742770
2014-07-11 00:30:14,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:14,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25352 synced till here 25350
2014-07-11 00:30:14,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063813501 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063814826
2014-07-11 00:30:16,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:16,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25430 synced till here 25426
2014-07-11 00:30:16,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063814826 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063816220
2014-07-11 00:30:17,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:18,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25528 synced till here 25518
2014-07-11 00:30:18,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063816220 with entries=98, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063817780
2014-07-11 00:30:19,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:19,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25606 synced till here 25604
2014-07-11 00:30:19,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063817780 with entries=78, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063819776
2014-07-11 00:30:21,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:21,225 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25682 synced till here 25677
2014-07-11 00:30:21,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063819776 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063821204
2014-07-11 00:30:22,730 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:22,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25758 synced till here 25754
2014-07-11 00:30:22,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063821204 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063822731
2014-07-11 00:30:24,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:24,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25837 synced till here 25835
2014-07-11 00:30:24,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063822731 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063824147
2014-07-11 00:30:25,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:25,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25925 synced till here 25916
2014-07-11 00:30:25,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063824147 with entries=88, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063825518
2014-07-11 00:30:26,364 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,377 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,378 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,411 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,424 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,431 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,914 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,934 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,958 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:26,994 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,589 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,637 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,691 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,735 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,783 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,828 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,873 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:28,919 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:29,883 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5009, memsize=403.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4bcf00f9e8df470f86eb6056742f2d34
2014-07-11 00:30:29,904 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/4bcf00f9e8df470f86eb6056742f2d34 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4bcf00f9e8df470f86eb6056742f2d34
2014-07-11 00:30:30,060 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/4bcf00f9e8df470f86eb6056742f2d34, entries=1467590, sequenceid=5009, filesize=104.5m
2014-07-11 00:30:30,060 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~854.8m/896286720, currentsize=309.7m/324771840 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 23209ms, sequenceid=5009, compaction requested=false
2014-07-11 00:30:30,061 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-11 00:30:30,061 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,062 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1188ms
2014-07-11 00:30:30,062 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,062 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2., current region memstore size 906.9m
2014-07-11 00:30:30,062 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1234ms
2014-07-11 00:30:30,062 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,062 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1280ms
2014-07-11 00:30:30,062 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,062 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1327ms
2014-07-11 00:30:30,063 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,063 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1372ms
2014-07-11 00:30:30,064 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,064 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1428ms
2014-07-11 00:30:30,064 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,065 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1476ms
2014-07-11 00:30:30,065 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,067 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3073ms
2014-07-11 00:30:30,068 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,068 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3110ms
2014-07-11 00:30:30,068 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,068 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3134ms
2014-07-11 00:30:30,068 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,069 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3155ms
2014-07-11 00:30:30,069 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,069 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3638ms
2014-07-11 00:30:30,069 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,069 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3645ms
2014-07-11 00:30:30,069 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,069 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3658ms
2014-07-11 00:30:30,069 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,070 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3692ms
2014-07-11 00:30:30,070 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,072 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3694ms
2014-07-11 00:30:30,072 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,072 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3708ms
2014-07-11 00:30:30,072 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:30,181 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f.
2014-07-11 00:30:30,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:30,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26015 synced till here 25999
2014-07-11 00:30:31,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063825518 with entries=90, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063830413
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063744348
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063745841
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063747321
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063749040
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063753132
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063755357
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063758766
2014-07-11 00:30:31,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063761052
2014-07-11 00:30:31,426 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:30:32,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:32,642 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26091 synced till here 26087
2014-07-11 00:30:32,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063830413 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063832112
2014-07-11 00:30:33,177 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5060, memsize=411.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/dc03c56963604fcaaedf547ef70e1fdf
2014-07-11 00:30:33,189 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/.tmp/dc03c56963604fcaaedf547ef70e1fdf as hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/dc03c56963604fcaaedf547ef70e1fdf
2014-07-11 00:30:33,200 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f41c69805823d0232eb4305b0b41c7e/family/dc03c56963604fcaaedf547ef70e1fdf, entries=1497300, sequenceid=5060, filesize=106.6m
2014-07-11 00:30:33,200 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~614.6m/644479440, currentsize=274.8m/288119840 for region usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e. in 20301ms, sequenceid=5060, compaction requested=true
2014-07-11 00:30:33,200 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-11 00:30:33,200 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 608.3m
2014-07-11 00:30:33,210 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e.
2014-07-11 00:30:33,424 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:33,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26166 synced till here 26164
2014-07-11 00:30:33,458 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063832112 with entries=75, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063833424
2014-07-11 00:30:34,133 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:30:34,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:34,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26239 synced till here 26237
2014-07-11 00:30:34,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063833424 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063834702
2014-07-11 00:30:36,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:36,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26319 synced till here 26318
2014-07-11 00:30:36,173 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063834702 with entries=80, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063836100
2014-07-11 00:30:37,552 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:37,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26404 synced till here 26401
2014-07-11 00:30:37,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063836100 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063837553
2014-07-11 00:30:39,418 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:39,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26480 synced till here 26479
2014-07-11 00:30:39,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063837553 with entries=76, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063839418
2014-07-11 00:30:40,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:40,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26554 synced till here 26553
2014-07-11 00:30:41,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063839418 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063840960
2014-07-11 00:30:42,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:42,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26637 synced till here 26635
2014-07-11 00:30:42,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063840960 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063842833
2014-07-11 00:30:44,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:44,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063842833 with entries=77, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063844602
2014-07-11 00:30:46,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:46,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063844602 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063846775
2014-07-11 00:30:48,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:48,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063846775 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063848607
2014-07-11 00:30:50,784 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:50,816 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:50,854 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:52,825 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:53,116 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405062809335: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 00:30:53,616 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5243, memsize=510.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/31d6338a0cda4003b60568000b85b39e
2014-07-11 00:30:53,632 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/.tmp/31d6338a0cda4003b60568000b85b39e as hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/31d6338a0cda4003b60568000b85b39e
2014-07-11 00:30:53,644 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/600e47c8102c939894f95b55fbbe3a1e/family/31d6338a0cda4003b60568000b85b39e, entries=1859670, sequenceid=5243, filesize=132.3m
2014-07-11 00:30:53,644 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~611.5m/641158800, currentsize=235.7m/247134480 for region usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e. in 20444ms, sequenceid=5243, compaction requested=true
2014-07-11 00:30:53,644 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-11 00:30:53,644 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 529ms
2014-07-11 00:30:53,644 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:53,645 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826., current region memstore size 884.4m
2014-07-11 00:30:53,645 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 820ms
2014-07-11 00:30:53,645 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:53,649 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2795ms
2014-07-11 00:30:53,649 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:53,649 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2833ms
2014-07-11 00:30:53,649 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:53,649 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2865ms
2014-07-11 00:30:53,649 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405062809335
2014-07-11 00:30:53,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:53,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26931 synced till here 26929
2014-07-11 00:30:53,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063848607 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063853724
2014-07-11 00:30:54,301 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:30:55,135 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e.
2014-07-11 00:30:55,666 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:30:56,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27013 synced till here 27012
2014-07-11 00:30:56,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063853724 with entries=82, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063855666
2014-07-11 00:30:57,277 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5206, memsize=622.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/163b9ef91c01430391f8070be98f32b9
2014-07-11 00:30:57,291 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/.tmp/163b9ef91c01430391f8070be98f32b9 as hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/163b9ef91c01430391f8070be98f32b9
2014-07-11 00:30:57,301 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a575cf61a8e56ddc4885c72863b830c2/family/163b9ef91c01430391f8070be98f32b9, entries=2267520, sequenceid=5206, filesize=161.4m
2014-07-11 00:30:57,301 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~906.9m/950913760, currentsize=327.1m/342984880 for region usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2. in 27239ms, sequenceid=5206, compaction requested=true
2014-07-11 00:30:57,301 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-11 00:30:57,301 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f., current region memstore size 632.3m
2014-07-11 00:30:57,492 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405063186548.a575cf61a8e56ddc4885c72863b830c2.
2014-07-11 00:30:57,767 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:31:00,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 00:31:00,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063855666 with entries=73, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063860607
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063763147
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063766948
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063769345
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063771861
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063773942
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063775599
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063777026
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063779020
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063780708
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063782801
2014-07-11 00:31:00,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405062809335/slave1%2C60020%2C1405062809335.1405063784865
2014-07-11 00:31:15,409 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5424, memsize=562.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/79886d90d23f4dfab437525e1ae6e7f4
2014-07-11 00:31:15,428 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/.tmp/79886d90d23f4dfab437525e1ae6e7f4 as hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/79886d90d23f4dfab437525e1ae6e7f4
2014-07-11 00:31:15,442 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/cee2ff08fd3c0bc377dccf8be24cbd0f/family/79886d90d23f4dfab437525e1ae6e7f4, entries=2049000, sequenceid=5424, filesize=145.9m
2014-07-11 00:31:15,443 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~633.8m/664615120, currentsize=24.3m/25461440 for region usertable,user1,1405063186548.cee2ff08fd3c0bc377dccf8be24cbd0f. in 18142ms, sequenceid=5424, compaction requested=false
2014-07-11 00:31:15,443 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405063186548.7f41c69805823d0232eb4305b0b41c7e., current region memstore size 581.5m
2014-07-11 00:31:15,877 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 00:31:18,342 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5396, memsize=753.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/d0cc5df85c78432ba391d15b7d1697b8
2014-07-11 00:31:18,364 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/.tmp/d0cc5df85c78432ba391d15b7d1697b8 as hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/d0cc5df85c78432ba391d15b7d1697b8
2014-07-11 00:31:18,381 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a814c9f2554f95576d7e3f7dd25bb826/family/d0cc5df85c78432ba391d15b7d1697b8, entries=2744490, sequenceid=5396, filesize=195.3m
2014-07-11 00:31:18,381 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~884.4m/927359600, currentsize=59.7m/62571920 for region usertable,user4,1405063186548.a814c9f2554f95576d7e3f7dd25bb826. in 24736ms, sequenceid=5396, compaction requested=true
2014-07-11 00:31:18,381 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-11 00:31:18,382 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405063186548.600e47c8102c939894f95b55fbbe3a1e., current region memstore size 293.4m
2014-07-11 00:31:18,584 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
