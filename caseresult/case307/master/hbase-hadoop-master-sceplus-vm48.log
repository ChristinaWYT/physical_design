Mon Aug  4 07:54:04 PDT 2014 Starting master on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-08-04 07:54:05,002 INFO  [main] util.VersionInfo: HBase 2.0.0-SNAPSHOT
2014-08-04 07:54:05,003 INFO  [main] util.VersionInfo: Subversion git://sceplus-vm48/home/hadoop/hbase-2.0.0-SNAPSHOT -r 50ac59fa8530bbd35c21cd61cfd64d2bd7d3eb57
2014-08-04 07:54:05,003 INFO  [main] util.VersionInfo: Compiled by hadoop on Sun Aug  3 14:37:33 PDT 2014
2014-08-04 07:54:05,285 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64/
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Dhbase.security.logger=INFO,RFAS
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.53 34936 22
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=12288
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-master.znode
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop
2014-08-04 07:54:05,286 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.53 34936 9.1.143.58 22
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-08-04 07:54:05,287 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-08-04 07:54:05,291 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-04 07:54:05,291 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-08-04 07:54:05,291 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-08-04 07:54:05,291 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-08-04 07:54:05,291 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=:/home/hadoop/hbase/selfdapql.jar
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-master.autorestart
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=2916
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-sceplus-vm48.log
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-sceplus-vm48
2014-08-04 07:54:05,292 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-08-04 07:54:05,295 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.51-b03
2014-08-04 07:54:05,296 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx12288m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Dhbase.security.logger=INFO,RFAS]
2014-08-04 07:54:05,744 INFO  [main] regionserver.RSRpcServices: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020 server-side HConnection retries=350
2014-08-04 07:54:05,961 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=5
2014-08-04 07:54:06,009 INFO  [main] ipc.RpcServer: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020: started 10 reader(s).
2014-08-04 07:54:06,130 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-08-04 07:54:06,146 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-08-04 07:54:06,239 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-08-04 07:54:06,239 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-08-04 07:54:06,481 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-08-04 07:54:06,487 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache size=4.76 GB, blockSize=64 KB
2014-08-04 07:54:06,511 INFO  [main] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 07:54:07,242 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-04 07:54:07,265 WARN  [main] trace.SpanReceiverHost: Class org.cloudera.htrace.impl.LocalFileSpanReceiver cannot be found. org.cloudera.htrace.impl.LocalFileSpanReceiver
2014-08-04 07:54:07,292 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_55
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-08-04 07:54:07,293 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop
2014-08-04 07:54:07,294 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=master:16020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 07:54:07,314 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 07:54:07,316 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 07:54:07,322 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-04 07:54:07,345 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147a18358d50000, negotiated timeout = 90000
2014-08-04 07:54:07,405 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-08-04 07:54:07,405 INFO  [RpcServer.listener,port=16020] ipc.RpcServer: RpcServer.listener,port=16020: starting
2014-08-04 07:54:07,493 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-08-04 07:54:07,498 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2014-08-04 07:54:07,513 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2014-08-04 07:54:07,516 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-08-04 07:54:07,516 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-08-04 07:54:07,517 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-08-04 07:54:07,538 INFO  [main] http.HttpServer: Jetty bound to port 16030
2014-08-04 07:54:07,538 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-04 07:54:07,925 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16030
2014-08-04 07:54:07,926 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:54310/hbase, hbase.cluster.distributed=true
2014-08-04 07:54:07,940 INFO  [main] master.HMaster: Adding ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407164046304 in backup master directory
2014-08-04 07:54:08,060 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-04 07:54:08,061 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2014-08-04 07:54:08,104 INFO  [ActiveMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407164046304 from backup master directory
2014-08-04 07:54:08,111 INFO  [ActiveMasterManager] master.ActiveMasterManager: Registered Active Master=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:08,248 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-04 07:54:18,253 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-04 07:54:28,827 INFO  [ActiveMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-04 07:54:28,844 INFO  [ActiveMasterManager] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=true
2014-08-04 07:54:28,847 INFO  [ActiveMasterManager] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-08-04 07:54:28,920 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x79195e17, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 07:54:28,921 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x79195e17 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 07:54:28,921 INFO  [ActiveMasterManager-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 07:54:28,922 INFO  [ActiveMasterManager-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-04 07:54:28,926 INFO  [ActiveMasterManager-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147a18358d50003, negotiated timeout = 90000
2014-08-04 07:54:29,075 INFO  [ActiveMasterManager] master.HMaster: Server active/primary master=sceplus-vm48.almaden.ibm.com,16020,1407164046304, sessionid=0x147a18358d50000, setting cluster-up flag (Was=false)
2014-08-04 07:54:29,079 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: ClusterId : 78c9dafc-f226-435b-aae6-e472cfc131f9
2014-08-04 07:54:29,102 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-08-04 07:54:29,108 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.8 G, globalMemStoreLimitLowMark=4.5 G, maxHeap=11.9 G
2014-08-04 07:54:29,115 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-08-04 07:54:29,133 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2014-08-04 07:54:29,139 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407164046304 with port=16020, startcode=1407164046304
2014-08-04 07:54:29,144 WARN  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2014-08-04 07:54:29,146 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 07:54:29,147 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 07:54:29,148 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 07:54:29,149 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-04 07:54:29,154 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47a1835bde0001, negotiated timeout = 90000
2014-08-04 07:54:29,181 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn false
2014-08-04 07:54:29,181 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407164046304 with port=16020, startcode=1407164046304
2014-08-04 07:54:29,196 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] master.ServerManager: Registering server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:29,231 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 50 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-04 07:54:29,239 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-04 07:54:29,547 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: Slow sync cost: 236 ms, current pipeline: []
2014-08-04 07:54:29,547 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407164069249
2014-08-04 07:54:29,589 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-08-04 07:54:29,603 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,16020,1407164046304] other RSs: [sceplus-vm48.almaden.ibm.com,16020,1407164046304, sceplus-vm49.almaden.ibm.com,16020,1407164047423]
2014-08-04 07:54:29,640 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x6e33766f, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 07:54:29,641 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6e33766f connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 07:54:29,641 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 07:54:29,642 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-04 07:54:29,646 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47a1835bde0002, negotiated timeout = 90000
2014-08-04 07:54:29,682 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,16020,1407164046304 starting
2014-08-04 07:54:29,684 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HeapMemoryManager: Starting HeapMemoryTuner chore.
2014-08-04 07:54:29,687 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x665c5316, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 07:54:29,688 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x665c5316 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 07:54:29,688 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 07:54:29,689 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-04 07:54:29,690 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: Serving as sceplus-vm48.almaden.ibm.com,16020,1407164046304, RpcServer on sceplus-vm48.almaden.ibm.com/9.1.143.58:16020, sessionid=0x147a18358d50000
2014-08-04 07:54:29,692 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47a1835bde0003, negotiated timeout = 90000
2014-08-04 07:54:29,697 INFO  [defaultRpcServer.handler=4,queue=4,port=16020] master.ServerManager: Registering server=slave1,16020,1407164047423
2014-08-04 07:54:29,732 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 551 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-04 07:54:31,238 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 2057 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-04 07:54:32,743 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 3562 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-04 07:54:33,696 INFO  [ActiveMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4515 ms, expecting minimum of 2, maximum of 2147483647, master is running, selfCheckedIn true
2014-08-04 07:54:33,697 INFO  [ActiveMasterManager] master.ServerManager: Registering server=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:33,697 INFO  [ActiveMasterManager] master.HMaster: Registered server found up in zk but who has not yet reported in: sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:33,702 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304 belongs to an existing region server
2014-08-04 07:54:33,702 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423 belongs to an existing region server
2014-08-04 07:54:33,772 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=sceplus-vm48.almaden.ibm.com,16020,1407141514169, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sceplus-vm48.almaden.ibm.com,16020,1407164046304
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2605)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:795)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1067)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20158)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2013)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:744)

2014-08-04 07:54:33,796 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Unsetting hbase:meta region location in ZooKeeper
2014-08-04 07:54:33,838 INFO  [ActiveMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:33,838 INFO  [ActiveMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1407164073713, server=null} to {1588230740 state=PENDING_OPEN, ts=1407164073838, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:54:33,851 INFO  [ActiveMasterManager] regionserver.RSRpcServices: Open hbase:meta,,1.1588230740
2014-08-04 07:54:33,857 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-04 07:54:33,866 INFO  [ActiveMasterManager] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407141514169 does not exist
2014-08-04 07:54:33,866 INFO  [ActiveMasterManager] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,16020,1407141514169]
2014-08-04 07:54:33,866 INFO  [ActiveMasterManager] master.SplitLogManager: started splitting 0 logs in []
2014-08-04 07:54:33,876 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/1588230740 znode deleted. Region: 1588230740 completes recovery.
2014-08-04 07:54:33,876 INFO  [ActiveMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 10ms
2014-08-04 07:54:33,876 INFO  [ActiveMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-08-04 07:54:33,887 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: Slow sync cost: 18 ms, current pipeline: []
2014-08-04 07:54:33,887 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407164073863.meta
2014-08-04 07:54:33,922 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-08-04 07:54:33,994 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 07:54:34,014 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 07:54:34,146 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for c3344614985941c98f9e652cbc8b8003
2014-08-04 07:54:34,170 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=4629
2014-08-04 07:54:34,172 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for hbase:meta,,1.1588230740
2014-08-04 07:54:34,174 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaTableLocator: Setting hbase:meta region location in ZooKeeper as sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,193 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1407164073838, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {1588230740 state=OPEN, ts=1407164074193, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:54:34,193 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Onlined 1588230740 on sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,195 INFO  [ActiveMasterManager] master.HMaster: hbase:meta assigned=1, rit=false, location=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,326 INFO  [ActiveMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-08-04 07:54:34,382 INFO  [ActiveMasterManager] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2014-08-04 07:54:34,382 WARN  [ActiveMasterManager] master.ServerManager: Expiration of slave1,16020,1407141591971 but server not online
2014-08-04 07:54:34,385 WARN  [ActiveMasterManager] master.ServerManager: Expiration of sceplus-vm48.almaden.ibm.com,16020,1407141514169 but server not online
2014-08-04 07:54:34,394 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Splitting logs for sceplus-vm48.almaden.ibm.com,16020,1407141514169 before assignment.
2014-08-04 07:54:34,394 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-04 07:54:34,394 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407141591971 before assignment.
2014-08-04 07:54:34,395 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-04 07:54:34,404 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164074374, server=sceplus-vm48.almaden.ibm.com,16020,1407141514169} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OFFLINE, ts=1407164074404, server=sceplus-vm48.almaden.ibm.com,16020,1407141514169}
2014-08-04 07:54:34,405 INFO  [ActiveMasterManager] master.AssignmentManager: Joined the cluster in 79ms, failover=true
2014-08-04 07:54:34,406 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OFFLINE
2014-08-04 07:54:34,435 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Reassigning 1 region(s) that sceplus-vm48.almaden.ibm.com,16020,1407141514169 was carrying (and 0 regions(s) that were opening on this server)
2014-08-04 07:54:34,458 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2014-08-04 07:54:34,461 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,466 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OFFLINE, ts=1407164074404, server=sceplus-vm48.almaden.ibm.com,16020,1407141514169} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164074466, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:54:34,466 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN&sn=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,471 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 07:54:34,479 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning done
2014-08-04 07:54:34,480 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for fe1c441ecb6e3789e0fdd62314d7b06a to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:54:34,486 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 07:54:34,487 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 07:54:34,516 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=40000008
2014-08-04 07:54:34,516 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 07:54:34,555 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164074466, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164074555, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:54:34,555 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=40000008&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,560 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Onlined fe1c441ecb6e3789e0fdd62314d7b06a on sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:54:34,565 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407141514169 does not exist
2014-08-04 07:54:34,565 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,16020,1407141514169]
2014-08-04 07:54:34,566 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: started splitting 0 logs in []
2014-08-04 07:54:34,572 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {8aabb426fd90134a056f48c057d6b5b0 state=OPEN, ts=1407164074375, server=slave1,16020,1407141591971} to {8aabb426fd90134a056f48c057d6b5b0 state=OFFLINE, ts=1407164074572, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,573 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user1,1407141581590.8aabb426fd90134a056f48c057d6b5b0. with state=OFFLINE
2014-08-04 07:54:34,576 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=OPEN, ts=1407164074379, server=slave1,16020,1407141591971} to {6440fdcf7907e8de395bf0c4a4da4666 state=OFFLINE, ts=1407164074576, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,576 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=OFFLINE
2014-08-04 07:54:34,579 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {89ee71eb3049399046b388114ed05a20 state=OPEN, ts=1407164074378, server=slave1,16020,1407141591971} to {89ee71eb3049399046b388114ed05a20 state=OFFLINE, ts=1407164074579, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,579 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user5,1407141581590.89ee71eb3049399046b388114ed05a20. with state=OFFLINE
2014-08-04 07:54:34,582 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=OPEN, ts=1407164074377, server=slave1,16020,1407141591971} to {f0f455acf010bd902304c7dfa78475b2 state=OFFLINE, ts=1407164074582, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,582 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=OFFLINE
2014-08-04 07:54:34,586 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {6af97adecf7548b39ed84aceba750cec state=OPEN, ts=1407164074379, server=slave1,16020,1407141591971} to {6af97adecf7548b39ed84aceba750cec state=OFFLINE, ts=1407164074586, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,586 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user6,1407141581590.6af97adecf7548b39ed84aceba750cec. with state=OFFLINE
2014-08-04 07:54:34,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=OPEN, ts=1407164074381, server=slave1,16020,1407141591971} to {f9e9efb2abb59b69f147274d49abecb3 state=OFFLINE, ts=1407164074589, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=OFFLINE
2014-08-04 07:54:34,592 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {b749d046cc995cfb046fdc87fd3ba6b8 state=OPEN, ts=1407164074380, server=slave1,16020,1407141591971} to {b749d046cc995cfb046fdc87fd3ba6b8 state=OFFLINE, ts=1407164074592, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,593 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user8,1407141581590.b749d046cc995cfb046fdc87fd3ba6b8. with state=OFFLINE
2014-08-04 07:54:34,596 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=OPEN, ts=1407164074375, server=slave1,16020,1407141591971} to {0da80de38f198fc51a0b47f37aaf6cb4 state=OFFLINE, ts=1407164074596, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,596 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=OFFLINE
2014-08-04 07:54:34,599 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {e5e5472e82c86a6ab4bdd45e0a00c245 state=OPEN, ts=1407164074376, server=slave1,16020,1407141591971} to {e5e5472e82c86a6ab4bdd45e0a00c245 state=OFFLINE, ts=1407164074599, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,599 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user2,1407141581590.e5e5472e82c86a6ab4bdd45e0a00c245. with state=OFFLINE
2014-08-04 07:54:34,602 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=OPEN, ts=1407164074377, server=slave1,16020,1407141591971} to {2d0de77fcf7523efe013bb011064599c state=OFFLINE, ts=1407164074602, server=slave1,16020,1407141591971}
2014-08-04 07:54:34,602 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=OFFLINE
2014-08-04 07:54:34,603 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/fe1c441ecb6e3789e0fdd62314d7b06a znode deleted. Region: fe1c441ecb6e3789e0fdd62314d7b06a completes recovery.
2014-08-04 07:54:34,605 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Reassigning 10 region(s) that slave1,16020,1407141591971 was carrying (and 0 regions(s) that were opening on this server)
2014-08-04 07:54:34,609 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 43ms
2014-08-04 07:54:34,609 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm48.almaden.ibm.com,16020,1407141514169
2014-08-04 07:54:34,686 INFO  [ActiveMasterManager] master.HMaster: Master has completed initialization
2014-08-04 07:54:35,343 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Bulk assigning 10 region(s) across 3 server(s), round-robin=true
2014-08-04 07:54:35,344 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 5 region(s) to sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,344 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407164047423
2014-08-04 07:54:35,344 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=OFFLINE, ts=1407164074576, server=slave1,16020,1407141591971} to {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164075344, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:35,344 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStates: Transition {8aabb426fd90134a056f48c057d6b5b0 state=OFFLINE, ts=1407164074572, server=slave1,16020,1407141591971} to {8aabb426fd90134a056f48c057d6b5b0 state=PENDING_OPEN, ts=1407164075344, server=slave1,16020,1407164047423}
2014-08-04 07:54:35,345 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,345 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user1,1407141581590.8aabb426fd90134a056f48c057d6b5b0. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:35,354 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=OFFLINE, ts=1407164074582, server=slave1,16020,1407141591971} to {f0f455acf010bd902304c7dfa78475b2 state=PENDING_OPEN, ts=1407164075354, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:35,354 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStates: Transition {89ee71eb3049399046b388114ed05a20 state=OFFLINE, ts=1407164074579, server=slave1,16020,1407141591971} to {89ee71eb3049399046b388114ed05a20 state=PENDING_OPEN, ts=1407164075354, server=slave1,16020,1407164047423}
2014-08-04 07:54:35,355 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,355 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user5,1407141581590.89ee71eb3049399046b388114ed05a20. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:35,358 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=OFFLINE, ts=1407164074589, server=slave1,16020,1407141591971} to {f9e9efb2abb59b69f147274d49abecb3 state=PENDING_OPEN, ts=1407164075358, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:35,358 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStates: Transition {6af97adecf7548b39ed84aceba750cec state=OFFLINE, ts=1407164074586, server=slave1,16020,1407141591971} to {6af97adecf7548b39ed84aceba750cec state=PENDING_OPEN, ts=1407164075358, server=slave1,16020,1407164047423}
2014-08-04 07:54:35,359 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,359 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user6,1407141581590.6af97adecf7548b39ed84aceba750cec. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:35,363 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=OFFLINE, ts=1407164074596, server=slave1,16020,1407141591971} to {0da80de38f198fc51a0b47f37aaf6cb4 state=PENDING_OPEN, ts=1407164075363, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:35,363 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStates: Transition {b749d046cc995cfb046fdc87fd3ba6b8 state=OFFLINE, ts=1407164074592, server=slave1,16020,1407141591971} to {b749d046cc995cfb046fdc87fd3ba6b8 state=PENDING_OPEN, ts=1407164075363, server=slave1,16020,1407164047423}
2014-08-04 07:54:35,363 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,364 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user8,1407141581590.b749d046cc995cfb046fdc87fd3ba6b8. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:35,367 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=OFFLINE, ts=1407164074602, server=slave1,16020,1407141591971} to {2d0de77fcf7523efe013bb011064599c state=PENDING_OPEN, ts=1407164075367, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:35,367 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStates: Transition {e5e5472e82c86a6ab4bdd45e0a00c245 state=OFFLINE, ts=1407164074599, server=slave1,16020,1407141591971} to {e5e5472e82c86a6ab4bdd45e0a00c245 state=PENDING_OPEN, ts=1407164075367, server=slave1,16020,1407164047423}
2014-08-04 07:54:35,368 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:35,368 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user2,1407141581590.e5e5472e82c86a6ab4bdd45e0a00c245. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:35,758 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Bulk assigning done
2014-08-04 07:54:35,759 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 8aabb426fd90134a056f48c057d6b5b0 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:54:36,891 ERROR [defaultRpcServer.handler=23,queue=3,port=16020] master.AssignmentManager: Failed to transtion region from {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164075344, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to OPENED by slave1,16020,1407164047423: 6440fdcf7907e8de395bf0c4a4da4666 is not pending open on slave1,16020,1407164047423
2014-08-04 07:54:36,917 ERROR [defaultRpcServer.handler=28,queue=3,port=16020] master.MasterRpcServices: Region server slave1,16020,1407164047423 reported a fatal error:
ABORTING region server slave1,16020,1407164047423: Exception running postOpenDeployTasks; region=6440fdcf7907e8de395bf0c4a4da4666
Cause:
java.io.IOException: Failed to report opened region to master: usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1730)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-04 07:54:40,191 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm49.almaden.ibm.com,16020,1407164047423]
2014-08-04 07:54:40,197 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm49.almaden.ibm.com,16020,1407164047423 znode expired, triggering replicatorRemoved event
2014-08-04 07:54:40,197 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Splitting logs for sceplus-vm49.almaden.ibm.com,16020,1407164047423 before assignment.
2014-08-04 07:54:40,198 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-04 07:54:40,198 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {f9e9efb2abb59b69f147274d49abecb3 state=PENDING_OPEN, ts=1407164075358, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:40,198 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {0da80de38f198fc51a0b47f37aaf6cb4 state=PENDING_OPEN, ts=1407164075363, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:40,199 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {2d0de77fcf7523efe013bb011064599c state=PENDING_OPEN, ts=1407164075367, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:40,199 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164075344, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:40,199 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {f0f455acf010bd902304c7dfa78475b2 state=PENDING_OPEN, ts=1407164075354, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:54:40,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f9e9efb2abb59b69f147274d49abecb3 already deleted, retry=false
2014-08-04 07:54:40,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=PENDING_OPEN, ts=1407164075358, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {f9e9efb2abb59b69f147274d49abecb3 state=OFFLINE, ts=1407164080207, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:40,208 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=OFFLINE
2014-08-04 07:54:40,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/0da80de38f198fc51a0b47f37aaf6cb4 already deleted, retry=false
2014-08-04 07:54:40,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=PENDING_OPEN, ts=1407164075363, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {0da80de38f198fc51a0b47f37aaf6cb4 state=OFFLINE, ts=1407164080219, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:40,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=OFFLINE
2014-08-04 07:54:40,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/2d0de77fcf7523efe013bb011064599c already deleted, retry=false
2014-08-04 07:54:40,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=PENDING_OPEN, ts=1407164075367, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {2d0de77fcf7523efe013bb011064599c state=OFFLINE, ts=1407164080224, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:40,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=OFFLINE
2014-08-04 07:54:40,231 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/6440fdcf7907e8de395bf0c4a4da4666 already deleted, retry=false
2014-08-04 07:54:40,231 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164075344, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {6440fdcf7907e8de395bf0c4a4da4666 state=OFFLINE, ts=1407164080231, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:40,231 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=OFFLINE
2014-08-04 07:54:40,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f0f455acf010bd902304c7dfa78475b2 already deleted, retry=false
2014-08-04 07:54:40,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=PENDING_OPEN, ts=1407164075354, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {f0f455acf010bd902304c7dfa78475b2 state=OFFLINE, ts=1407164080236, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423}
2014-08-04 07:54:40,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=OFFLINE
2014-08-04 07:54:40,239 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Reassigning 0 region(s) that sceplus-vm49.almaden.ibm.com,16020,1407164047423 was carrying (and 5 regions(s) that were opening on this server)
2014-08-04 07:54:40,240 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407164047423
2014-08-04 07:54:40,240 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=OFFLINE, ts=1407164080207, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {f9e9efb2abb59b69f147274d49abecb3 state=PENDING_OPEN, ts=1407164080240, server=slave1,16020,1407164047423}
2014-08-04 07:54:40,240 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:40,243 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=OFFLINE, ts=1407164080219, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {0da80de38f198fc51a0b47f37aaf6cb4 state=PENDING_OPEN, ts=1407164080243, server=slave1,16020,1407164047423}
2014-08-04 07:54:40,243 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:40,245 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=OFFLINE, ts=1407164080224, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {2d0de77fcf7523efe013bb011064599c state=PENDING_OPEN, ts=1407164080245, server=slave1,16020,1407164047423}
2014-08-04 07:54:40,245 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:40,247 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=OFFLINE, ts=1407164080231, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164080247, server=slave1,16020,1407164047423}
2014-08-04 07:54:40,247 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:40,250 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=OFFLINE, ts=1407164080236, server=sceplus-vm49.almaden.ibm.com,16020,1407164047423} to {f0f455acf010bd902304c7dfa78475b2 state=PENDING_OPEN, ts=1407164080250, server=slave1,16020,1407164047423}
2014-08-04 07:54:40,250 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=PENDING_OPEN&sn=slave1,16020,1407164047423
2014-08-04 07:54:40,255 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Unable to communicate with slave1,16020,1407164047423 in order to assign regions, 
java.io.IOException: Call to slave1/9.1.143.59:16020 failed on local exception: java.io.IOException: Connection to slave1/9.1.143.59:16020 is closing. Call id=12, waitTime=1
	at org.apache.hadoop.hbase.ipc.RpcClient.wrapException(RpcClient.java:1571)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1542)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.openRegion(AdminProtos.java:20964)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(ServerManager.java:766)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1679)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2653)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2634)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:291)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.io.IOException: Connection to slave1/9.1.143.59:16020 is closing. Call id=12, waitTime=1
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.cleanupCalls(RpcClient.java:1265)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.close(RpcClient.java:1059)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.run(RpcClient.java:792)
2014-08-04 07:54:40,261 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for f9e9efb2abb59b69f147274d49abecb3 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:54:40,267 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=1 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:40,267 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:40,267 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:40,267 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:40,267 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:40,649 INFO  [defaultRpcServer.handler=17,queue=2,port=16020] master.HMaster: Client=hadoop//9.1.143.58 disable usertable
2014-08-04 07:54:40,705 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Attempting to disable table usertable
2014-08-04 07:54:40,705 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLING
2014-08-04 07:54:40,709 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLED
2014-08-04 07:54:40,713 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Disabled table, usertable, is done=true
2014-08-04 07:54:40,793 INFO  [defaultRpcServer.handler=22,queue=2,port=16020] master.HMaster: Client=hadoop//9.1.143.58 delete usertable
2014-08-04 07:54:40,818 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table usertable
2014-08-04 07:54:42,269 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,271 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,272 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=3 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,273 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,272 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,275 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:42,552 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm49.almaden.ibm.com,16020,1407164047423's hlogs to my queue
2014-08-04 07:54:42,564 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/sceplus-vm49.almaden.ibm.com,16020,1407164047423/lock
2014-08-04 07:54:44,274 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,275 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,276 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,277 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=5 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,277 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=4 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,277 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:44,278 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,280 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,282 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,283 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=5 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,284 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,285 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:46,310 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,285 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,286 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,287 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,288 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,287 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=8 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:48,312 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,289 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,290 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,291 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,292 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=8 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,292 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=8 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,292 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,319 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:50,768 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Timed out on waiting for 8aabb426fd90134a056f48c057d6b5b0 to be assigned.
2014-08-04 07:54:50,768 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Region 8aabb426fd90134a056f48c057d6b5b0 didn't complete assignment in time
2014-08-04 07:54:50,768 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 6440fdcf7907e8de395bf0c4a4da4666 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:54:52,294 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,295 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,296 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,297 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=8 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,297 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.io.IOException: This connection is closing for usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4., try=10 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,299 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:52,301 WARN  [AM.-pool1-t5] master.RegionStates: Failed to open/close f0f455acf010bd902304c7dfa78475b2 on slave1,16020,1407164047423, set to FAILED_CLOSE
2014-08-04 07:54:52,300 WARN  [AM.-pool1-t2] master.RegionStates: Failed to open/close 0da80de38f198fc51a0b47f37aaf6cb4 on slave1,16020,1407164047423, set to FAILED_CLOSE
2014-08-04 07:54:52,301 INFO  [AM.-pool1-t5] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=PENDING_OPEN, ts=1407164080250, server=slave1,16020,1407164047423} to {f0f455acf010bd902304c7dfa78475b2 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423}
2014-08-04 07:54:52,301 INFO  [AM.-pool1-t2] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=PENDING_OPEN, ts=1407164080243, server=slave1,16020,1407164047423} to {0da80de38f198fc51a0b47f37aaf6cb4 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423}
2014-08-04 07:54:52,301 INFO  [AM.-pool1-t5] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=FAILED_CLOSE
2014-08-04 07:54:52,302 INFO  [AM.-pool1-t2] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=FAILED_CLOSE
2014-08-04 07:54:52,310 INFO  [AM.-pool1-t5] master.AssignmentManager: Skip assigning {ENCODED => f0f455acf010bd902304c7dfa78475b2, NAME => 'usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2.', STARTKEY => 'user4', ENDKEY => 'user5'}, we couldn't close it: {f0f455acf010bd902304c7dfa78475b2 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423}
2014-08-04 07:54:52,310 INFO  [AM.-pool1-t2] master.AssignmentManager: Skip assigning {ENCODED => 0da80de38f198fc51a0b47f37aaf6cb4, NAME => 'usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4.', STARTKEY => '', ENDKEY => 'user1'}, we couldn't close it: {0da80de38f198fc51a0b47f37aaf6cb4 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423}
2014-08-04 07:54:52,322 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:54,299 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:54,300 WARN  [AM.-pool1-t1] master.RegionStates: Failed to open/close f9e9efb2abb59b69f147274d49abecb3 on slave1,16020,1407164047423, set to FAILED_CLOSE
2014-08-04 07:54:54,300 INFO  [AM.-pool1-t1] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=PENDING_OPEN, ts=1407164080240, server=slave1,16020,1407164047423} to {f9e9efb2abb59b69f147274d49abecb3 state=FAILED_CLOSE, ts=1407164094300, server=slave1,16020,1407164047423}
2014-08-04 07:54:54,300 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:54,300 INFO  [AM.-pool1-t1] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=FAILED_CLOSE
2014-08-04 07:54:54,303 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c., try=10 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:54,305 WARN  [AM.-pool1-t3] master.RegionStates: Failed to open/close 2d0de77fcf7523efe013bb011064599c on slave1,16020,1407164047423, set to FAILED_CLOSE
2014-08-04 07:54:54,305 INFO  [AM.-pool1-t3] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=PENDING_OPEN, ts=1407164080245, server=slave1,16020,1407164047423} to {2d0de77fcf7523efe013bb011064599c state=FAILED_CLOSE, ts=1407164094305, server=slave1,16020,1407164047423}
2014-08-04 07:54:54,305 INFO  [AM.-pool1-t3] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=FAILED_CLOSE
2014-08-04 07:54:54,307 INFO  [AM.-pool1-t1] master.AssignmentManager: Skip assigning {ENCODED => f9e9efb2abb59b69f147274d49abecb3, NAME => 'usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3.', STARTKEY => 'user9', ENDKEY => ''}, we couldn't close it: {f9e9efb2abb59b69f147274d49abecb3 state=FAILED_CLOSE, ts=1407164094300, server=slave1,16020,1407164047423}
2014-08-04 07:54:54,310 INFO  [AM.-pool1-t3] master.AssignmentManager: Skip assigning {ENCODED => 2d0de77fcf7523efe013bb011064599c, NAME => 'usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c.', STARTKEY => 'user3', ENDKEY => 'user4'}, we couldn't close it: {2d0de77fcf7523efe013bb011064599c state=FAILED_CLOSE, ts=1407164094305, server=slave1,16020,1407164047423}
2014-08-04 07:54:54,324 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:55,312 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Timed out on waiting for f9e9efb2abb59b69f147274d49abecb3 to be assigned.
2014-08-04 07:54:55,312 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Region f9e9efb2abb59b69f147274d49abecb3 didn't complete assignment in time
2014-08-04 07:54:55,312 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 0da80de38f198fc51a0b47f37aaf6cb4 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:54:56,326 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:56,329 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407164047423 returned java.net.ConnectException: Connection refused for usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666., try=10 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-04 07:54:56,329 WARN  [AM.-pool1-t4] master.RegionStates: Failed to open/close 6440fdcf7907e8de395bf0c4a4da4666 on slave1,16020,1407164047423, set to FAILED_CLOSE
2014-08-04 07:54:56,330 INFO  [AM.-pool1-t4] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=PENDING_OPEN, ts=1407164080247, server=slave1,16020,1407164047423} to {6440fdcf7907e8de395bf0c4a4da4666 state=FAILED_CLOSE, ts=1407164096330, server=slave1,16020,1407164047423}
2014-08-04 07:54:56,330 INFO  [AM.-pool1-t4] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=FAILED_CLOSE
2014-08-04 07:54:56,334 INFO  [AM.-pool1-t4] master.AssignmentManager: Skip assigning {ENCODED => 6440fdcf7907e8de395bf0c4a4da4666, NAME => 'usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666.', STARTKEY => 'user7', ENDKEY => 'user8'}, we couldn't close it: {6440fdcf7907e8de395bf0c4a4da4666 state=FAILED_CLOSE, ts=1407164096330, server=slave1,16020,1407164047423}
2014-08-04 07:55:05,847 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Timed out on waiting for 6440fdcf7907e8de395bf0c4a4da4666 to be assigned.
2014-08-04 07:55:05,848 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Region 6440fdcf7907e8de395bf0c4a4da4666 didn't complete assignment in time
2014-08-04 07:55:05,848 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 89ee71eb3049399046b388114ed05a20 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:55:10,353 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Timed out on waiting for 0da80de38f198fc51a0b47f37aaf6cb4 to be assigned.
2014-08-04 07:55:10,354 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Region 0da80de38f198fc51a0b47f37aaf6cb4 didn't complete assignment in time
2014-08-04 07:55:10,354 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 2d0de77fcf7523efe013bb011064599c to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:55:12,175 INFO  [defaultRpcServer.handler=11,queue=1,port=16020] master.ServerManager: Registering server=slave1,16020,1407164109260
2014-08-04 07:55:12,175 INFO  [defaultRpcServer.handler=11,queue=1,port=16020] master.ServerManager: Triggering server recovery; existingServer slave1,16020,1407164047423 looks stale, new server:slave1,16020,1407164109260
2014-08-04 07:55:12,179 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407164047423 before assignment.
2014-08-04 07:55:12,180 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-04 07:55:12,180 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {f9e9efb2abb59b69f147274d49abecb3 state=FAILED_CLOSE, ts=1407164094300, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,180 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {e5e5472e82c86a6ab4bdd45e0a00c245 state=PENDING_OPEN, ts=1407164075367, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,180 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {8aabb426fd90134a056f48c057d6b5b0 state=PENDING_OPEN, ts=1407164075344, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,180 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {0da80de38f198fc51a0b47f37aaf6cb4 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {b749d046cc995cfb046fdc87fd3ba6b8 state=PENDING_OPEN, ts=1407164075363, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {89ee71eb3049399046b388114ed05a20 state=PENDING_OPEN, ts=1407164075354, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {6af97adecf7548b39ed84aceba750cec state=PENDING_OPEN, ts=1407164075358, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {2d0de77fcf7523efe013bb011064599c state=FAILED_CLOSE, ts=1407164094305, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {6440fdcf7907e8de395bf0c4a4da4666 state=FAILED_CLOSE, ts=1407164096330, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,181 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {f0f455acf010bd902304c7dfa78475b2 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423} to be reassigned by SSH for slave1,16020,1407164047423
2014-08-04 07:55:12,184 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f9e9efb2abb59b69f147274d49abecb3 already deleted, retry=false
2014-08-04 07:55:12,184 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {f9e9efb2abb59b69f147274d49abecb3 state=FAILED_CLOSE, ts=1407164094300, server=slave1,16020,1407164047423} to {f9e9efb2abb59b69f147274d49abecb3 state=OFFLINE, ts=1407164112184, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,184 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3. with state=OFFLINE
2014-08-04 07:55:12,190 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/e5e5472e82c86a6ab4bdd45e0a00c245 already deleted, retry=false
2014-08-04 07:55:12,190 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {e5e5472e82c86a6ab4bdd45e0a00c245 state=PENDING_OPEN, ts=1407164075367, server=slave1,16020,1407164047423} to {e5e5472e82c86a6ab4bdd45e0a00c245 state=OFFLINE, ts=1407164112190, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,191 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407141581590.e5e5472e82c86a6ab4bdd45e0a00c245. with state=OFFLINE
2014-08-04 07:55:12,196 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/8aabb426fd90134a056f48c057d6b5b0 already deleted, retry=false
2014-08-04 07:55:12,196 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {8aabb426fd90134a056f48c057d6b5b0 state=PENDING_OPEN, ts=1407164075344, server=slave1,16020,1407164047423} to {8aabb426fd90134a056f48c057d6b5b0 state=OFFLINE, ts=1407164112196, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,196 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407141581590.8aabb426fd90134a056f48c057d6b5b0. with state=OFFLINE
2014-08-04 07:55:12,201 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/0da80de38f198fc51a0b47f37aaf6cb4 already deleted, retry=false
2014-08-04 07:55:12,202 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {0da80de38f198fc51a0b47f37aaf6cb4 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423} to {0da80de38f198fc51a0b47f37aaf6cb4 state=OFFLINE, ts=1407164112201, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,202 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4. with state=OFFLINE
2014-08-04 07:55:12,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/b749d046cc995cfb046fdc87fd3ba6b8 already deleted, retry=false
2014-08-04 07:55:12,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {b749d046cc995cfb046fdc87fd3ba6b8 state=PENDING_OPEN, ts=1407164075363, server=slave1,16020,1407164047423} to {b749d046cc995cfb046fdc87fd3ba6b8 state=OFFLINE, ts=1407164112207, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,208 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407141581590.b749d046cc995cfb046fdc87fd3ba6b8. with state=OFFLINE
2014-08-04 07:55:12,213 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/89ee71eb3049399046b388114ed05a20 already deleted, retry=false
2014-08-04 07:55:12,213 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {89ee71eb3049399046b388114ed05a20 state=PENDING_OPEN, ts=1407164075354, server=slave1,16020,1407164047423} to {89ee71eb3049399046b388114ed05a20 state=OFFLINE, ts=1407164112213, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,213 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407141581590.89ee71eb3049399046b388114ed05a20. with state=OFFLINE
2014-08-04 07:55:12,216 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for f0f455acf010bd902304c7dfa78475b2 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:55:12,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/6af97adecf7548b39ed84aceba750cec already deleted, retry=false
2014-08-04 07:55:12,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {6af97adecf7548b39ed84aceba750cec state=PENDING_OPEN, ts=1407164075358, server=slave1,16020,1407164047423} to {6af97adecf7548b39ed84aceba750cec state=OFFLINE, ts=1407164112219, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,219 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407141581590.6af97adecf7548b39ed84aceba750cec. with state=OFFLINE
2014-08-04 07:55:12,229 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/2d0de77fcf7523efe013bb011064599c already deleted, retry=false
2014-08-04 07:55:12,229 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {2d0de77fcf7523efe013bb011064599c state=FAILED_CLOSE, ts=1407164094305, server=slave1,16020,1407164047423} to {2d0de77fcf7523efe013bb011064599c state=OFFLINE, ts=1407164112229, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,229 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c. with state=OFFLINE
2014-08-04 07:55:12,233 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 6440fdcf7907e8de395bf0c4a4da4666 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:55:12,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/6440fdcf7907e8de395bf0c4a4da4666 already deleted, retry=false
2014-08-04 07:55:12,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {6440fdcf7907e8de395bf0c4a4da4666 state=FAILED_CLOSE, ts=1407164096330, server=slave1,16020,1407164047423} to {6440fdcf7907e8de395bf0c4a4da4666 state=OFFLINE, ts=1407164112236, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,236 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666. with state=OFFLINE
2014-08-04 07:55:12,239 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for f0f455acf010bd902304c7dfa78475b2 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 07:55:12,241 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f0f455acf010bd902304c7dfa78475b2 already deleted, retry=false
2014-08-04 07:55:12,241 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {f0f455acf010bd902304c7dfa78475b2 state=FAILED_CLOSE, ts=1407164092301, server=slave1,16020,1407164047423} to {f0f455acf010bd902304c7dfa78475b2 state=OFFLINE, ts=1407164112241, server=slave1,16020,1407164047423}
2014-08-04 07:55:12,242 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2. with state=OFFLINE
2014-08-04 07:55:12,245 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Reassigning 0 region(s) that slave1,16020,1407164047423 was carrying (and 0 regions(s) that were opening on this server)
2014-08-04 07:55:12,258 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.MasterFileSystem: Log dir for server sceplus-vm49.almaden.ibm.com,16020,1407164047423 does not exist
2014-08-04 07:55:12,258 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: dead splitlog workers [sceplus-vm49.almaden.ibm.com,16020,1407164047423]
2014-08-04 07:55:12,259 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: started splitting 0 logs in []
2014-08-04 07:55:12,262 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.MasterFileSystem: Log dir for server slave1,16020,1407141591971 does not exist
2014-08-04 07:55:12,263 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: dead splitlog workers [slave1,16020,1407141591971]
2014-08-04 07:55:12,263 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: started splitting 0 logs in []
2014-08-04 07:55:12,270 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 11ms
2014-08-04 07:55:12,270 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm49.almaden.ibm.com,16020,1407164047423
2014-08-04 07:55:12,305 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: dead splitlog workers [slave1,16020,1407164047423]
2014-08-04 07:55:12,311 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting]
2014-08-04 07:55:12,359 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072
2014-08-04 07:55:12,359 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:55:12,378 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 115ms
2014-08-04 07:55:12,378 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407141591971
2014-08-04 07:55:12,411 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting/slave1%2C16020%2C1407164047423.1407164069072, length=17
2014-08-04 07:55:12,411 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 07:55:12,415 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting/slave1%2C16020%2C1407164047423.1407164069072
2014-08-04 07:55:12,428 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting/slave1%2C16020%2C1407164047423.1407164069072 after 13ms
2014-08-04 07:55:12,448 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 07:55:12,449 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting/slave1%2C16020%2C1407164047423.1407164069072 is corrupted = false progress failed = false
2014-08-04 07:55:12,457 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:55:12,457 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072 in 92ms
2014-08-04 07:55:12,458 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:55:12,484 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting/slave1%2C16020%2C1407164047423.1407164069072 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164047423.1407164069072
2014-08-04 07:55:12,488 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164047423-splitting%2Fslave1%252C16020%252C1407164047423.1407164069072
2014-08-04 07:55:12,495 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: finished splitting (more than or equal to) 17 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407164047423-splitting] in 184ms
2014-08-04 07:55:12,495 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407164047423
2014-08-04 07:55:12,918 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Deleted [{ENCODED => 0da80de38f198fc51a0b47f37aaf6cb4, NAME => 'usertable,,1407141581590.0da80de38f198fc51a0b47f37aaf6cb4.', STARTKEY => '', ENDKEY => 'user1'}, {ENCODED => 8aabb426fd90134a056f48c057d6b5b0, NAME => 'usertable,user1,1407141581590.8aabb426fd90134a056f48c057d6b5b0.', STARTKEY => 'user1', ENDKEY => 'user2'}, {ENCODED => e5e5472e82c86a6ab4bdd45e0a00c245, NAME => 'usertable,user2,1407141581590.e5e5472e82c86a6ab4bdd45e0a00c245.', STARTKEY => 'user2', ENDKEY => 'user3'}, {ENCODED => 2d0de77fcf7523efe013bb011064599c, NAME => 'usertable,user3,1407141581590.2d0de77fcf7523efe013bb011064599c.', STARTKEY => 'user3', ENDKEY => 'user4'}, {ENCODED => f0f455acf010bd902304c7dfa78475b2, NAME => 'usertable,user4,1407141581590.f0f455acf010bd902304c7dfa78475b2.', STARTKEY => 'user4', ENDKEY => 'user5'}, {ENCODED => 89ee71eb3049399046b388114ed05a20, NAME => 'usertable,user5,1407141581590.89ee71eb3049399046b388114ed05a20.', STARTKEY => 'user5', ENDKEY => 'user6'}, {ENCODED => 6af97adecf7548b39ed84aceba750cec, NAME => 'usertable,user6,1407141581590.6af97adecf7548b39ed84aceba750cec.', STARTKEY => 'user6', ENDKEY => 'user7'}, {ENCODED => 6440fdcf7907e8de395bf0c4a4da4666, NAME => 'usertable,user7,1407141581590.6440fdcf7907e8de395bf0c4a4da4666.', STARTKEY => 'user7', ENDKEY => 'user8'}, {ENCODED => b749d046cc995cfb046fdc87fd3ba6b8, NAME => 'usertable,user8,1407141581590.b749d046cc995cfb046fdc87fd3ba6b8.', STARTKEY => 'user8', ENDKEY => 'user9'}, {ENCODED => f9e9efb2abb59b69f147274d49abecb3, NAME => 'usertable,user9,1407141581590.f9e9efb2abb59b69f147274d49abecb3.', STARTKEY => 'user9', ENDKEY => ''}]
2014-08-04 07:55:19,108 INFO  [PriorityRpcServer.handler=6,queue=0,port=16020] regionserver.RSRpcServices: Compacting hbase:meta,,1.1588230740
2014-08-04 07:55:19,114 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407164119113] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-08-04 07:55:19,116 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407164119113] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=50.7 K
2014-08-04 07:55:19,120 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407164119113] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 07:55:19,320 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407164119113] regionserver.HStore: Completed major compaction of 2 (all) file(s) in info of hbase:meta,,1.1588230740 into 5c9bad3cf9e34d489ee255c8342410d7(size=25.1 K), total size for store is 25.1 K. This selection was in queue for 0sec, and took 0sec to execute.
2014-08-04 07:55:19,323 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407164119113] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=50.7 K, priority=1, time=822526475494064; duration=0sec
2014-08-04 07:55:29,789 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-HeapMemoryTunerChore] regionserver.HeapMemoryManager: Setting block cache heap size to 5364040704 and memstore heap size to 4853179392
2014-08-04 07:55:47,833 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] compress.CodecPool: Got brand-new compressor [.gz]
2014-08-04 07:55:47,834 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.HMaster: Client=hadoop//9.1.143.58 create 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-08-04 07:55:47,891 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: Create table usertable
2014-08-04 07:55:47,945 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,945 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,945 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,945 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,946 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,946 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,947 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,948 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,949 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:47,949 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-04 07:55:48,023 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Closed usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707.
2014-08-04 07:55:48,023 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Closed usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741.
2014-08-04 07:55:48,024 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Closed usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c.
2014-08-04 07:55:48,030 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Closed usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2.
2014-08-04 07:55:48,031 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Closed usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5.
2014-08-04 07:55:48,032 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Closed usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6.
2014-08-04 07:55:48,035 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Closed usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90.
2014-08-04 07:55:48,073 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Closed usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6.
2014-08-04 07:55:48,411 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Closed usertable,user2,1407164147821.0319f025449b981e780aad47b334574b.
2014-08-04 07:55:48,422 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Closed usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9.
2014-08-04 07:55:48,448 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Added 10
2014-08-04 07:55:48,513 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407164109260
2014-08-04 07:55:48,513 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {22f316c375bacd077bd95547f14e8707 state=OFFLINE, ts=1407164148448, server=null} to {22f316c375bacd077bd95547f14e8707 state=PENDING_OPEN, ts=1407164148513, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,514 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,519 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {85dfef280c26a8842e702a75c31a0741 state=OFFLINE, ts=1407164148449, server=null} to {85dfef280c26a8842e702a75c31a0741 state=PENDING_OPEN, ts=1407164148518, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,519 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,523 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {b68f7d23758f0f6c6643c8234627907c state=OFFLINE, ts=1407164148449, server=null} to {b68f7d23758f0f6c6643c8234627907c state=PENDING_OPEN, ts=1407164148523, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,524 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,528 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {9f61875a9063b8a1b946a96e849e35c2 state=OFFLINE, ts=1407164148449, server=null} to {9f61875a9063b8a1b946a96e849e35c2 state=PENDING_OPEN, ts=1407164148528, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,528 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,533 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {6cf2055c04723081bb67b2c2b74f81e5 state=OFFLINE, ts=1407164148450, server=null} to {6cf2055c04723081bb67b2c2b74f81e5 state=PENDING_OPEN, ts=1407164148533, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,533 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,537 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {2b9f522e7f5863abacba6eed038e0de6 state=OFFLINE, ts=1407164148450, server=null} to {2b9f522e7f5863abacba6eed038e0de6 state=PENDING_OPEN, ts=1407164148537, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,537 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,541 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {9e39dd4a553932b6730f19ab8f94ec90 state=OFFLINE, ts=1407164148451, server=null} to {9e39dd4a553932b6730f19ab8f94ec90 state=PENDING_OPEN, ts=1407164148541, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,541 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,545 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {7a099ad1a4b326851a78e587dbe929c6 state=OFFLINE, ts=1407164148451, server=null} to {7a099ad1a4b326851a78e587dbe929c6 state=PENDING_OPEN, ts=1407164148545, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,545 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,549 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {0319f025449b981e780aad47b334574b state=OFFLINE, ts=1407164148451, server=null} to {0319f025449b981e780aad47b334574b state=PENDING_OPEN, ts=1407164148549, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,550 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407164147821.0319f025449b981e780aad47b334574b. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,554 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {6c68c713468230ac9d6a9b57c7f1eed9 state=OFFLINE, ts=1407164148451, server=null} to {6c68c713468230ac9d6a9b57c7f1eed9 state=PENDING_OPEN, ts=1407164148554, server=slave1,16020,1407164109260}
2014-08-04 07:55:48,554 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9. with state=PENDING_OPEN&sn=slave1,16020,1407164109260
2014-08-04 07:55:48,919 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from ENABLING to ENABLED
2014-08-04 07:55:48,927 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: failed. null
2014-08-04 07:55:49,091 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Transition {22f316c375bacd077bd95547f14e8707 state=PENDING_OPEN, ts=1407164148513, server=slave1,16020,1407164109260} to {22f316c375bacd077bd95547f14e8707 state=OPEN, ts=1407164149091, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,091 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStates: Transition {b68f7d23758f0f6c6643c8234627907c state=PENDING_OPEN, ts=1407164148523, server=slave1,16020,1407164109260} to {b68f7d23758f0f6c6643c8234627907c state=OPEN, ts=1407164149091, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,091 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,091 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,097 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Onlined 22f316c375bacd077bd95547f14e8707 on slave1,16020,1407164109260
2014-08-04 07:55:49,097 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStates: Onlined b68f7d23758f0f6c6643c8234627907c on slave1,16020,1407164109260
2014-08-04 07:55:49,111 INFO  [defaultRpcServer.handler=39,queue=4,port=16020] master.RegionStates: Transition {85dfef280c26a8842e702a75c31a0741 state=PENDING_OPEN, ts=1407164148518, server=slave1,16020,1407164109260} to {85dfef280c26a8842e702a75c31a0741 state=OPEN, ts=1407164149111, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,111 INFO  [defaultRpcServer.handler=39,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,116 INFO  [defaultRpcServer.handler=39,queue=4,port=16020] master.RegionStates: Onlined 85dfef280c26a8842e702a75c31a0741 on slave1,16020,1407164109260
2014-08-04 07:55:49,133 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStates: Transition {6cf2055c04723081bb67b2c2b74f81e5 state=PENDING_OPEN, ts=1407164148533, server=slave1,16020,1407164109260} to {6cf2055c04723081bb67b2c2b74f81e5 state=OPEN, ts=1407164149133, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,133 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStateStore: Updating row usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,134 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Transition {9f61875a9063b8a1b946a96e849e35c2 state=PENDING_OPEN, ts=1407164148528, server=slave1,16020,1407164109260} to {9f61875a9063b8a1b946a96e849e35c2 state=OPEN, ts=1407164149134, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,134 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,137 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStates: Onlined 6cf2055c04723081bb67b2c2b74f81e5 on slave1,16020,1407164109260
2014-08-04 07:55:49,137 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Onlined 9f61875a9063b8a1b946a96e849e35c2 on slave1,16020,1407164109260
2014-08-04 07:55:49,158 INFO  [defaultRpcServer.handler=35,queue=0,port=16020] master.RegionStates: Transition {2b9f522e7f5863abacba6eed038e0de6 state=PENDING_OPEN, ts=1407164148537, server=slave1,16020,1407164109260} to {2b9f522e7f5863abacba6eed038e0de6 state=OPEN, ts=1407164149158, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,158 INFO  [defaultRpcServer.handler=35,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,161 INFO  [defaultRpcServer.handler=35,queue=0,port=16020] master.RegionStates: Onlined 2b9f522e7f5863abacba6eed038e0de6 on slave1,16020,1407164109260
2014-08-04 07:55:49,169 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStates: Transition {7a099ad1a4b326851a78e587dbe929c6 state=PENDING_OPEN, ts=1407164148545, server=slave1,16020,1407164109260} to {7a099ad1a4b326851a78e587dbe929c6 state=OPEN, ts=1407164149169, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,170 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,183 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Transition {9e39dd4a553932b6730f19ab8f94ec90 state=PENDING_OPEN, ts=1407164148541, server=slave1,16020,1407164109260} to {9e39dd4a553932b6730f19ab8f94ec90 state=OPEN, ts=1407164149182, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,183 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,185 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStates: Onlined 7a099ad1a4b326851a78e587dbe929c6 on slave1,16020,1407164109260
2014-08-04 07:55:49,186 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Onlined 9e39dd4a553932b6730f19ab8f94ec90 on slave1,16020,1407164109260
2014-08-04 07:55:49,219 INFO  [defaultRpcServer.handler=46,queue=1,port=16020] master.RegionStates: Transition {0319f025449b981e780aad47b334574b state=PENDING_OPEN, ts=1407164148549, server=slave1,16020,1407164109260} to {0319f025449b981e780aad47b334574b state=OPEN, ts=1407164149219, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,219 INFO  [defaultRpcServer.handler=46,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user2,1407164147821.0319f025449b981e780aad47b334574b. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,224 INFO  [defaultRpcServer.handler=46,queue=1,port=16020] master.RegionStates: Onlined 0319f025449b981e780aad47b334574b on slave1,16020,1407164109260
2014-08-04 07:55:49,260 INFO  [defaultRpcServer.handler=1,queue=1,port=16020] master.RegionStates: Transition {6c68c713468230ac9d6a9b57c7f1eed9 state=PENDING_OPEN, ts=1407164148554, server=slave1,16020,1407164109260} to {6c68c713468230ac9d6a9b57c7f1eed9 state=OPEN, ts=1407164149260, server=slave1,16020,1407164109260}
2014-08-04 07:55:49,261 INFO  [defaultRpcServer.handler=1,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9. with state=OPEN&openSeqNum=2&server=slave1,16020,1407164109260
2014-08-04 07:55:49,264 INFO  [defaultRpcServer.handler=1,queue=1,port=16020] master.RegionStates: Onlined 6c68c713468230ac9d6a9b57c7f1eed9 on slave1,16020,1407164109260
2014-08-04 07:59:06,520 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=158, hits=147, hitRatio=93.04%, , cachingAccesses=152, cachingHits=141, cachingHitsRatio=92.76%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-04 07:59:34,450 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:59:34,451 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164074555, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164374451, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:59:34,451 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 07:59:34,474 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:59:34,540 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 07:59:34,545 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 07:59:34,545 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 07:59:34,551 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164374451, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164374551, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:59:34,551 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 07:59:34,561 INFO  [AM.-pool1-t6] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 07:59:34,561 INFO  [AM.-pool1-t6] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164374551, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164374561, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:59:34,561 INFO  [AM.-pool1-t6] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 07:59:34,568 INFO  [AM.-pool1-t6] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 07:59:34,591 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 07:59:34,592 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 07:59:34,654 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 07:59:34,655 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 07:59:34,655 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164374561, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164374655, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 07:59:34,655 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:02:51,795 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm49.almaden.ibm.com,16020,1407164109260]
2014-08-04 08:02:51,796 WARN  [main-EventThread] zookeeper.RegionServerTracker: sceplus-vm49.almaden.ibm.com,16020,1407164109260 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2014-08-04 08:02:51,799 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm49.almaden.ibm.com,16020,1407164109260 znode expired, triggering replicatorRemoved event
2014-08-04 08:02:53,921 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm49.almaden.ibm.com,16020,1407164109260's hlogs to my queue
2014-08-04 08:02:53,931 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/sceplus-vm49.almaden.ibm.com,16020,1407164109260/lock
2014-08-04 08:02:57,616 ERROR [defaultRpcServer.handler=1,queue=1,port=16020] master.MasterRpcServices: Region server slave1,16020,1407164109260 reported a fatal error:
ABORTING region server slave1,16020,1407164109260: regionserver:16020-0x47a1835bde0006, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase regionserver:16020-0x47a1835bde0006 received expired from ZooKeeper, aborting
Cause:
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:409)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:320)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)

2014-08-04 08:04:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=685, hits=674, hitRatio=98.39%, , cachingAccesses=679, cachingHits=668, cachingHitsRatio=98.38%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:04:34,455 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:04:34,459 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164374655, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164674459, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:04:34,459 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:04:34,467 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:04:34,490 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:04:34,492 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:04:34,492 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:04:34,494 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164674459, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164674493, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:04:34,494 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:04:34,500 INFO  [AM.-pool1-t7] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:04:34,500 INFO  [AM.-pool1-t7] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164674493, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164674500, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:04:34,500 INFO  [AM.-pool1-t7] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:04:34,505 INFO  [AM.-pool1-t7] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:04:34,531 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:04:34,533 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:04:34,589 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:04:34,589 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:04:34,590 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164674500, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164674590, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:04:34,590 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:10,657 INFO  [defaultRpcServer.handler=9,queue=4,port=16020] master.ServerManager: Registering server=slave1,16020,1407164827090
2014-08-04 08:07:10,657 INFO  [defaultRpcServer.handler=9,queue=4,port=16020] master.ServerManager: Triggering server recovery; existingServer slave1,16020,1407164109260 looks stale, new server:slave1,16020,1407164827090
2014-08-04 08:07:10,670 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407164109260 before assignment.
2014-08-04 08:07:10,670 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-04 08:07:10,885 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {85dfef280c26a8842e702a75c31a0741 state=OPEN, ts=1407164149111, server=slave1,16020,1407164109260} to {85dfef280c26a8842e702a75c31a0741 state=OFFLINE, ts=1407164830885, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,886 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741. with state=OFFLINE
2014-08-04 08:07:10,892 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {6cf2055c04723081bb67b2c2b74f81e5 state=OPEN, ts=1407164149133, server=slave1,16020,1407164109260} to {6cf2055c04723081bb67b2c2b74f81e5 state=OFFLINE, ts=1407164830892, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,892 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5. with state=OFFLINE
2014-08-04 08:07:10,899 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {b68f7d23758f0f6c6643c8234627907c state=OPEN, ts=1407164149091, server=slave1,16020,1407164109260} to {b68f7d23758f0f6c6643c8234627907c state=OFFLINE, ts=1407164830899, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,899 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c. with state=OFFLINE
2014-08-04 08:07:10,902 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {7a099ad1a4b326851a78e587dbe929c6 state=OPEN, ts=1407164149169, server=slave1,16020,1407164109260} to {7a099ad1a4b326851a78e587dbe929c6 state=OFFLINE, ts=1407164830902, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,902 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6. with state=OFFLINE
2014-08-04 08:07:10,905 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {2b9f522e7f5863abacba6eed038e0de6 state=OPEN, ts=1407164149158, server=slave1,16020,1407164109260} to {2b9f522e7f5863abacba6eed038e0de6 state=OFFLINE, ts=1407164830905, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,905 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6. with state=OFFLINE
2014-08-04 08:07:10,908 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {0319f025449b981e780aad47b334574b state=OPEN, ts=1407164149219, server=slave1,16020,1407164109260} to {0319f025449b981e780aad47b334574b state=OFFLINE, ts=1407164830908, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,908 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user2,1407164147821.0319f025449b981e780aad47b334574b. with state=OFFLINE
2014-08-04 08:07:10,910 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {9e39dd4a553932b6730f19ab8f94ec90 state=OPEN, ts=1407164149182, server=slave1,16020,1407164109260} to {9e39dd4a553932b6730f19ab8f94ec90 state=OFFLINE, ts=1407164830910, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,910 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90. with state=OFFLINE
2014-08-04 08:07:10,915 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {6c68c713468230ac9d6a9b57c7f1eed9 state=OPEN, ts=1407164149260, server=slave1,16020,1407164109260} to {6c68c713468230ac9d6a9b57c7f1eed9 state=OFFLINE, ts=1407164830915, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,915 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9. with state=OFFLINE
2014-08-04 08:07:10,918 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {22f316c375bacd077bd95547f14e8707 state=OPEN, ts=1407164149091, server=slave1,16020,1407164109260} to {22f316c375bacd077bd95547f14e8707 state=OFFLINE, ts=1407164830918, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,918 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707. with state=OFFLINE
2014-08-04 08:07:10,921 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {9f61875a9063b8a1b946a96e849e35c2 state=OPEN, ts=1407164149134, server=slave1,16020,1407164109260} to {9f61875a9063b8a1b946a96e849e35c2 state=OFFLINE, ts=1407164830921, server=slave1,16020,1407164109260}
2014-08-04 08:07:10,921 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2. with state=OFFLINE
2014-08-04 08:07:10,926 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Reassigning 10 region(s) that slave1,16020,1407164109260 was carrying (and 0 regions(s) that were opening on this server)
2014-08-04 08:07:10,927 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407164827090
2014-08-04 08:07:10,927 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {85dfef280c26a8842e702a75c31a0741 state=OFFLINE, ts=1407164830885, server=slave1,16020,1407164109260} to {85dfef280c26a8842e702a75c31a0741 state=PENDING_OPEN, ts=1407164830927, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,928 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,930 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {6cf2055c04723081bb67b2c2b74f81e5 state=OFFLINE, ts=1407164830892, server=slave1,16020,1407164109260} to {6cf2055c04723081bb67b2c2b74f81e5 state=PENDING_OPEN, ts=1407164830930, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,930 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,933 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {b68f7d23758f0f6c6643c8234627907c state=OFFLINE, ts=1407164830899, server=slave1,16020,1407164109260} to {b68f7d23758f0f6c6643c8234627907c state=PENDING_OPEN, ts=1407164830933, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,933 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,935 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {7a099ad1a4b326851a78e587dbe929c6 state=OFFLINE, ts=1407164830902, server=slave1,16020,1407164109260} to {7a099ad1a4b326851a78e587dbe929c6 state=PENDING_OPEN, ts=1407164830935, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,935 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,939 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {2b9f522e7f5863abacba6eed038e0de6 state=OFFLINE, ts=1407164830905, server=slave1,16020,1407164109260} to {2b9f522e7f5863abacba6eed038e0de6 state=PENDING_OPEN, ts=1407164830939, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,939 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,943 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {0319f025449b981e780aad47b334574b state=OFFLINE, ts=1407164830908, server=slave1,16020,1407164109260} to {0319f025449b981e780aad47b334574b state=PENDING_OPEN, ts=1407164830943, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,943 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user2,1407164147821.0319f025449b981e780aad47b334574b. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,947 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {9e39dd4a553932b6730f19ab8f94ec90 state=OFFLINE, ts=1407164830910, server=slave1,16020,1407164109260} to {9e39dd4a553932b6730f19ab8f94ec90 state=PENDING_OPEN, ts=1407164830947, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,947 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,951 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {6c68c713468230ac9d6a9b57c7f1eed9 state=OFFLINE, ts=1407164830915, server=slave1,16020,1407164109260} to {6c68c713468230ac9d6a9b57c7f1eed9 state=PENDING_OPEN, ts=1407164830951, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,951 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,957 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {22f316c375bacd077bd95547f14e8707 state=OFFLINE, ts=1407164830918, server=slave1,16020,1407164109260} to {22f316c375bacd077bd95547f14e8707 state=PENDING_OPEN, ts=1407164830957, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,957 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:10,963 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {9f61875a9063b8a1b946a96e849e35c2 state=OFFLINE, ts=1407164830921, server=slave1,16020,1407164109260} to {9f61875a9063b8a1b946a96e849e35c2 state=PENDING_OPEN, ts=1407164830963, server=slave1,16020,1407164827090}
2014-08-04 08:07:10,964 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2. with state=PENDING_OPEN&sn=slave1,16020,1407164827090
2014-08-04 08:07:11,780 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 85dfef280c26a8842e702a75c31a0741 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,133 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Transition {6cf2055c04723081bb67b2c2b74f81e5 state=PENDING_OPEN, ts=1407164830930, server=slave1,16020,1407164827090} to {6cf2055c04723081bb67b2c2b74f81e5 state=OPEN, ts=1407164832133, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,133 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStateStore: Updating row usertable,,1407164147821.6cf2055c04723081bb67b2c2b74f81e5. with state=OPEN&openSeqNum=40000002&server=slave1,16020,1407164827090
2014-08-04 08:07:12,137 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Onlined 6cf2055c04723081bb67b2c2b74f81e5 on slave1,16020,1407164827090
2014-08-04 08:07:12,184 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Transition {85dfef280c26a8842e702a75c31a0741 state=PENDING_OPEN, ts=1407164830927, server=slave1,16020,1407164827090} to {85dfef280c26a8842e702a75c31a0741 state=OPEN, ts=1407164832183, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,184 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user7,1407164147821.85dfef280c26a8842e702a75c31a0741. with state=OPEN&openSeqNum=40001613&server=slave1,16020,1407164827090
2014-08-04 08:07:12,187 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Onlined 85dfef280c26a8842e702a75c31a0741 on slave1,16020,1407164827090
2014-08-04 08:07:12,188 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for b68f7d23758f0f6c6643c8234627907c to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,286 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStates: Transition {b68f7d23758f0f6c6643c8234627907c state=PENDING_OPEN, ts=1407164830933, server=slave1,16020,1407164827090} to {b68f7d23758f0f6c6643c8234627907c state=OPEN, ts=1407164832286, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,287 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user1,1407164147821.b68f7d23758f0f6c6643c8234627907c. with state=OPEN&openSeqNum=40002096&server=slave1,16020,1407164827090
2014-08-04 08:07:12,290 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStates: Onlined b68f7d23758f0f6c6643c8234627907c on slave1,16020,1407164827090
2014-08-04 08:07:12,290 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 7a099ad1a4b326851a78e587dbe929c6 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,333 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStates: Transition {7a099ad1a4b326851a78e587dbe929c6 state=PENDING_OPEN, ts=1407164830935, server=slave1,16020,1407164827090} to {7a099ad1a4b326851a78e587dbe929c6 state=OPEN, ts=1407164832332, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,333 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user3,1407164147821.7a099ad1a4b326851a78e587dbe929c6. with state=OPEN&openSeqNum=40001205&server=slave1,16020,1407164827090
2014-08-04 08:07:12,336 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStates: Onlined 7a099ad1a4b326851a78e587dbe929c6 on slave1,16020,1407164827090
2014-08-04 08:07:12,336 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 2b9f522e7f5863abacba6eed038e0de6 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,357 INFO  [defaultRpcServer.handler=47,queue=2,port=16020] master.RegionStates: Transition {2b9f522e7f5863abacba6eed038e0de6 state=PENDING_OPEN, ts=1407164830939, server=slave1,16020,1407164827090} to {2b9f522e7f5863abacba6eed038e0de6 state=OPEN, ts=1407164832357, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,357 INFO  [defaultRpcServer.handler=47,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user6,1407164147821.2b9f522e7f5863abacba6eed038e0de6. with state=OPEN&openSeqNum=40001437&server=slave1,16020,1407164827090
2014-08-04 08:07:12,360 INFO  [defaultRpcServer.handler=47,queue=2,port=16020] master.RegionStates: Onlined 2b9f522e7f5863abacba6eed038e0de6 on slave1,16020,1407164827090
2014-08-04 08:07:12,360 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 0319f025449b981e780aad47b334574b to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,452 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Transition {9e39dd4a553932b6730f19ab8f94ec90 state=PENDING_OPEN, ts=1407164830947, server=slave1,16020,1407164827090} to {9e39dd4a553932b6730f19ab8f94ec90 state=OPEN, ts=1407164832451, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,452 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user9,1407164147821.9e39dd4a553932b6730f19ab8f94ec90. with state=OPEN&openSeqNum=40001850&server=slave1,16020,1407164827090
2014-08-04 08:07:12,455 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Onlined 9e39dd4a553932b6730f19ab8f94ec90 on slave1,16020,1407164827090
2014-08-04 08:07:12,480 INFO  [defaultRpcServer.handler=10,queue=0,port=16020] master.RegionStates: Transition {0319f025449b981e780aad47b334574b state=PENDING_OPEN, ts=1407164830943, server=slave1,16020,1407164827090} to {0319f025449b981e780aad47b334574b state=OPEN, ts=1407164832480, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,480 INFO  [defaultRpcServer.handler=10,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user2,1407164147821.0319f025449b981e780aad47b334574b. with state=OPEN&openSeqNum=40001898&server=slave1,16020,1407164827090
2014-08-04 08:07:12,483 INFO  [defaultRpcServer.handler=10,queue=0,port=16020] master.RegionStates: Onlined 0319f025449b981e780aad47b334574b on slave1,16020,1407164827090
2014-08-04 08:07:12,483 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 6c68c713468230ac9d6a9b57c7f1eed9 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,640 INFO  [defaultRpcServer.handler=6,queue=1,port=16020] master.RegionStates: Transition {6c68c713468230ac9d6a9b57c7f1eed9 state=PENDING_OPEN, ts=1407164830951, server=slave1,16020,1407164827090} to {6c68c713468230ac9d6a9b57c7f1eed9 state=OPEN, ts=1407164832640, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,641 INFO  [defaultRpcServer.handler=6,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user5,1407164147821.6c68c713468230ac9d6a9b57c7f1eed9. with state=OPEN&openSeqNum=40001425&server=slave1,16020,1407164827090
2014-08-04 08:07:12,644 INFO  [defaultRpcServer.handler=6,queue=1,port=16020] master.RegionStates: Onlined 6c68c713468230ac9d6a9b57c7f1eed9 on slave1,16020,1407164827090
2014-08-04 08:07:12,644 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 22f316c375bacd077bd95547f14e8707 to leave regions-in-transition, timeOut=15000 ms.
2014-08-04 08:07:12,672 INFO  [defaultRpcServer.handler=15,queue=0,port=16020] master.RegionStates: Transition {9f61875a9063b8a1b946a96e849e35c2 state=PENDING_OPEN, ts=1407164830963, server=slave1,16020,1407164827090} to {9f61875a9063b8a1b946a96e849e35c2 state=OPEN, ts=1407164832672, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,672 INFO  [defaultRpcServer.handler=15,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user8,1407164147821.9f61875a9063b8a1b946a96e849e35c2. with state=OPEN&openSeqNum=40001617&server=slave1,16020,1407164827090
2014-08-04 08:07:12,675 INFO  [defaultRpcServer.handler=15,queue=0,port=16020] master.RegionStates: Onlined 9f61875a9063b8a1b946a96e849e35c2 on slave1,16020,1407164827090
2014-08-04 08:07:12,689 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Transition {22f316c375bacd077bd95547f14e8707 state=PENDING_OPEN, ts=1407164830957, server=slave1,16020,1407164827090} to {22f316c375bacd077bd95547f14e8707 state=OPEN, ts=1407164832689, server=slave1,16020,1407164827090}
2014-08-04 08:07:12,689 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user4,1407164147821.22f316c375bacd077bd95547f14e8707. with state=OPEN&openSeqNum=40002170&server=slave1,16020,1407164827090
2014-08-04 08:07:12,700 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Onlined 22f316c375bacd077bd95547f14e8707 on slave1,16020,1407164827090
2014-08-04 08:07:12,716 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: dead splitlog workers [slave1,16020,1407164109260]
2014-08-04 08:07:12,734 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: started splitting 35 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting]
2014-08-04 08:07:12,766 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872
2014-08-04 08:07:12,767 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:12,830 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164329872, length=129490677
2014-08-04 08:07:12,830 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:12,841 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164329872
2014-08-04 08:07:12,843 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164329872 after 2ms
2014-08-04 08:07:12,906 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164325294 acquired by slave1,16020,1407164827090
2014-08-04 08:07:13,274 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 35 unassigned = 33 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164374690=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164334785=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164325294=last_update = 1407164832974 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872=last_update = 1407164832844 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 0 error = 0}
2014-08-04 08:07:13,469 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164334785 acquired by slave1,16020,1407164827090
2014-08-04 08:07:13,571 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418
2014-08-04 08:07:13,574 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:13,607 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164320418, length=130729589
2014-08-04 08:07:13,607 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:13,623 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164320418
2014-08-04 08:07:13,625 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164320418 after 2ms
2014-08-04 08:07:14,430 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2078b6ef, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 08:07:14,431 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2078b6ef connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 08:07:14,432 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 08:07:14,438 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-04 08:07:14,459 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147a18358d50009, negotiated timeout = 90000
2014-08-04 08:07:14,463 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:14,464 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x147a18358d50009
2014-08-04 08:07:14,469 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] zookeeper.ZooKeeper: Session: 0x147a18358d50009 closed
2014-08-04 08:07:14,469 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 1 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164329872 is corrupted = false progress failed = false
2014-08-04 08:07:14,469 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-04 08:07:14,483 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:14,484 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872 in 1716ms
2014-08-04 08:07:14,485 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:14,502 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164329872 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164329872
2014-08-04 08:07:14,503 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164329872
2014-08-04 08:07:14,578 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853
2014-08-04 08:07:14,580 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:14,635 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164344853, length=128851501
2014-08-04 08:07:14,636 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:14,643 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164344853
2014-08-04 08:07:14,646 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164344853 after 2ms
2014-08-04 08:07:14,739 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x648dae84, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 08:07:14,740 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x648dae84 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 08:07:14,741 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 08:07:14,742 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-04 08:07:14,751 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147a18358d5000a, negotiated timeout = 90000
2014-08-04 08:07:15,123 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:15,123 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164320418 is corrupted = false progress failed = false
2014-08-04 08:07:15,127 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:15,127 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418 in 1554ms
2014-08-04 08:07:15,128 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:15,138 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164320418 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164320418
2014-08-04 08:07:15,158 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164320418
2014-08-04 08:07:15,251 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011
2014-08-04 08:07:15,253 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:15,282 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164340011, length=131696848
2014-08-04 08:07:15,282 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:15,299 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164340011
2014-08-04 08:07:15,301 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164340011 after 2ms
2014-08-04 08:07:16,331 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164325294 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:16,346 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164325294 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164325294
2014-08-04 08:07:16,347 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164325294
2014-08-04 08:07:16,450 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164374690 acquired by slave1,16020,1407164827090
2014-08-04 08:07:18,845 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164334785 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:18,856 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164334785 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164334785
2014-08-04 08:07:18,857 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164334785
2014-08-04 08:07:18,872 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679 acquired by slave1,16020,1407164827090
2014-08-04 08:07:19,045 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:19,046 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 17 edits across 1 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164344853 is corrupted = false progress failed = false
2014-08-04 08:07:19,051 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,051 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853 in 4472ms
2014-08-04 08:07:19,052 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,054 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:19,057 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x147a18358d5000a
2014-08-04 08:07:19,062 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x147a18358d5000a closed
2014-08-04 08:07:19,062 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-04 08:07:19,066 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164344853 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164344853
2014-08-04 08:07:19,068 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164344853
2014-08-04 08:07:19,077 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584
2014-08-04 08:07:19,078 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,114 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164450584, length=130222369
2014-08-04 08:07:19,114 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:19,119 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164450584
2014-08-04 08:07:19,121 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164450584 after 2ms
2014-08-04 08:07:19,163 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 17 edits across 1 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164340011 is corrupted = false progress failed = false
2014-08-04 08:07:19,165 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x5a61b2ee, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-04 08:07:19,166 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5a61b2ee connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-04 08:07:19,167 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-04 08:07:19,168 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-04 08:07:19,169 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,170 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011 in 3919ms
2014-08-04 08:07:19,171 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,181 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47a1835bde000f, negotiated timeout = 90000
2014-08-04 08:07:19,182 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164340011 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164340011
2014-08-04 08:07:19,184 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164340011
2014-08-04 08:07:19,256 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 29 unassigned = 26 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164374690=last_update = 1407164836641 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679=last_update = 1407164838910 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584=last_update = 1407164839120 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 6 error = 0}
2014-08-04 08:07:19,873 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829
2014-08-04 08:07:19,895 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:19,942 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164379829, length=129595361
2014-08-04 08:07:19,942 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:19,986 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164379829
2014-08-04 08:07:19,988 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164379829 after 2ms
2014-08-04 08:07:22,048 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164374690 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:22,070 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164374690 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164374690
2014-08-04 08:07:22,071 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164374690
2014-08-04 08:07:22,124 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420 acquired by slave1,16020,1407164827090
2014-08-04 08:07:25,257 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 28 unassigned = 24 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420=last_update = 1407164842165 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679=last_update = 1407164838910 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829=last_update = 1407164839989 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584=last_update = 1407164839120 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 7 error = 0}
2014-08-04 08:07:27,876 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:27,886 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164425679 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164425679
2014-08-04 08:07:27,887 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164425679
2014-08-04 08:07:27,916 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818 acquired by slave1,16020,1407164827090
2014-08-04 08:07:28,203 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:28,204 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 51 edits across 3 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164379829 is corrupted = false progress failed = false
2014-08-04 08:07:28,213 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,213 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829 in 8340ms
2014-08-04 08:07:28,217 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,226 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164379829 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164379829
2014-08-04 08:07:28,227 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164379829
2014-08-04 08:07:28,249 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274
2014-08-04 08:07:28,250 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,282 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164460274, length=131319059
2014-08-04 08:07:28,282 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:28,293 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164460274
2014-08-04 08:07:28,295 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164460274 after 2ms
2014-08-04 08:07:28,479 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:28,480 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 125 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164450584 is corrupted = false progress failed = false
2014-08-04 08:07:28,485 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,485 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584 in 9408ms
2014-08-04 08:07:28,487 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,496 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164450584 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164450584
2014-08-04 08:07:28,497 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164450584
2014-08-04 08:07:28,892 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876
2014-08-04 08:07:28,893 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:28,989 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164309876, length=128860171
2014-08-04 08:07:28,989 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:28,996 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164309876
2014-08-04 08:07:28,998 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164309876 after 2ms
2014-08-04 08:07:30,088 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:30,088 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164309876 is corrupted = false progress failed = false
2014-08-04 08:07:30,095 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:30,095 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876 in 1203ms
2014-08-04 08:07:30,095 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:30,104 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164309876 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164309876
2014-08-04 08:07:30,105 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164309876
2014-08-04 08:07:30,115 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068
2014-08-04 08:07:30,116 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:30,146 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164479068, length=130270450
2014-08-04 08:07:30,146 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:30,153 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164479068
2014-08-04 08:07:30,154 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164479068 after 1ms
2014-08-04 08:07:31,258 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 24 unassigned = 20 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420=last_update = 1407164842165 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818=last_update = 1407164847957 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068=last_update = 1407164850154 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274=last_update = 1407164848298 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 11 error = 0}
2014-08-04 08:07:33,912 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:33,921 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164405420 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164405420
2014-08-04 08:07:33,923 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164405420
2014-08-04 08:07:33,939 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343 acquired by slave1,16020,1407164827090
2014-08-04 08:07:37,258 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 23 unassigned = 19 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818=last_update = 1407164847957 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068=last_update = 1407164850154 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274=last_update = 1407164848298 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343=last_update = 1407164854043 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 12 error = 0}
2014-08-04 08:07:39,037 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:39,046 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164355343 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164355343
2014-08-04 08:07:39,047 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164355343
2014-08-04 08:07:39,062 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315 acquired by slave1,16020,1407164827090
2014-08-04 08:07:39,937 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:39,953 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164455818 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164455818
2014-08-04 08:07:39,954 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164455818
2014-08-04 08:07:39,974 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388 acquired by slave1,16020,1407164827090
2014-08-04 08:07:41,007 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:41,009 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 120 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164460274 is corrupted = false progress failed = false
2014-08-04 08:07:41,018 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:41,018 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274 in 12769ms
2014-08-04 08:07:41,018 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:41,029 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164460274 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164460274
2014-08-04 08:07:41,030 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164460274
2014-08-04 08:07:41,045 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738
2014-08-04 08:07:41,046 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:41,075 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164391738, length=141610697
2014-08-04 08:07:41,075 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:41,078 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164391738
2014-08-04 08:07:41,080 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164391738 after 2ms
2014-08-04 08:07:42,230 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:42,233 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 140 edits across 8 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164479068 is corrupted = false progress failed = false
2014-08-04 08:07:42,398 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:42,399 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068 in 12284ms
2014-08-04 08:07:42,404 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:42,415 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164479068 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164479068
2014-08-04 08:07:42,417 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164479068
2014-08-04 08:07:42,727 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229
2014-08-04 08:07:42,728 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:42,758 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164360229, length=129624690
2014-08-04 08:07:42,758 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:42,973 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164360229
2014-08-04 08:07:42,975 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164360229 after 2ms
2014-08-04 08:07:43,258 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 19 unassigned = 15 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315=last_update = 1407164859115 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = 1407164862977 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738=last_update = 1407164861079 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388=last_update = 1407164860092 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 16 error = 0}
2014-08-04 08:07:46,437 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:46,448 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164445315 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164445315
2014-08-04 08:07:46,449 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164445315
2014-08-04 08:07:46,470 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932 acquired by slave1,16020,1407164827090
2014-08-04 08:07:47,649 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:47,652 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 51 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164391738 is corrupted = false progress failed = false
2014-08-04 08:07:47,658 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:47,658 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738 in 6613ms
2014-08-04 08:07:47,660 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:47,670 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164391738 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164391738
2014-08-04 08:07:47,671 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164391738
2014-08-04 08:07:47,686 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136
2014-08-04 08:07:47,687 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:47,716 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164350136, length=132266488
2014-08-04 08:07:47,717 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:47,723 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164350136
2014-08-04 08:07:47,724 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164350136 after 1ms
2014-08-04 08:07:48,226 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:48,240 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164365388 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164365388
2014-08-04 08:07:48,242 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164365388
2014-08-04 08:07:48,260 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 16 unassigned = 13 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229=last_update = 1407164862977 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136=last_update = 1407164867726 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932=last_update = 1407164866549 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 19 error = 0}
2014-08-04 08:07:48,284 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382 acquired by slave1,16020,1407164827090
2014-08-04 08:07:48,289 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:48,298 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164314932 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164314932
2014-08-04 08:07:48,299 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164314932
2014-08-04 08:07:49,125 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671 acquired by slave1,16020,1407164827090
2014-08-04 08:07:49,287 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:49,306 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 17 edits across 1 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164360229 is corrupted = false progress failed = false
2014-08-04 08:07:49,313 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:49,313 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229 in 6585ms
2014-08-04 08:07:49,318 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:49,329 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164360229 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164360229
2014-08-04 08:07:49,331 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164360229
2014-08-04 08:07:49,351 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478
2014-08-04 08:07:49,354 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:49,382 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164414478, length=129501981
2014-08-04 08:07:49,382 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:49,386 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164414478
2014-08-04 08:07:49,387 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164414478 after 1ms
2014-08-04 08:07:51,830 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:51,831 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 17 edits across 1 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164350136 is corrupted = false progress failed = false
2014-08-04 08:07:51,840 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:51,840 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136 in 4153ms
2014-08-04 08:07:51,842 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:51,854 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164350136 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164350136
2014-08-04 08:07:51,855 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164350136
2014-08-04 08:07:51,872 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739
2014-08-04 08:07:51,873 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:51,908 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164576739, length=113402219
2014-08-04 08:07:51,909 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:51,919 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164576739
2014-08-04 08:07:51,920 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164576739 after 1ms
2014-08-04 08:07:54,260 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 13 unassigned = 9 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382=last_update = 1407164868334 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = 1407164871923 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = 1407164869387 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671=last_update = 1407164869166 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 22 error = 0}
2014-08-04 08:07:56,854 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:56,863 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164385382 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164385382
2014-08-04 08:07:56,864 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164385382
2014-08-04 08:07:56,941 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648 acquired by slave1,16020,1407164827090
2014-08-04 08:07:59,105 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:07:59,114 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164466671 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164466671
2014-08-04 08:07:59,115 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164466671
2014-08-04 08:07:59,156 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098 acquired by slave1,16020,1407164827090
2014-08-04 08:07:59,260 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 11 unassigned = 7 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = 1407164879156 last_version = 1 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739=last_update = 1407164871923 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478=last_update = 1407164869387 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = 1407164877044 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 24 error = 0}
2014-08-04 08:07:59,613 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:07:59,614 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 85 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164414478 is corrupted = false progress failed = false
2014-08-04 08:07:59,621 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:59,621 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478 in 10269ms
2014-08-04 08:07:59,622 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:59,633 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164414478 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164414478
2014-08-04 08:07:59,634 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164414478
2014-08-04 08:07:59,644 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791
2014-08-04 08:07:59,645 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:07:59,681 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164441791, length=134237121
2014-08-04 08:07:59,681 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:07:59,689 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164441791
2014-08-04 08:07:59,690 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164441791 after 1ms
2014-08-04 08:08:01,683 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:08:01,688 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 142 edits across 9 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164576739 is corrupted = false progress failed = false
2014-08-04 08:08:01,885 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:01,885 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739 in 10013ms
2014-08-04 08:08:01,888 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:01,899 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164576739 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164576739
2014-08-04 08:08:01,900 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164576739
2014-08-04 08:08:02,265 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907
2014-08-04 08:08:02,267 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:02,302 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164419907, length=131343119
2014-08-04 08:08:02,303 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:08:02,466 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164419907
2014-08-04 08:08:02,468 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164419907 after 2ms
2014-08-04 08:08:04,287 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 9 unassigned = 5 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = 1407164882468 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = 1407164879293 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648=last_update = 1407164877044 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = 1407164879690 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 26 error = 0}
2014-08-04 08:08:05,839 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:08:05,849 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164472648 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164472648
2014-08-04 08:08:05,850 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164472648
2014-08-04 08:08:05,929 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201 acquired by slave1,16020,1407164827090
2014-08-04 08:08:09,287 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 8 unassigned = 4 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907=last_update = 1407164882468 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098=last_update = 1407164879293 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791=last_update = 1407164879690 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = 1407164885977 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 27 error = 0}
2014-08-04 08:08:11,075 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:08:11,077 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 130 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164441791 is corrupted = false progress failed = false
2014-08-04 08:08:11,081 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:11,081 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791 in 11436ms
2014-08-04 08:08:11,084 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:11,096 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164441791 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164441791
2014-08-04 08:08:11,097 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164441791
2014-08-04 08:08:11,116 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268
2014-08-04 08:08:11,117 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:11,147 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164485268, length=35787363
2014-08-04 08:08:11,147 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:08:11,152 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164485268
2014-08-04 08:08:11,154 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164485268 after 1ms
2014-08-04 08:08:13,264 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:08:13,274 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164402098 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164402098
2014-08-04 08:08:13,275 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164402098
2014-08-04 08:08:13,297 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816 acquired by slave1,16020,1407164827090
2014-08-04 08:08:13,839 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:08:13,841 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 88 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164419907 is corrupted = false progress failed = false
2014-08-04 08:08:13,849 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:13,849 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907 in 11583ms
2014-08-04 08:08:13,852 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:13,860 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164419907 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164419907
2014-08-04 08:08:13,861 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164419907
2014-08-04 08:08:13,879 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407164046304] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875
2014-08-04 08:08:13,880 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875 acquired by sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:13,922 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164430875, length=135823796
2014-08-04 08:08:13,922 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-04 08:08:13,929 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164430875
2014-08-04 08:08:13,930 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164430875 after 1ms
2014-08-04 08:08:14,315 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 5 unassigned = 1 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268=last_update = 1407164891153 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = 1407164893930 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816=last_update = 1407164893338 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201=last_update = 1407164885977 last_version = 2 cur_worker_name = slave1,16020,1407164827090 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 30 error = 0}
2014-08-04 08:08:16,343 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:08:16,353 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164410201 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164410201
2014-08-04 08:08:16,354 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164410201
2014-08-04 08:08:16,411 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982 acquired by slave1,16020,1407164827090
2014-08-04 08:08:16,942 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-04 08:08:16,944 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 39 edits across 8 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164485268 is corrupted = false progress failed = false
2014-08-04 08:08:16,952 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:16,952 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268 in 5835ms
2014-08-04 08:08:16,956 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:16,963 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164485268 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164485268
2014-08-04 08:08:16,964 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164485268
2014-08-04 08:08:18,112 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:08:18,120 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164304982 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164304982
2014-08-04 08:08:18,121 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164304982
2014-08-04 08:08:20,136 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816 entered state: DONE slave1,16020,1407164827090
2014-08-04 08:08:20,144 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164369816 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164369816
2014-08-04 08:08:20,145 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164369816
2014-08-04 08:08:20,316 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875=last_update = 1407164893930 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407164046304 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 35 done = 34 error = 0}
2014-08-04 08:08:22,013 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-04 08:08:22,024 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47a1835bde000f
2014-08-04 08:08:22,033 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x47a1835bde000f closed
2014-08-04 08:08:22,033 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-04 08:08:22,133 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 82 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164430875 is corrupted = false progress failed = false
2014-08-04 08:08:22,140 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:22,140 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407164046304 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875 in 8261ms
2014-08-04 08:08:22,141 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:08:22,150 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting/slave1%2C16020%2C1407164109260.1407164430875 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407164109260.1407164430875
2014-08-04 08:08:22,151 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407164109260-splitting%2Fslave1%252C16020%252C1407164109260.1407164430875
2014-08-04 08:08:22,322 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: finished splitting (more than or equal to) 4494068769 bytes in 35 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407164109260-splitting] in 69587ms
2014-08-04 08:08:22,322 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407164109260
2014-08-04 08:09:06,510 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2055, hits=2044, hitRatio=99.46%, , cachingAccesses=2049, cachingHits=2038, cachingHitsRatio=99.46%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:09:34,447 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:09:34,447 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164674590, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164974447, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:09:34,447 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:09:34,451 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:09:34,459 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:09:34,461 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:09:34,461 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:09:34,462 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407164974447, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164974462, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:09:34,462 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:09:34,466 INFO  [AM.-pool1-t8] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:09:34,466 INFO  [AM.-pool1-t8] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407164974462, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164974466, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:09:34,466 INFO  [AM.-pool1-t8] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:09:34,472 INFO  [AM.-pool1-t8] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:09:34,481 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:09:34,482 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:09:34,503 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:09:34,503 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:09:34,504 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407164974466, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164974504, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:09:34,504 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:14:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2058, hits=2047, hitRatio=99.47%, , cachingAccesses=2052, cachingHits=2041, cachingHitsRatio=99.46%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:14:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:14:34,446 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407164974504, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165274446, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:14:34,447 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:14:34,457 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:14:34,466 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:14:34,467 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:14:34,469 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:14:34,470 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165274446, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165274470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:14:34,470 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:14:34,475 INFO  [AM.-pool1-t9] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:14:34,475 INFO  [AM.-pool1-t9] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165274470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165274475, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:14:34,475 INFO  [AM.-pool1-t9] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:14:34,480 INFO  [AM.-pool1-t9] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:14:34,494 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:14:34,495 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:14:34,523 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:14:34,524 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:14:34,525 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165274475, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165274525, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:14:34,525 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:19:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2061, hits=2050, hitRatio=99.47%, , cachingAccesses=2055, cachingHits=2044, cachingHitsRatio=99.46%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:19:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:19:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165274525, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165574445, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:19:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:19:34,480 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:19:34,484 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:19:34,485 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:19:34,485 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:19:34,486 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165574445, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165574486, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:19:34,486 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:19:34,489 INFO  [AM.-pool1-t10] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:19:34,489 INFO  [AM.-pool1-t10] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165574486, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165574489, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:19:34,489 INFO  [AM.-pool1-t10] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:19:34,492 INFO  [AM.-pool1-t10] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:19:34,505 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:19:34,505 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:19:34,533 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:19:34,533 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:19:34,534 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165574489, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165574534, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:19:34,534 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:24:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2064, hits=2053, hitRatio=99.47%, , cachingAccesses=2058, cachingHits=2047, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:24:34,446 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:24:34,447 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165574534, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165874447, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:24:34,448 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:24:34,466 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:24:34,472 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:24:34,473 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:24:34,473 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:24:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407165874447, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165874474, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:24:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:24:34,480 INFO  [AM.-pool1-t11] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:24:34,480 INFO  [AM.-pool1-t11] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407165874474, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165874480, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:24:34,480 INFO  [AM.-pool1-t11] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:24:34,484 INFO  [AM.-pool1-t11] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:24:34,498 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:24:34,498 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:24:34,518 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:24:34,518 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:24:34,519 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407165874480, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165874519, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:24:34,519 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:29:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2067, hits=2056, hitRatio=99.47%, , cachingAccesses=2061, cachingHits=2050, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:29:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:29:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407165874519, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166174444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:29:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:29:34,458 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:29:34,467 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:29:34,469 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:29:34,469 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:29:34,471 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166174444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166174470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:29:34,471 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:29:34,479 INFO  [AM.-pool1-t12] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:29:34,479 INFO  [AM.-pool1-t12] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166174470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166174479, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:29:34,479 INFO  [AM.-pool1-t12] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:29:34,483 INFO  [AM.-pool1-t12] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:29:34,497 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:29:34,498 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:29:34,530 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:29:34,531 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:29:34,531 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166174479, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166174531, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:29:34,532 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:34:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2070, hits=2059, hitRatio=99.47%, , cachingAccesses=2064, cachingHits=2053, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:34:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:34:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166174531, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166474444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:34:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:34:34,449 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:34:34,455 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:34:34,457 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:34:34,457 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:34:34,458 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166474444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166474458, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:34:34,459 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:34:34,463 INFO  [AM.-pool1-t13] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:34:34,464 INFO  [AM.-pool1-t13] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166474458, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166474464, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:34:34,464 INFO  [AM.-pool1-t13] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:34:34,468 INFO  [AM.-pool1-t13] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:34:34,478 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:34:34,479 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:34:34,499 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:34:34,499 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:34:34,500 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166474464, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166474500, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:34:34,500 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:39:06,510 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2073, hits=2062, hitRatio=99.47%, , cachingAccesses=2067, cachingHits=2056, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:39:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:39:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166474500, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166774444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:39:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:39:34,468 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:39:34,472 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:39:34,473 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:39:34,473 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:39:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407166774444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166774474, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:39:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:39:34,481 INFO  [AM.-pool1-t14] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:39:34,481 INFO  [AM.-pool1-t14] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407166774474, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166774481, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:39:34,481 INFO  [AM.-pool1-t14] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:39:34,489 INFO  [AM.-pool1-t14] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:39:34,498 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:39:34,499 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:39:34,516 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:39:34,517 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:39:34,517 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407166774481, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166774517, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:39:34,517 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:44:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2076, hits=2065, hitRatio=99.47%, , cachingAccesses=2070, cachingHits=2059, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:44:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:44:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407166774517, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167074445, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:44:34,446 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:44:34,457 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:44:34,467 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:44:34,468 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:44:34,473 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:44:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167074445, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167074473, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:44:34,474 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:44:34,480 INFO  [AM.-pool1-t15] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:44:34,480 INFO  [AM.-pool1-t15] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167074473, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167074480, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:44:34,480 INFO  [AM.-pool1-t15] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:44:34,491 INFO  [AM.-pool1-t15] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:44:34,504 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:44:34,505 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:44:34,527 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:44:34,527 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:44:34,528 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167074480, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407167074528, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:44:34,528 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:49:06,510 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2079, hits=2068, hitRatio=99.47%, , cachingAccesses=2073, cachingHits=2062, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:49:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:49:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407167074528, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167374444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:49:34,444 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:49:34,449 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:49:34,457 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:49:34,458 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:49:34,459 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:49:34,460 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167374444, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167374460, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:49:34,460 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:49:34,464 INFO  [AM.-pool1-t16] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:49:34,464 INFO  [AM.-pool1-t16] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167374460, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167374464, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:49:34,464 INFO  [AM.-pool1-t16] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:49:34,470 INFO  [AM.-pool1-t16] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:49:34,482 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:49:34,483 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:49:34,507 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:49:34,508 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:49:34,508 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167374464, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407167374508, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:49:34,508 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:54:06,511 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2082, hits=2071, hitRatio=99.47%, , cachingAccesses=2076, cachingHits=2065, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
2014-08-04 08:54:29,813 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407164069249 with entries=0, filesize=17 B; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407167669677
2014-08-04 08:54:33,958 INFO  [RS_OPEN_META-sceplus-vm48:16020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407164073863.meta with entries=145, filesize=37.44 KB; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407164046304/sceplus-vm48.almaden.ibm.com%2C16020%2C1407164046304.1407167673917.meta
2014-08-04 08:54:34,445 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407141514169, dest=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:54:34,446 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407167374508, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167674446, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:54:34,446 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-04 08:54:34,455 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407164046304-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:54:34,461 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-04 08:54:34,464 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:54:34,464 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-04 08:54:34,465 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407167674446, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167674465, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:54:34,465 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-04 08:54:34,470 INFO  [AM.-pool1-t17] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:54:34,470 INFO  [AM.-pool1-t17] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407167674465, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167674470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:54:34,470 INFO  [AM.-pool1-t17] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-04 08:54:34,474 INFO  [AM.-pool1-t17] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:54:34,486 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@58c06b1d, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-04 08:54:34,488 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-04 08:54:34,513 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-04 08:54:34,516 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-04 08:54:34,517 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407167674470, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407167674517, server=sceplus-vm48.almaden.ibm.com,16020,1407164046304}
2014-08-04 08:54:34,517 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407164046304
2014-08-04 08:54:39,671 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020.periodicFlusher] regionserver.HRegionServer: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 3701
2014-08-04 08:54:44,565 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4927, memsize=70.1 K, hasBloomFilter=false, into tmp file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/fd77c6341f3f42e98bcc0444a8d70498
2014-08-04 08:54:44,582 INFO  [MemStoreFlusher.1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for fd77c6341f3f42e98bcc0444a8d70498
2014-08-04 08:54:44,732 INFO  [MemStoreFlusher.1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for fd77c6341f3f42e98bcc0444a8d70498
2014-08-04 08:54:44,732 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/fd77c6341f3f42e98bcc0444a8d70498, entries=191, sequenceid=4927, filesize=26.4 K
2014-08-04 08:54:44,736 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~70.14 KB/71824, currentsize=0 B/0 for region hbase:meta,,1.1588230740 in 1350ms, sequenceid=4927, compaction requested=false
2014-08-04 08:59:06,510 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=4.99 GB, max=5.00 GB, accesses=2085, hits=2074, hitRatio=99.47%, , cachingAccesses=2079, cachingHits=2068, cachingHitsRatio=99.47%, evictions=0, evicted=8, evictedPerRun=Infinity
